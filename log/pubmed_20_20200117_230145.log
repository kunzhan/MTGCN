pubmed
1
labels of each class :  [20 20 20]
t= [975 975 975]
547218871
Epoch: 0020 Model_1_loss: 1.0514 Model_2_loss: 0.9938 Model_1_trainacc: 0.5833 Model_2_trainacc: 0.7667 Model_1_val:0.5349 Model_2_val:0.5402
Epoch: 0040 Model_1_loss: 0.9089 Model_2_loss: 0.8256 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7500 Model_1_val:0.6075 Model_2_val:0.6247
Epoch: 0060 Model_1_loss: 0.6792 Model_2_loss: 0.5739 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9167 Model_1_val:0.6330 Model_2_val:0.6599
Epoch: 0080 Model_1_loss: 0.5495 Model_2_loss: 0.3933 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9833 Model_1_val:0.6495 Model_2_val:0.6668
Epoch: 0100 Model_1_loss: 0.4066 Model_2_loss: 0.3851 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.6576 Model_2_val:0.6736
Epoch: 0120 Model_1_loss: 0.3519 Model_2_loss: 0.2649 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6668 Model_2_val:0.6758
Epoch: 0140 Model_1_loss: 0.3548 Model_2_loss: 0.2579 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9833 Model_1_val:0.6721 Model_2_val:0.6782
Epoch: 0160 Model_1_loss: 0.2667 Model_2_loss: 0.2409 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6667 Model_2_val:0.6796
Epoch: 0180 Model_1_loss: 0.2154 Model_2_loss: 0.2169 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6717 Model_2_val:0.6806
Epoch: 0200 Model_1_loss: 0.2150 Model_2_loss: 0.1952 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6754 Model_2_val:0.6855
Epoch: 0220 Model_1_loss: 0.3092 Model_2_loss: 0.2208 Model_1_trainacc: 0.9500 Model_2_trainacc: 1.0000 Model_1_val:0.6783 Model_2_val:0.6765
Epoch: 0240 Model_1_loss: 0.2185 Model_2_loss: 0.1899 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6832 Model_2_val:0.6828
Epoch: 0260 Model_1_loss: 0.2095 Model_2_loss: 0.1963 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6762 Model_2_val:0.6822
Epoch: 0280 Model_1_loss: 0.2302 Model_2_loss: 0.1781 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6751 Model_2_val:0.6811
Epoch: 0300 Model_1_loss: 0.1860 Model_2_loss: 0.1910 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6778 Model_2_val:0.6831
Epoch: 0320 Model_1_loss: 0.1644 Model_2_loss: 0.1476 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6721 Model_2_val:0.6810
Epoch: 0340 Model_1_loss: 0.1665 Model_2_loss: 0.1538 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6790 Model_2_val:0.6850
Epoch: 0360 Model_1_loss: 0.2098 Model_2_loss: 0.1718 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6856 Model_2_val:0.6798
Epoch: 0380 Model_1_loss: 0.1914 Model_2_loss: 0.1568 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6797 Model_2_val:0.6865
Epoch: 0400 Model_1_loss: 0.1939 Model_2_loss: 0.1433 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6773 Model_2_val:0.6855
Model_one_test:0.6903 Model_two_test:0.6931
added by two output: 0.6917
2
labels of each class :  [20 20 20]
t= [975 975 975]
652705788
Epoch: 0020 Model_1_loss: 0.9550 Model_2_loss: 0.9837 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7667 Model_1_val:0.5452 Model_2_val:0.6077
Epoch: 0040 Model_1_loss: 0.7813 Model_2_loss: 0.7430 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9000 Model_1_val:0.6447 Model_2_val:0.6592
Epoch: 0060 Model_1_loss: 0.5739 Model_2_loss: 0.5038 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9167 Model_1_val:0.6870 Model_2_val:0.6846
Epoch: 0080 Model_1_loss: 0.4228 Model_2_loss: 0.4079 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.6906 Model_2_val:0.7085
Epoch: 0100 Model_1_loss: 0.3538 Model_2_loss: 0.3414 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.7187 Model_2_val:0.7175
Epoch: 0120 Model_1_loss: 0.2763 Model_2_loss: 0.2398 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7230 Model_2_val:0.7272
Epoch: 0140 Model_1_loss: 0.2612 Model_2_loss: 0.2613 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.7230 Model_2_val:0.7335
Epoch: 0160 Model_1_loss: 0.1960 Model_2_loss: 0.1688 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7318 Model_2_val:0.7407
Epoch: 0180 Model_1_loss: 0.2138 Model_2_loss: 0.1827 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7362 Model_2_val:0.7349
Epoch: 0200 Model_1_loss: 0.1470 Model_2_loss: 0.1429 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7389 Model_2_val:0.7472
Epoch: 0220 Model_1_loss: 0.2181 Model_2_loss: 0.1859 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7389 Model_2_val:0.7334
Epoch: 0240 Model_1_loss: 0.2022 Model_2_loss: 0.1572 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7535 Model_2_val:0.7488
Epoch: 0260 Model_1_loss: 0.2141 Model_2_loss: 0.1484 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7485 Model_2_val:0.7465
Epoch: 0280 Model_1_loss: 0.1566 Model_2_loss: 0.1394 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7516 Model_2_val:0.7475
Epoch: 0300 Model_1_loss: 0.2006 Model_2_loss: 0.1243 Model_1_trainacc: 0.9500 Model_2_trainacc: 1.0000 Model_1_val:0.7550 Model_2_val:0.7540
Epoch: 0320 Model_1_loss: 0.1663 Model_2_loss: 0.1457 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7591 Model_2_val:0.7579
Epoch: 0340 Model_1_loss: 0.1291 Model_2_loss: 0.1300 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7500 Model_2_val:0.7549
Epoch: 0360 Model_1_loss: 0.1272 Model_2_loss: 0.0939 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7593 Model_2_val:0.7560
Epoch: 0380 Model_1_loss: 0.1473 Model_2_loss: 0.1398 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7572 Model_2_val:0.7528
Epoch: 0400 Model_1_loss: 0.1125 Model_2_loss: 0.1294 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7592 Model_2_val:0.7579
Model_one_test:0.7692 Model_two_test:0.7681
added by two output: 0.7686
3
labels of each class :  [20 20 20]
t= [975 975 975]
947166772
Epoch: 0020 Model_1_loss: 1.0580 Model_2_loss: 1.0206 Model_1_trainacc: 0.5333 Model_2_trainacc: 0.6667 Model_1_val:0.4537 Model_2_val:0.5294
Epoch: 0040 Model_1_loss: 0.8894 Model_2_loss: 0.8796 Model_1_trainacc: 0.7000 Model_2_trainacc: 0.7833 Model_1_val:0.5766 Model_2_val:0.6308
Epoch: 0060 Model_1_loss: 0.6975 Model_2_loss: 0.6605 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8667 Model_1_val:0.6464 Model_2_val:0.6802
Epoch: 0080 Model_1_loss: 0.5234 Model_2_loss: 0.5050 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9167 Model_1_val:0.6785 Model_2_val:0.7079
Epoch: 0100 Model_1_loss: 0.3990 Model_2_loss: 0.4279 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.8833 Model_1_val:0.7086 Model_2_val:0.7332
Epoch: 0120 Model_1_loss: 0.3993 Model_2_loss: 0.2961 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9333 Model_1_val:0.7183 Model_2_val:0.7220
Epoch: 0140 Model_1_loss: 0.2816 Model_2_loss: 0.2644 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7238 Model_2_val:0.7494
Epoch: 0160 Model_1_loss: 0.2373 Model_2_loss: 0.1959 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7274 Model_2_val:0.7504
Epoch: 0180 Model_1_loss: 0.2039 Model_2_loss: 0.2362 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7338 Model_2_val:0.7499
Epoch: 0200 Model_1_loss: 0.2252 Model_2_loss: 0.2039 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7378 Model_2_val:0.7518
Epoch: 0220 Model_1_loss: 0.2527 Model_2_loss: 0.2376 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7679 Model_2_val:0.7704
Epoch: 0240 Model_1_loss: 0.2161 Model_2_loss: 0.2012 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7620 Model_2_val:0.7697
Epoch: 0260 Model_1_loss: 0.2173 Model_2_loss: 0.1858 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7689 Model_2_val:0.7730
Epoch: 0280 Model_1_loss: 0.1677 Model_2_loss: 0.1966 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7676 Model_2_val:0.7678
Epoch: 0300 Model_1_loss: 0.1638 Model_2_loss: 0.1782 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7679 Model_2_val:0.7662
Epoch: 0320 Model_1_loss: 0.1529 Model_2_loss: 0.1497 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7699 Model_2_val:0.7693
Epoch: 0340 Model_1_loss: 0.1905 Model_2_loss: 0.1376 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7665 Model_2_val:0.7699
Epoch: 0360 Model_1_loss: 0.1399 Model_2_loss: 0.1619 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7627 Model_2_val:0.7714
Epoch: 0380 Model_1_loss: 0.1450 Model_2_loss: 0.1308 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7653 Model_2_val:0.7703
Epoch: 0400 Model_1_loss: 0.1312 Model_2_loss: 0.1341 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7688 Model_2_val:0.7718
Model_one_test:0.7783 Model_two_test:0.7867
added by two output: 0.7838
4
labels of each class :  [20 20 20]
t= [975 975 975]
861950695
Epoch: 0020 Model_1_loss: 1.0335 Model_2_loss: 0.9855 Model_1_trainacc: 0.5333 Model_2_trainacc: 0.6167 Model_1_val:0.4252 Model_2_val:0.4330
Epoch: 0040 Model_1_loss: 0.8650 Model_2_loss: 0.8567 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.7333 Model_1_val:0.5794 Model_2_val:0.5697
Epoch: 0060 Model_1_loss: 0.6946 Model_2_loss: 0.6514 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8667 Model_1_val:0.6054 Model_2_val:0.6100
Epoch: 0080 Model_1_loss: 0.5400 Model_2_loss: 0.5522 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9167 Model_1_val:0.6242 Model_2_val:0.6439
Epoch: 0100 Model_1_loss: 0.4930 Model_2_loss: 0.4594 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9000 Model_1_val:0.6634 Model_2_val:0.6654
Epoch: 0120 Model_1_loss: 0.4142 Model_2_loss: 0.3894 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.6740 Model_2_val:0.6820
Epoch: 0140 Model_1_loss: 0.4120 Model_2_loss: 0.3030 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.6858 Model_2_val:0.6813
Epoch: 0160 Model_1_loss: 0.3531 Model_2_loss: 0.2888 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.6830 Model_2_val:0.6896
Epoch: 0180 Model_1_loss: 0.2677 Model_2_loss: 0.2231 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6913 Model_2_val:0.6873
Epoch: 0200 Model_1_loss: 0.2421 Model_2_loss: 0.2400 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6901 Model_2_val:0.6991
Epoch: 0220 Model_1_loss: 0.3429 Model_2_loss: 0.2564 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7005 Model_2_val:0.7125
Epoch: 0240 Model_1_loss: 0.2354 Model_2_loss: 0.2112 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7129 Model_2_val:0.7149
Epoch: 0260 Model_1_loss: 0.2431 Model_2_loss: 0.2500 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7196 Model_2_val:0.7243
Epoch: 0280 Model_1_loss: 0.2237 Model_2_loss: 0.1807 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7107 Model_2_val:0.7271
Epoch: 0300 Model_1_loss: 0.2144 Model_2_loss: 0.2447 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7151 Model_2_val:0.7276
Epoch: 0320 Model_1_loss: 0.2371 Model_2_loss: 0.1931 Model_1_trainacc: 0.9500 Model_2_trainacc: 1.0000 Model_1_val:0.7175 Model_2_val:0.7248
Epoch: 0340 Model_1_loss: 0.2326 Model_2_loss: 0.1773 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7142 Model_2_val:0.7262
Epoch: 0360 Model_1_loss: 0.2488 Model_2_loss: 0.1497 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7240 Model_2_val:0.7299
Epoch: 0380 Model_1_loss: 0.2153 Model_2_loss: 0.1648 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7208 Model_2_val:0.7269
Epoch: 0400 Model_1_loss: 0.1606 Model_2_loss: 0.1590 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7204 Model_2_val:0.7343
Model_one_test:0.7421 Model_two_test:0.7458
added by two output: 0.7436
5
labels of each class :  [20 20 20]
t= [975 975 975]
1156634048
Epoch: 0020 Model_1_loss: 0.9793 Model_2_loss: 1.0252 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.6000 Model_1_val:0.5574 Model_2_val:0.5062
Epoch: 0040 Model_1_loss: 0.7587 Model_2_loss: 0.8531 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8333 Model_1_val:0.6540 Model_2_val:0.6360
Epoch: 0060 Model_1_loss: 0.5310 Model_2_loss: 0.6715 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8500 Model_1_val:0.7047 Model_2_val:0.6902
Epoch: 0080 Model_1_loss: 0.4454 Model_2_loss: 0.4688 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9333 Model_1_val:0.7307 Model_2_val:0.7089
Epoch: 0100 Model_1_loss: 0.3338 Model_2_loss: 0.3919 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.7439 Model_2_val:0.7216
Epoch: 0120 Model_1_loss: 0.2660 Model_2_loss: 0.3709 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7420 Model_2_val:0.7266
Epoch: 0140 Model_1_loss: 0.2396 Model_2_loss: 0.2900 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7426 Model_2_val:0.7417
Epoch: 0160 Model_1_loss: 0.2346 Model_2_loss: 0.2325 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7513 Model_2_val:0.7360
Epoch: 0180 Model_1_loss: 0.1925 Model_2_loss: 0.2368 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7431 Model_2_val:0.7416
Epoch: 0200 Model_1_loss: 0.2239 Model_2_loss: 0.2565 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.7496 Model_2_val:0.7374
Epoch: 0220 Model_1_loss: 0.2444 Model_2_loss: 0.2894 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7674 Model_2_val:0.7435
Epoch: 0240 Model_1_loss: 0.2209 Model_2_loss: 0.2635 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7752 Model_2_val:0.7661
Epoch: 0260 Model_1_loss: 0.2042 Model_2_loss: 0.1988 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7721 Model_2_val:0.7597
Epoch: 0280 Model_1_loss: 0.1992 Model_2_loss: 0.1789 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7731 Model_2_val:0.7636
Epoch: 0300 Model_1_loss: 0.1677 Model_2_loss: 0.1807 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7737 Model_2_val:0.7666
Epoch: 0320 Model_1_loss: 0.1527 Model_2_loss: 0.1604 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7769 Model_2_val:0.7741
Epoch: 0340 Model_1_loss: 0.1432 Model_2_loss: 0.1612 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7718 Model_2_val:0.7683
Epoch: 0360 Model_1_loss: 0.1681 Model_2_loss: 0.1556 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7772 Model_2_val:0.7711
Epoch: 0380 Model_1_loss: 0.1650 Model_2_loss: 0.1554 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7736 Model_2_val:0.7736
Epoch: 0400 Model_1_loss: 0.1806 Model_2_loss: 0.1595 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7664 Model_2_val:0.7708
Model_one_test:0.7866 Model_two_test:0.7803
added by two output: 0.7839
6
labels of each class :  [20 20 20]
t= [975 975 975]
926603976
Epoch: 0020 Model_1_loss: 1.0104 Model_2_loss: 0.9790 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.6000 Model_1_val:0.5470 Model_2_val:0.5325
Epoch: 0040 Model_1_loss: 0.8148 Model_2_loss: 0.7386 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8167 Model_1_val:0.6591 Model_2_val:0.6716
Epoch: 0060 Model_1_loss: 0.5739 Model_2_loss: 0.5283 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9500 Model_1_val:0.6847 Model_2_val:0.6887
Epoch: 0080 Model_1_loss: 0.4203 Model_2_loss: 0.4267 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9167 Model_1_val:0.6964 Model_2_val:0.7005
Epoch: 0100 Model_1_loss: 0.3618 Model_2_loss: 0.3489 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7167 Model_2_val:0.7197
Epoch: 0120 Model_1_loss: 0.3124 Model_2_loss: 0.3123 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.7110 Model_2_val:0.7109
Epoch: 0140 Model_1_loss: 0.2709 Model_2_loss: 0.2532 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7091 Model_2_val:0.7271
Epoch: 0160 Model_1_loss: 0.2399 Model_2_loss: 0.2752 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7175 Model_2_val:0.7204
Epoch: 0180 Model_1_loss: 0.2005 Model_2_loss: 0.2328 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7300 Model_2_val:0.7298
Epoch: 0200 Model_1_loss: 0.2390 Model_2_loss: 0.1930 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7222 Model_2_val:0.7332
Epoch: 0220 Model_1_loss: 0.2458 Model_2_loss: 0.2624 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7467 Model_2_val:0.7409
Epoch: 0240 Model_1_loss: 0.2325 Model_2_loss: 0.2543 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7493 Model_2_val:0.7545
Epoch: 0260 Model_1_loss: 0.1950 Model_2_loss: 0.2079 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7455 Model_2_val:0.7495
Epoch: 0280 Model_1_loss: 0.2007 Model_2_loss: 0.2049 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7491 Model_2_val:0.7428
Epoch: 0300 Model_1_loss: 0.1615 Model_2_loss: 0.1910 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7565 Model_2_val:0.7451
Epoch: 0320 Model_1_loss: 0.1521 Model_2_loss: 0.1858 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7460 Model_2_val:0.7513
Epoch: 0340 Model_1_loss: 0.1788 Model_2_loss: 0.1730 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7559 Model_2_val:0.7526
Epoch: 0360 Model_1_loss: 0.1674 Model_2_loss: 0.1733 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7507 Model_2_val:0.7529
Epoch: 0380 Model_1_loss: 0.1566 Model_2_loss: 0.1504 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7539 Model_2_val:0.7480
Epoch: 0400 Model_1_loss: 0.1727 Model_2_loss: 0.1501 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7501 Model_2_val:0.7522
Model_one_test:0.7735 Model_two_test:0.7747
added by two output: 0.7746
7
labels of each class :  [20 20 20]
t= [975 975 975]
1479014264
Epoch: 0020 Model_1_loss: 0.9803 Model_2_loss: 0.9448 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.9000 Model_1_val:0.5921 Model_2_val:0.6672
Epoch: 0040 Model_1_loss: 0.7084 Model_2_loss: 0.6982 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8833 Model_1_val:0.6621 Model_2_val:0.6929
Epoch: 0060 Model_1_loss: 0.5291 Model_2_loss: 0.4636 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9333 Model_1_val:0.6999 Model_2_val:0.7157
Epoch: 0080 Model_1_loss: 0.3499 Model_2_loss: 0.2754 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7286 Model_2_val:0.7379
Epoch: 0100 Model_1_loss: 0.2706 Model_2_loss: 0.2633 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7463 Model_2_val:0.7502
Epoch: 0120 Model_1_loss: 0.2380 Model_2_loss: 0.2496 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7477 Model_2_val:0.7505
Epoch: 0140 Model_1_loss: 0.1933 Model_2_loss: 0.2094 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7509 Model_2_val:0.7499
Epoch: 0160 Model_1_loss: 0.1612 Model_2_loss: 0.1549 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7523 Model_2_val:0.7581
Epoch: 0180 Model_1_loss: 0.1713 Model_2_loss: 0.1429 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7550 Model_2_val:0.7661
Epoch: 0200 Model_1_loss: 0.1806 Model_2_loss: 0.1430 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7633 Model_2_val:0.7615
Epoch: 0220 Model_1_loss: 0.2035 Model_2_loss: 0.1477 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7584 Model_2_val:0.7572
Epoch: 0240 Model_1_loss: 0.1574 Model_2_loss: 0.1433 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7564 Model_2_val:0.7607
Epoch: 0260 Model_1_loss: 0.1636 Model_2_loss: 0.1401 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7610 Model_2_val:0.7633
Epoch: 0280 Model_1_loss: 0.1163 Model_2_loss: 0.1753 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7589 Model_2_val:0.7667
Epoch: 0300 Model_1_loss: 0.1312 Model_2_loss: 0.1233 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7686 Model_2_val:0.7667
Epoch: 0320 Model_1_loss: 0.1230 Model_2_loss: 0.1261 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7623 Model_2_val:0.7662
Epoch: 0340 Model_1_loss: 0.1288 Model_2_loss: 0.1145 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7647 Model_2_val:0.7644
Epoch: 0360 Model_1_loss: 0.1242 Model_2_loss: 0.1087 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7688 Model_2_val:0.7649
Epoch: 0380 Model_1_loss: 0.1205 Model_2_loss: 0.1157 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7559 Model_2_val:0.7645
Epoch: 0400 Model_1_loss: 0.0985 Model_2_loss: 0.1065 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7608 Model_2_val:0.7665
Model_one_test:0.7784 Model_two_test:0.7794
added by two output: 0.7780
8
labels of each class :  [20 20 20]
t= [975 975 975]
564921002
Epoch: 0020 Model_1_loss: 0.9580 Model_2_loss: 1.0119 Model_1_trainacc: 0.7000 Model_2_trainacc: 0.6167 Model_1_val:0.5455 Model_2_val:0.4838
Epoch: 0040 Model_1_loss: 0.6871 Model_2_loss: 0.8431 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.7500 Model_1_val:0.6504 Model_2_val:0.5466
Epoch: 0060 Model_1_loss: 0.4380 Model_2_loss: 0.5901 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.8833 Model_1_val:0.6823 Model_2_val:0.6483
Epoch: 0080 Model_1_loss: 0.3234 Model_2_loss: 0.4502 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9167 Model_1_val:0.6968 Model_2_val:0.6805
Epoch: 0100 Model_1_loss: 0.2700 Model_2_loss: 0.3540 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9167 Model_1_val:0.7191 Model_2_val:0.7017
Epoch: 0120 Model_1_loss: 0.2381 Model_2_loss: 0.2656 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7278 Model_2_val:0.7056
Epoch: 0140 Model_1_loss: 0.1867 Model_2_loss: 0.2516 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7342 Model_2_val:0.7269
Epoch: 0160 Model_1_loss: 0.1838 Model_2_loss: 0.2133 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7389 Model_2_val:0.7357
Epoch: 0180 Model_1_loss: 0.1664 Model_2_loss: 0.1670 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7371 Model_2_val:0.7348
Epoch: 0200 Model_1_loss: 0.1644 Model_2_loss: 0.1590 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7434 Model_2_val:0.7449
Epoch: 0220 Model_1_loss: 0.1567 Model_2_loss: 0.2281 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7591 Model_2_val:0.7607
Epoch: 0240 Model_1_loss: 0.1297 Model_2_loss: 0.2021 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7615 Model_2_val:0.7700
Epoch: 0260 Model_1_loss: 0.1388 Model_2_loss: 0.2098 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7734 Model_2_val:0.7691
Epoch: 0280 Model_1_loss: 0.1403 Model_2_loss: 0.1782 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7669 Model_2_val:0.7691
Epoch: 0300 Model_1_loss: 0.1420 Model_2_loss: 0.1726 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7704 Model_2_val:0.7705
Epoch: 0320 Model_1_loss: 0.1087 Model_2_loss: 0.1429 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7762 Model_2_val:0.7725
Epoch: 0340 Model_1_loss: 0.1157 Model_2_loss: 0.1667 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7735 Model_2_val:0.7723
Epoch: 0360 Model_1_loss: 0.1252 Model_2_loss: 0.1045 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7733 Model_2_val:0.7764
Epoch: 0380 Model_1_loss: 0.1249 Model_2_loss: 0.1154 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7745 Model_2_val:0.7749
Epoch: 0400 Model_1_loss: 0.1059 Model_2_loss: 0.0895 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7769 Model_2_val:0.7768
Model_one_test:0.7930 Model_two_test:0.7948
added by two output: 0.7944
9
labels of each class :  [20 20 20]
t= [975 975 975]
1155840114
Epoch: 0020 Model_1_loss: 0.9651 Model_2_loss: 1.0178 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.5833 Model_1_val:0.5515 Model_2_val:0.5005
Epoch: 0040 Model_1_loss: 0.7529 Model_2_loss: 0.7704 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8500 Model_1_val:0.6246 Model_2_val:0.6020
Epoch: 0060 Model_1_loss: 0.5297 Model_2_loss: 0.5901 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9000 Model_1_val:0.6749 Model_2_val:0.6568
Epoch: 0080 Model_1_loss: 0.3598 Model_2_loss: 0.4279 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.8833 Model_1_val:0.7054 Model_2_val:0.6965
Epoch: 0100 Model_1_loss: 0.3414 Model_2_loss: 0.3700 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.7288 Model_2_val:0.7239
Epoch: 0120 Model_1_loss: 0.2557 Model_2_loss: 0.2778 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7418 Model_2_val:0.7306
Epoch: 0140 Model_1_loss: 0.2189 Model_2_loss: 0.2502 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7511 Model_2_val:0.7356
Epoch: 0160 Model_1_loss: 0.1954 Model_2_loss: 0.2166 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7489 Model_2_val:0.7372
Epoch: 0180 Model_1_loss: 0.1902 Model_2_loss: 0.1643 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7517 Model_2_val:0.7410
Epoch: 0200 Model_1_loss: 0.1484 Model_2_loss: 0.1713 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7589 Model_2_val:0.7522
Epoch: 0220 Model_1_loss: 0.2152 Model_2_loss: 0.2207 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7705 Model_2_val:0.7596
Epoch: 0240 Model_1_loss: 0.1466 Model_2_loss: 0.1918 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7724 Model_2_val:0.7733
Epoch: 0260 Model_1_loss: 0.1679 Model_2_loss: 0.1623 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7767 Model_2_val:0.7736
Epoch: 0280 Model_1_loss: 0.1596 Model_2_loss: 0.1947 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7779 Model_2_val:0.7725
Epoch: 0300 Model_1_loss: 0.1429 Model_2_loss: 0.1518 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7809 Model_2_val:0.7747
Epoch: 0320 Model_1_loss: 0.1377 Model_2_loss: 0.1495 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7843 Model_2_val:0.7772
Epoch: 0340 Model_1_loss: 0.1035 Model_2_loss: 0.1297 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7821 Model_2_val:0.7782
Epoch: 0360 Model_1_loss: 0.1207 Model_2_loss: 0.1356 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7835 Model_2_val:0.7843
Epoch: 0380 Model_1_loss: 0.1264 Model_2_loss: 0.1220 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7787 Model_2_val:0.7806
Epoch: 0400 Model_1_loss: 0.1549 Model_2_loss: 0.0898 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7867 Model_2_val:0.7810
Model_one_test:0.7991 Model_two_test:0.8017
added by two output: 0.8004
10
labels of each class :  [20 20 20]
t= [975 975 975]
759504206
Epoch: 0020 Model_1_loss: 1.0099 Model_2_loss: 0.9803 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7333 Model_1_val:0.6096 Model_2_val:0.5287
Epoch: 0040 Model_1_loss: 0.8042 Model_2_loss: 0.7286 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9167 Model_1_val:0.6928 Model_2_val:0.6726
Epoch: 0060 Model_1_loss: 0.5328 Model_2_loss: 0.4968 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9000 Model_1_val:0.7165 Model_2_val:0.7061
Epoch: 0080 Model_1_loss: 0.3214 Model_2_loss: 0.3636 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7386 Model_2_val:0.7295
Epoch: 0100 Model_1_loss: 0.2863 Model_2_loss: 0.2959 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7417 Model_2_val:0.7365
Epoch: 0120 Model_1_loss: 0.2696 Model_2_loss: 0.2321 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7597 Model_2_val:0.7379
Epoch: 0140 Model_1_loss: 0.2134 Model_2_loss: 0.2432 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7577 Model_2_val:0.7447
Epoch: 0160 Model_1_loss: 0.1645 Model_2_loss: 0.2103 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7603 Model_2_val:0.7479
Epoch: 0180 Model_1_loss: 0.1655 Model_2_loss: 0.1740 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7678 Model_2_val:0.7476
Epoch: 0200 Model_1_loss: 0.1308 Model_2_loss: 0.1928 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7691 Model_2_val:0.7530
Epoch: 0220 Model_1_loss: 0.1927 Model_2_loss: 0.1982 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7708 Model_2_val:0.7631
Epoch: 0240 Model_1_loss: 0.1360 Model_2_loss: 0.1908 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7768 Model_2_val:0.7706
Epoch: 0260 Model_1_loss: 0.1584 Model_2_loss: 0.1781 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7777 Model_2_val:0.7716
Epoch: 0280 Model_1_loss: 0.1521 Model_2_loss: 0.1409 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7799 Model_2_val:0.7746
Epoch: 0300 Model_1_loss: 0.1468 Model_2_loss: 0.1549 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7750 Model_2_val:0.7756
Epoch: 0320 Model_1_loss: 0.1349 Model_2_loss: 0.1262 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7774 Model_2_val:0.7751
Epoch: 0340 Model_1_loss: 0.1444 Model_2_loss: 0.1076 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7822 Model_2_val:0.7740
Epoch: 0360 Model_1_loss: 0.1325 Model_2_loss: 0.1266 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7764 Model_2_val:0.7727
Epoch: 0380 Model_1_loss: 0.1390 Model_2_loss: 0.1584 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7784 Model_2_val:0.7734
Epoch: 0400 Model_1_loss: 0.1295 Model_2_loss: 0.1281 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7742 Model_2_val:0.7770
Model_one_test:0.7922 Model_two_test:0.7918
added by two output: 0.7919
Model1 Acc: 0.770250 Model2 Acc: 0.771650
Maxacc Mean: 0.772419
[0.7724194482998152]
Maxacc of all experiments: 0.7724194482998152
1
labels of each class :  [20 20 20]
t= [975 975 975]
807966259
Epoch: 0020 Model_1_loss: 0.9741 Model_2_loss: 0.9650 Model_1_trainacc: 0.7000 Model_2_trainacc: 0.7333 Model_1_val:0.5365 Model_2_val:0.5549
Epoch: 0040 Model_1_loss: 0.7383 Model_2_loss: 0.7456 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8333 Model_1_val:0.6717 Model_2_val:0.6217
Epoch: 0060 Model_1_loss: 0.5172 Model_2_loss: 0.5735 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8833 Model_1_val:0.7166 Model_2_val:0.6833
Epoch: 0080 Model_1_loss: 0.3631 Model_2_loss: 0.4147 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.7243 Model_2_val:0.7147
Epoch: 0100 Model_1_loss: 0.2722 Model_2_loss: 0.3053 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7360 Model_2_val:0.7143
Epoch: 0120 Model_1_loss: 0.2244 Model_2_loss: 0.2769 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7402 Model_2_val:0.7292
Epoch: 0140 Model_1_loss: 0.2062 Model_2_loss: 0.2413 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7416 Model_2_val:0.7309
Epoch: 0160 Model_1_loss: 0.1495 Model_2_loss: 0.1888 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7456 Model_2_val:0.7387
Epoch: 0180 Model_1_loss: 0.1512 Model_2_loss: 0.1842 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7391 Model_2_val:0.7409
Epoch: 0200 Model_1_loss: 0.1307 Model_2_loss: 0.1953 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7392 Model_2_val:0.7372
Epoch: 0220 Model_1_loss: 0.1692 Model_2_loss: 0.1783 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7352 Model_2_val:0.7350
Epoch: 0240 Model_1_loss: 0.1525 Model_2_loss: 0.2116 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7435 Model_2_val:0.7418
Epoch: 0260 Model_1_loss: 0.1404 Model_2_loss: 0.1866 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7393 Model_2_val:0.7365
Epoch: 0280 Model_1_loss: 0.1689 Model_2_loss: 0.1379 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7372 Model_2_val:0.7417
Epoch: 0300 Model_1_loss: 0.1380 Model_2_loss: 0.2042 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7322 Model_2_val:0.7302
Epoch: 0320 Model_1_loss: 0.1231 Model_2_loss: 0.1450 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7358 Model_2_val:0.7384
Epoch: 0340 Model_1_loss: 0.1226 Model_2_loss: 0.1202 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7374 Model_2_val:0.7388
Epoch: 0360 Model_1_loss: 0.1216 Model_2_loss: 0.1114 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7319 Model_2_val:0.7304
Epoch: 0380 Model_1_loss: 0.1026 Model_2_loss: 0.1208 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7399 Model_2_val:0.7426
Epoch: 0400 Model_1_loss: 0.1084 Model_2_loss: 0.1034 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7298 Model_2_val:0.7422
Model_one_test:0.7382 Model_two_test:0.7489
added by two output: 0.7437
2
labels of each class :  [20 20 20]
t= [975 975 975]
1129481621
Epoch: 0020 Model_1_loss: 1.0265 Model_2_loss: 1.0089 Model_1_trainacc: 0.5167 Model_2_trainacc: 0.6333 Model_1_val:0.4189 Model_2_val:0.4853
Epoch: 0040 Model_1_loss: 0.8609 Model_2_loss: 0.8191 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.8333 Model_1_val:0.5754 Model_2_val:0.6358
Epoch: 0060 Model_1_loss: 0.6624 Model_2_loss: 0.5548 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8833 Model_1_val:0.6820 Model_2_val:0.6828
Epoch: 0080 Model_1_loss: 0.4849 Model_2_loss: 0.4205 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.7069 Model_2_val:0.7273
Epoch: 0100 Model_1_loss: 0.3905 Model_2_loss: 0.3232 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9667 Model_1_val:0.7187 Model_2_val:0.7316
Epoch: 0120 Model_1_loss: 0.3421 Model_2_loss: 0.3146 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7267 Model_2_val:0.7325
Epoch: 0140 Model_1_loss: 0.2766 Model_2_loss: 0.2254 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7337 Model_2_val:0.7415
Epoch: 0160 Model_1_loss: 0.2143 Model_2_loss: 0.1928 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7327 Model_2_val:0.7412
Epoch: 0180 Model_1_loss: 0.2414 Model_2_loss: 0.2153 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7386 Model_2_val:0.7469
Epoch: 0200 Model_1_loss: 0.2008 Model_2_loss: 0.1865 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7422 Model_2_val:0.7500
Epoch: 0220 Model_1_loss: 0.2348 Model_2_loss: 0.2136 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7529 Model_2_val:0.7425
Epoch: 0240 Model_1_loss: 0.1758 Model_2_loss: 0.1692 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7575 Model_2_val:0.7520
Epoch: 0260 Model_1_loss: 0.2083 Model_2_loss: 0.1704 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7571 Model_2_val:0.7560
Epoch: 0280 Model_1_loss: 0.1794 Model_2_loss: 0.1656 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7503 Model_2_val:0.7551
Epoch: 0300 Model_1_loss: 0.1691 Model_2_loss: 0.1302 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7533 Model_2_val:0.7555
Epoch: 0320 Model_1_loss: 0.1633 Model_2_loss: 0.1569 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7547 Model_2_val:0.7629
Epoch: 0340 Model_1_loss: 0.1331 Model_2_loss: 0.1505 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7627 Model_2_val:0.7590
Epoch: 0360 Model_1_loss: 0.1448 Model_2_loss: 0.1245 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7604 Model_2_val:0.7629
Epoch: 0380 Model_1_loss: 0.1194 Model_2_loss: 0.1487 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7637 Model_2_val:0.7659
Epoch: 0400 Model_1_loss: 0.1101 Model_2_loss: 0.1029 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7633 Model_2_val:0.7637
Model_one_test:0.7818 Model_two_test:0.7790
added by two output: 0.7801
3
labels of each class :  [20 20 20]
t= [975 975 975]
1242799747
Epoch: 0020 Model_1_loss: 1.0448 Model_2_loss: 0.9912 Model_1_trainacc: 0.5000 Model_2_trainacc: 0.8000 Model_1_val:0.3838 Model_2_val:0.5406
Epoch: 0040 Model_1_loss: 0.8712 Model_2_loss: 0.7987 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.8500 Model_1_val:0.5563 Model_2_val:0.6558
Epoch: 0060 Model_1_loss: 0.6391 Model_2_loss: 0.5150 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9667 Model_1_val:0.6511 Model_2_val:0.6889
Epoch: 0080 Model_1_loss: 0.4581 Model_2_loss: 0.3971 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9167 Model_1_val:0.6861 Model_2_val:0.7104
Epoch: 0100 Model_1_loss: 0.3773 Model_2_loss: 0.2755 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7060 Model_2_val:0.7084
Epoch: 0120 Model_1_loss: 0.3006 Model_2_loss: 0.2554 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7161 Model_2_val:0.7225
Epoch: 0140 Model_1_loss: 0.2563 Model_2_loss: 0.2026 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7232 Model_2_val:0.7227
Epoch: 0160 Model_1_loss: 0.2118 Model_2_loss: 0.2215 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7201 Model_2_val:0.7253
Epoch: 0180 Model_1_loss: 0.1896 Model_2_loss: 0.1858 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7359 Model_2_val:0.7249
Epoch: 0200 Model_1_loss: 0.1861 Model_2_loss: 0.1574 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7244 Model_2_val:0.7221
Epoch: 0220 Model_1_loss: 0.2286 Model_2_loss: 0.2691 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7695 Model_2_val:0.7694
Epoch: 0240 Model_1_loss: 0.1987 Model_2_loss: 0.2044 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7754 Model_2_val:0.7643
Epoch: 0260 Model_1_loss: 0.1789 Model_2_loss: 0.1803 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7770 Model_2_val:0.7718
Epoch: 0280 Model_1_loss: 0.1735 Model_2_loss: 0.1428 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7789 Model_2_val:0.7617
Epoch: 0300 Model_1_loss: 0.1491 Model_2_loss: 0.1572 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7643 Model_2_val:0.7664
Epoch: 0320 Model_1_loss: 0.1822 Model_2_loss: 0.1617 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7607 Model_2_val:0.7602
Epoch: 0340 Model_1_loss: 0.1304 Model_2_loss: 0.1171 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7618 Model_2_val:0.7569
Epoch: 0360 Model_1_loss: 0.1702 Model_2_loss: 0.1281 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7651 Model_2_val:0.7716
Epoch: 0380 Model_1_loss: 0.1525 Model_2_loss: 0.1203 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7624 Model_2_val:0.7532
Epoch: 0400 Model_1_loss: 0.1632 Model_2_loss: 0.1437 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7576 Model_2_val:0.7620
Model_one_test:0.7762 Model_two_test:0.7828
added by two output: 0.7796
4
labels of each class :  [20 20 20]
t= [975 975 975]
78633162
Epoch: 0020 Model_1_loss: 0.9702 Model_2_loss: 0.9917 Model_1_trainacc: 0.6000 Model_2_trainacc: 0.6000 Model_1_val:0.4720 Model_2_val:0.5265
Epoch: 0040 Model_1_loss: 0.8268 Model_2_loss: 0.7633 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8167 Model_1_val:0.6317 Model_2_val:0.6506
Epoch: 0060 Model_1_loss: 0.6355 Model_2_loss: 0.5424 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9500 Model_1_val:0.6851 Model_2_val:0.6938
Epoch: 0080 Model_1_loss: 0.4818 Model_2_loss: 0.3982 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.7027 Model_2_val:0.7110
Epoch: 0100 Model_1_loss: 0.3870 Model_2_loss: 0.2914 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.7029 Model_2_val:0.7243
Epoch: 0120 Model_1_loss: 0.3118 Model_2_loss: 0.2368 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7150 Model_2_val:0.7282
Epoch: 0140 Model_1_loss: 0.2589 Model_2_loss: 0.2201 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7161 Model_2_val:0.7392
Epoch: 0160 Model_1_loss: 0.2262 Model_2_loss: 0.2104 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7128 Model_2_val:0.7378
Epoch: 0180 Model_1_loss: 0.2135 Model_2_loss: 0.1833 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7251 Model_2_val:0.7431
Epoch: 0200 Model_1_loss: 0.1660 Model_2_loss: 0.1880 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7222 Model_2_val:0.7441
Epoch: 0220 Model_1_loss: 0.2536 Model_2_loss: 0.1867 Model_1_trainacc: 0.9500 Model_2_trainacc: 1.0000 Model_1_val:0.7253 Model_2_val:0.7409
Epoch: 0240 Model_1_loss: 0.2418 Model_2_loss: 0.1719 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7267 Model_2_val:0.7433
Epoch: 0260 Model_1_loss: 0.1726 Model_2_loss: 0.1481 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7268 Model_2_val:0.7419
Epoch: 0280 Model_1_loss: 0.1827 Model_2_loss: 0.1398 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7322 Model_2_val:0.7482
Epoch: 0300 Model_1_loss: 0.1766 Model_2_loss: 0.1716 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7402 Model_2_val:0.7461
Epoch: 0320 Model_1_loss: 0.1539 Model_2_loss: 0.1339 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7337 Model_2_val:0.7491
Epoch: 0340 Model_1_loss: 0.1667 Model_2_loss: 0.1568 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7340 Model_2_val:0.7566
Epoch: 0360 Model_1_loss: 0.1369 Model_2_loss: 0.1510 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7380 Model_2_val:0.7461
Epoch: 0380 Model_1_loss: 0.1626 Model_2_loss: 0.1556 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7394 Model_2_val:0.7461
Epoch: 0400 Model_1_loss: 0.1335 Model_2_loss: 0.1464 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7402 Model_2_val:0.7481
Model_one_test:0.7620 Model_two_test:0.7610
added by two output: 0.7620
5
labels of each class :  [20 20 20]
t= [975 975 975]
241694486
Epoch: 0020 Model_1_loss: 1.0152 Model_2_loss: 0.9754 Model_1_trainacc: 0.6333 Model_2_trainacc: 0.6833 Model_1_val:0.4831 Model_2_val:0.5278
Epoch: 0040 Model_1_loss: 0.8380 Model_2_loss: 0.7456 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.8500 Model_1_val:0.6013 Model_2_val:0.6519
Epoch: 0060 Model_1_loss: 0.6447 Model_2_loss: 0.5054 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.9333 Model_1_val:0.6645 Model_2_val:0.7038
Epoch: 0080 Model_1_loss: 0.4515 Model_2_loss: 0.3309 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7046 Model_2_val:0.7117
Epoch: 0100 Model_1_loss: 0.3332 Model_2_loss: 0.2922 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7094 Model_2_val:0.7149
Epoch: 0120 Model_1_loss: 0.3109 Model_2_loss: 0.2403 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7201 Model_2_val:0.7262
Epoch: 0140 Model_1_loss: 0.2304 Model_2_loss: 0.2015 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7158 Model_2_val:0.7275
Epoch: 0160 Model_1_loss: 0.2456 Model_2_loss: 0.1955 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7251 Model_2_val:0.7289
Epoch: 0180 Model_1_loss: 0.1838 Model_2_loss: 0.1847 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7252 Model_2_val:0.7302
Epoch: 0200 Model_1_loss: 0.1915 Model_2_loss: 0.1535 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7243 Model_2_val:0.7360
Epoch: 0220 Model_1_loss: 0.2187 Model_2_loss: 0.2033 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7647 Model_2_val:0.7597
Epoch: 0240 Model_1_loss: 0.1945 Model_2_loss: 0.1587 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7647 Model_2_val:0.7623
Epoch: 0260 Model_1_loss: 0.1899 Model_2_loss: 0.1558 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7640 Model_2_val:0.7618
Epoch: 0280 Model_1_loss: 0.2025 Model_2_loss: 0.1494 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7635 Model_2_val:0.7597
Epoch: 0300 Model_1_loss: 0.1703 Model_2_loss: 0.1489 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7659 Model_2_val:0.7631
Epoch: 0320 Model_1_loss: 0.1285 Model_2_loss: 0.1219 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7594 Model_2_val:0.7612
Epoch: 0340 Model_1_loss: 0.1431 Model_2_loss: 0.1483 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7677 Model_2_val:0.7661
Epoch: 0360 Model_1_loss: 0.1603 Model_2_loss: 0.1297 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7663 Model_2_val:0.7561
Epoch: 0380 Model_1_loss: 0.1329 Model_2_loss: 0.1458 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7668 Model_2_val:0.7627
Epoch: 0400 Model_1_loss: 0.1546 Model_2_loss: 0.1524 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7677 Model_2_val:0.7629
Model_one_test:0.7864 Model_two_test:0.7787
added by two output: 0.7820
6
labels of each class :  [20 20 20]
t= [975 975 975]
141126769
Epoch: 0020 Model_1_loss: 1.0096 Model_2_loss: 0.9880 Model_1_trainacc: 0.5667 Model_2_trainacc: 0.7167 Model_1_val:0.4824 Model_2_val:0.5590
Epoch: 0040 Model_1_loss: 0.8509 Model_2_loss: 0.8280 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.8833 Model_1_val:0.6278 Model_2_val:0.6379
Epoch: 0060 Model_1_loss: 0.6773 Model_2_loss: 0.6054 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8833 Model_1_val:0.6742 Model_2_val:0.6909
Epoch: 0080 Model_1_loss: 0.4738 Model_2_loss: 0.4994 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8667 Model_1_val:0.7071 Model_2_val:0.7223
Epoch: 0100 Model_1_loss: 0.3591 Model_2_loss: 0.3599 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7285 Model_2_val:0.7343
Epoch: 0120 Model_1_loss: 0.3352 Model_2_loss: 0.3122 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7371 Model_2_val:0.7378
Epoch: 0140 Model_1_loss: 0.2824 Model_2_loss: 0.2304 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7426 Model_2_val:0.7392
Epoch: 0160 Model_1_loss: 0.2189 Model_2_loss: 0.2292 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7597 Model_2_val:0.7507
Epoch: 0180 Model_1_loss: 0.1969 Model_2_loss: 0.1941 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7570 Model_2_val:0.7531
Epoch: 0200 Model_1_loss: 0.1775 Model_2_loss: 0.1918 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7602 Model_2_val:0.7586
Epoch: 0220 Model_1_loss: 0.2012 Model_2_loss: 0.1837 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7475 Model_2_val:0.7559
Epoch: 0240 Model_1_loss: 0.1651 Model_2_loss: 0.1765 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7594 Model_2_val:0.7562
Epoch: 0260 Model_1_loss: 0.1619 Model_2_loss: 0.1556 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7574 Model_2_val:0.7588
Epoch: 0280 Model_1_loss: 0.1461 Model_2_loss: 0.1596 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7569 Model_2_val:0.7599
Epoch: 0300 Model_1_loss: 0.1379 Model_2_loss: 0.1609 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7577 Model_2_val:0.7571
Epoch: 0320 Model_1_loss: 0.1311 Model_2_loss: 0.1787 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7633 Model_2_val:0.7640
Epoch: 0340 Model_1_loss: 0.1207 Model_2_loss: 0.1397 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7674 Model_2_val:0.7642
Epoch: 0360 Model_1_loss: 0.1339 Model_2_loss: 0.1027 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7629 Model_2_val:0.7591
Epoch: 0380 Model_1_loss: 0.1372 Model_2_loss: 0.1284 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7673 Model_2_val:0.7640
Epoch: 0400 Model_1_loss: 0.1347 Model_2_loss: 0.1296 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7659 Model_2_val:0.7615
Model_one_test:0.7739 Model_two_test:0.7809
added by two output: 0.7775
7
labels of each class :  [20 20 20]
t= [975 975 975]
210135580
Epoch: 0020 Model_1_loss: 0.9430 Model_2_loss: 1.0580 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.6167 Model_1_val:0.5566 Model_2_val:0.5230
Epoch: 0040 Model_1_loss: 0.7273 Model_2_loss: 0.9024 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8167 Model_1_val:0.6032 Model_2_val:0.5905
Epoch: 0060 Model_1_loss: 0.5333 Model_2_loss: 0.6240 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8167 Model_1_val:0.6348 Model_2_val:0.6113
Epoch: 0080 Model_1_loss: 0.4203 Model_2_loss: 0.4421 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9333 Model_1_val:0.6641 Model_2_val:0.6663
Epoch: 0100 Model_1_loss: 0.2820 Model_2_loss: 0.3849 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9333 Model_1_val:0.6781 Model_2_val:0.6859
Epoch: 0120 Model_1_loss: 0.2634 Model_2_loss: 0.2884 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6936 Model_2_val:0.6864
Epoch: 0140 Model_1_loss: 0.2371 Model_2_loss: 0.2793 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6950 Model_2_val:0.7035
Epoch: 0160 Model_1_loss: 0.2298 Model_2_loss: 0.2350 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7069 Model_2_val:0.7040
Epoch: 0180 Model_1_loss: 0.1659 Model_2_loss: 0.2161 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7005 Model_2_val:0.7062
Epoch: 0200 Model_1_loss: 0.1768 Model_2_loss: 0.2077 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7071 Model_2_val:0.7014
Epoch: 0220 Model_1_loss: 0.2297 Model_2_loss: 0.2442 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7422 Model_2_val:0.7381
Epoch: 0240 Model_1_loss: 0.2007 Model_2_loss: 0.1956 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7388 Model_2_val:0.7349
Epoch: 0260 Model_1_loss: 0.1824 Model_2_loss: 0.1836 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7474 Model_2_val:0.7429
Epoch: 0280 Model_1_loss: 0.1688 Model_2_loss: 0.1699 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7420 Model_2_val:0.7396
Epoch: 0300 Model_1_loss: 0.1587 Model_2_loss: 0.1529 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7362 Model_2_val:0.7393
Epoch: 0320 Model_1_loss: 0.1593 Model_2_loss: 0.1552 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7409 Model_2_val:0.7458
Epoch: 0340 Model_1_loss: 0.1327 Model_2_loss: 0.1475 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7418 Model_2_val:0.7385
Epoch: 0360 Model_1_loss: 0.1377 Model_2_loss: 0.1474 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7389 Model_2_val:0.7443
Epoch: 0380 Model_1_loss: 0.1230 Model_2_loss: 0.1444 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7397 Model_2_val:0.7370
Epoch: 0400 Model_1_loss: 0.1298 Model_2_loss: 0.1362 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7460 Model_2_val:0.7386
Model_one_test:0.7620 Model_two_test:0.7547
added by two output: 0.7586
8
labels of each class :  [20 20 20]
t= [975 975 975]
1027723907
Epoch: 0020 Model_1_loss: 1.0207 Model_2_loss: 1.0460 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.6000 Model_1_val:0.6267 Model_2_val:0.4788
Epoch: 0040 Model_1_loss: 0.8304 Model_2_loss: 0.9175 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8333 Model_1_val:0.6776 Model_2_val:0.6599
Epoch: 0060 Model_1_loss: 0.6046 Model_2_loss: 0.7266 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8833 Model_1_val:0.7142 Model_2_val:0.6663
Epoch: 0080 Model_1_loss: 0.4675 Model_2_loss: 0.5901 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8833 Model_1_val:0.7295 Model_2_val:0.6979
Epoch: 0100 Model_1_loss: 0.3789 Model_2_loss: 0.4587 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.7468 Model_2_val:0.7348
Epoch: 0120 Model_1_loss: 0.2825 Model_2_loss: 0.3930 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.7512 Model_2_val:0.7385
Epoch: 0140 Model_1_loss: 0.2669 Model_2_loss: 0.3704 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9167 Model_1_val:0.7541 Model_2_val:0.7483
Epoch: 0160 Model_1_loss: 0.2377 Model_2_loss: 0.2666 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7499 Model_2_val:0.7559
Epoch: 0180 Model_1_loss: 0.2538 Model_2_loss: 0.2769 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.7649 Model_2_val:0.7589
Epoch: 0200 Model_1_loss: 0.1782 Model_2_loss: 0.2370 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7678 Model_2_val:0.7571
Epoch: 0220 Model_1_loss: 0.2405 Model_2_loss: 0.3244 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7936 Model_2_val:0.7915
Epoch: 0240 Model_1_loss: 0.2383 Model_2_loss: 0.2621 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.8018 Model_2_val:0.7966
Epoch: 0260 Model_1_loss: 0.2113 Model_2_loss: 0.2328 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.8036 Model_2_val:0.7972
Epoch: 0280 Model_1_loss: 0.1864 Model_2_loss: 0.1756 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.8043 Model_2_val:0.7983
Epoch: 0300 Model_1_loss: 0.1712 Model_2_loss: 0.2175 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.8009 Model_2_val:0.7983
Epoch: 0320 Model_1_loss: 0.2005 Model_2_loss: 0.2173 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.8030 Model_2_val:0.7983
Epoch: 0340 Model_1_loss: 0.1646 Model_2_loss: 0.1926 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.8043 Model_2_val:0.8007
Epoch: 0360 Model_1_loss: 0.1744 Model_2_loss: 0.1934 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7985 Model_2_val:0.8006
Epoch: 0380 Model_1_loss: 0.1607 Model_2_loss: 0.1871 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7987 Model_2_val:0.8037
Epoch: 0400 Model_1_loss: 0.1508 Model_2_loss: 0.1763 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.8001 Model_2_val:0.8012
Model_one_test:0.8224 Model_two_test:0.8274
added by two output: 0.8263
9
labels of each class :  [20 20 20]
t= [975 975 975]
669883793
Epoch: 0020 Model_1_loss: 0.9838 Model_2_loss: 0.9663 Model_1_trainacc: 0.5667 Model_2_trainacc: 0.6000 Model_1_val:0.4652 Model_2_val:0.4461
Epoch: 0040 Model_1_loss: 0.8041 Model_2_loss: 0.7330 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.8167 Model_1_val:0.6137 Model_2_val:0.6041
Epoch: 0060 Model_1_loss: 0.5686 Model_2_loss: 0.6166 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8000 Model_1_val:0.6645 Model_2_val:0.6654
Epoch: 0080 Model_1_loss: 0.4766 Model_2_loss: 0.4665 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9167 Model_1_val:0.6942 Model_2_val:0.7128
Epoch: 0100 Model_1_loss: 0.3513 Model_2_loss: 0.3621 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7160 Model_2_val:0.7163
Epoch: 0120 Model_1_loss: 0.3898 Model_2_loss: 0.3188 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9500 Model_1_val:0.7375 Model_2_val:0.7215
Epoch: 0140 Model_1_loss: 0.3515 Model_2_loss: 0.2788 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7343 Model_2_val:0.7338
Epoch: 0160 Model_1_loss: 0.2817 Model_2_loss: 0.2707 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7449 Model_2_val:0.7383
Epoch: 0180 Model_1_loss: 0.2668 Model_2_loss: 0.2287 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7452 Model_2_val:0.7442
Epoch: 0200 Model_1_loss: 0.1760 Model_2_loss: 0.1976 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7477 Model_2_val:0.7516
Epoch: 0220 Model_1_loss: 0.2752 Model_2_loss: 0.2355 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7838 Model_2_val:0.7701
Epoch: 0240 Model_1_loss: 0.2348 Model_2_loss: 0.2316 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7742 Model_2_val:0.7752
Epoch: 0260 Model_1_loss: 0.2413 Model_2_loss: 0.2191 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7845 Model_2_val:0.7884
Epoch: 0280 Model_1_loss: 0.1559 Model_2_loss: 0.1883 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7835 Model_2_val:0.7773
Epoch: 0300 Model_1_loss: 0.1904 Model_2_loss: 0.1585 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7878 Model_2_val:0.7796
Epoch: 0320 Model_1_loss: 0.1417 Model_2_loss: 0.1642 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7776 Model_2_val:0.7769
Epoch: 0340 Model_1_loss: 0.1962 Model_2_loss: 0.1610 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7791 Model_2_val:0.7821
Epoch: 0360 Model_1_loss: 0.1566 Model_2_loss: 0.1770 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7824 Model_2_val:0.7911
Epoch: 0380 Model_1_loss: 0.1566 Model_2_loss: 0.1379 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7848 Model_2_val:0.7788
Epoch: 0400 Model_1_loss: 0.1381 Model_2_loss: 0.1198 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7834 Model_2_val:0.7780
Model_one_test:0.8047 Model_two_test:0.7992
added by two output: 0.8022
10
labels of each class :  [20 20 20]
t= [975 975 975]
1039392038
Epoch: 0020 Model_1_loss: 1.0008 Model_2_loss: 1.0008 Model_1_trainacc: 0.7000 Model_2_trainacc: 0.7167 Model_1_val:0.5713 Model_2_val:0.6019
Epoch: 0040 Model_1_loss: 0.8149 Model_2_loss: 0.7776 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8833 Model_1_val:0.7046 Model_2_val:0.6981
Epoch: 0060 Model_1_loss: 0.5674 Model_2_loss: 0.5433 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8833 Model_1_val:0.7423 Model_2_val:0.7279
Epoch: 0080 Model_1_loss: 0.4105 Model_2_loss: 0.3578 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.7616 Model_2_val:0.7530
Epoch: 0100 Model_1_loss: 0.2712 Model_2_loss: 0.2851 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7650 Model_2_val:0.7584
Epoch: 0120 Model_1_loss: 0.2862 Model_2_loss: 0.2346 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7609 Model_2_val:0.7642
Epoch: 0140 Model_1_loss: 0.2298 Model_2_loss: 0.2705 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9333 Model_1_val:0.7691 Model_2_val:0.7674
Epoch: 0160 Model_1_loss: 0.2039 Model_2_loss: 0.2301 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7705 Model_2_val:0.7688
Epoch: 0180 Model_1_loss: 0.1949 Model_2_loss: 0.2377 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7691 Model_2_val:0.7733
Epoch: 0200 Model_1_loss: 0.1511 Model_2_loss: 0.1605 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7777 Model_2_val:0.7737
Epoch: 0220 Model_1_loss: 0.2031 Model_2_loss: 0.2380 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7674 Model_2_val:0.7772
Epoch: 0240 Model_1_loss: 0.2185 Model_2_loss: 0.2036 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7778 Model_2_val:0.7763
Epoch: 0260 Model_1_loss: 0.2021 Model_2_loss: 0.2035 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7735 Model_2_val:0.7813
Epoch: 0280 Model_1_loss: 0.1976 Model_2_loss: 0.1637 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7700 Model_2_val:0.7812
Epoch: 0300 Model_1_loss: 0.1720 Model_2_loss: 0.2109 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9333 Model_1_val:0.7763 Model_2_val:0.7730
Epoch: 0320 Model_1_loss: 0.1798 Model_2_loss: 0.1816 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7777 Model_2_val:0.7767
Epoch: 0340 Model_1_loss: 0.1571 Model_2_loss: 0.1653 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7752 Model_2_val:0.7812
Epoch: 0360 Model_1_loss: 0.1367 Model_2_loss: 0.1713 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7801 Model_2_val:0.7790
Epoch: 0380 Model_1_loss: 0.1284 Model_2_loss: 0.2086 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9333 Model_1_val:0.7721 Model_2_val:0.7823
Epoch: 0400 Model_1_loss: 0.1374 Model_2_loss: 0.1467 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7791 Model_2_val:0.7871
Model_one_test:0.7953 Model_two_test:0.8036
added by two output: 0.8010
Model1 Acc: 0.780288 Model2 Acc: 0.781620
Maxacc Mean: 0.784036
[0.7724194482998152, 0.784036321393279]
Maxacc of all experiments: 0.784036321393279
1
labels of each class :  [20 20 20]
t= [975 975 975]
863307691
Epoch: 0020 Model_1_loss: 0.9551 Model_2_loss: 0.9832 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.6167 Model_1_val:0.5634 Model_2_val:0.4347
Epoch: 0040 Model_1_loss: 0.6784 Model_2_loss: 0.8041 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.7833 Model_1_val:0.6377 Model_2_val:0.6067
Epoch: 0060 Model_1_loss: 0.5179 Model_2_loss: 0.5801 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9167 Model_1_val:0.6654 Model_2_val:0.6441
Epoch: 0080 Model_1_loss: 0.3785 Model_2_loss: 0.4216 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6822 Model_2_val:0.6777
Epoch: 0100 Model_1_loss: 0.3254 Model_2_loss: 0.3118 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6978 Model_2_val:0.7000
Epoch: 0120 Model_1_loss: 0.2640 Model_2_loss: 0.3247 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9000 Model_1_val:0.7058 Model_2_val:0.7038
Epoch: 0140 Model_1_loss: 0.2370 Model_2_loss: 0.2062 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7073 Model_2_val:0.7181
Epoch: 0160 Model_1_loss: 0.2182 Model_2_loss: 0.1968 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7063 Model_2_val:0.7083
Epoch: 0180 Model_1_loss: 0.2424 Model_2_loss: 0.2045 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7137 Model_2_val:0.7313
Epoch: 0200 Model_1_loss: 0.1685 Model_2_loss: 0.1535 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7186 Model_2_val:0.7277
Epoch: 0220 Model_1_loss: 0.2218 Model_2_loss: 0.2070 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7219 Model_2_val:0.7239
Epoch: 0240 Model_1_loss: 0.1579 Model_2_loss: 0.1838 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7241 Model_2_val:0.7253
Epoch: 0260 Model_1_loss: 0.1706 Model_2_loss: 0.1600 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7317 Model_2_val:0.7301
Epoch: 0280 Model_1_loss: 0.1771 Model_2_loss: 0.1511 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7202 Model_2_val:0.7261
Epoch: 0300 Model_1_loss: 0.1702 Model_2_loss: 0.1324 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7337 Model_2_val:0.7322
Epoch: 0320 Model_1_loss: 0.1301 Model_2_loss: 0.1509 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7306 Model_2_val:0.7261
Epoch: 0340 Model_1_loss: 0.1494 Model_2_loss: 0.1473 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7298 Model_2_val:0.7345
Epoch: 0360 Model_1_loss: 0.1295 Model_2_loss: 0.1282 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7275 Model_2_val:0.7314
Epoch: 0380 Model_1_loss: 0.1312 Model_2_loss: 0.1231 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7350 Model_2_val:0.7396
Epoch: 0400 Model_1_loss: 0.1391 Model_2_loss: 0.1361 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7316 Model_2_val:0.7312
Model_one_test:0.7505 Model_two_test:0.7444
added by two output: 0.7476
2
labels of each class :  [20 20 20]
t= [975 975 975]
480239130
Epoch: 0020 Model_1_loss: 1.0341 Model_2_loss: 1.0313 Model_1_trainacc: 0.4667 Model_2_trainacc: 0.4833 Model_1_val:0.4928 Model_2_val:0.3826
Epoch: 0040 Model_1_loss: 0.8542 Model_2_loss: 0.8880 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.7167 Model_1_val:0.6352 Model_2_val:0.6179
Epoch: 0060 Model_1_loss: 0.6407 Model_2_loss: 0.6264 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8833 Model_1_val:0.6963 Model_2_val:0.7016
Epoch: 0080 Model_1_loss: 0.4643 Model_2_loss: 0.5016 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.8667 Model_1_val:0.7198 Model_2_val:0.7232
Epoch: 0100 Model_1_loss: 0.4172 Model_2_loss: 0.3971 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9000 Model_1_val:0.7190 Model_2_val:0.7368
Epoch: 0120 Model_1_loss: 0.3531 Model_2_loss: 0.3187 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.7406 Model_2_val:0.7455
Epoch: 0140 Model_1_loss: 0.3170 Model_2_loss: 0.2639 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9833 Model_1_val:0.7456 Model_2_val:0.7521
Epoch: 0160 Model_1_loss: 0.2695 Model_2_loss: 0.2589 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7428 Model_2_val:0.7597
Epoch: 0180 Model_1_loss: 0.2541 Model_2_loss: 0.2120 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7378 Model_2_val:0.7639
Epoch: 0200 Model_1_loss: 0.2063 Model_2_loss: 0.2073 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7517 Model_2_val:0.7588
Epoch: 0220 Model_1_loss: 0.2750 Model_2_loss: 0.2144 Model_1_trainacc: 0.9500 Model_2_trainacc: 1.0000 Model_1_val:0.7661 Model_2_val:0.7627
Epoch: 0240 Model_1_loss: 0.2207 Model_2_loss: 0.1919 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7690 Model_2_val:0.7707
Epoch: 0260 Model_1_loss: 0.1991 Model_2_loss: 0.2132 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7687 Model_2_val:0.7714
Epoch: 0280 Model_1_loss: 0.2152 Model_2_loss: 0.1678 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7699 Model_2_val:0.7765
Epoch: 0300 Model_1_loss: 0.1754 Model_2_loss: 0.1679 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7667 Model_2_val:0.7750
Epoch: 0320 Model_1_loss: 0.1892 Model_2_loss: 0.1829 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7759 Model_2_val:0.7760
Epoch: 0340 Model_1_loss: 0.1662 Model_2_loss: 0.1578 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7798 Model_2_val:0.7797
Epoch: 0360 Model_1_loss: 0.1614 Model_2_loss: 0.1475 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7766 Model_2_val:0.7787
Epoch: 0380 Model_1_loss: 0.1562 Model_2_loss: 0.1392 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7783 Model_2_val:0.7836
Epoch: 0400 Model_1_loss: 0.1659 Model_2_loss: 0.1370 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7684 Model_2_val:0.7728
Model_one_test:0.7916 Model_two_test:0.7936
added by two output: 0.7931
3
labels of each class :  [20 20 20]
t= [975 975 975]
757868105
Epoch: 0020 Model_1_loss: 1.0003 Model_2_loss: 1.0128 Model_1_trainacc: 0.5833 Model_2_trainacc: 0.6333 Model_1_val:0.4641 Model_2_val:0.4819
Epoch: 0040 Model_1_loss: 0.7631 Model_2_loss: 0.8311 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8000 Model_1_val:0.6274 Model_2_val:0.6277
Epoch: 0060 Model_1_loss: 0.5654 Model_2_loss: 0.6164 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8667 Model_1_val:0.6779 Model_2_val:0.6920
Epoch: 0080 Model_1_loss: 0.4427 Model_2_loss: 0.4584 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8833 Model_1_val:0.7048 Model_2_val:0.7114
Epoch: 0100 Model_1_loss: 0.3691 Model_2_loss: 0.3735 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9000 Model_1_val:0.7257 Model_2_val:0.7229
Epoch: 0120 Model_1_loss: 0.3143 Model_2_loss: 0.3127 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9833 Model_1_val:0.7316 Model_2_val:0.7346
Epoch: 0140 Model_1_loss: 0.2841 Model_2_loss: 0.2390 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7419 Model_2_val:0.7472
Epoch: 0160 Model_1_loss: 0.2186 Model_2_loss: 0.2480 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7333 Model_2_val:0.7467
Epoch: 0180 Model_1_loss: 0.2182 Model_2_loss: 0.2012 Model_1_trainacc: 0.9500 Model_2_trainacc: 1.0000 Model_1_val:0.7555 Model_2_val:0.7475
Epoch: 0200 Model_1_loss: 0.1818 Model_2_loss: 0.2048 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7406 Model_2_val:0.7448
Epoch: 0220 Model_1_loss: 0.2625 Model_2_loss: 0.2806 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.7450 Model_2_val:0.7561
Epoch: 0240 Model_1_loss: 0.1809 Model_2_loss: 0.2131 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7482 Model_2_val:0.7572
Epoch: 0260 Model_1_loss: 0.1762 Model_2_loss: 0.1940 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7513 Model_2_val:0.7562
Epoch: 0280 Model_1_loss: 0.1927 Model_2_loss: 0.1894 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7480 Model_2_val:0.7577
Epoch: 0300 Model_1_loss: 0.1548 Model_2_loss: 0.1873 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7578 Model_2_val:0.7622
Epoch: 0320 Model_1_loss: 0.1405 Model_2_loss: 0.1404 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7558 Model_2_val:0.7641
Epoch: 0340 Model_1_loss: 0.1621 Model_2_loss: 0.1675 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7618 Model_2_val:0.7642
Epoch: 0360 Model_1_loss: 0.1377 Model_2_loss: 0.1778 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7662 Model_2_val:0.7630
Epoch: 0380 Model_1_loss: 0.1643 Model_2_loss: 0.1473 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7608 Model_2_val:0.7706
Epoch: 0400 Model_1_loss: 0.1380 Model_2_loss: 0.1223 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7585 Model_2_val:0.7628
Model_one_test:0.7767 Model_two_test:0.7796
added by two output: 0.7781
4
labels of each class :  [20 20 20]
t= [975 975 975]
536535441
Epoch: 0020 Model_1_loss: 1.0285 Model_2_loss: 1.0084 Model_1_trainacc: 0.5833 Model_2_trainacc: 0.6500 Model_1_val:0.5690 Model_2_val:0.5671
Epoch: 0040 Model_1_loss: 0.8304 Model_2_loss: 0.7943 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8167 Model_1_val:0.6830 Model_2_val:0.6868
Epoch: 0060 Model_1_loss: 0.6036 Model_2_loss: 0.5537 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9000 Model_1_val:0.7134 Model_2_val:0.7161
Epoch: 0080 Model_1_loss: 0.4566 Model_2_loss: 0.4007 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7273 Model_2_val:0.7276
Epoch: 0100 Model_1_loss: 0.3527 Model_2_loss: 0.3258 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.7369 Model_2_val:0.7428
Epoch: 0120 Model_1_loss: 0.2989 Model_2_loss: 0.2801 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7432 Model_2_val:0.7433
Epoch: 0140 Model_1_loss: 0.2666 Model_2_loss: 0.2404 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7452 Model_2_val:0.7476
Epoch: 0160 Model_1_loss: 0.2287 Model_2_loss: 0.2130 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7470 Model_2_val:0.7498
Epoch: 0180 Model_1_loss: 0.2386 Model_2_loss: 0.2678 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7364 Model_2_val:0.7521
Epoch: 0200 Model_1_loss: 0.2057 Model_2_loss: 0.2150 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7517 Model_2_val:0.7508
Epoch: 0220 Model_1_loss: 0.2350 Model_2_loss: 0.2126 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7533 Model_2_val:0.7570
Epoch: 0240 Model_1_loss: 0.2036 Model_2_loss: 0.2146 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7621 Model_2_val:0.7633
Epoch: 0260 Model_1_loss: 0.1882 Model_2_loss: 0.1908 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7623 Model_2_val:0.7627
Epoch: 0280 Model_1_loss: 0.1820 Model_2_loss: 0.1781 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7612 Model_2_val:0.7603
Epoch: 0300 Model_1_loss: 0.1454 Model_2_loss: 0.2101 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7658 Model_2_val:0.7674
Epoch: 0320 Model_1_loss: 0.1480 Model_2_loss: 0.1533 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7650 Model_2_val:0.7675
Epoch: 0340 Model_1_loss: 0.1615 Model_2_loss: 0.1432 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7599 Model_2_val:0.7657
Epoch: 0360 Model_1_loss: 0.1586 Model_2_loss: 0.1405 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7599 Model_2_val:0.7615
Epoch: 0380 Model_1_loss: 0.1670 Model_2_loss: 0.1355 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7643 Model_2_val:0.7632
Epoch: 0400 Model_1_loss: 0.1323 Model_2_loss: 0.1722 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7644 Model_2_val:0.7623
Model_one_test:0.7829 Model_two_test:0.7815
added by two output: 0.7817
5
labels of each class :  [20 20 20]
t= [975 975 975]
226820521
Epoch: 0020 Model_1_loss: 1.0395 Model_2_loss: 0.9542 Model_1_trainacc: 0.5000 Model_2_trainacc: 0.7000 Model_1_val:0.3839 Model_2_val:0.4719
Epoch: 0040 Model_1_loss: 0.8991 Model_2_loss: 0.7664 Model_1_trainacc: 0.6333 Model_2_trainacc: 0.8500 Model_1_val:0.5104 Model_2_val:0.6190
Epoch: 0060 Model_1_loss: 0.7159 Model_2_loss: 0.6124 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.9000 Model_1_val:0.6081 Model_2_val:0.6844
Epoch: 0080 Model_1_loss: 0.5649 Model_2_loss: 0.4639 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6683 Model_2_val:0.7037
Epoch: 0100 Model_1_loss: 0.4193 Model_2_loss: 0.3654 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6983 Model_2_val:0.7087
Epoch: 0120 Model_1_loss: 0.3663 Model_2_loss: 0.3037 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.7150 Model_2_val:0.7124
Epoch: 0140 Model_1_loss: 0.3226 Model_2_loss: 0.2509 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.7142 Model_2_val:0.7129
Epoch: 0160 Model_1_loss: 0.2993 Model_2_loss: 0.2353 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7130 Model_2_val:0.7141
Epoch: 0180 Model_1_loss: 0.2182 Model_2_loss: 0.2270 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7189 Model_2_val:0.7117
Epoch: 0200 Model_1_loss: 0.2373 Model_2_loss: 0.2521 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7166 Model_2_val:0.7114
Epoch: 0220 Model_1_loss: 0.2984 Model_2_loss: 0.2787 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7280 Model_2_val:0.7336
Epoch: 0240 Model_1_loss: 0.2316 Model_2_loss: 0.2236 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7353 Model_2_val:0.7315
Epoch: 0260 Model_1_loss: 0.2156 Model_2_loss: 0.2108 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7322 Model_2_val:0.7347
Epoch: 0280 Model_1_loss: 0.2470 Model_2_loss: 0.1765 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7362 Model_2_val:0.7318
Epoch: 0300 Model_1_loss: 0.2424 Model_2_loss: 0.2076 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7340 Model_2_val:0.7343
Epoch: 0320 Model_1_loss: 0.2258 Model_2_loss: 0.1759 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7364 Model_2_val:0.7401
Epoch: 0340 Model_1_loss: 0.1801 Model_2_loss: 0.2009 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7362 Model_2_val:0.7364
Epoch: 0360 Model_1_loss: 0.2108 Model_2_loss: 0.1933 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9833 Model_1_val:0.7315 Model_2_val:0.7377
Epoch: 0380 Model_1_loss: 0.1913 Model_2_loss: 0.1725 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7338 Model_2_val:0.7413
Epoch: 0400 Model_1_loss: 0.1722 Model_2_loss: 0.1595 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7354 Model_2_val:0.7403
Model_one_test:0.7503 Model_two_test:0.7508
added by two output: 0.7513
6
labels of each class :  [20 20 20]
t= [975 975 975]
195978550
Epoch: 0020 Model_1_loss: 0.9492 Model_2_loss: 1.0496 Model_1_trainacc: 0.6833 Model_2_trainacc: 0.4833 Model_1_val:0.5057 Model_2_val:0.4735
Epoch: 0040 Model_1_loss: 0.7726 Model_2_loss: 0.8318 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.7667 Model_1_val:0.6044 Model_2_val:0.6220
Epoch: 0060 Model_1_loss: 0.5929 Model_2_loss: 0.6311 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8833 Model_1_val:0.6586 Model_2_val:0.6732
Epoch: 0080 Model_1_loss: 0.4304 Model_2_loss: 0.4809 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.6806 Model_2_val:0.6852
Epoch: 0100 Model_1_loss: 0.3816 Model_2_loss: 0.3773 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.6979 Model_2_val:0.7023
Epoch: 0120 Model_1_loss: 0.2782 Model_2_loss: 0.3100 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.7000 Model_2_val:0.6966
Epoch: 0140 Model_1_loss: 0.2572 Model_2_loss: 0.2851 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7133 Model_2_val:0.7115
Epoch: 0160 Model_1_loss: 0.1873 Model_2_loss: 0.2156 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7088 Model_2_val:0.7129
Epoch: 0180 Model_1_loss: 0.1810 Model_2_loss: 0.2449 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7190 Model_2_val:0.7135
Epoch: 0200 Model_1_loss: 0.1679 Model_2_loss: 0.1971 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7206 Model_2_val:0.7174
Epoch: 0220 Model_1_loss: 0.2488 Model_2_loss: 0.2736 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7359 Model_2_val:0.7342
Epoch: 0240 Model_1_loss: 0.1700 Model_2_loss: 0.2207 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7385 Model_2_val:0.7327
Epoch: 0260 Model_1_loss: 0.2194 Model_2_loss: 0.1867 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7440 Model_2_val:0.7323
Epoch: 0280 Model_1_loss: 0.1703 Model_2_loss: 0.1786 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7479 Model_2_val:0.7401
Epoch: 0300 Model_1_loss: 0.1908 Model_2_loss: 0.1638 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7392 Model_2_val:0.7453
Epoch: 0320 Model_1_loss: 0.1688 Model_2_loss: 0.1919 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7437 Model_2_val:0.7378
Epoch: 0340 Model_1_loss: 0.1471 Model_2_loss: 0.1693 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7456 Model_2_val:0.7426
Epoch: 0360 Model_1_loss: 0.1562 Model_2_loss: 0.1712 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7493 Model_2_val:0.7474
Epoch: 0380 Model_1_loss: 0.1374 Model_2_loss: 0.1521 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7483 Model_2_val:0.7461
Epoch: 0400 Model_1_loss: 0.1635 Model_2_loss: 0.1589 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7493 Model_2_val:0.7451
Model_one_test:0.7672 Model_two_test:0.7636
added by two output: 0.7658
7
labels of each class :  [20 20 20]
t= [975 975 975]
1327170916
Epoch: 0020 Model_1_loss: 1.0226 Model_2_loss: 0.9443 Model_1_trainacc: 0.5833 Model_2_trainacc: 0.8167 Model_1_val:0.5015 Model_2_val:0.6561
Epoch: 0040 Model_1_loss: 0.8414 Model_2_loss: 0.7261 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8833 Model_1_val:0.6396 Model_2_val:0.7038
Epoch: 0060 Model_1_loss: 0.5833 Model_2_loss: 0.5310 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.7046 Model_2_val:0.7341
Epoch: 0080 Model_1_loss: 0.3845 Model_2_loss: 0.3712 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7337 Model_2_val:0.7431
Epoch: 0100 Model_1_loss: 0.2948 Model_2_loss: 0.2985 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7478 Model_2_val:0.7491
Epoch: 0120 Model_1_loss: 0.2227 Model_2_loss: 0.2646 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7465 Model_2_val:0.7523
Epoch: 0140 Model_1_loss: 0.2500 Model_2_loss: 0.2092 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7588 Model_2_val:0.7580
Epoch: 0160 Model_1_loss: 0.1903 Model_2_loss: 0.2165 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7552 Model_2_val:0.7574
Epoch: 0180 Model_1_loss: 0.1813 Model_2_loss: 0.1597 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7637 Model_2_val:0.7612
Epoch: 0200 Model_1_loss: 0.1690 Model_2_loss: 0.1760 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7644 Model_2_val:0.7614
Epoch: 0220 Model_1_loss: 0.2135 Model_2_loss: 0.2051 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7564 Model_2_val:0.7626
Epoch: 0240 Model_1_loss: 0.1870 Model_2_loss: 0.1819 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7560 Model_2_val:0.7676
Epoch: 0260 Model_1_loss: 0.1731 Model_2_loss: 0.1472 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7674 Model_2_val:0.7586
Epoch: 0280 Model_1_loss: 0.1401 Model_2_loss: 0.1380 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7659 Model_2_val:0.7666
Epoch: 0300 Model_1_loss: 0.1348 Model_2_loss: 0.1322 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7636 Model_2_val:0.7682
Epoch: 0320 Model_1_loss: 0.1076 Model_2_loss: 0.1215 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7680 Model_2_val:0.7596
Epoch: 0340 Model_1_loss: 0.1410 Model_2_loss: 0.1574 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7681 Model_2_val:0.7688
Epoch: 0360 Model_1_loss: 0.0909 Model_2_loss: 0.1767 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7669 Model_2_val:0.7620
Epoch: 0380 Model_1_loss: 0.1241 Model_2_loss: 0.1084 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7720 Model_2_val:0.7671
Epoch: 0400 Model_1_loss: 0.1225 Model_2_loss: 0.1320 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7697 Model_2_val:0.7647
Model_one_test:0.7828 Model_two_test:0.7809
added by two output: 0.7818
8
labels of each class :  [20 20 20]
t= [975 975 975]
717859321
Epoch: 0020 Model_1_loss: 0.9777 Model_2_loss: 1.0346 Model_1_trainacc: 0.7000 Model_2_trainacc: 0.6167 Model_1_val:0.5137 Model_2_val:0.5047
Epoch: 0040 Model_1_loss: 0.7876 Model_2_loss: 0.8237 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8167 Model_1_val:0.5833 Model_2_val:0.6036
Epoch: 0060 Model_1_loss: 0.5710 Model_2_loss: 0.6532 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8167 Model_1_val:0.6467 Model_2_val:0.6266
Epoch: 0080 Model_1_loss: 0.4066 Model_2_loss: 0.4875 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8833 Model_1_val:0.6629 Model_2_val:0.6600
Epoch: 0100 Model_1_loss: 0.3533 Model_2_loss: 0.3956 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.8833 Model_1_val:0.6785 Model_2_val:0.6833
Epoch: 0120 Model_1_loss: 0.2630 Model_2_loss: 0.3033 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6845 Model_2_val:0.6902
Epoch: 0140 Model_1_loss: 0.2177 Model_2_loss: 0.1877 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6976 Model_2_val:0.6996
Epoch: 0160 Model_1_loss: 0.1822 Model_2_loss: 0.2555 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7080 Model_2_val:0.7094
Epoch: 0180 Model_1_loss: 0.2058 Model_2_loss: 0.1927 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7059 Model_2_val:0.7090
Epoch: 0200 Model_1_loss: 0.1453 Model_2_loss: 0.1952 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7060 Model_2_val:0.7156
Epoch: 0220 Model_1_loss: 0.2512 Model_2_loss: 0.2242 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7477 Model_2_val:0.7519
Epoch: 0240 Model_1_loss: 0.1747 Model_2_loss: 0.2059 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7684 Model_2_val:0.7676
Epoch: 0260 Model_1_loss: 0.1971 Model_2_loss: 0.1802 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7679 Model_2_val:0.7705
Epoch: 0280 Model_1_loss: 0.1543 Model_2_loss: 0.1739 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7652 Model_2_val:0.7662
Epoch: 0300 Model_1_loss: 0.1514 Model_2_loss: 0.1913 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7747 Model_2_val:0.7698
Epoch: 0320 Model_1_loss: 0.1839 Model_2_loss: 0.1570 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7789 Model_2_val:0.7718
Epoch: 0340 Model_1_loss: 0.1523 Model_2_loss: 0.1337 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7789 Model_2_val:0.7759
Epoch: 0360 Model_1_loss: 0.1613 Model_2_loss: 0.1755 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7778 Model_2_val:0.7740
Epoch: 0380 Model_1_loss: 0.1545 Model_2_loss: 0.1746 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7763 Model_2_val:0.7819
Epoch: 0400 Model_1_loss: 0.1268 Model_2_loss: 0.1424 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7717 Model_2_val:0.7738
Model_one_test:0.7971 Model_two_test:0.7981
added by two output: 0.7984
9
labels of each class :  [20 20 20]
t= [975 975 975]
779553323
Epoch: 0020 Model_1_loss: 1.0084 Model_2_loss: 0.9874 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7500 Model_1_val:0.5652 Model_2_val:0.5796
Epoch: 0040 Model_1_loss: 0.8254 Model_2_loss: 0.7996 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8500 Model_1_val:0.6591 Model_2_val:0.6679
Epoch: 0060 Model_1_loss: 0.5537 Model_2_loss: 0.5731 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.6973 Model_2_val:0.6957
Epoch: 0080 Model_1_loss: 0.3993 Model_2_loss: 0.3976 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.7139 Model_2_val:0.7072
Epoch: 0100 Model_1_loss: 0.3111 Model_2_loss: 0.3649 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9667 Model_1_val:0.7272 Model_2_val:0.7253
Epoch: 0120 Model_1_loss: 0.2459 Model_2_loss: 0.2362 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7334 Model_2_val:0.7335
Epoch: 0140 Model_1_loss: 0.2324 Model_2_loss: 0.2388 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7326 Model_2_val:0.7334
Epoch: 0160 Model_1_loss: 0.2355 Model_2_loss: 0.1855 Model_1_trainacc: 0.9333 Model_2_trainacc: 1.0000 Model_1_val:0.7367 Model_2_val:0.7379
Epoch: 0180 Model_1_loss: 0.2077 Model_2_loss: 0.1534 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7509 Model_2_val:0.7414
Epoch: 0200 Model_1_loss: 0.1638 Model_2_loss: 0.1781 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7528 Model_2_val:0.7489
Epoch: 0220 Model_1_loss: 0.2134 Model_2_loss: 0.2198 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7530 Model_2_val:0.7489
Epoch: 0240 Model_1_loss: 0.1727 Model_2_loss: 0.1913 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7578 Model_2_val:0.7593
Epoch: 0260 Model_1_loss: 0.1990 Model_2_loss: 0.1673 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7590 Model_2_val:0.7588
Epoch: 0280 Model_1_loss: 0.1391 Model_2_loss: 0.1513 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7633 Model_2_val:0.7566
Epoch: 0300 Model_1_loss: 0.1408 Model_2_loss: 0.1247 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7569 Model_2_val:0.7602
Epoch: 0320 Model_1_loss: 0.1461 Model_2_loss: 0.1601 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7636 Model_2_val:0.7557
Epoch: 0340 Model_1_loss: 0.1534 Model_2_loss: 0.1562 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7623 Model_2_val:0.7615
Epoch: 0360 Model_1_loss: 0.1158 Model_2_loss: 0.1195 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7635 Model_2_val:0.7592
Epoch: 0380 Model_1_loss: 0.1364 Model_2_loss: 0.1182 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7688 Model_2_val:0.7611
Epoch: 0400 Model_1_loss: 0.1237 Model_2_loss: 0.0954 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7633 Model_2_val:0.7655
Model_one_test:0.7802 Model_two_test:0.7857
added by two output: 0.7838
10
labels of each class :  [20 20 20]
t= [975 975 975]
551143558
Epoch: 0020 Model_1_loss: 1.0111 Model_2_loss: 0.9611 Model_1_trainacc: 0.6167 Model_2_trainacc: 0.7500 Model_1_val:0.5125 Model_2_val:0.5997
Epoch: 0040 Model_1_loss: 0.8447 Model_2_loss: 0.7185 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8167 Model_1_val:0.6162 Model_2_val:0.6527
Epoch: 0060 Model_1_loss: 0.6864 Model_2_loss: 0.5061 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8833 Model_1_val:0.6445 Model_2_val:0.6743
Epoch: 0080 Model_1_loss: 0.4681 Model_2_loss: 0.4186 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9000 Model_1_val:0.6703 Model_2_val:0.6970
Epoch: 0100 Model_1_loss: 0.4021 Model_2_loss: 0.3116 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9667 Model_1_val:0.6898 Model_2_val:0.7032
Epoch: 0120 Model_1_loss: 0.3959 Model_2_loss: 0.2362 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9667 Model_1_val:0.6844 Model_2_val:0.7128
Epoch: 0140 Model_1_loss: 0.2990 Model_2_loss: 0.2367 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.6955 Model_2_val:0.7047
Epoch: 0160 Model_1_loss: 0.3031 Model_2_loss: 0.2497 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.6970 Model_2_val:0.7122
Epoch: 0180 Model_1_loss: 0.2856 Model_2_loss: 0.2248 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9833 Model_1_val:0.7019 Model_2_val:0.7227
Epoch: 0200 Model_1_loss: 0.2098 Model_2_loss: 0.2410 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7074 Model_2_val:0.7195
Epoch: 0220 Model_1_loss: 0.2879 Model_2_loss: 0.2490 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.7294 Model_2_val:0.7314
Epoch: 0240 Model_1_loss: 0.2879 Model_2_loss: 0.2294 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.7345 Model_2_val:0.7375
Epoch: 0260 Model_1_loss: 0.2126 Model_2_loss: 0.1975 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7365 Model_2_val:0.7393
Epoch: 0280 Model_1_loss: 0.1839 Model_2_loss: 0.1566 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7327 Model_2_val:0.7388
Epoch: 0300 Model_1_loss: 0.1846 Model_2_loss: 0.1907 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7414 Model_2_val:0.7395
Epoch: 0320 Model_1_loss: 0.2188 Model_2_loss: 0.1513 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7428 Model_2_val:0.7478
Epoch: 0340 Model_1_loss: 0.2178 Model_2_loss: 0.1709 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7451 Model_2_val:0.7374
Epoch: 0360 Model_1_loss: 0.1213 Model_2_loss: 0.1695 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7364 Model_2_val:0.7410
Epoch: 0380 Model_1_loss: 0.1672 Model_2_loss: 0.1465 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7416 Model_2_val:0.7452
Epoch: 0400 Model_1_loss: 0.1421 Model_2_loss: 0.1464 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7385 Model_2_val:0.7414
Model_one_test:0.7622 Model_two_test:0.7597
added by two output: 0.7615
Model1 Acc: 0.774158 Model2 Acc: 0.773786
Maxacc Mean: 0.775341
[0.7724194482998152, 0.784036321393279, 0.7753405892386516]
Maxacc of all experiments: 0.784036321393279
1
labels of each class :  [20 20 20]
t= [975 975 975]
548682782
Epoch: 0020 Model_1_loss: 0.9414 Model_2_loss: 0.9794 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.6833 Model_1_val:0.6142 Model_2_val:0.4217
Epoch: 0040 Model_1_loss: 0.6557 Model_2_loss: 0.7811 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8333 Model_1_val:0.6949 Model_2_val:0.6176
Epoch: 0060 Model_1_loss: 0.4281 Model_2_loss: 0.6132 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8500 Model_1_val:0.7107 Model_2_val:0.6827
Epoch: 0080 Model_1_loss: 0.3466 Model_2_loss: 0.3882 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9333 Model_1_val:0.7284 Model_2_val:0.7142
Epoch: 0100 Model_1_loss: 0.2890 Model_2_loss: 0.3017 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.7416 Model_2_val:0.7286
Epoch: 0120 Model_1_loss: 0.2371 Model_2_loss: 0.2775 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9333 Model_1_val:0.7469 Model_2_val:0.7462
Epoch: 0140 Model_1_loss: 0.2125 Model_2_loss: 0.2437 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7572 Model_2_val:0.7497
Epoch: 0160 Model_1_loss: 0.2209 Model_2_loss: 0.2098 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7599 Model_2_val:0.7595
Epoch: 0180 Model_1_loss: 0.1761 Model_2_loss: 0.1980 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7623 Model_2_val:0.7610
Epoch: 0200 Model_1_loss: 0.1223 Model_2_loss: 0.1787 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7681 Model_2_val:0.7592
Epoch: 0220 Model_1_loss: 0.1995 Model_2_loss: 0.1985 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7539 Model_2_val:0.7495
Epoch: 0240 Model_1_loss: 0.1719 Model_2_loss: 0.1529 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7568 Model_2_val:0.7550
Epoch: 0260 Model_1_loss: 0.1264 Model_2_loss: 0.1698 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7581 Model_2_val:0.7525
Epoch: 0280 Model_1_loss: 0.1196 Model_2_loss: 0.1479 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7529 Model_2_val:0.7521
Epoch: 0300 Model_1_loss: 0.1292 Model_2_loss: 0.1632 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7541 Model_2_val:0.7571
Epoch: 0320 Model_1_loss: 0.1244 Model_2_loss: 0.1481 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7573 Model_2_val:0.7545
Epoch: 0340 Model_1_loss: 0.1026 Model_2_loss: 0.1493 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7540 Model_2_val:0.7511
Epoch: 0360 Model_1_loss: 0.1126 Model_2_loss: 0.1484 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7578 Model_2_val:0.7596
Epoch: 0380 Model_1_loss: 0.0983 Model_2_loss: 0.1477 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7579 Model_2_val:0.7533
Epoch: 0400 Model_1_loss: 0.1235 Model_2_loss: 0.1126 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7653 Model_2_val:0.7555
Model_one_test:0.7746 Model_two_test:0.7650
added by two output: 0.7705
2
labels of each class :  [20 20 20]
t= [975 975 975]
938221214
Epoch: 0020 Model_1_loss: 0.9774 Model_2_loss: 1.0073 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.6833 Model_1_val:0.6560 Model_2_val:0.5446
Epoch: 0040 Model_1_loss: 0.7844 Model_2_loss: 0.8232 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.7500 Model_1_val:0.6788 Model_2_val:0.6170
Epoch: 0060 Model_1_loss: 0.5325 Model_2_loss: 0.5759 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9000 Model_1_val:0.7112 Model_2_val:0.6755
Epoch: 0080 Model_1_loss: 0.4263 Model_2_loss: 0.4794 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8667 Model_1_val:0.7330 Model_2_val:0.6968
Epoch: 0100 Model_1_loss: 0.3513 Model_2_loss: 0.3861 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.7353 Model_2_val:0.7206
Epoch: 0120 Model_1_loss: 0.3135 Model_2_loss: 0.3125 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7551 Model_2_val:0.7348
Epoch: 0140 Model_1_loss: 0.2429 Model_2_loss: 0.2877 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7572 Model_2_val:0.7477
Epoch: 0160 Model_1_loss: 0.2256 Model_2_loss: 0.2381 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7637 Model_2_val:0.7674
Epoch: 0180 Model_1_loss: 0.1786 Model_2_loss: 0.2070 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7685 Model_2_val:0.7629
Epoch: 0200 Model_1_loss: 0.2112 Model_2_loss: 0.1940 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7665 Model_2_val:0.7681
Epoch: 0220 Model_1_loss: 0.2439 Model_2_loss: 0.2234 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7868 Model_2_val:0.7881
Epoch: 0240 Model_1_loss: 0.1972 Model_2_loss: 0.1777 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7845 Model_2_val:0.7809
Epoch: 0260 Model_1_loss: 0.1745 Model_2_loss: 0.1730 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7882 Model_2_val:0.7900
Epoch: 0280 Model_1_loss: 0.1827 Model_2_loss: 0.1592 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7891 Model_2_val:0.7914
Epoch: 0300 Model_1_loss: 0.1671 Model_2_loss: 0.1631 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7849 Model_2_val:0.7872
Epoch: 0320 Model_1_loss: 0.1537 Model_2_loss: 0.1475 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7845 Model_2_val:0.7901
Epoch: 0340 Model_1_loss: 0.1410 Model_2_loss: 0.1357 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7882 Model_2_val:0.7856
Epoch: 0360 Model_1_loss: 0.1462 Model_2_loss: 0.1349 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7849 Model_2_val:0.7874
Epoch: 0380 Model_1_loss: 0.1181 Model_2_loss: 0.1311 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7887 Model_2_val:0.7927
Epoch: 0400 Model_1_loss: 0.1534 Model_2_loss: 0.1277 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7848 Model_2_val:0.7826
Model_one_test:0.8028 Model_two_test:0.8030
added by two output: 0.8032
3
labels of each class :  [20 20 20]
t= [975 975 975]
884908265
Epoch: 0020 Model_1_loss: 0.9938 Model_2_loss: 0.9993 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.6000 Model_1_val:0.5602 Model_2_val:0.5087
Epoch: 0040 Model_1_loss: 0.7844 Model_2_loss: 0.7838 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8000 Model_1_val:0.6333 Model_2_val:0.6340
Epoch: 0060 Model_1_loss: 0.5986 Model_2_loss: 0.5356 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.9000 Model_1_val:0.6625 Model_2_val:0.6806
Epoch: 0080 Model_1_loss: 0.4143 Model_2_loss: 0.3939 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6852 Model_2_val:0.7050
Epoch: 0100 Model_1_loss: 0.3241 Model_2_loss: 0.3237 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6940 Model_2_val:0.7136
Epoch: 0120 Model_1_loss: 0.2825 Model_2_loss: 0.2802 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6979 Model_2_val:0.7227
Epoch: 0140 Model_1_loss: 0.2488 Model_2_loss: 0.2355 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7063 Model_2_val:0.7167
Epoch: 0160 Model_1_loss: 0.2437 Model_2_loss: 0.2174 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7048 Model_2_val:0.7218
Epoch: 0180 Model_1_loss: 0.2103 Model_2_loss: 0.2076 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7075 Model_2_val:0.7305
Epoch: 0200 Model_1_loss: 0.2035 Model_2_loss: 0.1962 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7162 Model_2_val:0.7280
Epoch: 0220 Model_1_loss: 0.2515 Model_2_loss: 0.2456 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7247 Model_2_val:0.7415
Epoch: 0240 Model_1_loss: 0.2238 Model_2_loss: 0.2182 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7333 Model_2_val:0.7649
Epoch: 0260 Model_1_loss: 0.2220 Model_2_loss: 0.1706 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7286 Model_2_val:0.7565
Epoch: 0280 Model_1_loss: 0.1985 Model_2_loss: 0.1594 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7317 Model_2_val:0.7610
Epoch: 0300 Model_1_loss: 0.1783 Model_2_loss: 0.1895 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7382 Model_2_val:0.7561
Epoch: 0320 Model_1_loss: 0.1571 Model_2_loss: 0.1722 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7452 Model_2_val:0.7538
Epoch: 0340 Model_1_loss: 0.1648 Model_2_loss: 0.1157 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7462 Model_2_val:0.7559
Epoch: 0360 Model_1_loss: 0.1580 Model_2_loss: 0.1537 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7571 Model_2_val:0.7585
Epoch: 0380 Model_1_loss: 0.1335 Model_2_loss: 0.1398 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7511 Model_2_val:0.7550
Epoch: 0400 Model_1_loss: 0.1560 Model_2_loss: 0.1403 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7475 Model_2_val:0.7529
Model_one_test:0.7646 Model_two_test:0.7755
added by two output: 0.7695
4
labels of each class :  [20 20 20]
t= [975 975 975]
1311468936
Epoch: 0020 Model_1_loss: 0.9796 Model_2_loss: 1.0022 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.7000 Model_1_val:0.6050 Model_2_val:0.4349
Epoch: 0040 Model_1_loss: 0.7955 Model_2_loss: 0.7992 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8000 Model_1_val:0.6731 Model_2_val:0.6314
Epoch: 0060 Model_1_loss: 0.5235 Model_2_loss: 0.6123 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8833 Model_1_val:0.7118 Model_2_val:0.6750
Epoch: 0080 Model_1_loss: 0.4216 Model_2_loss: 0.4897 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8500 Model_1_val:0.7326 Model_2_val:0.7148
Epoch: 0100 Model_1_loss: 0.3485 Model_2_loss: 0.3262 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7353 Model_2_val:0.7278
Epoch: 0120 Model_1_loss: 0.2587 Model_2_loss: 0.3444 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.7576 Model_2_val:0.7384
Epoch: 0140 Model_1_loss: 0.2376 Model_2_loss: 0.2502 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7505 Model_2_val:0.7511
Epoch: 0160 Model_1_loss: 0.2404 Model_2_loss: 0.2018 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7566 Model_2_val:0.7517
Epoch: 0180 Model_1_loss: 0.2276 Model_2_loss: 0.1977 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7655 Model_2_val:0.7586
Epoch: 0200 Model_1_loss: 0.2030 Model_2_loss: 0.1833 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7673 Model_2_val:0.7628
Epoch: 0220 Model_1_loss: 0.2222 Model_2_loss: 0.2197 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7700 Model_2_val:0.7739
Epoch: 0240 Model_1_loss: 0.1869 Model_2_loss: 0.2124 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7755 Model_2_val:0.7763
Epoch: 0260 Model_1_loss: 0.2018 Model_2_loss: 0.1916 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7764 Model_2_val:0.7827
Epoch: 0280 Model_1_loss: 0.1787 Model_2_loss: 0.1746 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7706 Model_2_val:0.7829
Epoch: 0300 Model_1_loss: 0.1585 Model_2_loss: 0.1713 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7749 Model_2_val:0.7798
Epoch: 0320 Model_1_loss: 0.2175 Model_2_loss: 0.1640 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7787 Model_2_val:0.7844
Epoch: 0340 Model_1_loss: 0.1579 Model_2_loss: 0.1657 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7767 Model_2_val:0.7829
Epoch: 0360 Model_1_loss: 0.1844 Model_2_loss: 0.1665 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7742 Model_2_val:0.7802
Epoch: 0380 Model_1_loss: 0.1508 Model_2_loss: 0.1319 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7755 Model_2_val:0.7784
Epoch: 0400 Model_1_loss: 0.1126 Model_2_loss: 0.1376 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7822 Model_2_val:0.7857
Model_one_test:0.8004 Model_two_test:0.8053
added by two output: 0.8036
5
labels of each class :  [20 20 20]
t= [975 975 975]
1456240202
Epoch: 0020 Model_1_loss: 0.9718 Model_2_loss: 0.9956 Model_1_trainacc: 0.6167 Model_2_trainacc: 0.5833 Model_1_val:0.5093 Model_2_val:0.4315
Epoch: 0040 Model_1_loss: 0.7569 Model_2_loss: 0.8374 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.7833 Model_1_val:0.6597 Model_2_val:0.6291
Epoch: 0060 Model_1_loss: 0.4851 Model_2_loss: 0.5846 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.8833 Model_1_val:0.7114 Model_2_val:0.6879
Epoch: 0080 Model_1_loss: 0.4034 Model_2_loss: 0.4313 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.7301 Model_2_val:0.7311
Epoch: 0100 Model_1_loss: 0.2802 Model_2_loss: 0.3242 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7400 Model_2_val:0.7337
Epoch: 0120 Model_1_loss: 0.2615 Model_2_loss: 0.3117 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7481 Model_2_val:0.7386
Epoch: 0140 Model_1_loss: 0.2387 Model_2_loss: 0.2290 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7463 Model_2_val:0.7486
Epoch: 0160 Model_1_loss: 0.1937 Model_2_loss: 0.2098 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7542 Model_2_val:0.7535
Epoch: 0180 Model_1_loss: 0.1742 Model_2_loss: 0.2054 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7585 Model_2_val:0.7592
Epoch: 0200 Model_1_loss: 0.1794 Model_2_loss: 0.1878 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7570 Model_2_val:0.7585
Epoch: 0220 Model_1_loss: 0.2024 Model_2_loss: 0.2251 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7542 Model_2_val:0.7499
Epoch: 0240 Model_1_loss: 0.1474 Model_2_loss: 0.1700 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7572 Model_2_val:0.7589
Epoch: 0260 Model_1_loss: 0.1873 Model_2_loss: 0.1978 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7599 Model_2_val:0.7578
Epoch: 0280 Model_1_loss: 0.1482 Model_2_loss: 0.1861 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7542 Model_2_val:0.7571
Epoch: 0300 Model_1_loss: 0.1624 Model_2_loss: 0.1915 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7611 Model_2_val:0.7591
Epoch: 0320 Model_1_loss: 0.1735 Model_2_loss: 0.1701 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7551 Model_2_val:0.7596
Epoch: 0340 Model_1_loss: 0.1165 Model_2_loss: 0.1391 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7612 Model_2_val:0.7681
Epoch: 0360 Model_1_loss: 0.1409 Model_2_loss: 0.1240 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7595 Model_2_val:0.7608
Epoch: 0380 Model_1_loss: 0.1190 Model_2_loss: 0.1362 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7626 Model_2_val:0.7581
Epoch: 0400 Model_1_loss: 0.1227 Model_2_loss: 0.1358 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7649 Model_2_val:0.7634
Model_one_test:0.7770 Model_two_test:0.7768
added by two output: 0.7774
6
labels of each class :  [20 20 20]
t= [975 975 975]
416146509
Epoch: 0020 Model_1_loss: 0.9806 Model_2_loss: 0.9927 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.6333 Model_1_val:0.6110 Model_2_val:0.5621
Epoch: 0040 Model_1_loss: 0.7854 Model_2_loss: 0.7188 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8667 Model_1_val:0.6561 Model_2_val:0.6538
Epoch: 0060 Model_1_loss: 0.6027 Model_2_loss: 0.5313 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8500 Model_1_val:0.6892 Model_2_val:0.6899
Epoch: 0080 Model_1_loss: 0.4285 Model_2_loss: 0.3702 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9500 Model_1_val:0.7076 Model_2_val:0.7125
Epoch: 0100 Model_1_loss: 0.3375 Model_2_loss: 0.3128 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.7264 Model_2_val:0.7286
Epoch: 0120 Model_1_loss: 0.3041 Model_2_loss: 0.2870 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7205 Model_2_val:0.7357
Epoch: 0140 Model_1_loss: 0.2445 Model_2_loss: 0.2105 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7277 Model_2_val:0.7378
Epoch: 0160 Model_1_loss: 0.2312 Model_2_loss: 0.1721 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7275 Model_2_val:0.7367
Epoch: 0180 Model_1_loss: 0.1970 Model_2_loss: 0.1643 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7316 Model_2_val:0.7256
Epoch: 0200 Model_1_loss: 0.1666 Model_2_loss: 0.1708 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7338 Model_2_val:0.7376
Epoch: 0220 Model_1_loss: 0.2217 Model_2_loss: 0.1834 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7459 Model_2_val:0.7433
Epoch: 0240 Model_1_loss: 0.2189 Model_2_loss: 0.1669 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7486 Model_2_val:0.7437
Epoch: 0260 Model_1_loss: 0.2109 Model_2_loss: 0.1743 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7412 Model_2_val:0.7450
Epoch: 0280 Model_1_loss: 0.1972 Model_2_loss: 0.1529 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7401 Model_2_val:0.7481
Epoch: 0300 Model_1_loss: 0.1787 Model_2_loss: 0.1783 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7382 Model_2_val:0.7456
Epoch: 0320 Model_1_loss: 0.1434 Model_2_loss: 0.1499 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7431 Model_2_val:0.7450
Epoch: 0340 Model_1_loss: 0.1528 Model_2_loss: 0.1470 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7467 Model_2_val:0.7456
Epoch: 0360 Model_1_loss: 0.1418 Model_2_loss: 0.1230 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7459 Model_2_val:0.7398
Epoch: 0380 Model_1_loss: 0.1637 Model_2_loss: 0.1456 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7421 Model_2_val:0.7491
Epoch: 0400 Model_1_loss: 0.1350 Model_2_loss: 0.1201 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7403 Model_2_val:0.7443
Model_one_test:0.7588 Model_two_test:0.7594
added by two output: 0.7583
7
labels of each class :  [20 20 20]
t= [975 975 975]
1482343247
Epoch: 0020 Model_1_loss: 1.0080 Model_2_loss: 0.9819 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.6833 Model_1_val:0.5498 Model_2_val:0.5485
Epoch: 0040 Model_1_loss: 0.8437 Model_2_loss: 0.8193 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8500 Model_1_val:0.6445 Model_2_val:0.6653
Epoch: 0060 Model_1_loss: 0.6252 Model_2_loss: 0.5862 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9000 Model_1_val:0.6842 Model_2_val:0.7020
Epoch: 0080 Model_1_loss: 0.5041 Model_2_loss: 0.4389 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9167 Model_1_val:0.7154 Model_2_val:0.7247
Epoch: 0100 Model_1_loss: 0.3577 Model_2_loss: 0.3800 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7235 Model_2_val:0.7306
Epoch: 0120 Model_1_loss: 0.2955 Model_2_loss: 0.2642 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9833 Model_1_val:0.7360 Model_2_val:0.7475
Epoch: 0140 Model_1_loss: 0.3159 Model_2_loss: 0.2882 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9833 Model_1_val:0.7405 Model_2_val:0.7470
Epoch: 0160 Model_1_loss: 0.2846 Model_2_loss: 0.2412 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7497 Model_2_val:0.7454
Epoch: 0180 Model_1_loss: 0.2833 Model_2_loss: 0.2260 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.7449 Model_2_val:0.7484
Epoch: 0200 Model_1_loss: 0.2323 Model_2_loss: 0.2272 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7540 Model_2_val:0.7538
Epoch: 0220 Model_1_loss: 0.2529 Model_2_loss: 0.2208 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7465 Model_2_val:0.7483
Epoch: 0240 Model_1_loss: 0.2137 Model_2_loss: 0.1982 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7569 Model_2_val:0.7545
Epoch: 0260 Model_1_loss: 0.1865 Model_2_loss: 0.1809 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7527 Model_2_val:0.7540
Epoch: 0280 Model_1_loss: 0.1864 Model_2_loss: 0.2042 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7517 Model_2_val:0.7585
Epoch: 0300 Model_1_loss: 0.1984 Model_2_loss: 0.1691 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7580 Model_2_val:0.7590
Epoch: 0320 Model_1_loss: 0.1849 Model_2_loss: 0.1779 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7602 Model_2_val:0.7606
Epoch: 0340 Model_1_loss: 0.2143 Model_2_loss: 0.1566 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7539 Model_2_val:0.7585
Epoch: 0360 Model_1_loss: 0.1389 Model_2_loss: 0.1848 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7584 Model_2_val:0.7591
Epoch: 0380 Model_1_loss: 0.1410 Model_2_loss: 0.1371 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7596 Model_2_val:0.7637
Epoch: 0400 Model_1_loss: 0.1488 Model_2_loss: 0.1501 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7646 Model_2_val:0.7593
Model_one_test:0.7776 Model_two_test:0.7765
added by two output: 0.7769
8
labels of each class :  [20 20 20]
t= [975 975 975]
257906542
Epoch: 0020 Model_1_loss: 0.9247 Model_2_loss: 0.9945 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.6333 Model_1_val:0.5938 Model_2_val:0.5180
Epoch: 0040 Model_1_loss: 0.6620 Model_2_loss: 0.7598 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8667 Model_1_val:0.6445 Model_2_val:0.6092
Epoch: 0060 Model_1_loss: 0.4714 Model_2_loss: 0.4856 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9333 Model_1_val:0.6568 Model_2_val:0.6544
Epoch: 0080 Model_1_loss: 0.3711 Model_2_loss: 0.3756 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6883 Model_2_val:0.6755
Epoch: 0100 Model_1_loss: 0.2917 Model_2_loss: 0.2519 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7006 Model_2_val:0.6829
Epoch: 0120 Model_1_loss: 0.2527 Model_2_loss: 0.2247 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6935 Model_2_val:0.7019
Epoch: 0140 Model_1_loss: 0.1991 Model_2_loss: 0.2466 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7001 Model_2_val:0.7048
Epoch: 0160 Model_1_loss: 0.1894 Model_2_loss: 0.2076 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7069 Model_2_val:0.6985
Epoch: 0180 Model_1_loss: 0.1673 Model_2_loss: 0.1503 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7070 Model_2_val:0.7094
Epoch: 0200 Model_1_loss: 0.1662 Model_2_loss: 0.1659 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7113 Model_2_val:0.7116
Epoch: 0220 Model_1_loss: 0.1893 Model_2_loss: 0.1951 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7242 Model_2_val:0.7157
Epoch: 0240 Model_1_loss: 0.1902 Model_2_loss: 0.1549 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7246 Model_2_val:0.7121
Epoch: 0260 Model_1_loss: 0.1665 Model_2_loss: 0.1511 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7254 Model_2_val:0.7231
Epoch: 0280 Model_1_loss: 0.1350 Model_2_loss: 0.1615 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7288 Model_2_val:0.7298
Epoch: 0300 Model_1_loss: 0.1639 Model_2_loss: 0.1447 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7271 Model_2_val:0.7251
Epoch: 0320 Model_1_loss: 0.1774 Model_2_loss: 0.1248 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7239 Model_2_val:0.7201
Epoch: 0340 Model_1_loss: 0.1249 Model_2_loss: 0.1147 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7336 Model_2_val:0.7280
Epoch: 0360 Model_1_loss: 0.1222 Model_2_loss: 0.1085 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7215 Model_2_val:0.7295
Epoch: 0380 Model_1_loss: 0.1088 Model_2_loss: 0.0997 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7275 Model_2_val:0.7216
Epoch: 0400 Model_1_loss: 0.1251 Model_2_loss: 0.1336 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7376 Model_2_val:0.7343
Model_one_test:0.7521 Model_two_test:0.7464
added by two output: 0.7499
9
labels of each class :  [20 20 20]
t= [975 975 975]
793093475
Epoch: 0020 Model_1_loss: 1.0152 Model_2_loss: 1.0007 Model_1_trainacc: 0.6333 Model_2_trainacc: 0.6333 Model_1_val:0.5249 Model_2_val:0.5031
Epoch: 0040 Model_1_loss: 0.8160 Model_2_loss: 0.7947 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8333 Model_1_val:0.6232 Model_2_val:0.6085
Epoch: 0060 Model_1_loss: 0.5823 Model_2_loss: 0.5809 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9000 Model_1_val:0.6653 Model_2_val:0.6709
Epoch: 0080 Model_1_loss: 0.4910 Model_2_loss: 0.4132 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6979 Model_2_val:0.7064
Epoch: 0100 Model_1_loss: 0.3031 Model_2_loss: 0.3285 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7105 Model_2_val:0.7257
Epoch: 0120 Model_1_loss: 0.2838 Model_2_loss: 0.2860 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7337 Model_2_val:0.7298
Epoch: 0140 Model_1_loss: 0.2706 Model_2_loss: 0.2295 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7472 Model_2_val:0.7325
Epoch: 0160 Model_1_loss: 0.2445 Model_2_loss: 0.2068 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7437 Model_2_val:0.7449
Epoch: 0180 Model_1_loss: 0.2069 Model_2_loss: 0.2120 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7424 Model_2_val:0.7497
Epoch: 0200 Model_1_loss: 0.1701 Model_2_loss: 0.1741 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7428 Model_2_val:0.7457
Epoch: 0220 Model_1_loss: 0.1970 Model_2_loss: 0.1982 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7516 Model_2_val:0.7591
Epoch: 0240 Model_1_loss: 0.1692 Model_2_loss: 0.1967 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7568 Model_2_val:0.7551
Epoch: 0260 Model_1_loss: 0.1594 Model_2_loss: 0.1673 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7669 Model_2_val:0.7685
Epoch: 0280 Model_1_loss: 0.1759 Model_2_loss: 0.1484 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7595 Model_2_val:0.7635
Epoch: 0300 Model_1_loss: 0.1453 Model_2_loss: 0.1829 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7631 Model_2_val:0.7665
Epoch: 0320 Model_1_loss: 0.1579 Model_2_loss: 0.1443 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7614 Model_2_val:0.7632
Epoch: 0340 Model_1_loss: 0.1410 Model_2_loss: 0.1245 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7577 Model_2_val:0.7600
Epoch: 0360 Model_1_loss: 0.1412 Model_2_loss: 0.1274 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7594 Model_2_val:0.7594
Epoch: 0380 Model_1_loss: 0.1435 Model_2_loss: 0.1258 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7584 Model_2_val:0.7663
Epoch: 0400 Model_1_loss: 0.1088 Model_2_loss: 0.1564 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7593 Model_2_val:0.7571
Model_one_test:0.7746 Model_two_test:0.7765
added by two output: 0.7752
10
labels of each class :  [20 20 20]
t= [975 975 975]
407625481
Epoch: 0020 Model_1_loss: 1.0364 Model_2_loss: 1.0252 Model_1_trainacc: 0.5667 Model_2_trainacc: 0.6500 Model_1_val:0.4646 Model_2_val:0.5305
Epoch: 0040 Model_1_loss: 0.9225 Model_2_loss: 0.8900 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.6667 Model_1_val:0.6179 Model_2_val:0.5596
Epoch: 0060 Model_1_loss: 0.7147 Model_2_loss: 0.6542 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8667 Model_1_val:0.6595 Model_2_val:0.6473
Epoch: 0080 Model_1_loss: 0.5173 Model_2_loss: 0.4927 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9333 Model_1_val:0.6937 Model_2_val:0.6931
Epoch: 0100 Model_1_loss: 0.4262 Model_2_loss: 0.3742 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7293 Model_2_val:0.7137
Epoch: 0120 Model_1_loss: 0.3755 Model_2_loss: 0.3611 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.7327 Model_2_val:0.7314
Epoch: 0140 Model_1_loss: 0.3305 Model_2_loss: 0.2761 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7302 Model_2_val:0.7331
Epoch: 0160 Model_1_loss: 0.2457 Model_2_loss: 0.2420 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7451 Model_2_val:0.7446
Epoch: 0180 Model_1_loss: 0.2783 Model_2_loss: 0.2056 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7484 Model_2_val:0.7449
Epoch: 0200 Model_1_loss: 0.3549 Model_2_loss: 0.1865 Model_1_trainacc: 0.9500 Model_2_trainacc: 1.0000 Model_1_val:0.7345 Model_2_val:0.7497
Epoch: 0220 Model_1_loss: 0.2553 Model_2_loss: 0.2079 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7583 Model_2_val:0.7554
Epoch: 0240 Model_1_loss: 0.2370 Model_2_loss: 0.2297 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7560 Model_2_val:0.7624
Epoch: 0260 Model_1_loss: 0.1924 Model_2_loss: 0.1923 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7639 Model_2_val:0.7698
Epoch: 0280 Model_1_loss: 0.1943 Model_2_loss: 0.2055 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7671 Model_2_val:0.7724
Epoch: 0300 Model_1_loss: 0.1765 Model_2_loss: 0.1853 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7646 Model_2_val:0.7688
Epoch: 0320 Model_1_loss: 0.1956 Model_2_loss: 0.1762 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7716 Model_2_val:0.7688
Epoch: 0340 Model_1_loss: 0.1835 Model_2_loss: 0.1671 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7650 Model_2_val:0.7694
Epoch: 0360 Model_1_loss: 0.1584 Model_2_loss: 0.1818 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7664 Model_2_val:0.7674
Epoch: 0380 Model_1_loss: 0.1922 Model_2_loss: 0.1675 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7626 Model_2_val:0.7727
Epoch: 0400 Model_1_loss: 0.1627 Model_2_loss: 0.1822 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7724 Model_2_val:0.7682
Model_one_test:0.7889 Model_two_test:0.7872
added by two output: 0.7883
Model1 Acc: 0.777143 Model2 Acc: 0.777158
Maxacc Mean: 0.778986
[0.7724194482998152, 0.784036321393279, 0.7753405892386516, 0.7789860521055665]
Maxacc of all experiments: 0.784036321393279
1
labels of each class :  [20 20 20]
t= [975 975 975]
1502753003
Epoch: 0020 Model_1_loss: 0.9543 Model_2_loss: 1.0124 Model_1_trainacc: 0.7000 Model_2_trainacc: 0.4000 Model_1_val:0.5052 Model_2_val:0.4386
Epoch: 0040 Model_1_loss: 0.7375 Model_2_loss: 0.8154 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.7833 Model_1_val:0.6357 Model_2_val:0.5839
Epoch: 0060 Model_1_loss: 0.5342 Model_2_loss: 0.6378 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8167 Model_1_val:0.6830 Model_2_val:0.6556
Epoch: 0080 Model_1_loss: 0.4060 Model_2_loss: 0.4906 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9000 Model_1_val:0.7035 Model_2_val:0.6769
Epoch: 0100 Model_1_loss: 0.3397 Model_2_loss: 0.3772 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.7077 Model_2_val:0.6960
Epoch: 0120 Model_1_loss: 0.3184 Model_2_loss: 0.3462 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9000 Model_1_val:0.7182 Model_2_val:0.7160
Epoch: 0140 Model_1_loss: 0.2391 Model_2_loss: 0.2980 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.8667 Model_1_val:0.7191 Model_2_val:0.7224
Epoch: 0160 Model_1_loss: 0.2525 Model_2_loss: 0.2858 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.7279 Model_2_val:0.7188
Epoch: 0180 Model_1_loss: 0.2007 Model_2_loss: 0.2475 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7210 Model_2_val:0.7254
Epoch: 0200 Model_1_loss: 0.1912 Model_2_loss: 0.2228 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7192 Model_2_val:0.7176
Epoch: 0220 Model_1_loss: 0.2598 Model_2_loss: 0.2549 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.7279 Model_2_val:0.7191
Epoch: 0240 Model_1_loss: 0.2338 Model_2_loss: 0.2095 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7359 Model_2_val:0.7281
Epoch: 0260 Model_1_loss: 0.2046 Model_2_loss: 0.2699 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7378 Model_2_val:0.7321
Epoch: 0280 Model_1_loss: 0.2045 Model_2_loss: 0.2669 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7382 Model_2_val:0.7376
Epoch: 0300 Model_1_loss: 0.1819 Model_2_loss: 0.2236 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7320 Model_2_val:0.7366
Epoch: 0320 Model_1_loss: 0.2089 Model_2_loss: 0.2118 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7390 Model_2_val:0.7308
Epoch: 0340 Model_1_loss: 0.1758 Model_2_loss: 0.1898 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7447 Model_2_val:0.7340
Epoch: 0360 Model_1_loss: 0.2011 Model_2_loss: 0.1849 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7366 Model_2_val:0.7331
Epoch: 0380 Model_1_loss: 0.1619 Model_2_loss: 0.1916 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7390 Model_2_val:0.7368
Epoch: 0400 Model_1_loss: 0.1539 Model_2_loss: 0.2162 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7376 Model_2_val:0.7376
Model_one_test:0.7487 Model_two_test:0.7477
added by two output: 0.7480
2
labels of each class :  [20 20 20]
t= [975 975 975]
450145579
Epoch: 0020 Model_1_loss: 1.0233 Model_2_loss: 1.0360 Model_1_trainacc: 0.5500 Model_2_trainacc: 0.4667 Model_1_val:0.4960 Model_2_val:0.4738
Epoch: 0040 Model_1_loss: 0.8382 Model_2_loss: 0.8143 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.7500 Model_1_val:0.6625 Model_2_val:0.6444
Epoch: 0060 Model_1_loss: 0.6239 Model_2_loss: 0.5611 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8333 Model_1_val:0.7093 Model_2_val:0.7038
Epoch: 0080 Model_1_loss: 0.3923 Model_2_loss: 0.4264 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.8667 Model_1_val:0.7258 Model_2_val:0.7280
Epoch: 0100 Model_1_loss: 0.3141 Model_2_loss: 0.3195 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7389 Model_2_val:0.7392
Epoch: 0120 Model_1_loss: 0.2603 Model_2_loss: 0.2315 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7378 Model_2_val:0.7489
Epoch: 0140 Model_1_loss: 0.2414 Model_2_loss: 0.2971 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7356 Model_2_val:0.7464
Epoch: 0160 Model_1_loss: 0.2363 Model_2_loss: 0.2521 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7399 Model_2_val:0.7519
Epoch: 0180 Model_1_loss: 0.2366 Model_2_loss: 0.1786 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7438 Model_2_val:0.7514
Epoch: 0200 Model_1_loss: 0.1828 Model_2_loss: 0.2158 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7476 Model_2_val:0.7571
Epoch: 0220 Model_1_loss: 0.2287 Model_2_loss: 0.2409 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7548 Model_2_val:0.7670
Epoch: 0240 Model_1_loss: 0.2049 Model_2_loss: 0.2036 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7639 Model_2_val:0.7708
Epoch: 0260 Model_1_loss: 0.1900 Model_2_loss: 0.2025 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7717 Model_2_val:0.7665
Epoch: 0280 Model_1_loss: 0.1808 Model_2_loss: 0.1975 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7743 Model_2_val:0.7727
Epoch: 0300 Model_1_loss: 0.1467 Model_2_loss: 0.1707 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7689 Model_2_val:0.7727
Epoch: 0320 Model_1_loss: 0.1471 Model_2_loss: 0.1735 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7709 Model_2_val:0.7701
Epoch: 0340 Model_1_loss: 0.1855 Model_2_loss: 0.1789 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7751 Model_2_val:0.7756
Epoch: 0360 Model_1_loss: 0.1563 Model_2_loss: 0.1662 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7719 Model_2_val:0.7749
Epoch: 0380 Model_1_loss: 0.1416 Model_2_loss: 0.1497 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7753 Model_2_val:0.7775
Epoch: 0400 Model_1_loss: 0.1577 Model_2_loss: 0.1561 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7816 Model_2_val:0.7750
Model_one_test:0.7927 Model_two_test:0.7925
added by two output: 0.7929
3
labels of each class :  [20 20 20]
t= [975 975 975]
1404979660
Epoch: 0020 Model_1_loss: 1.0065 Model_2_loss: 0.9841 Model_1_trainacc: 0.4833 Model_2_trainacc: 0.6000 Model_1_val:0.4063 Model_2_val:0.5062
Epoch: 0040 Model_1_loss: 0.7434 Model_2_loss: 0.7277 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9000 Model_1_val:0.6208 Model_2_val:0.6308
Epoch: 0060 Model_1_loss: 0.4446 Model_2_loss: 0.5053 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.6873 Model_2_val:0.6807
Epoch: 0080 Model_1_loss: 0.3717 Model_2_loss: 0.3552 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.7173 Model_2_val:0.7108
Epoch: 0100 Model_1_loss: 0.2890 Model_2_loss: 0.2676 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7347 Model_2_val:0.7301
Epoch: 0120 Model_1_loss: 0.2280 Model_2_loss: 0.2250 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7443 Model_2_val:0.7381
Epoch: 0140 Model_1_loss: 0.1931 Model_2_loss: 0.2243 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7450 Model_2_val:0.7480
Epoch: 0160 Model_1_loss: 0.1636 Model_2_loss: 0.1738 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7483 Model_2_val:0.7455
Epoch: 0180 Model_1_loss: 0.1096 Model_2_loss: 0.1506 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7529 Model_2_val:0.7496
Epoch: 0200 Model_1_loss: 0.1448 Model_2_loss: 0.1423 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7598 Model_2_val:0.7445
Epoch: 0220 Model_1_loss: 0.1571 Model_2_loss: 0.1761 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7662 Model_2_val:0.7584
Epoch: 0240 Model_1_loss: 0.1781 Model_2_loss: 0.1838 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7632 Model_2_val:0.7598
Epoch: 0260 Model_1_loss: 0.1371 Model_2_loss: 0.1719 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7650 Model_2_val:0.7625
Epoch: 0280 Model_1_loss: 0.1804 Model_2_loss: 0.1511 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7637 Model_2_val:0.7635
Epoch: 0300 Model_1_loss: 0.1354 Model_2_loss: 0.1538 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7633 Model_2_val:0.7615
Epoch: 0320 Model_1_loss: 0.1211 Model_2_loss: 0.1405 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7640 Model_2_val:0.7612
Epoch: 0340 Model_1_loss: 0.1219 Model_2_loss: 0.1473 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7666 Model_2_val:0.7595
Epoch: 0360 Model_1_loss: 0.1157 Model_2_loss: 0.1232 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7659 Model_2_val:0.7656
Epoch: 0380 Model_1_loss: 0.1054 Model_2_loss: 0.1223 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7736 Model_2_val:0.7624
Epoch: 0400 Model_1_loss: 0.0985 Model_2_loss: 0.1211 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7619 Model_2_val:0.7605
Model_one_test:0.7794 Model_two_test:0.7782
added by two output: 0.7778
4
labels of each class :  [20 20 20]
t= [975 975 975]
381345758
Epoch: 0020 Model_1_loss: 1.0281 Model_2_loss: 0.9529 Model_1_trainacc: 0.5333 Model_2_trainacc: 0.6833 Model_1_val:0.4840 Model_2_val:0.5523
Epoch: 0040 Model_1_loss: 0.8457 Model_2_loss: 0.7915 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.8167 Model_1_val:0.6211 Model_2_val:0.6570
Epoch: 0060 Model_1_loss: 0.6603 Model_2_loss: 0.5852 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8500 Model_1_val:0.6747 Model_2_val:0.6993
Epoch: 0080 Model_1_loss: 0.5209 Model_2_loss: 0.4239 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9167 Model_1_val:0.6857 Model_2_val:0.7126
Epoch: 0100 Model_1_loss: 0.4139 Model_2_loss: 0.3591 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9167 Model_1_val:0.7101 Model_2_val:0.7278
Epoch: 0120 Model_1_loss: 0.3411 Model_2_loss: 0.3186 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.7231 Model_2_val:0.7269
Epoch: 0140 Model_1_loss: 0.3105 Model_2_loss: 0.2650 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7257 Model_2_val:0.7233
Epoch: 0160 Model_1_loss: 0.2590 Model_2_loss: 0.2416 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7224 Model_2_val:0.7340
Epoch: 0180 Model_1_loss: 0.2710 Model_2_loss: 0.2192 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7239 Model_2_val:0.7325
Epoch: 0200 Model_1_loss: 0.2712 Model_2_loss: 0.1787 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7297 Model_2_val:0.7262
Epoch: 0220 Model_1_loss: 0.2882 Model_2_loss: 0.2627 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.7407 Model_2_val:0.7474
Epoch: 0240 Model_1_loss: 0.2646 Model_2_loss: 0.2312 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7487 Model_2_val:0.7537
Epoch: 0260 Model_1_loss: 0.2438 Model_2_loss: 0.1776 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7528 Model_2_val:0.7554
Epoch: 0280 Model_1_loss: 0.2290 Model_2_loss: 0.2005 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7558 Model_2_val:0.7567
Epoch: 0300 Model_1_loss: 0.1987 Model_2_loss: 0.1816 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7568 Model_2_val:0.7671
Epoch: 0320 Model_1_loss: 0.1704 Model_2_loss: 0.1579 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7601 Model_2_val:0.7567
Epoch: 0340 Model_1_loss: 0.1985 Model_2_loss: 0.1764 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7652 Model_2_val:0.7603
Epoch: 0360 Model_1_loss: 0.1645 Model_2_loss: 0.1655 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7595 Model_2_val:0.7652
Epoch: 0380 Model_1_loss: 0.1636 Model_2_loss: 0.1803 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7580 Model_2_val:0.7608
Epoch: 0400 Model_1_loss: 0.1457 Model_2_loss: 0.1452 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7646 Model_2_val:0.7632
Model_one_test:0.7844 Model_two_test:0.7841
added by two output: 0.7845
5
labels of each class :  [20 20 20]
t= [975 975 975]
1299617265
Epoch: 0020 Model_1_loss: 0.9972 Model_2_loss: 1.0252 Model_1_trainacc: 0.6500 Model_2_trainacc: 0.6333 Model_1_val:0.5202 Model_2_val:0.5148
Epoch: 0040 Model_1_loss: 0.8153 Model_2_loss: 0.8329 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8167 Model_1_val:0.6349 Model_2_val:0.6118
Epoch: 0060 Model_1_loss: 0.5638 Model_2_loss: 0.6575 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8500 Model_1_val:0.6752 Model_2_val:0.6709
Epoch: 0080 Model_1_loss: 0.4127 Model_2_loss: 0.4399 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7063 Model_2_val:0.7030
Epoch: 0100 Model_1_loss: 0.3431 Model_2_loss: 0.4220 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.7175 Model_2_val:0.7203
Epoch: 0120 Model_1_loss: 0.2634 Model_2_loss: 0.2971 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7305 Model_2_val:0.7263
Epoch: 0140 Model_1_loss: 0.2456 Model_2_loss: 0.2446 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7293 Model_2_val:0.7332
Epoch: 0160 Model_1_loss: 0.2362 Model_2_loss: 0.2079 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7328 Model_2_val:0.7372
Epoch: 0180 Model_1_loss: 0.2177 Model_2_loss: 0.1760 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7410 Model_2_val:0.7364
Epoch: 0200 Model_1_loss: 0.1717 Model_2_loss: 0.1538 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7458 Model_2_val:0.7422
Epoch: 0220 Model_1_loss: 0.1990 Model_2_loss: 0.2381 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7478 Model_2_val:0.7492
Epoch: 0240 Model_1_loss: 0.1913 Model_2_loss: 0.1864 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7629 Model_2_val:0.7542
Epoch: 0260 Model_1_loss: 0.1937 Model_2_loss: 0.1676 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7590 Model_2_val:0.7562
Epoch: 0280 Model_1_loss: 0.1864 Model_2_loss: 0.2003 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7592 Model_2_val:0.7584
Epoch: 0300 Model_1_loss: 0.1528 Model_2_loss: 0.1430 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7658 Model_2_val:0.7670
Epoch: 0320 Model_1_loss: 0.1470 Model_2_loss: 0.1530 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7673 Model_2_val:0.7638
Epoch: 0340 Model_1_loss: 0.1738 Model_2_loss: 0.1511 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7625 Model_2_val:0.7631
Epoch: 0360 Model_1_loss: 0.1341 Model_2_loss: 0.1504 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7631 Model_2_val:0.7652
Epoch: 0380 Model_1_loss: 0.1219 Model_2_loss: 0.1407 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7640 Model_2_val:0.7638
Epoch: 0400 Model_1_loss: 0.1570 Model_2_loss: 0.1292 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7659 Model_2_val:0.7632
Model_one_test:0.7807 Model_two_test:0.7794
added by two output: 0.7804
6
labels of each class :  [20 20 20]
t= [975 975 975]
423594539
Epoch: 0020 Model_1_loss: 0.9977 Model_2_loss: 1.0027 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.6167 Model_1_val:0.6132 Model_2_val:0.4934
Epoch: 0040 Model_1_loss: 0.7284 Model_2_loss: 0.7939 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8333 Model_1_val:0.6767 Model_2_val:0.6507
Epoch: 0060 Model_1_loss: 0.4924 Model_2_loss: 0.5808 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8833 Model_1_val:0.7051 Model_2_val:0.6932
Epoch: 0080 Model_1_loss: 0.3796 Model_2_loss: 0.4144 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9667 Model_1_val:0.7235 Model_2_val:0.7142
Epoch: 0100 Model_1_loss: 0.2698 Model_2_loss: 0.3354 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9333 Model_1_val:0.7268 Model_2_val:0.7208
Epoch: 0120 Model_1_loss: 0.2629 Model_2_loss: 0.2692 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7320 Model_2_val:0.7154
Epoch: 0140 Model_1_loss: 0.1948 Model_2_loss: 0.2568 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7280 Model_2_val:0.7277
Epoch: 0160 Model_1_loss: 0.1870 Model_2_loss: 0.2163 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7332 Model_2_val:0.7297
Epoch: 0180 Model_1_loss: 0.1841 Model_2_loss: 0.1802 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7328 Model_2_val:0.7326
Epoch: 0200 Model_1_loss: 0.1944 Model_2_loss: 0.1645 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7367 Model_2_val:0.7341
Epoch: 0220 Model_1_loss: 0.2096 Model_2_loss: 0.2284 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7355 Model_2_val:0.7458
Epoch: 0240 Model_1_loss: 0.1690 Model_2_loss: 0.1940 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7430 Model_2_val:0.7464
Epoch: 0260 Model_1_loss: 0.1661 Model_2_loss: 0.1638 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7383 Model_2_val:0.7454
Epoch: 0280 Model_1_loss: 0.1256 Model_2_loss: 0.1717 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7448 Model_2_val:0.7474
Epoch: 0300 Model_1_loss: 0.1600 Model_2_loss: 0.1752 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7418 Model_2_val:0.7448
Epoch: 0320 Model_1_loss: 0.1386 Model_2_loss: 0.1656 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7400 Model_2_val:0.7503
Epoch: 0340 Model_1_loss: 0.1436 Model_2_loss: 0.1286 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7433 Model_2_val:0.7511
Epoch: 0360 Model_1_loss: 0.1633 Model_2_loss: 0.1533 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7472 Model_2_val:0.7420
Epoch: 0380 Model_1_loss: 0.1424 Model_2_loss: 0.1302 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7478 Model_2_val:0.7480
Epoch: 0400 Model_1_loss: 0.1163 Model_2_loss: 0.1108 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7415 Model_2_val:0.7479
Model_one_test:0.7646 Model_two_test:0.7684
added by two output: 0.7673
7
labels of each class :  [20 20 20]
t= [975 975 975]
60912022
Epoch: 0020 Model_1_loss: 0.9950 Model_2_loss: 0.9832 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.7500 Model_1_val:0.5568 Model_2_val:0.6098
Epoch: 0040 Model_1_loss: 0.7338 Model_2_loss: 0.7269 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9000 Model_1_val:0.6952 Model_2_val:0.6574
Epoch: 0060 Model_1_loss: 0.4815 Model_2_loss: 0.5234 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9333 Model_1_val:0.7104 Model_2_val:0.6931
Epoch: 0080 Model_1_loss: 0.3811 Model_2_loss: 0.3887 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.7256 Model_2_val:0.7236
Epoch: 0100 Model_1_loss: 0.3191 Model_2_loss: 0.3175 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.7265 Model_2_val:0.7233
Epoch: 0120 Model_1_loss: 0.2722 Model_2_loss: 0.2677 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7305 Model_2_val:0.7217
Epoch: 0140 Model_1_loss: 0.2300 Model_2_loss: 0.2106 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7360 Model_2_val:0.7324
Epoch: 0160 Model_1_loss: 0.2181 Model_2_loss: 0.1823 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7364 Model_2_val:0.7392
Epoch: 0180 Model_1_loss: 0.1715 Model_2_loss: 0.1907 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7361 Model_2_val:0.7297
Epoch: 0200 Model_1_loss: 0.1473 Model_2_loss: 0.1535 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7319 Model_2_val:0.7401
Epoch: 0220 Model_1_loss: 0.2023 Model_2_loss: 0.2129 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7573 Model_2_val:0.7638
Epoch: 0240 Model_1_loss: 0.1743 Model_2_loss: 0.1875 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7723 Model_2_val:0.7645
Epoch: 0260 Model_1_loss: 0.1772 Model_2_loss: 0.1827 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7626 Model_2_val:0.7606
Epoch: 0280 Model_1_loss: 0.1518 Model_2_loss: 0.1735 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7695 Model_2_val:0.7624
Epoch: 0300 Model_1_loss: 0.1480 Model_2_loss: 0.1486 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7644 Model_2_val:0.7651
Epoch: 0320 Model_1_loss: 0.1359 Model_2_loss: 0.1947 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7656 Model_2_val:0.7610
Epoch: 0340 Model_1_loss: 0.1231 Model_2_loss: 0.1564 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7566 Model_2_val:0.7578
Epoch: 0360 Model_1_loss: 0.1751 Model_2_loss: 0.1044 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7641 Model_2_val:0.7588
Epoch: 0380 Model_1_loss: 0.1453 Model_2_loss: 0.1117 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7599 Model_2_val:0.7639
Epoch: 0400 Model_1_loss: 0.1176 Model_2_loss: 0.1186 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7628 Model_2_val:0.7619
Model_one_test:0.7755 Model_two_test:0.7801
added by two output: 0.7790
8
labels of each class :  [20 20 20]
t= [975 975 975]
635953051
Epoch: 0020 Model_1_loss: 1.0406 Model_2_loss: 1.0071 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.6500 Model_1_val:0.4917 Model_2_val:0.5243
Epoch: 0040 Model_1_loss: 0.8774 Model_2_loss: 0.8202 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8167 Model_1_val:0.6161 Model_2_val:0.6723
Epoch: 0060 Model_1_loss: 0.6402 Model_2_loss: 0.5234 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9167 Model_1_val:0.6965 Model_2_val:0.7129
Epoch: 0080 Model_1_loss: 0.3822 Model_2_loss: 0.3466 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.7254 Model_2_val:0.7388
Epoch: 0100 Model_1_loss: 0.3534 Model_2_loss: 0.2919 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9833 Model_1_val:0.7528 Model_2_val:0.7549
Epoch: 0120 Model_1_loss: 0.2729 Model_2_loss: 0.2449 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7631 Model_2_val:0.7582
Epoch: 0140 Model_1_loss: 0.2246 Model_2_loss: 0.2309 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7510 Model_2_val:0.7739
Epoch: 0160 Model_1_loss: 0.2010 Model_2_loss: 0.1743 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7717 Model_2_val:0.7611
Epoch: 0180 Model_1_loss: 0.1742 Model_2_loss: 0.1687 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7720 Model_2_val:0.7669
Epoch: 0200 Model_1_loss: 0.1553 Model_2_loss: 0.2177 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7675 Model_2_val:0.7815
Epoch: 0220 Model_1_loss: 0.2066 Model_2_loss: 0.2134 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7891 Model_2_val:0.7890
Epoch: 0240 Model_1_loss: 0.1518 Model_2_loss: 0.1541 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7882 Model_2_val:0.7866
Epoch: 0260 Model_1_loss: 0.1723 Model_2_loss: 0.1596 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7918 Model_2_val:0.7824
Epoch: 0280 Model_1_loss: 0.1645 Model_2_loss: 0.1668 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7957 Model_2_val:0.7856
Epoch: 0300 Model_1_loss: 0.1657 Model_2_loss: 0.1185 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7899 Model_2_val:0.7860
Epoch: 0320 Model_1_loss: 0.1246 Model_2_loss: 0.1603 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7942 Model_2_val:0.7889
Epoch: 0340 Model_1_loss: 0.1301 Model_2_loss: 0.1308 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7971 Model_2_val:0.7935
Epoch: 0360 Model_1_loss: 0.1262 Model_2_loss: 0.1084 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7920 Model_2_val:0.7935
Epoch: 0380 Model_1_loss: 0.1474 Model_2_loss: 0.1492 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7897 Model_2_val:0.7876
Epoch: 0400 Model_1_loss: 0.1280 Model_2_loss: 0.1462 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7931 Model_2_val:0.7948
Model_one_test:0.8080 Model_two_test:0.8049
added by two output: 0.8050
9
labels of each class :  [20 20 20]
t= [975 975 975]
1283575278
Epoch: 0020 Model_1_loss: 1.0371 Model_2_loss: 1.0072 Model_1_trainacc: 0.5167 Model_2_trainacc: 0.6167 Model_1_val:0.4408 Model_2_val:0.5124
Epoch: 0040 Model_1_loss: 0.9103 Model_2_loss: 0.8360 Model_1_trainacc: 0.6333 Model_2_trainacc: 0.8167 Model_1_val:0.5703 Model_2_val:0.6374
Epoch: 0060 Model_1_loss: 0.6673 Model_2_loss: 0.6287 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8833 Model_1_val:0.6735 Model_2_val:0.6830
Epoch: 0080 Model_1_loss: 0.5245 Model_2_loss: 0.5606 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8500 Model_1_val:0.6899 Model_2_val:0.7012
Epoch: 0100 Model_1_loss: 0.3946 Model_2_loss: 0.3819 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9500 Model_1_val:0.7111 Model_2_val:0.7053
Epoch: 0120 Model_1_loss: 0.3735 Model_2_loss: 0.3337 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9833 Model_1_val:0.7084 Model_2_val:0.7148
Epoch: 0140 Model_1_loss: 0.3100 Model_2_loss: 0.2853 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.7246 Model_2_val:0.7126
Epoch: 0160 Model_1_loss: 0.2910 Model_2_loss: 0.2227 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7130 Model_2_val:0.7168
Epoch: 0180 Model_1_loss: 0.2740 Model_2_loss: 0.2422 Model_1_trainacc: 0.9333 Model_2_trainacc: 1.0000 Model_1_val:0.7279 Model_2_val:0.7161
Epoch: 0200 Model_1_loss: 0.2230 Model_2_loss: 0.2017 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7138 Model_2_val:0.7219
Epoch: 0220 Model_1_loss: 0.2625 Model_2_loss: 0.2572 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7561 Model_2_val:0.7545
Epoch: 0240 Model_1_loss: 0.2280 Model_2_loss: 0.1880 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7552 Model_2_val:0.7530
Epoch: 0260 Model_1_loss: 0.2261 Model_2_loss: 0.2055 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7474 Model_2_val:0.7450
Epoch: 0280 Model_1_loss: 0.2173 Model_2_loss: 0.2164 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7535 Model_2_val:0.7480
Epoch: 0300 Model_1_loss: 0.2070 Model_2_loss: 0.2000 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7470 Model_2_val:0.7415
Epoch: 0320 Model_1_loss: 0.1874 Model_2_loss: 0.1876 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7405 Model_2_val:0.7426
Epoch: 0340 Model_1_loss: 0.1917 Model_2_loss: 0.1687 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7420 Model_2_val:0.7373
Epoch: 0360 Model_1_loss: 0.1534 Model_2_loss: 0.1733 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7438 Model_2_val:0.7420
Epoch: 0380 Model_1_loss: 0.1667 Model_2_loss: 0.1544 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7460 Model_2_val:0.7422
Epoch: 0400 Model_1_loss: 0.1467 Model_2_loss: 0.1631 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7457 Model_2_val:0.7388
Model_one_test:0.7669 Model_two_test:0.7635
added by two output: 0.7653
10
labels of each class :  [20 20 20]
t= [975 975 975]
1289228690
Epoch: 0020 Model_1_loss: 1.0438 Model_2_loss: 0.9707 Model_1_trainacc: 0.5000 Model_2_trainacc: 0.6500 Model_1_val:0.4969 Model_2_val:0.5353
Epoch: 0040 Model_1_loss: 0.8862 Model_2_loss: 0.8206 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7000 Model_1_val:0.6551 Model_2_val:0.6373
Epoch: 0060 Model_1_loss: 0.6360 Model_2_loss: 0.6337 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8667 Model_1_val:0.7031 Model_2_val:0.6787
Epoch: 0080 Model_1_loss: 0.4905 Model_2_loss: 0.4672 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9500 Model_1_val:0.7228 Model_2_val:0.7026
Epoch: 0100 Model_1_loss: 0.3452 Model_2_loss: 0.4006 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9333 Model_1_val:0.7312 Model_2_val:0.7135
Epoch: 0120 Model_1_loss: 0.3237 Model_2_loss: 0.3189 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9333 Model_1_val:0.7332 Model_2_val:0.7190
Epoch: 0140 Model_1_loss: 0.2654 Model_2_loss: 0.3151 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.7346 Model_2_val:0.7251
Epoch: 0160 Model_1_loss: 0.2840 Model_2_loss: 0.2421 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7390 Model_2_val:0.7273
Epoch: 0180 Model_1_loss: 0.2273 Model_2_loss: 0.2183 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7321 Model_2_val:0.7261
Epoch: 0200 Model_1_loss: 0.1939 Model_2_loss: 0.2228 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7335 Model_2_val:0.7271
Epoch: 0220 Model_1_loss: 0.3062 Model_2_loss: 0.2870 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9833 Model_1_val:0.7621 Model_2_val:0.7494
Epoch: 0240 Model_1_loss: 0.2200 Model_2_loss: 0.1960 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7765 Model_2_val:0.7694
Epoch: 0260 Model_1_loss: 0.2226 Model_2_loss: 0.2007 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7737 Model_2_val:0.7690
Epoch: 0280 Model_1_loss: 0.2227 Model_2_loss: 0.2141 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7752 Model_2_val:0.7659
Epoch: 0300 Model_1_loss: 0.1934 Model_2_loss: 0.1880 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7759 Model_2_val:0.7716
Epoch: 0320 Model_1_loss: 0.2032 Model_2_loss: 0.1770 Model_1_trainacc: 0.9500 Model_2_trainacc: 1.0000 Model_1_val:0.7793 Model_2_val:0.7766
Epoch: 0340 Model_1_loss: 0.2079 Model_2_loss: 0.1782 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7758 Model_2_val:0.7655
Epoch: 0360 Model_1_loss: 0.1567 Model_2_loss: 0.1619 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7729 Model_2_val:0.7714
Epoch: 0380 Model_1_loss: 0.1555 Model_2_loss: 0.1579 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7733 Model_2_val:0.7687
Epoch: 0400 Model_1_loss: 0.1559 Model_2_loss: 0.1467 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7777 Model_2_val:0.7701
Model_one_test:0.7891 Model_two_test:0.7906
added by two output: 0.7905
Model1 Acc: 0.779023 Model2 Acc: 0.778932
Maxacc Mean: 0.780002
[0.7724194482998152, 0.784036321393279, 0.7753405892386516, 0.7789860521055665, 0.780001540983086]
Maxacc of all experiments: 0.784036321393279
1
labels of each class :  [20 20 20]
t= [975 975 975]
840460411
Epoch: 0020 Model_1_loss: 1.0030 Model_2_loss: 1.0161 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.6833 Model_1_val:0.5510 Model_2_val:0.5270
Epoch: 0040 Model_1_loss: 0.7735 Model_2_loss: 0.8609 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.7333 Model_1_val:0.5977 Model_2_val:0.5785
Epoch: 0060 Model_1_loss: 0.5760 Model_2_loss: 0.6228 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8833 Model_1_val:0.6512 Model_2_val:0.6234
Epoch: 0080 Model_1_loss: 0.4752 Model_2_loss: 0.5062 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.6729 Model_2_val:0.6664
Epoch: 0100 Model_1_loss: 0.3307 Model_2_loss: 0.3986 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6929 Model_2_val:0.6725
Epoch: 0120 Model_1_loss: 0.3137 Model_2_loss: 0.3580 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6899 Model_2_val:0.6867
Epoch: 0140 Model_1_loss: 0.2530 Model_2_loss: 0.2932 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6999 Model_2_val:0.6954
Epoch: 0160 Model_1_loss: 0.2634 Model_2_loss: 0.2731 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7119 Model_2_val:0.7000
Epoch: 0180 Model_1_loss: 0.2309 Model_2_loss: 0.2636 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7064 Model_2_val:0.7023
Epoch: 0200 Model_1_loss: 0.2124 Model_2_loss: 0.2453 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7156 Model_2_val:0.6975
Epoch: 0220 Model_1_loss: 0.2647 Model_2_loss: 0.3538 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7423 Model_2_val:0.7406
Epoch: 0240 Model_1_loss: 0.2373 Model_2_loss: 0.2518 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7516 Model_2_val:0.7496
Epoch: 0260 Model_1_loss: 0.2389 Model_2_loss: 0.2321 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7561 Model_2_val:0.7542
Epoch: 0280 Model_1_loss: 0.2373 Model_2_loss: 0.2393 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.7547 Model_2_val:0.7435
Epoch: 0300 Model_1_loss: 0.1810 Model_2_loss: 0.2453 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7494 Model_2_val:0.7483
Epoch: 0320 Model_1_loss: 0.1846 Model_2_loss: 0.2061 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7494 Model_2_val:0.7498
Epoch: 0340 Model_1_loss: 0.1483 Model_2_loss: 0.2123 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7513 Model_2_val:0.7477
Epoch: 0360 Model_1_loss: 0.1648 Model_2_loss: 0.2244 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7452 Model_2_val:0.7442
Epoch: 0380 Model_1_loss: 0.1642 Model_2_loss: 0.2261 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9333 Model_1_val:0.7557 Model_2_val:0.7537
Epoch: 0400 Model_1_loss: 0.1436 Model_2_loss: 0.1709 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7537 Model_2_val:0.7440
Model_one_test:0.7711 Model_two_test:0.7660
added by two output: 0.7683
2
labels of each class :  [20 20 20]
t= [975 975 975]
1269207600
Epoch: 0020 Model_1_loss: 0.9941 Model_2_loss: 1.0309 Model_1_trainacc: 0.5333 Model_2_trainacc: 0.6333 Model_1_val:0.4424 Model_2_val:0.4566
Epoch: 0040 Model_1_loss: 0.8138 Model_2_loss: 0.8642 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8167 Model_1_val:0.6394 Model_2_val:0.6235
Epoch: 0060 Model_1_loss: 0.6009 Model_2_loss: 0.5680 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9167 Model_1_val:0.6912 Model_2_val:0.6904
Epoch: 0080 Model_1_loss: 0.4116 Model_2_loss: 0.3868 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9333 Model_1_val:0.7245 Model_2_val:0.7220
Epoch: 0100 Model_1_loss: 0.3644 Model_2_loss: 0.3209 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.7229 Model_2_val:0.7421
Epoch: 0120 Model_1_loss: 0.2784 Model_2_loss: 0.3048 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7282 Model_2_val:0.7483
Epoch: 0140 Model_1_loss: 0.2803 Model_2_loss: 0.2182 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7281 Model_2_val:0.7461
Epoch: 0160 Model_1_loss: 0.2223 Model_2_loss: 0.2447 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7301 Model_2_val:0.7512
Epoch: 0180 Model_1_loss: 0.2295 Model_2_loss: 0.1883 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7348 Model_2_val:0.7388
Epoch: 0200 Model_1_loss: 0.1992 Model_2_loss: 0.1847 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7380 Model_2_val:0.7502
Epoch: 0220 Model_1_loss: 0.2368 Model_2_loss: 0.2704 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7429 Model_2_val:0.7517
Epoch: 0240 Model_1_loss: 0.2058 Model_2_loss: 0.2099 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7530 Model_2_val:0.7576
Epoch: 0260 Model_1_loss: 0.1882 Model_2_loss: 0.2290 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7527 Model_2_val:0.7572
Epoch: 0280 Model_1_loss: 0.1886 Model_2_loss: 0.2060 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7588 Model_2_val:0.7614
Epoch: 0300 Model_1_loss: 0.2173 Model_2_loss: 0.1783 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7510 Model_2_val:0.7559
Epoch: 0320 Model_1_loss: 0.1769 Model_2_loss: 0.1725 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7556 Model_2_val:0.7583
Epoch: 0340 Model_1_loss: 0.1538 Model_2_loss: 0.1619 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7533 Model_2_val:0.7620
Epoch: 0360 Model_1_loss: 0.1516 Model_2_loss: 0.1730 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7560 Model_2_val:0.7688
Epoch: 0380 Model_1_loss: 0.1874 Model_2_loss: 0.1589 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7563 Model_2_val:0.7643
Epoch: 0400 Model_1_loss: 0.1717 Model_2_loss: 0.1467 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7569 Model_2_val:0.7646
Model_one_test:0.7853 Model_two_test:0.7849
added by two output: 0.7858
3
labels of each class :  [20 20 20]
t= [975 975 975]
760868215
Epoch: 0020 Model_1_loss: 0.9891 Model_2_loss: 0.9410 Model_1_trainacc: 0.6167 Model_2_trainacc: 0.7000 Model_1_val:0.4977 Model_2_val:0.5479
Epoch: 0040 Model_1_loss: 0.7753 Model_2_loss: 0.6851 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.8667 Model_1_val:0.5880 Model_2_val:0.6621
Epoch: 0060 Model_1_loss: 0.5879 Model_2_loss: 0.5228 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8500 Model_1_val:0.6421 Model_2_val:0.7091
Epoch: 0080 Model_1_loss: 0.4749 Model_2_loss: 0.3765 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9667 Model_1_val:0.6884 Model_2_val:0.7305
Epoch: 0100 Model_1_loss: 0.3924 Model_2_loss: 0.2951 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.7177 Model_2_val:0.7488
Epoch: 0120 Model_1_loss: 0.3011 Model_2_loss: 0.2564 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7446 Model_2_val:0.7620
Epoch: 0140 Model_1_loss: 0.2681 Model_2_loss: 0.2603 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7564 Model_2_val:0.7652
Epoch: 0160 Model_1_loss: 0.2468 Model_2_loss: 0.1933 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7600 Model_2_val:0.7646
Epoch: 0180 Model_1_loss: 0.1998 Model_2_loss: 0.2161 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.7640 Model_2_val:0.7699
Epoch: 0200 Model_1_loss: 0.1705 Model_2_loss: 0.1905 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.7598 Model_2_val:0.7752
Epoch: 0220 Model_1_loss: 0.2260 Model_2_loss: 0.2022 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7622 Model_2_val:0.7733
Epoch: 0240 Model_1_loss: 0.1698 Model_2_loss: 0.2085 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7739 Model_2_val:0.7817
Epoch: 0260 Model_1_loss: 0.1320 Model_2_loss: 0.2057 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7771 Model_2_val:0.7812
Epoch: 0280 Model_1_loss: 0.1911 Model_2_loss: 0.1782 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7761 Model_2_val:0.7857
Epoch: 0300 Model_1_loss: 0.1362 Model_2_loss: 0.1527 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7730 Model_2_val:0.7834
Epoch: 0320 Model_1_loss: 0.1308 Model_2_loss: 0.1524 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7827 Model_2_val:0.7863
Epoch: 0340 Model_1_loss: 0.1533 Model_2_loss: 0.1445 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7815 Model_2_val:0.7901
Epoch: 0360 Model_1_loss: 0.1401 Model_2_loss: 0.1369 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7824 Model_2_val:0.7886
Epoch: 0380 Model_1_loss: 0.1356 Model_2_loss: 0.1409 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7836 Model_2_val:0.7936
Epoch: 0400 Model_1_loss: 0.1373 Model_2_loss: 0.1529 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7850 Model_2_val:0.7907
Model_one_test:0.8064 Model_two_test:0.8098
added by two output: 0.8081
4
labels of each class :  [20 20 20]
t= [975 975 975]
1561234716
Epoch: 0020 Model_1_loss: 0.9918 Model_2_loss: 0.9820 Model_1_trainacc: 0.6833 Model_2_trainacc: 0.7167 Model_1_val:0.5757 Model_2_val:0.5174
Epoch: 0040 Model_1_loss: 0.7666 Model_2_loss: 0.7768 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8167 Model_1_val:0.6377 Model_2_val:0.6482
Epoch: 0060 Model_1_loss: 0.5333 Model_2_loss: 0.5232 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.7023 Model_2_val:0.6903
Epoch: 0080 Model_1_loss: 0.3850 Model_2_loss: 0.3789 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.7232 Model_2_val:0.7080
Epoch: 0100 Model_1_loss: 0.2701 Model_2_loss: 0.2889 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7339 Model_2_val:0.7368
Epoch: 0120 Model_1_loss: 0.2262 Model_2_loss: 0.2175 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7413 Model_2_val:0.7328
Epoch: 0140 Model_1_loss: 0.2092 Model_2_loss: 0.2117 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7407 Model_2_val:0.7280
Epoch: 0160 Model_1_loss: 0.1507 Model_2_loss: 0.2477 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7429 Model_2_val:0.7428
Epoch: 0180 Model_1_loss: 0.1496 Model_2_loss: 0.1723 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7406 Model_2_val:0.7441
Epoch: 0200 Model_1_loss: 0.1382 Model_2_loss: 0.1486 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7453 Model_2_val:0.7463
Epoch: 0220 Model_1_loss: 0.1558 Model_2_loss: 0.1968 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7677 Model_2_val:0.7607
Epoch: 0240 Model_1_loss: 0.1451 Model_2_loss: 0.1475 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7669 Model_2_val:0.7683
Epoch: 0260 Model_1_loss: 0.1455 Model_2_loss: 0.1472 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7682 Model_2_val:0.7691
Epoch: 0280 Model_1_loss: 0.1309 Model_2_loss: 0.1792 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7694 Model_2_val:0.7592
Epoch: 0300 Model_1_loss: 0.1281 Model_2_loss: 0.1351 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7736 Model_2_val:0.7580
Epoch: 0320 Model_1_loss: 0.1290 Model_2_loss: 0.1742 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7702 Model_2_val:0.7719
Epoch: 0340 Model_1_loss: 0.1125 Model_2_loss: 0.1145 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7721 Model_2_val:0.7683
Epoch: 0360 Model_1_loss: 0.1042 Model_2_loss: 0.1386 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7681 Model_2_val:0.7699
Epoch: 0380 Model_1_loss: 0.1339 Model_2_loss: 0.0985 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7746 Model_2_val:0.7696
Epoch: 0400 Model_1_loss: 0.1150 Model_2_loss: 0.1226 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7678 Model_2_val:0.7699
Model_one_test:0.7842 Model_two_test:0.7829
added by two output: 0.7839
5
labels of each class :  [20 20 20]
t= [975 975 975]
107530765
Epoch: 0020 Model_1_loss: 0.9900 Model_2_loss: 1.0118 Model_1_trainacc: 0.6000 Model_2_trainacc: 0.6333 Model_1_val:0.5161 Model_2_val:0.5083
Epoch: 0040 Model_1_loss: 0.7601 Model_2_loss: 0.8212 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8000 Model_1_val:0.6308 Model_2_val:0.6318
Epoch: 0060 Model_1_loss: 0.5535 Model_2_loss: 0.5043 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9000 Model_1_val:0.6565 Model_2_val:0.6760
Epoch: 0080 Model_1_loss: 0.3936 Model_2_loss: 0.3322 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9667 Model_1_val:0.6828 Model_2_val:0.6925
Epoch: 0100 Model_1_loss: 0.3239 Model_2_loss: 0.3080 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.6945 Model_2_val:0.7044
Epoch: 0120 Model_1_loss: 0.2566 Model_2_loss: 0.2657 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.7020 Model_2_val:0.7113
Epoch: 0140 Model_1_loss: 0.1971 Model_2_loss: 0.2284 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7148 Model_2_val:0.7188
Epoch: 0160 Model_1_loss: 0.2076 Model_2_loss: 0.2138 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7115 Model_2_val:0.7192
Epoch: 0180 Model_1_loss: 0.1977 Model_2_loss: 0.1686 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7152 Model_2_val:0.7233
Epoch: 0200 Model_1_loss: 0.1969 Model_2_loss: 0.1553 Model_1_trainacc: 0.9500 Model_2_trainacc: 1.0000 Model_1_val:0.7265 Model_2_val:0.7150
Epoch: 0220 Model_1_loss: 0.2156 Model_2_loss: 0.1894 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7095 Model_2_val:0.7132
Epoch: 0240 Model_1_loss: 0.1914 Model_2_loss: 0.1772 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7211 Model_2_val:0.7251
Epoch: 0260 Model_1_loss: 0.1453 Model_2_loss: 0.1534 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7224 Model_2_val:0.7177
Epoch: 0280 Model_1_loss: 0.1317 Model_2_loss: 0.1599 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7209 Model_2_val:0.7219
Epoch: 0300 Model_1_loss: 0.1392 Model_2_loss: 0.1767 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7207 Model_2_val:0.7207
Epoch: 0320 Model_1_loss: 0.1851 Model_2_loss: 0.1252 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7300 Model_2_val:0.7239
Epoch: 0340 Model_1_loss: 0.1346 Model_2_loss: 0.1460 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7271 Model_2_val:0.7238
Epoch: 0360 Model_1_loss: 0.1140 Model_2_loss: 0.1272 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7243 Model_2_val:0.7306
Epoch: 0380 Model_1_loss: 0.1449 Model_2_loss: 0.1251 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7308 Model_2_val:0.7257
Epoch: 0400 Model_1_loss: 0.1184 Model_2_loss: 0.1232 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7297 Model_2_val:0.7269
Model_one_test:0.7421 Model_two_test:0.7435
added by two output: 0.7416
6
labels of each class :  [20 20 20]
t= [975 975 975]
416310972
Epoch: 0020 Model_1_loss: 1.0195 Model_2_loss: 1.0025 Model_1_trainacc: 0.5167 Model_2_trainacc: 0.6167 Model_1_val:0.4753 Model_2_val:0.4873
Epoch: 0040 Model_1_loss: 0.8448 Model_2_loss: 0.8075 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.7333 Model_1_val:0.6061 Model_2_val:0.5509
Epoch: 0060 Model_1_loss: 0.6007 Model_2_loss: 0.6023 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8833 Model_1_val:0.6606 Model_2_val:0.6303
Epoch: 0080 Model_1_loss: 0.4640 Model_2_loss: 0.4033 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9333 Model_1_val:0.6894 Model_2_val:0.6732
Epoch: 0100 Model_1_loss: 0.3675 Model_2_loss: 0.3084 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9833 Model_1_val:0.6932 Model_2_val:0.6877
Epoch: 0120 Model_1_loss: 0.2913 Model_2_loss: 0.2642 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7015 Model_2_val:0.6942
Epoch: 0140 Model_1_loss: 0.2826 Model_2_loss: 0.2461 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7012 Model_2_val:0.7040
Epoch: 0160 Model_1_loss: 0.2510 Model_2_loss: 0.2271 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6955 Model_2_val:0.7041
Epoch: 0180 Model_1_loss: 0.1923 Model_2_loss: 0.1783 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7127 Model_2_val:0.7090
Epoch: 0200 Model_1_loss: 0.1904 Model_2_loss: 0.1896 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7111 Model_2_val:0.7098
Epoch: 0220 Model_1_loss: 0.2127 Model_2_loss: 0.2354 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7575 Model_2_val:0.7558
Epoch: 0240 Model_1_loss: 0.1939 Model_2_loss: 0.1778 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7608 Model_2_val:0.7613
Epoch: 0260 Model_1_loss: 0.2016 Model_2_loss: 0.1882 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7546 Model_2_val:0.7606
Epoch: 0280 Model_1_loss: 0.2042 Model_2_loss: 0.2097 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7566 Model_2_val:0.7583
Epoch: 0300 Model_1_loss: 0.1890 Model_2_loss: 0.1794 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7556 Model_2_val:0.7602
Epoch: 0320 Model_1_loss: 0.1398 Model_2_loss: 0.1598 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7565 Model_2_val:0.7590
Epoch: 0340 Model_1_loss: 0.1303 Model_2_loss: 0.2023 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9333 Model_1_val:0.7590 Model_2_val:0.7588
Epoch: 0360 Model_1_loss: 0.1772 Model_2_loss: 0.1518 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7579 Model_2_val:0.7558
Epoch: 0380 Model_1_loss: 0.1602 Model_2_loss: 0.1436 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7599 Model_2_val:0.7606
Epoch: 0400 Model_1_loss: 0.1266 Model_2_loss: 0.1341 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7568 Model_2_val:0.7611
Model_one_test:0.7815 Model_two_test:0.7813
added by two output: 0.7808
7
labels of each class :  [20 20 20]
t= [975 975 975]
1349936511
Epoch: 0020 Model_1_loss: 0.9573 Model_2_loss: 0.9751 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.7500 Model_1_val:0.5807 Model_2_val:0.6085
Epoch: 0040 Model_1_loss: 0.7382 Model_2_loss: 0.7415 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8500 Model_1_val:0.6616 Model_2_val:0.6599
Epoch: 0060 Model_1_loss: 0.5237 Model_2_loss: 0.4905 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9167 Model_1_val:0.6911 Model_2_val:0.6985
Epoch: 0080 Model_1_loss: 0.3770 Model_2_loss: 0.3954 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7101 Model_2_val:0.7222
Epoch: 0100 Model_1_loss: 0.3214 Model_2_loss: 0.2947 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7227 Model_2_val:0.7226
Epoch: 0120 Model_1_loss: 0.2188 Model_2_loss: 0.2552 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7238 Model_2_val:0.7332
Epoch: 0140 Model_1_loss: 0.2129 Model_2_loss: 0.2050 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7323 Model_2_val:0.7431
Epoch: 0160 Model_1_loss: 0.1809 Model_2_loss: 0.1751 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7380 Model_2_val:0.7364
Epoch: 0180 Model_1_loss: 0.1749 Model_2_loss: 0.1557 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7340 Model_2_val:0.7331
Epoch: 0200 Model_1_loss: 0.1736 Model_2_loss: 0.1778 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7397 Model_2_val:0.7411
Epoch: 0220 Model_1_loss: 0.1809 Model_2_loss: 0.1991 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7382 Model_2_val:0.7423
Epoch: 0240 Model_1_loss: 0.1524 Model_2_loss: 0.1896 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7498 Model_2_val:0.7372
Epoch: 0260 Model_1_loss: 0.1615 Model_2_loss: 0.1638 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7517 Model_2_val:0.7518
Epoch: 0280 Model_1_loss: 0.1504 Model_2_loss: 0.1628 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7502 Model_2_val:0.7496
Epoch: 0300 Model_1_loss: 0.1402 Model_2_loss: 0.1335 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7495 Model_2_val:0.7481
Epoch: 0320 Model_1_loss: 0.1682 Model_2_loss: 0.1317 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7477 Model_2_val:0.7500
Epoch: 0340 Model_1_loss: 0.1733 Model_2_loss: 0.1449 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7519 Model_2_val:0.7491
Epoch: 0360 Model_1_loss: 0.1502 Model_2_loss: 0.1437 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7536 Model_2_val:0.7542
Epoch: 0380 Model_1_loss: 0.1373 Model_2_loss: 0.1383 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7471 Model_2_val:0.7509
Epoch: 0400 Model_1_loss: 0.1150 Model_2_loss: 0.1323 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7483 Model_2_val:0.7546
Model_one_test:0.7696 Model_two_test:0.7717
added by two output: 0.7716
8
labels of each class :  [20 20 20]
t= [975 975 975]
694186800
Epoch: 0020 Model_1_loss: 0.9847 Model_2_loss: 0.9939 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.7333 Model_1_val:0.5202 Model_2_val:0.5531
Epoch: 0040 Model_1_loss: 0.8195 Model_2_loss: 0.7666 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.9000 Model_1_val:0.6183 Model_2_val:0.6421
Epoch: 0060 Model_1_loss: 0.5885 Model_2_loss: 0.5522 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9000 Model_1_val:0.6762 Model_2_val:0.6769
Epoch: 0080 Model_1_loss: 0.4109 Model_2_loss: 0.3944 Model_1_trainacc: 0.9167 Model_2_trainacc: 1.0000 Model_1_val:0.6936 Model_2_val:0.7171
Epoch: 0100 Model_1_loss: 0.3803 Model_2_loss: 0.2935 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9667 Model_1_val:0.7150 Model_2_val:0.7167
Epoch: 0120 Model_1_loss: 0.2743 Model_2_loss: 0.2809 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7290 Model_2_val:0.7274
Epoch: 0140 Model_1_loss: 0.2316 Model_2_loss: 0.2118 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7378 Model_2_val:0.7331
Epoch: 0160 Model_1_loss: 0.1890 Model_2_loss: 0.1550 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7438 Model_2_val:0.7418
Epoch: 0180 Model_1_loss: 0.1743 Model_2_loss: 0.1432 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7461 Model_2_val:0.7425
Epoch: 0200 Model_1_loss: 0.1448 Model_2_loss: 0.1539 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7529 Model_2_val:0.7407
Epoch: 0220 Model_1_loss: 0.2040 Model_2_loss: 0.1900 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7818 Model_2_val:0.7810
Epoch: 0240 Model_1_loss: 0.1566 Model_2_loss: 0.1454 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7901 Model_2_val:0.7903
Epoch: 0260 Model_1_loss: 0.2192 Model_2_loss: 0.1590 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7938 Model_2_val:0.7909
Epoch: 0280 Model_1_loss: 0.1731 Model_2_loss: 0.1585 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7894 Model_2_val:0.7887
Epoch: 0300 Model_1_loss: 0.1439 Model_2_loss: 0.1471 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7908 Model_2_val:0.7928
Epoch: 0320 Model_1_loss: 0.1633 Model_2_loss: 0.1232 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7922 Model_2_val:0.7952
Epoch: 0340 Model_1_loss: 0.1252 Model_2_loss: 0.1388 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7913 Model_2_val:0.7904
Epoch: 0360 Model_1_loss: 0.1079 Model_2_loss: 0.1059 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7913 Model_2_val:0.7880
Epoch: 0380 Model_1_loss: 0.1144 Model_2_loss: 0.1321 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7954 Model_2_val:0.7955
Epoch: 0400 Model_1_loss: 0.1278 Model_2_loss: 0.1049 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7925 Model_2_val:0.7949
Model_one_test:0.8125 Model_two_test:0.8102
added by two output: 0.8124
9
labels of each class :  [20 20 20]
t= [975 975 975]
772253165
Epoch: 0020 Model_1_loss: 0.9826 Model_2_loss: 0.9705 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.7333 Model_1_val:0.5501 Model_2_val:0.6003
Epoch: 0040 Model_1_loss: 0.7970 Model_2_loss: 0.7272 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8667 Model_1_val:0.6430 Model_2_val:0.6862
Epoch: 0060 Model_1_loss: 0.5827 Model_2_loss: 0.5039 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9000 Model_1_val:0.6862 Model_2_val:0.7031
Epoch: 0080 Model_1_loss: 0.4104 Model_2_loss: 0.3679 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9167 Model_1_val:0.7042 Model_2_val:0.7216
Epoch: 0100 Model_1_loss: 0.3129 Model_2_loss: 0.3343 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.7130 Model_2_val:0.7334
Epoch: 0120 Model_1_loss: 0.2625 Model_2_loss: 0.2448 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.7236 Model_2_val:0.7416
Epoch: 0140 Model_1_loss: 0.2625 Model_2_loss: 0.2151 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7260 Model_2_val:0.7351
Epoch: 0160 Model_1_loss: 0.2406 Model_2_loss: 0.2523 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7281 Model_2_val:0.7455
Epoch: 0180 Model_1_loss: 0.2026 Model_2_loss: 0.2034 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7333 Model_2_val:0.7476
Epoch: 0200 Model_1_loss: 0.1843 Model_2_loss: 0.1945 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7343 Model_2_val:0.7399
Epoch: 0220 Model_1_loss: 0.2185 Model_2_loss: 0.2356 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7559 Model_2_val:0.7603
Epoch: 0240 Model_1_loss: 0.1886 Model_2_loss: 0.1824 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7565 Model_2_val:0.7585
Epoch: 0260 Model_1_loss: 0.2146 Model_2_loss: 0.1750 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7645 Model_2_val:0.7670
Epoch: 0280 Model_1_loss: 0.1724 Model_2_loss: 0.1460 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7698 Model_2_val:0.7697
Epoch: 0300 Model_1_loss: 0.1346 Model_2_loss: 0.1504 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7660 Model_2_val:0.7669
Epoch: 0320 Model_1_loss: 0.1427 Model_2_loss: 0.1696 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7723 Model_2_val:0.7693
Epoch: 0340 Model_1_loss: 0.1362 Model_2_loss: 0.1530 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7691 Model_2_val:0.7683
Epoch: 0360 Model_1_loss: 0.1311 Model_2_loss: 0.1238 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7687 Model_2_val:0.7744
Epoch: 0380 Model_1_loss: 0.1499 Model_2_loss: 0.1215 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7650 Model_2_val:0.7687
Epoch: 0400 Model_1_loss: 0.1232 Model_2_loss: 0.1158 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7755 Model_2_val:0.7784
Model_one_test:0.7977 Model_two_test:0.7947
added by two output: 0.7978
10
labels of each class :  [20 20 20]
t= [975 975 975]
1171102492
Epoch: 0020 Model_1_loss: 1.0336 Model_2_loss: 0.9611 Model_1_trainacc: 0.5667 Model_2_trainacc: 0.7500 Model_1_val:0.5147 Model_2_val:0.5869
Epoch: 0040 Model_1_loss: 0.8737 Model_2_loss: 0.7263 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.8167 Model_1_val:0.5989 Model_2_val:0.6587
Epoch: 0060 Model_1_loss: 0.7007 Model_2_loss: 0.5478 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8833 Model_1_val:0.6797 Model_2_val:0.7060
Epoch: 0080 Model_1_loss: 0.5036 Model_2_loss: 0.4000 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.6949 Model_2_val:0.7329
Epoch: 0100 Model_1_loss: 0.4257 Model_2_loss: 0.3699 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.7186 Model_2_val:0.7446
Epoch: 0120 Model_1_loss: 0.3496 Model_2_loss: 0.3134 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.7285 Model_2_val:0.7444
Epoch: 0140 Model_1_loss: 0.3354 Model_2_loss: 0.2168 Model_1_trainacc: 0.9333 Model_2_trainacc: 1.0000 Model_1_val:0.7398 Model_2_val:0.7492
Epoch: 0160 Model_1_loss: 0.2521 Model_2_loss: 0.2492 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7490 Model_2_val:0.7613
Epoch: 0180 Model_1_loss: 0.2363 Model_2_loss: 0.2684 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.7472 Model_2_val:0.7577
Epoch: 0200 Model_1_loss: 0.2242 Model_2_loss: 0.2358 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7574 Model_2_val:0.7653
Epoch: 0220 Model_1_loss: 0.2395 Model_2_loss: 0.2680 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7543 Model_2_val:0.7606
Epoch: 0240 Model_1_loss: 0.2019 Model_2_loss: 0.1882 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7613 Model_2_val:0.7601
Epoch: 0260 Model_1_loss: 0.1720 Model_2_loss: 0.1736 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7606 Model_2_val:0.7644
Epoch: 0280 Model_1_loss: 0.1908 Model_2_loss: 0.1882 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7622 Model_2_val:0.7621
Epoch: 0300 Model_1_loss: 0.1824 Model_2_loss: 0.1892 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7656 Model_2_val:0.7670
Epoch: 0320 Model_1_loss: 0.1929 Model_2_loss: 0.1678 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7630 Model_2_val:0.7700
Epoch: 0340 Model_1_loss: 0.1856 Model_2_loss: 0.1530 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7665 Model_2_val:0.7611
Epoch: 0360 Model_1_loss: 0.1790 Model_2_loss: 0.1666 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7692 Model_2_val:0.7700
Epoch: 0380 Model_1_loss: 0.1222 Model_2_loss: 0.1699 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7689 Model_2_val:0.7713
Epoch: 0400 Model_1_loss: 0.1366 Model_2_loss: 0.1448 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7715 Model_2_val:0.7672
Model_one_test:0.7874 Model_two_test:0.7861
added by two output: 0.7868
Model1 Acc: 0.783775 Model2 Acc: 0.783119
Maxacc Mean: 0.784464
[0.7724194482998152, 0.784036321393279, 0.7753405892386516, 0.7789860521055665, 0.780001540983086, 0.7844636490501327]
Maxacc of all experiments: 0.7844636490501327
1
labels of each class :  [20 20 20]
t= [975 975 975]
570408544
Epoch: 0020 Model_1_loss: 1.0178 Model_2_loss: 0.9692 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.8167 Model_1_val:0.5152 Model_2_val:0.5481
Epoch: 0040 Model_1_loss: 0.8593 Model_2_loss: 0.6939 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.9000 Model_1_val:0.6285 Model_2_val:0.6614
Epoch: 0060 Model_1_loss: 0.6279 Model_2_loss: 0.5097 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8833 Model_1_val:0.6635 Model_2_val:0.6997
Epoch: 0080 Model_1_loss: 0.4709 Model_2_loss: 0.3769 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9167 Model_1_val:0.6974 Model_2_val:0.7293
Epoch: 0100 Model_1_loss: 0.4024 Model_2_loss: 0.2634 Model_1_trainacc: 0.8833 Model_2_trainacc: 1.0000 Model_1_val:0.7089 Model_2_val:0.7395
Epoch: 0120 Model_1_loss: 0.3704 Model_2_loss: 0.2650 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9667 Model_1_val:0.7231 Model_2_val:0.7486
Epoch: 0140 Model_1_loss: 0.2694 Model_2_loss: 0.2272 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7306 Model_2_val:0.7484
Epoch: 0160 Model_1_loss: 0.2566 Model_2_loss: 0.2088 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7358 Model_2_val:0.7482
Epoch: 0180 Model_1_loss: 0.1893 Model_2_loss: 0.1900 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7355 Model_2_val:0.7506
Epoch: 0200 Model_1_loss: 0.1862 Model_2_loss: 0.1500 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7396 Model_2_val:0.7510
Epoch: 0220 Model_1_loss: 0.1786 Model_2_loss: 0.1895 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7609 Model_2_val:0.7550
Epoch: 0240 Model_1_loss: 0.1786 Model_2_loss: 0.1775 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7646 Model_2_val:0.7673
Epoch: 0260 Model_1_loss: 0.1564 Model_2_loss: 0.1528 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7634 Model_2_val:0.7637
Epoch: 0280 Model_1_loss: 0.1665 Model_2_loss: 0.1522 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7623 Model_2_val:0.7639
Epoch: 0300 Model_1_loss: 0.1382 Model_2_loss: 0.1571 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7683 Model_2_val:0.7652
Epoch: 0320 Model_1_loss: 0.1227 Model_2_loss: 0.1401 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7658 Model_2_val:0.7679
Epoch: 0340 Model_1_loss: 0.1596 Model_2_loss: 0.1292 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7643 Model_2_val:0.7696
Epoch: 0360 Model_1_loss: 0.1230 Model_2_loss: 0.1181 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7692 Model_2_val:0.7684
Epoch: 0380 Model_1_loss: 0.1270 Model_2_loss: 0.1318 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7685 Model_2_val:0.7646
Epoch: 0400 Model_1_loss: 0.1263 Model_2_loss: 0.1186 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7666 Model_2_val:0.7691
Model_one_test:0.7838 Model_two_test:0.7854
added by two output: 0.7853
2
labels of each class :  [20 20 20]
t= [975 975 975]
387688301
Epoch: 0020 Model_1_loss: 0.9870 Model_2_loss: 0.9668 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7167 Model_1_val:0.5119 Model_2_val:0.5159
Epoch: 0040 Model_1_loss: 0.8325 Model_2_loss: 0.7483 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.8667 Model_1_val:0.5976 Model_2_val:0.6403
Epoch: 0060 Model_1_loss: 0.5949 Model_2_loss: 0.5287 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9000 Model_1_val:0.6674 Model_2_val:0.6685
Epoch: 0080 Model_1_loss: 0.4111 Model_2_loss: 0.4480 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9000 Model_1_val:0.6865 Model_2_val:0.6976
Epoch: 0100 Model_1_loss: 0.3392 Model_2_loss: 0.3275 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.7032 Model_2_val:0.7178
Epoch: 0120 Model_1_loss: 0.2765 Model_2_loss: 0.2848 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7234 Model_2_val:0.7201
Epoch: 0140 Model_1_loss: 0.2466 Model_2_loss: 0.2123 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7184 Model_2_val:0.7250
Epoch: 0160 Model_1_loss: 0.2583 Model_2_loss: 0.2371 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7354 Model_2_val:0.7361
Epoch: 0180 Model_1_loss: 0.1993 Model_2_loss: 0.2088 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7409 Model_2_val:0.7336
Epoch: 0200 Model_1_loss: 0.1919 Model_2_loss: 0.2435 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7369 Model_2_val:0.7351
Epoch: 0220 Model_1_loss: 0.2194 Model_2_loss: 0.1993 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7412 Model_2_val:0.7432
Epoch: 0240 Model_1_loss: 0.2326 Model_2_loss: 0.2028 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7519 Model_2_val:0.7475
Epoch: 0260 Model_1_loss: 0.1606 Model_2_loss: 0.2004 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7542 Model_2_val:0.7457
Epoch: 0280 Model_1_loss: 0.1541 Model_2_loss: 0.1732 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7615 Model_2_val:0.7587
Epoch: 0300 Model_1_loss: 0.1576 Model_2_loss: 0.1804 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7538 Model_2_val:0.7547
Epoch: 0320 Model_1_loss: 0.1600 Model_2_loss: 0.1788 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7591 Model_2_val:0.7508
Epoch: 0340 Model_1_loss: 0.1520 Model_2_loss: 0.1361 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7632 Model_2_val:0.7557
Epoch: 0360 Model_1_loss: 0.1618 Model_2_loss: 0.1645 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7540 Model_2_val:0.7587
Epoch: 0380 Model_1_loss: 0.1322 Model_2_loss: 0.1213 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7570 Model_2_val:0.7526
Epoch: 0400 Model_1_loss: 0.1168 Model_2_loss: 0.1462 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7607 Model_2_val:0.7548
Model_one_test:0.7776 Model_two_test:0.7756
added by two output: 0.7771
3
labels of each class :  [20 20 20]
t= [975 975 975]
128895413
Epoch: 0020 Model_1_loss: 0.9912 Model_2_loss: 0.9752 Model_1_trainacc: 0.5000 Model_2_trainacc: 0.5667 Model_1_val:0.4552 Model_2_val:0.5156
Epoch: 0040 Model_1_loss: 0.7776 Model_2_loss: 0.8193 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8500 Model_1_val:0.6088 Model_2_val:0.6329
Epoch: 0060 Model_1_loss: 0.6174 Model_2_loss: 0.5980 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9000 Model_1_val:0.6829 Model_2_val:0.6880
Epoch: 0080 Model_1_loss: 0.4395 Model_2_loss: 0.4706 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.7181 Model_2_val:0.7119
Epoch: 0100 Model_1_loss: 0.3170 Model_2_loss: 0.3876 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.7382 Model_2_val:0.7351
Epoch: 0120 Model_1_loss: 0.2768 Model_2_loss: 0.3006 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7474 Model_2_val:0.7364
Epoch: 0140 Model_1_loss: 0.1863 Model_2_loss: 0.2823 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7585 Model_2_val:0.7479
Epoch: 0160 Model_1_loss: 0.1950 Model_2_loss: 0.2119 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7558 Model_2_val:0.7526
Epoch: 0180 Model_1_loss: 0.2089 Model_2_loss: 0.2188 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7504 Model_2_val:0.7579
Epoch: 0200 Model_1_loss: 0.1760 Model_2_loss: 0.2208 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7573 Model_2_val:0.7554
Epoch: 0220 Model_1_loss: 0.2138 Model_2_loss: 0.2296 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7702 Model_2_val:0.7540
Epoch: 0240 Model_1_loss: 0.1587 Model_2_loss: 0.2017 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7768 Model_2_val:0.7689
Epoch: 0260 Model_1_loss: 0.1628 Model_2_loss: 0.1846 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7704 Model_2_val:0.7619
Epoch: 0280 Model_1_loss: 0.1442 Model_2_loss: 0.1728 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7722 Model_2_val:0.7659
Epoch: 0300 Model_1_loss: 0.1548 Model_2_loss: 0.1982 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7816 Model_2_val:0.7696
Epoch: 0320 Model_1_loss: 0.1764 Model_2_loss: 0.1878 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7812 Model_2_val:0.7722
Epoch: 0340 Model_1_loss: 0.1463 Model_2_loss: 0.1722 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7740 Model_2_val:0.7709
Epoch: 0360 Model_1_loss: 0.1525 Model_2_loss: 0.1378 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7721 Model_2_val:0.7707
Epoch: 0380 Model_1_loss: 0.1688 Model_2_loss: 0.1794 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7761 Model_2_val:0.7761
Epoch: 0400 Model_1_loss: 0.1514 Model_2_loss: 0.1793 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7813 Model_2_val:0.7689
Model_one_test:0.8004 Model_two_test:0.7915
added by two output: 0.7968
4
labels of each class :  [20 20 20]
t= [975 975 975]
1272452740
Epoch: 0020 Model_1_loss: 0.9903 Model_2_loss: 1.0465 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.6667 Model_1_val:0.5834 Model_2_val:0.5558
Epoch: 0040 Model_1_loss: 0.7619 Model_2_loss: 0.8384 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8167 Model_1_val:0.6408 Model_2_val:0.6513
Epoch: 0060 Model_1_loss: 0.5487 Model_2_loss: 0.5430 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9167 Model_1_val:0.6767 Model_2_val:0.6760
Epoch: 0080 Model_1_loss: 0.3699 Model_2_loss: 0.3602 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7163 Model_2_val:0.7120
Epoch: 0100 Model_1_loss: 0.2797 Model_2_loss: 0.3364 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7273 Model_2_val:0.7219
Epoch: 0120 Model_1_loss: 0.2951 Model_2_loss: 0.2884 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7311 Model_2_val:0.7329
Epoch: 0140 Model_1_loss: 0.2425 Model_2_loss: 0.2263 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7366 Model_2_val:0.7326
Epoch: 0160 Model_1_loss: 0.2155 Model_2_loss: 0.1898 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7355 Model_2_val:0.7372
Epoch: 0180 Model_1_loss: 0.1604 Model_2_loss: 0.2161 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7463 Model_2_val:0.7391
Epoch: 0200 Model_1_loss: 0.1503 Model_2_loss: 0.1902 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7448 Model_2_val:0.7367
Epoch: 0220 Model_1_loss: 0.2000 Model_2_loss: 0.1797 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7417 Model_2_val:0.7423
Epoch: 0240 Model_1_loss: 0.1772 Model_2_loss: 0.2000 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7488 Model_2_val:0.7545
Epoch: 0260 Model_1_loss: 0.1763 Model_2_loss: 0.1810 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7571 Model_2_val:0.7517
Epoch: 0280 Model_1_loss: 0.1729 Model_2_loss: 0.1638 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7504 Model_2_val:0.7543
Epoch: 0300 Model_1_loss: 0.1491 Model_2_loss: 0.1437 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7495 Model_2_val:0.7538
Epoch: 0320 Model_1_loss: 0.1871 Model_2_loss: 0.1423 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7533 Model_2_val:0.7571
Epoch: 0340 Model_1_loss: 0.1516 Model_2_loss: 0.1275 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7508 Model_2_val:0.7579
Epoch: 0360 Model_1_loss: 0.1508 Model_2_loss: 0.1349 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7513 Model_2_val:0.7548
Epoch: 0380 Model_1_loss: 0.1139 Model_2_loss: 0.1088 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7585 Model_2_val:0.7532
Epoch: 0400 Model_1_loss: 0.1338 Model_2_loss: 0.1084 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7576 Model_2_val:0.7544
Model_one_test:0.7688 Model_two_test:0.7651
added by two output: 0.7664
5
labels of each class :  [20 20 20]
t= [975 975 975]
1040919796
Epoch: 0020 Model_1_loss: 0.9981 Model_2_loss: 0.9801 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.7833 Model_1_val:0.5870 Model_2_val:0.5691
Epoch: 0040 Model_1_loss: 0.8090 Model_2_loss: 0.7407 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8167 Model_1_val:0.6344 Model_2_val:0.6407
Epoch: 0060 Model_1_loss: 0.5825 Model_2_loss: 0.5213 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8833 Model_1_val:0.6749 Model_2_val:0.6752
Epoch: 0080 Model_1_loss: 0.4256 Model_2_loss: 0.4108 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.6913 Model_2_val:0.6919
Epoch: 0100 Model_1_loss: 0.3520 Model_2_loss: 0.2766 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7047 Model_2_val:0.7227
Epoch: 0120 Model_1_loss: 0.2906 Model_2_loss: 0.2966 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.7197 Model_2_val:0.7288
Epoch: 0140 Model_1_loss: 0.2381 Model_2_loss: 0.2618 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7260 Model_2_val:0.7290
Epoch: 0160 Model_1_loss: 0.2176 Model_2_loss: 0.2133 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7319 Model_2_val:0.7371
Epoch: 0180 Model_1_loss: 0.2078 Model_2_loss: 0.1838 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7359 Model_2_val:0.7396
Epoch: 0200 Model_1_loss: 0.1989 Model_2_loss: 0.1691 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7354 Model_2_val:0.7387
Epoch: 0220 Model_1_loss: 0.2403 Model_2_loss: 0.2854 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7453 Model_2_val:0.7429
Epoch: 0240 Model_1_loss: 0.1701 Model_2_loss: 0.1745 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7565 Model_2_val:0.7547
Epoch: 0260 Model_1_loss: 0.1657 Model_2_loss: 0.1670 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7666 Model_2_val:0.7511
Epoch: 0280 Model_1_loss: 0.1729 Model_2_loss: 0.1625 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7570 Model_2_val:0.7499
Epoch: 0300 Model_1_loss: 0.1838 Model_2_loss: 0.1678 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7566 Model_2_val:0.7644
Epoch: 0320 Model_1_loss: 0.1337 Model_2_loss: 0.1475 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7593 Model_2_val:0.7546
Epoch: 0340 Model_1_loss: 0.1745 Model_2_loss: 0.1658 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7615 Model_2_val:0.7661
Epoch: 0360 Model_1_loss: 0.1638 Model_2_loss: 0.1559 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7649 Model_2_val:0.7635
Epoch: 0380 Model_1_loss: 0.1226 Model_2_loss: 0.1482 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7555 Model_2_val:0.7622
Epoch: 0400 Model_1_loss: 0.1346 Model_2_loss: 0.1288 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7662 Model_2_val:0.7659
Model_one_test:0.7793 Model_two_test:0.7779
added by two output: 0.7783
6
labels of each class :  [20 20 20]
t= [975 975 975]
399967804
Epoch: 0020 Model_1_loss: 1.0025 Model_2_loss: 0.9835 Model_1_trainacc: 0.6833 Model_2_trainacc: 0.6167 Model_1_val:0.5198 Model_2_val:0.4551
Epoch: 0040 Model_1_loss: 0.7659 Model_2_loss: 0.8072 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.7833 Model_1_val:0.6285 Model_2_val:0.5894
Epoch: 0060 Model_1_loss: 0.5463 Model_2_loss: 0.6110 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8667 Model_1_val:0.6817 Model_2_val:0.6611
Epoch: 0080 Model_1_loss: 0.4290 Model_2_loss: 0.4684 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.6932 Model_2_val:0.6917
Epoch: 0100 Model_1_loss: 0.3415 Model_2_loss: 0.3616 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7104 Model_2_val:0.7028
Epoch: 0120 Model_1_loss: 0.2828 Model_2_loss: 0.3456 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.7090 Model_2_val:0.7074
Epoch: 0140 Model_1_loss: 0.2507 Model_2_loss: 0.2849 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7206 Model_2_val:0.7071
Epoch: 0160 Model_1_loss: 0.2176 Model_2_loss: 0.2929 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7140 Model_2_val:0.7146
Epoch: 0180 Model_1_loss: 0.2008 Model_2_loss: 0.2281 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7174 Model_2_val:0.7088
Epoch: 0200 Model_1_loss: 0.1948 Model_2_loss: 0.1944 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7179 Model_2_val:0.7076
Epoch: 0220 Model_1_loss: 0.2813 Model_2_loss: 0.3217 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7525 Model_2_val:0.7459
Epoch: 0240 Model_1_loss: 0.1961 Model_2_loss: 0.2313 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7559 Model_2_val:0.7453
Epoch: 0260 Model_1_loss: 0.1995 Model_2_loss: 0.2207 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7532 Model_2_val:0.7426
Epoch: 0280 Model_1_loss: 0.2142 Model_2_loss: 0.1887 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7532 Model_2_val:0.7512
Epoch: 0300 Model_1_loss: 0.2189 Model_2_loss: 0.1703 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7520 Model_2_val:0.7523
Epoch: 0320 Model_1_loss: 0.1834 Model_2_loss: 0.1693 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7529 Model_2_val:0.7504
Epoch: 0340 Model_1_loss: 0.1657 Model_2_loss: 0.1636 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7574 Model_2_val:0.7402
Epoch: 0360 Model_1_loss: 0.1851 Model_2_loss: 0.1924 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7525 Model_2_val:0.7508
Epoch: 0380 Model_1_loss: 0.1569 Model_2_loss: 0.1582 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7532 Model_2_val:0.7427
Epoch: 0400 Model_1_loss: 0.1833 Model_2_loss: 0.1609 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7540 Model_2_val:0.7472
Model_one_test:0.7755 Model_two_test:0.7627
added by two output: 0.7681
7
labels of each class :  [20 20 20]
t= [975 975 975]
145431670
Epoch: 0020 Model_1_loss: 0.9914 Model_2_loss: 1.0102 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.6000 Model_1_val:0.4485 Model_2_val:0.3921
Epoch: 0040 Model_1_loss: 0.7628 Model_2_loss: 0.8271 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8500 Model_1_val:0.6027 Model_2_val:0.5829
Epoch: 0060 Model_1_loss: 0.5413 Model_2_loss: 0.6220 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8833 Model_1_val:0.6318 Model_2_val:0.6121
Epoch: 0080 Model_1_loss: 0.3929 Model_2_loss: 0.4593 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6464 Model_2_val:0.6440
Epoch: 0100 Model_1_loss: 0.3335 Model_2_loss: 0.3546 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6617 Model_2_val:0.6538
Epoch: 0120 Model_1_loss: 0.2576 Model_2_loss: 0.3381 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9333 Model_1_val:0.6603 Model_2_val:0.6496
Epoch: 0140 Model_1_loss: 0.2382 Model_2_loss: 0.2516 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6643 Model_2_val:0.6562
Epoch: 0160 Model_1_loss: 0.1852 Model_2_loss: 0.2331 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6584 Model_2_val:0.6597
Epoch: 0180 Model_1_loss: 0.1844 Model_2_loss: 0.2178 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6636 Model_2_val:0.6566
Epoch: 0200 Model_1_loss: 0.1796 Model_2_loss: 0.1766 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6668 Model_2_val:0.6706
Epoch: 0220 Model_1_loss: 0.2051 Model_2_loss: 0.2380 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6893 Model_2_val:0.6864
Epoch: 0240 Model_1_loss: 0.1941 Model_2_loss: 0.1988 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6926 Model_2_val:0.6911
Epoch: 0260 Model_1_loss: 0.1826 Model_2_loss: 0.1772 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6937 Model_2_val:0.6872
Epoch: 0280 Model_1_loss: 0.1925 Model_2_loss: 0.1843 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6922 Model_2_val:0.6959
Epoch: 0300 Model_1_loss: 0.1747 Model_2_loss: 0.1528 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6986 Model_2_val:0.6935
Epoch: 0320 Model_1_loss: 0.1359 Model_2_loss: 0.1547 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6981 Model_2_val:0.6945
Epoch: 0340 Model_1_loss: 0.1265 Model_2_loss: 0.1457 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6996 Model_2_val:0.6992
Epoch: 0360 Model_1_loss: 0.1390 Model_2_loss: 0.1711 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7015 Model_2_val:0.7022
Epoch: 0380 Model_1_loss: 0.1401 Model_2_loss: 0.1305 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6969 Model_2_val:0.7005
Epoch: 0400 Model_1_loss: 0.1394 Model_2_loss: 0.1451 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7015 Model_2_val:0.7016
Model_one_test:0.7188 Model_two_test:0.7174
added by two output: 0.7191
8
labels of each class :  [20 20 20]
t= [975 975 975]
1134953803
Epoch: 0020 Model_1_loss: 0.9659 Model_2_loss: 1.0204 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.6667 Model_1_val:0.6113 Model_2_val:0.4936
Epoch: 0040 Model_1_loss: 0.7452 Model_2_loss: 0.9029 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.7667 Model_1_val:0.7093 Model_2_val:0.6147
Epoch: 0060 Model_1_loss: 0.5199 Model_2_loss: 0.6488 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8667 Model_1_val:0.7210 Model_2_val:0.6731
Epoch: 0080 Model_1_loss: 0.3639 Model_2_loss: 0.5156 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.7300 Model_2_val:0.7024
Epoch: 0100 Model_1_loss: 0.2852 Model_2_loss: 0.3865 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7306 Model_2_val:0.7153
Epoch: 0120 Model_1_loss: 0.2361 Model_2_loss: 0.3340 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7297 Model_2_val:0.7207
Epoch: 0140 Model_1_loss: 0.2160 Model_2_loss: 0.2916 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7229 Model_2_val:0.7168
Epoch: 0160 Model_1_loss: 0.2208 Model_2_loss: 0.2831 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7310 Model_2_val:0.7181
Epoch: 0180 Model_1_loss: 0.1875 Model_2_loss: 0.2444 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7241 Model_2_val:0.7187
Epoch: 0200 Model_1_loss: 0.1855 Model_2_loss: 0.2403 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7306 Model_2_val:0.7166
Epoch: 0220 Model_1_loss: 0.2078 Model_2_loss: 0.2560 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7570 Model_2_val:0.7426
Epoch: 0240 Model_1_loss: 0.1644 Model_2_loss: 0.2240 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7592 Model_2_val:0.7472
Epoch: 0260 Model_1_loss: 0.1663 Model_2_loss: 0.1993 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7660 Model_2_val:0.7532
Epoch: 0280 Model_1_loss: 0.1593 Model_2_loss: 0.1663 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7614 Model_2_val:0.7538
Epoch: 0300 Model_1_loss: 0.1334 Model_2_loss: 0.1630 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7673 Model_2_val:0.7440
Epoch: 0320 Model_1_loss: 0.1223 Model_2_loss: 0.1570 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7577 Model_2_val:0.7527
Epoch: 0340 Model_1_loss: 0.1215 Model_2_loss: 0.1819 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7649 Model_2_val:0.7572
Epoch: 0360 Model_1_loss: 0.1289 Model_2_loss: 0.1455 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7656 Model_2_val:0.7552
Epoch: 0380 Model_1_loss: 0.1255 Model_2_loss: 0.1581 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7601 Model_2_val:0.7557
Epoch: 0400 Model_1_loss: 0.1189 Model_2_loss: 0.1679 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7529 Model_2_val:0.7588
Model_one_test:0.7756 Model_two_test:0.7752
added by two output: 0.7758
9
labels of each class :  [20 20 20]
t= [975 975 975]
997279492
Epoch: 0020 Model_1_loss: 0.9641 Model_2_loss: 1.0339 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.5333 Model_1_val:0.6516 Model_2_val:0.3228
Epoch: 0040 Model_1_loss: 0.7770 Model_2_loss: 0.8732 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8000 Model_1_val:0.7083 Model_2_val:0.5837
Epoch: 0060 Model_1_loss: 0.5404 Model_2_loss: 0.7200 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8167 Model_1_val:0.7364 Model_2_val:0.6742
Epoch: 0080 Model_1_loss: 0.3685 Model_2_loss: 0.5420 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.8833 Model_1_val:0.7557 Model_2_val:0.7095
Epoch: 0100 Model_1_loss: 0.2716 Model_2_loss: 0.4323 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7565 Model_2_val:0.7305
Epoch: 0120 Model_1_loss: 0.2670 Model_2_loss: 0.3668 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7662 Model_2_val:0.7382
Epoch: 0140 Model_1_loss: 0.2452 Model_2_loss: 0.3297 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7704 Model_2_val:0.7460
Epoch: 0160 Model_1_loss: 0.2223 Model_2_loss: 0.3468 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.7749 Model_2_val:0.7476
Epoch: 0180 Model_1_loss: 0.2253 Model_2_loss: 0.2581 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7717 Model_2_val:0.7542
Epoch: 0200 Model_1_loss: 0.1941 Model_2_loss: 0.2738 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7764 Model_2_val:0.7573
Epoch: 0220 Model_1_loss: 0.2477 Model_2_loss: 0.3308 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.7893 Model_2_val:0.7738
Epoch: 0240 Model_1_loss: 0.2022 Model_2_loss: 0.2578 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7898 Model_2_val:0.7771
Epoch: 0260 Model_1_loss: 0.1928 Model_2_loss: 0.2659 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7944 Model_2_val:0.7772
Epoch: 0280 Model_1_loss: 0.1919 Model_2_loss: 0.2135 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7912 Model_2_val:0.7829
Epoch: 0300 Model_1_loss: 0.1739 Model_2_loss: 0.2047 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7916 Model_2_val:0.7815
Epoch: 0320 Model_1_loss: 0.1630 Model_2_loss: 0.2270 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7925 Model_2_val:0.7857
Epoch: 0340 Model_1_loss: 0.1825 Model_2_loss: 0.1823 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7984 Model_2_val:0.7849
Epoch: 0360 Model_1_loss: 0.1688 Model_2_loss: 0.1980 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7923 Model_2_val:0.7867
Epoch: 0380 Model_1_loss: 0.1581 Model_2_loss: 0.1882 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7980 Model_2_val:0.7878
Epoch: 0400 Model_1_loss: 0.1620 Model_2_loss: 0.2016 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7956 Model_2_val:0.7841
Model_one_test:0.8073 Model_two_test:0.8051
added by two output: 0.8069
10
labels of each class :  [20 20 20]
t= [975 975 975]
1158020392
Epoch: 0020 Model_1_loss: 1.0073 Model_2_loss: 1.0197 Model_1_trainacc: 0.5333 Model_2_trainacc: 0.3833 Model_1_val:0.4260 Model_2_val:0.3833
Epoch: 0040 Model_1_loss: 0.7967 Model_2_loss: 0.8693 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8333 Model_1_val:0.5882 Model_2_val:0.5794
Epoch: 0060 Model_1_loss: 0.5501 Model_2_loss: 0.6963 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.8667 Model_1_val:0.6348 Model_2_val:0.6323
Epoch: 0080 Model_1_loss: 0.4669 Model_2_loss: 0.5330 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9167 Model_1_val:0.6592 Model_2_val:0.6476
Epoch: 0100 Model_1_loss: 0.3449 Model_2_loss: 0.4105 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.6672 Model_2_val:0.6577
Epoch: 0120 Model_1_loss: 0.2928 Model_2_loss: 0.3793 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.6763 Model_2_val:0.6549
Epoch: 0140 Model_1_loss: 0.2800 Model_2_loss: 0.2976 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6693 Model_2_val:0.6524
Epoch: 0160 Model_1_loss: 0.2212 Model_2_loss: 0.2833 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6736 Model_2_val:0.6603
Epoch: 0180 Model_1_loss: 0.2184 Model_2_loss: 0.2585 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6696 Model_2_val:0.6616
Epoch: 0200 Model_1_loss: 0.2008 Model_2_loss: 0.2258 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.6802 Model_2_val:0.6661
Epoch: 0220 Model_1_loss: 0.2503 Model_2_loss: 0.2757 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6792 Model_2_val:0.6654
Epoch: 0240 Model_1_loss: 0.2115 Model_2_loss: 0.2401 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6699 Model_2_val:0.6661
Epoch: 0260 Model_1_loss: 0.1963 Model_2_loss: 0.1839 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6777 Model_2_val:0.6765
Epoch: 0280 Model_1_loss: 0.2172 Model_2_loss: 0.2020 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6740 Model_2_val:0.6653
Epoch: 0300 Model_1_loss: 0.2009 Model_2_loss: 0.2022 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6723 Model_2_val:0.6644
Epoch: 0320 Model_1_loss: 0.1801 Model_2_loss: 0.2307 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6736 Model_2_val:0.6709
Epoch: 0340 Model_1_loss: 0.1634 Model_2_loss: 0.1556 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6763 Model_2_val:0.6727
Epoch: 0360 Model_1_loss: 0.1393 Model_2_loss: 0.2066 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6756 Model_2_val:0.6650
Epoch: 0380 Model_1_loss: 0.1346 Model_2_loss: 0.2060 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.6776 Model_2_val:0.6649
Epoch: 0400 Model_1_loss: 0.1865 Model_2_loss: 0.1350 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6759 Model_2_val:0.6661
Model_one_test:0.6874 Model_two_test:0.6787
added by two output: 0.6837
Model1 Acc: 0.767449 Model2 Acc: 0.763465
Maxacc Mean: 0.767612
[0.7724194482998152, 0.784036321393279, 0.7753405892386516, 0.7789860521055665, 0.780001540983086, 0.7844636490501327, 0.7676116657325908]
Maxacc of all experiments: 0.7844636490501327
1
labels of each class :  [20 20 20]
t= [975 975 975]
648206576
Epoch: 0020 Model_1_loss: 0.9594 Model_2_loss: 1.0260 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.6000 Model_1_val:0.5369 Model_2_val:0.4682
Epoch: 0040 Model_1_loss: 0.8066 Model_2_loss: 0.8715 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8167 Model_1_val:0.6509 Model_2_val:0.6287
Epoch: 0060 Model_1_loss: 0.6055 Model_2_loss: 0.6626 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9333 Model_1_val:0.6900 Model_2_val:0.6777
Epoch: 0080 Model_1_loss: 0.4584 Model_2_loss: 0.4902 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9500 Model_1_val:0.7198 Model_2_val:0.7111
Epoch: 0100 Model_1_loss: 0.3809 Model_2_loss: 0.4177 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.7298 Model_2_val:0.7164
Epoch: 0120 Model_1_loss: 0.3454 Model_2_loss: 0.3806 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9000 Model_1_val:0.7337 Model_2_val:0.7232
Epoch: 0140 Model_1_loss: 0.2273 Model_2_loss: 0.2709 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7418 Model_2_val:0.7332
Epoch: 0160 Model_1_loss: 0.2306 Model_2_loss: 0.2511 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7385 Model_2_val:0.7293
Epoch: 0180 Model_1_loss: 0.2001 Model_2_loss: 0.2202 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7351 Model_2_val:0.7365
Epoch: 0200 Model_1_loss: 0.1711 Model_2_loss: 0.2033 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7393 Model_2_val:0.7375
Epoch: 0220 Model_1_loss: 0.2718 Model_2_loss: 0.2411 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7557 Model_2_val:0.7524
Epoch: 0240 Model_1_loss: 0.2431 Model_2_loss: 0.2410 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7571 Model_2_val:0.7560
Epoch: 0260 Model_1_loss: 0.2078 Model_2_loss: 0.2115 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7610 Model_2_val:0.7564
Epoch: 0280 Model_1_loss: 0.2088 Model_2_loss: 0.1910 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7572 Model_2_val:0.7610
Epoch: 0300 Model_1_loss: 0.2111 Model_2_loss: 0.1875 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7630 Model_2_val:0.7636
Epoch: 0320 Model_1_loss: 0.1920 Model_2_loss: 0.1953 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7611 Model_2_val:0.7601
Epoch: 0340 Model_1_loss: 0.1924 Model_2_loss: 0.1747 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7635 Model_2_val:0.7638
Epoch: 0360 Model_1_loss: 0.1906 Model_2_loss: 0.2054 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7623 Model_2_val:0.7632
Epoch: 0380 Model_1_loss: 0.1924 Model_2_loss: 0.1246 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7636 Model_2_val:0.7624
Epoch: 0400 Model_1_loss: 0.1802 Model_2_loss: 0.1426 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7642 Model_2_val:0.7659
Model_one_test:0.7832 Model_two_test:0.7833
added by two output: 0.7839
2
labels of each class :  [20 20 20]
t= [975 975 975]
804074609
Epoch: 0020 Model_1_loss: 0.9648 Model_2_loss: 0.9627 Model_1_trainacc: 0.6167 Model_2_trainacc: 0.6667 Model_1_val:0.5333 Model_2_val:0.5476
Epoch: 0040 Model_1_loss: 0.7441 Model_2_loss: 0.7854 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.7667 Model_1_val:0.6384 Model_2_val:0.6471
Epoch: 0060 Model_1_loss: 0.5367 Model_2_loss: 0.5620 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8333 Model_1_val:0.6836 Model_2_val:0.6814
Epoch: 0080 Model_1_loss: 0.4292 Model_2_loss: 0.4432 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9000 Model_1_val:0.7022 Model_2_val:0.6932
Epoch: 0100 Model_1_loss: 0.3426 Model_2_loss: 0.3787 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9333 Model_1_val:0.7065 Model_2_val:0.6963
Epoch: 0120 Model_1_loss: 0.3039 Model_2_loss: 0.3467 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.7052 Model_2_val:0.7018
Epoch: 0140 Model_1_loss: 0.2803 Model_2_loss: 0.2505 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7128 Model_2_val:0.7086
Epoch: 0160 Model_1_loss: 0.2440 Model_2_loss: 0.2445 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7129 Model_2_val:0.7094
Epoch: 0180 Model_1_loss: 0.1928 Model_2_loss: 0.2361 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7148 Model_2_val:0.7074
Epoch: 0200 Model_1_loss: 0.1588 Model_2_loss: 0.1633 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7146 Model_2_val:0.7188
Epoch: 0220 Model_1_loss: 0.2281 Model_2_loss: 0.2975 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7244 Model_2_val:0.7228
Epoch: 0240 Model_1_loss: 0.1795 Model_2_loss: 0.2666 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7202 Model_2_val:0.7241
Epoch: 0260 Model_1_loss: 0.1694 Model_2_loss: 0.1934 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7229 Model_2_val:0.7225
Epoch: 0280 Model_1_loss: 0.1696 Model_2_loss: 0.2108 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7316 Model_2_val:0.7257
Epoch: 0300 Model_1_loss: 0.1581 Model_2_loss: 0.2148 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7270 Model_2_val:0.7209
Epoch: 0320 Model_1_loss: 0.1737 Model_2_loss: 0.1605 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7231 Model_2_val:0.7228
Epoch: 0340 Model_1_loss: 0.1493 Model_2_loss: 0.1797 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7255 Model_2_val:0.7231
Epoch: 0360 Model_1_loss: 0.1499 Model_2_loss: 0.1555 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7277 Model_2_val:0.7278
Epoch: 0380 Model_1_loss: 0.1429 Model_2_loss: 0.1669 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7273 Model_2_val:0.7261
Epoch: 0400 Model_1_loss: 0.1494 Model_2_loss: 0.1623 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7294 Model_2_val:0.7245
Model_one_test:0.7449 Model_two_test:0.7469
added by two output: 0.7458
3
labels of each class :  [20 20 20]
t= [975 975 975]
553035030
Epoch: 0020 Model_1_loss: 0.9544 Model_2_loss: 0.9516 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.7167 Model_1_val:0.5256 Model_2_val:0.5391
Epoch: 0040 Model_1_loss: 0.6902 Model_2_loss: 0.6752 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9000 Model_1_val:0.6585 Model_2_val:0.6442
Epoch: 0060 Model_1_loss: 0.4581 Model_2_loss: 0.4922 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.8667 Model_1_val:0.7040 Model_2_val:0.6948
Epoch: 0080 Model_1_loss: 0.2793 Model_2_loss: 0.3178 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7261 Model_2_val:0.7326
Epoch: 0100 Model_1_loss: 0.2301 Model_2_loss: 0.2476 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7443 Model_2_val:0.7324
Epoch: 0120 Model_1_loss: 0.1818 Model_2_loss: 0.2389 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7451 Model_2_val:0.7413
Epoch: 0140 Model_1_loss: 0.1506 Model_2_loss: 0.1706 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7489 Model_2_val:0.7441
Epoch: 0160 Model_1_loss: 0.1326 Model_2_loss: 0.1399 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7559 Model_2_val:0.7544
Epoch: 0180 Model_1_loss: 0.1464 Model_2_loss: 0.1819 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7585 Model_2_val:0.7483
Epoch: 0200 Model_1_loss: 0.1111 Model_2_loss: 0.1463 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7610 Model_2_val:0.7504
Epoch: 0220 Model_1_loss: 0.1297 Model_2_loss: 0.1353 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7488 Model_2_val:0.7454
Epoch: 0240 Model_1_loss: 0.1231 Model_2_loss: 0.1336 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7499 Model_2_val:0.7616
Epoch: 0260 Model_1_loss: 0.1450 Model_2_loss: 0.1487 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7587 Model_2_val:0.7530
Epoch: 0280 Model_1_loss: 0.1227 Model_2_loss: 0.1189 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7527 Model_2_val:0.7616
Epoch: 0300 Model_1_loss: 0.1000 Model_2_loss: 0.1147 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7563 Model_2_val:0.7537
Epoch: 0320 Model_1_loss: 0.1035 Model_2_loss: 0.0974 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7558 Model_2_val:0.7692
Epoch: 0340 Model_1_loss: 0.0947 Model_2_loss: 0.1037 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7567 Model_2_val:0.7628
Epoch: 0360 Model_1_loss: 0.0987 Model_2_loss: 0.1309 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7607 Model_2_val:0.7625
Epoch: 0380 Model_1_loss: 0.0878 Model_2_loss: 0.0995 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7598 Model_2_val:0.7686
Epoch: 0400 Model_1_loss: 0.1086 Model_2_loss: 0.1079 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7529 Model_2_val:0.7630
Model_one_test:0.7698 Model_two_test:0.7729
added by two output: 0.7713
4
labels of each class :  [20 20 20]
t= [975 975 975]
1022103493
Epoch: 0020 Model_1_loss: 1.0241 Model_2_loss: 0.9837 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7833 Model_1_val:0.5729 Model_2_val:0.5441
Epoch: 0040 Model_1_loss: 0.8609 Model_2_loss: 0.8010 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8333 Model_1_val:0.6534 Model_2_val:0.6284
Epoch: 0060 Model_1_loss: 0.5991 Model_2_loss: 0.5790 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9000 Model_1_val:0.6715 Model_2_val:0.6673
Epoch: 0080 Model_1_loss: 0.4596 Model_2_loss: 0.4230 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9667 Model_1_val:0.6840 Model_2_val:0.6926
Epoch: 0100 Model_1_loss: 0.3285 Model_2_loss: 0.3211 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6903 Model_2_val:0.6985
Epoch: 0120 Model_1_loss: 0.2687 Model_2_loss: 0.2944 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9333 Model_1_val:0.6939 Model_2_val:0.7138
Epoch: 0140 Model_1_loss: 0.2931 Model_2_loss: 0.2140 Model_1_trainacc: 0.9500 Model_2_trainacc: 1.0000 Model_1_val:0.7017 Model_2_val:0.7128
Epoch: 0160 Model_1_loss: 0.1875 Model_2_loss: 0.2430 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6978 Model_2_val:0.7121
Epoch: 0180 Model_1_loss: 0.1909 Model_2_loss: 0.1881 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7020 Model_2_val:0.7094
Epoch: 0200 Model_1_loss: 0.1920 Model_2_loss: 0.1509 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7118 Model_2_val:0.7191
Epoch: 0220 Model_1_loss: 0.2145 Model_2_loss: 0.2004 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7311 Model_2_val:0.7402
Epoch: 0240 Model_1_loss: 0.2029 Model_2_loss: 0.1797 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7369 Model_2_val:0.7464
Epoch: 0260 Model_1_loss: 0.2273 Model_2_loss: 0.1705 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7387 Model_2_val:0.7456
Epoch: 0280 Model_1_loss: 0.1813 Model_2_loss: 0.1459 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7387 Model_2_val:0.7435
Epoch: 0300 Model_1_loss: 0.1760 Model_2_loss: 0.1708 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7394 Model_2_val:0.7481
Epoch: 0320 Model_1_loss: 0.1922 Model_2_loss: 0.1472 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7374 Model_2_val:0.7449
Epoch: 0340 Model_1_loss: 0.1410 Model_2_loss: 0.1680 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7417 Model_2_val:0.7444
Epoch: 0360 Model_1_loss: 0.1423 Model_2_loss: 0.1190 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7413 Model_2_val:0.7458
Epoch: 0380 Model_1_loss: 0.1416 Model_2_loss: 0.1186 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7447 Model_2_val:0.7384
Epoch: 0400 Model_1_loss: 0.1366 Model_2_loss: 0.1526 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7463 Model_2_val:0.7442
Model_one_test:0.7581 Model_two_test:0.7627
added by two output: 0.7608
5
labels of each class :  [20 20 20]
t= [975 975 975]
593185960
Epoch: 0020 Model_1_loss: 1.0511 Model_2_loss: 1.0683 Model_1_trainacc: 0.5333 Model_2_trainacc: 0.4000 Model_1_val:0.4772 Model_2_val:0.2921
Epoch: 0040 Model_1_loss: 0.8976 Model_2_loss: 0.9084 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.7333 Model_1_val:0.6251 Model_2_val:0.5476
Epoch: 0060 Model_1_loss: 0.7079 Model_2_loss: 0.6920 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8833 Model_1_val:0.6925 Model_2_val:0.6659
Epoch: 0080 Model_1_loss: 0.4890 Model_2_loss: 0.4461 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.7169 Model_2_val:0.7081
Epoch: 0100 Model_1_loss: 0.4186 Model_2_loss: 0.3613 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.7268 Model_2_val:0.7185
Epoch: 0120 Model_1_loss: 0.3627 Model_2_loss: 0.2628 Model_1_trainacc: 0.9167 Model_2_trainacc: 1.0000 Model_1_val:0.7230 Model_2_val:0.7280
Epoch: 0140 Model_1_loss: 0.2544 Model_2_loss: 0.2895 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9333 Model_1_val:0.7396 Model_2_val:0.7283
Epoch: 0160 Model_1_loss: 0.2232 Model_2_loss: 0.2528 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7431 Model_2_val:0.7308
Epoch: 0180 Model_1_loss: 0.1528 Model_2_loss: 0.2166 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7361 Model_2_val:0.7275
Epoch: 0200 Model_1_loss: 0.1698 Model_2_loss: 0.1952 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7428 Model_2_val:0.7247
Epoch: 0220 Model_1_loss: 0.1969 Model_2_loss: 0.2216 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7428 Model_2_val:0.7283
Epoch: 0240 Model_1_loss: 0.1689 Model_2_loss: 0.1663 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7442 Model_2_val:0.7336
Epoch: 0260 Model_1_loss: 0.1499 Model_2_loss: 0.2089 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7414 Model_2_val:0.7324
Epoch: 0280 Model_1_loss: 0.1661 Model_2_loss: 0.1952 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7485 Model_2_val:0.7348
Epoch: 0300 Model_1_loss: 0.1781 Model_2_loss: 0.1606 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7435 Model_2_val:0.7449
Epoch: 0320 Model_1_loss: 0.1325 Model_2_loss: 0.1777 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7414 Model_2_val:0.7380
Epoch: 0340 Model_1_loss: 0.1496 Model_2_loss: 0.1750 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7434 Model_2_val:0.7446
Epoch: 0360 Model_1_loss: 0.1088 Model_2_loss: 0.1103 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7438 Model_2_val:0.7326
Epoch: 0380 Model_1_loss: 0.1306 Model_2_loss: 0.1260 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7431 Model_2_val:0.7442
Epoch: 0400 Model_1_loss: 0.1201 Model_2_loss: 0.1318 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7407 Model_2_val:0.7358
Model_one_test:0.7519 Model_two_test:0.7479
added by two output: 0.7497
6
labels of each class :  [20 20 20]
t= [975 975 975]
494579165
Epoch: 0020 Model_1_loss: 1.0318 Model_2_loss: 1.0036 Model_1_trainacc: 0.6000 Model_2_trainacc: 0.7667 Model_1_val:0.4787 Model_2_val:0.5167
Epoch: 0040 Model_1_loss: 0.8987 Model_2_loss: 0.8329 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.7833 Model_1_val:0.5995 Model_2_val:0.6239
Epoch: 0060 Model_1_loss: 0.7043 Model_2_loss: 0.6101 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.9000 Model_1_val:0.6463 Model_2_val:0.6659
Epoch: 0080 Model_1_loss: 0.4658 Model_2_loss: 0.4469 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9167 Model_1_val:0.6825 Model_2_val:0.6923
Epoch: 0100 Model_1_loss: 0.3613 Model_2_loss: 0.2992 Model_1_trainacc: 0.9500 Model_2_trainacc: 1.0000 Model_1_val:0.6979 Model_2_val:0.7064
Epoch: 0120 Model_1_loss: 0.3101 Model_2_loss: 0.3092 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7070 Model_2_val:0.7085
Epoch: 0140 Model_1_loss: 0.2571 Model_2_loss: 0.2150 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7042 Model_2_val:0.7134
Epoch: 0160 Model_1_loss: 0.2135 Model_2_loss: 0.2413 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7073 Model_2_val:0.7169
Epoch: 0180 Model_1_loss: 0.2142 Model_2_loss: 0.1806 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7100 Model_2_val:0.7147
Epoch: 0200 Model_1_loss: 0.1866 Model_2_loss: 0.1876 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7183 Model_2_val:0.7111
Epoch: 0220 Model_1_loss: 0.2177 Model_2_loss: 0.2147 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7310 Model_2_val:0.7352
Epoch: 0240 Model_1_loss: 0.2017 Model_2_loss: 0.1626 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7337 Model_2_val:0.7395
Epoch: 0260 Model_1_loss: 0.1867 Model_2_loss: 0.1737 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7332 Model_2_val:0.7369
Epoch: 0280 Model_1_loss: 0.1602 Model_2_loss: 0.1592 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7388 Model_2_val:0.7381
Epoch: 0300 Model_1_loss: 0.1872 Model_2_loss: 0.1667 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7387 Model_2_val:0.7335
Epoch: 0320 Model_1_loss: 0.1630 Model_2_loss: 0.1547 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7329 Model_2_val:0.7339
Epoch: 0340 Model_1_loss: 0.1388 Model_2_loss: 0.1267 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7358 Model_2_val:0.7316
Epoch: 0360 Model_1_loss: 0.1646 Model_2_loss: 0.1773 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7395 Model_2_val:0.7356
Epoch: 0380 Model_1_loss: 0.1354 Model_2_loss: 0.1367 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7333 Model_2_val:0.7351
Epoch: 0400 Model_1_loss: 0.1147 Model_2_loss: 0.1115 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7373 Model_2_val:0.7311
Model_one_test:0.7533 Model_two_test:0.7512
added by two output: 0.7521
7
labels of each class :  [20 20 20]
t= [975 975 975]
1054671646
Epoch: 0020 Model_1_loss: 1.0510 Model_2_loss: 0.9668 Model_1_trainacc: 0.4833 Model_2_trainacc: 0.7000 Model_1_val:0.4055 Model_2_val:0.5710
Epoch: 0040 Model_1_loss: 0.8809 Model_2_loss: 0.8182 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.7500 Model_1_val:0.5527 Model_2_val:0.6448
Epoch: 0060 Model_1_loss: 0.6668 Model_2_loss: 0.5611 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8667 Model_1_val:0.6444 Model_2_val:0.6846
Epoch: 0080 Model_1_loss: 0.5090 Model_2_loss: 0.4960 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8667 Model_1_val:0.6793 Model_2_val:0.7001
Epoch: 0100 Model_1_loss: 0.4148 Model_2_loss: 0.3477 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6975 Model_2_val:0.7110
Epoch: 0120 Model_1_loss: 0.2982 Model_2_loss: 0.2896 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9167 Model_1_val:0.7169 Model_2_val:0.7227
Epoch: 0140 Model_1_loss: 0.3009 Model_2_loss: 0.3130 Model_1_trainacc: 0.9167 Model_2_trainacc: 1.0000 Model_1_val:0.7214 Model_2_val:0.7175
Epoch: 0160 Model_1_loss: 0.3060 Model_2_loss: 0.2594 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9333 Model_1_val:0.7281 Model_2_val:0.7274
Epoch: 0180 Model_1_loss: 0.2239 Model_2_loss: 0.3094 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9333 Model_1_val:0.7324 Model_2_val:0.7262
Epoch: 0200 Model_1_loss: 0.2222 Model_2_loss: 0.2038 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7294 Model_2_val:0.7374
Epoch: 0220 Model_1_loss: 0.2530 Model_2_loss: 0.2482 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7413 Model_2_val:0.7356
Epoch: 0240 Model_1_loss: 0.2506 Model_2_loss: 0.2428 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7497 Model_2_val:0.7472
Epoch: 0260 Model_1_loss: 0.2123 Model_2_loss: 0.2456 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7546 Model_2_val:0.7537
Epoch: 0280 Model_1_loss: 0.1771 Model_2_loss: 0.2111 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7480 Model_2_val:0.7524
Epoch: 0300 Model_1_loss: 0.1781 Model_2_loss: 0.2244 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7529 Model_2_val:0.7514
Epoch: 0320 Model_1_loss: 0.1730 Model_2_loss: 0.1400 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7556 Model_2_val:0.7500
Epoch: 0340 Model_1_loss: 0.1907 Model_2_loss: 0.1743 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7647 Model_2_val:0.7619
Epoch: 0360 Model_1_loss: 0.1508 Model_2_loss: 0.1605 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7646 Model_2_val:0.7599
Epoch: 0380 Model_1_loss: 0.1689 Model_2_loss: 0.1353 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7575 Model_2_val:0.7673
Epoch: 0400 Model_1_loss: 0.1778 Model_2_loss: 0.1326 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7494 Model_2_val:0.7650
Model_one_test:0.7634 Model_two_test:0.7759
added by two output: 0.7710
8
labels of each class :  [20 20 20]
t= [975 975 975]
95195843
Epoch: 0020 Model_1_loss: 1.0466 Model_2_loss: 0.9772 Model_1_trainacc: 0.5333 Model_2_trainacc: 0.6667 Model_1_val:0.4853 Model_2_val:0.5249
Epoch: 0040 Model_1_loss: 0.8571 Model_2_loss: 0.7506 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8500 Model_1_val:0.6641 Model_2_val:0.6221
Epoch: 0060 Model_1_loss: 0.5977 Model_2_loss: 0.5180 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9000 Model_1_val:0.6922 Model_2_val:0.6662
Epoch: 0080 Model_1_loss: 0.4107 Model_2_loss: 0.3636 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7029 Model_2_val:0.6896
Epoch: 0100 Model_1_loss: 0.2968 Model_2_loss: 0.3329 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7214 Model_2_val:0.6998
Epoch: 0120 Model_1_loss: 0.2971 Model_2_loss: 0.2789 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.7241 Model_2_val:0.7025
Epoch: 0140 Model_1_loss: 0.2598 Model_2_loss: 0.2489 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7348 Model_2_val:0.7084
Epoch: 0160 Model_1_loss: 0.2043 Model_2_loss: 0.2652 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7398 Model_2_val:0.7146
Epoch: 0180 Model_1_loss: 0.2202 Model_2_loss: 0.1824 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7376 Model_2_val:0.7170
Epoch: 0200 Model_1_loss: 0.1576 Model_2_loss: 0.2047 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7410 Model_2_val:0.7205
Epoch: 0220 Model_1_loss: 0.2687 Model_2_loss: 0.2668 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.7325 Model_2_val:0.7320
Epoch: 0240 Model_1_loss: 0.1872 Model_2_loss: 0.2063 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7354 Model_2_val:0.7366
Epoch: 0260 Model_1_loss: 0.2539 Model_2_loss: 0.2072 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7386 Model_2_val:0.7433
Epoch: 0280 Model_1_loss: 0.1849 Model_2_loss: 0.1920 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7361 Model_2_val:0.7397
Epoch: 0300 Model_1_loss: 0.1749 Model_2_loss: 0.1555 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7391 Model_2_val:0.7398
Epoch: 0320 Model_1_loss: 0.1476 Model_2_loss: 0.1517 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7385 Model_2_val:0.7476
Epoch: 0340 Model_1_loss: 0.1758 Model_2_loss: 0.1750 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7482 Model_2_val:0.7418
Epoch: 0360 Model_1_loss: 0.1832 Model_2_loss: 0.1231 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7421 Model_2_val:0.7450
Epoch: 0380 Model_1_loss: 0.1448 Model_2_loss: 0.1347 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7469 Model_2_val:0.7474
Epoch: 0400 Model_1_loss: 0.1307 Model_2_loss: 0.1376 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7400 Model_2_val:0.7475
Model_one_test:0.7593 Model_two_test:0.7611
added by two output: 0.7608
9
labels of each class :  [20 20 20]
t= [975 975 975]
604373275
Epoch: 0020 Model_1_loss: 1.0500 Model_2_loss: 1.0240 Model_1_trainacc: 0.4000 Model_2_trainacc: 0.5833 Model_1_val:0.4612 Model_2_val:0.4384
Epoch: 0040 Model_1_loss: 0.9267 Model_2_loss: 0.8689 Model_1_trainacc: 0.6167 Model_2_trainacc: 0.8167 Model_1_val:0.5590 Model_2_val:0.6160
Epoch: 0060 Model_1_loss: 0.7330 Model_2_loss: 0.6645 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8500 Model_1_val:0.6497 Model_2_val:0.6771
Epoch: 0080 Model_1_loss: 0.5877 Model_2_loss: 0.5733 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8333 Model_1_val:0.6933 Model_2_val:0.7125
Epoch: 0100 Model_1_loss: 0.4370 Model_2_loss: 0.4419 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9000 Model_1_val:0.7112 Model_2_val:0.7136
Epoch: 0120 Model_1_loss: 0.3690 Model_2_loss: 0.3922 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.7301 Model_2_val:0.7267
Epoch: 0140 Model_1_loss: 0.3512 Model_2_loss: 0.3263 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7390 Model_2_val:0.7316
Epoch: 0160 Model_1_loss: 0.2487 Model_2_loss: 0.2702 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7368 Model_2_val:0.7299
Epoch: 0180 Model_1_loss: 0.2459 Model_2_loss: 0.2296 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7386 Model_2_val:0.7281
Epoch: 0200 Model_1_loss: 0.2594 Model_2_loss: 0.2599 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7404 Model_2_val:0.7349
Epoch: 0220 Model_1_loss: 0.3100 Model_2_loss: 0.2717 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7722 Model_2_val:0.7778
Epoch: 0240 Model_1_loss: 0.2821 Model_2_loss: 0.2499 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7786 Model_2_val:0.7832
Epoch: 0260 Model_1_loss: 0.2509 Model_2_loss: 0.2384 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7768 Model_2_val:0.7852
Epoch: 0280 Model_1_loss: 0.2452 Model_2_loss: 0.1971 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7801 Model_2_val:0.7831
Epoch: 0300 Model_1_loss: 0.2537 Model_2_loss: 0.1834 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7792 Model_2_val:0.7808
Epoch: 0320 Model_1_loss: 0.1841 Model_2_loss: 0.1662 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7737 Model_2_val:0.7848
Epoch: 0340 Model_1_loss: 0.2040 Model_2_loss: 0.1702 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7734 Model_2_val:0.7723
Epoch: 0360 Model_1_loss: 0.1895 Model_2_loss: 0.1881 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7740 Model_2_val:0.7818
Epoch: 0380 Model_1_loss: 0.2039 Model_2_loss: 0.2075 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7796 Model_2_val:0.7740
Epoch: 0400 Model_1_loss: 0.1868 Model_2_loss: 0.1393 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7656 Model_2_val:0.7753
Model_one_test:0.7899 Model_two_test:0.7882
added by two output: 0.7897
10
labels of each class :  [20 20 20]
t= [975 975 975]
1503585933
Epoch: 0020 Model_1_loss: 1.0446 Model_2_loss: 1.0065 Model_1_trainacc: 0.4833 Model_2_trainacc: 0.5833 Model_1_val:0.4418 Model_2_val:0.5363
Epoch: 0040 Model_1_loss: 0.8911 Model_2_loss: 0.8245 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8667 Model_1_val:0.5892 Model_2_val:0.6689
Epoch: 0060 Model_1_loss: 0.6740 Model_2_loss: 0.6224 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8333 Model_1_val:0.6559 Model_2_val:0.6924
Epoch: 0080 Model_1_loss: 0.5200 Model_2_loss: 0.4334 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.6970 Model_2_val:0.6900
Epoch: 0100 Model_1_loss: 0.4371 Model_2_loss: 0.3836 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.7070 Model_2_val:0.7002
Epoch: 0120 Model_1_loss: 0.3327 Model_2_loss: 0.3216 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7136 Model_2_val:0.7148
Epoch: 0140 Model_1_loss: 0.2726 Model_2_loss: 0.2535 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7155 Model_2_val:0.7174
Epoch: 0160 Model_1_loss: 0.2716 Model_2_loss: 0.2436 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7216 Model_2_val:0.7124
Epoch: 0180 Model_1_loss: 0.1934 Model_2_loss: 0.2276 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7137 Model_2_val:0.7198
Epoch: 0200 Model_1_loss: 0.2289 Model_2_loss: 0.2102 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7110 Model_2_val:0.7164
Epoch: 0220 Model_1_loss: 0.2789 Model_2_loss: 0.2826 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7405 Model_2_val:0.7447
Epoch: 0240 Model_1_loss: 0.2134 Model_2_loss: 0.2307 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7489 Model_2_val:0.7502
Epoch: 0260 Model_1_loss: 0.1979 Model_2_loss: 0.2290 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7465 Model_2_val:0.7442
Epoch: 0280 Model_1_loss: 0.2163 Model_2_loss: 0.2062 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7448 Model_2_val:0.7476
Epoch: 0300 Model_1_loss: 0.2043 Model_2_loss: 0.1949 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7445 Model_2_val:0.7488
Epoch: 0320 Model_1_loss: 0.2053 Model_2_loss: 0.1800 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7397 Model_2_val:0.7481
Epoch: 0340 Model_1_loss: 0.1546 Model_2_loss: 0.1787 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7450 Model_2_val:0.7510
Epoch: 0360 Model_1_loss: 0.2096 Model_2_loss: 0.1650 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7391 Model_2_val:0.7465
Epoch: 0380 Model_1_loss: 0.1860 Model_2_loss: 0.1568 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7455 Model_2_val:0.7478
Epoch: 0400 Model_1_loss: 0.1783 Model_2_loss: 0.1443 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7384 Model_2_val:0.7437
Model_one_test:0.7646 Model_two_test:0.7688
added by two output: 0.7662
Model1 Acc: 0.763848 Model2 Acc: 0.765899
Maxacc Mean: 0.766669
[0.7724194482998152, 0.784036321393279, 0.7753405892386516, 0.7789860521055665, 0.780001540983086, 0.7844636490501327, 0.7676116657325908, 0.7666694514691771]
Maxacc of all experiments: 0.7844636490501327
1
labels of each class :  [20 20 20]
t= [975 975 975]
387542060
Epoch: 0020 Model_1_loss: 1.0232 Model_2_loss: 0.9983 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.6667 Model_1_val:0.5061 Model_2_val:0.5476
Epoch: 0040 Model_1_loss: 0.8348 Model_2_loss: 0.8077 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8333 Model_1_val:0.6511 Model_2_val:0.6666
Epoch: 0060 Model_1_loss: 0.6318 Model_2_loss: 0.6091 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9000 Model_1_val:0.6784 Model_2_val:0.6676
Epoch: 0080 Model_1_loss: 0.5083 Model_2_loss: 0.4541 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9000 Model_1_val:0.7037 Model_2_val:0.6874
Epoch: 0100 Model_1_loss: 0.3984 Model_2_loss: 0.3310 Model_1_trainacc: 0.8833 Model_2_trainacc: 1.0000 Model_1_val:0.7053 Model_2_val:0.7087
Epoch: 0120 Model_1_loss: 0.3184 Model_2_loss: 0.3485 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9333 Model_1_val:0.7171 Model_2_val:0.7194
Epoch: 0140 Model_1_loss: 0.3149 Model_2_loss: 0.2877 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7246 Model_2_val:0.7233
Epoch: 0160 Model_1_loss: 0.2812 Model_2_loss: 0.2582 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7288 Model_2_val:0.7139
Epoch: 0180 Model_1_loss: 0.2438 Model_2_loss: 0.2576 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.7301 Model_2_val:0.7235
Epoch: 0200 Model_1_loss: 0.2114 Model_2_loss: 0.1927 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7396 Model_2_val:0.7294
Epoch: 0220 Model_1_loss: 0.2669 Model_2_loss: 0.2958 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7515 Model_2_val:0.7520
Epoch: 0240 Model_1_loss: 0.2152 Model_2_loss: 0.2115 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7622 Model_2_val:0.7580
Epoch: 0260 Model_1_loss: 0.2007 Model_2_loss: 0.2084 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7614 Model_2_val:0.7458
Epoch: 0280 Model_1_loss: 0.1709 Model_2_loss: 0.2159 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7721 Model_2_val:0.7614
Epoch: 0300 Model_1_loss: 0.2128 Model_2_loss: 0.1589 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7628 Model_2_val:0.7594
Epoch: 0320 Model_1_loss: 0.1791 Model_2_loss: 0.1667 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7618 Model_2_val:0.7606
Epoch: 0340 Model_1_loss: 0.1872 Model_2_loss: 0.1747 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7604 Model_2_val:0.7576
Epoch: 0360 Model_1_loss: 0.1731 Model_2_loss: 0.1434 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7659 Model_2_val:0.7643
Epoch: 0380 Model_1_loss: 0.1622 Model_2_loss: 0.1336 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7685 Model_2_val:0.7665
Epoch: 0400 Model_1_loss: 0.1401 Model_2_loss: 0.1618 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7624 Model_2_val:0.7680
Model_one_test:0.7853 Model_two_test:0.7878
added by two output: 0.7860
2
labels of each class :  [20 20 20]
t= [975 975 975]
296361393
Epoch: 0020 Model_1_loss: 0.9455 Model_2_loss: 0.8731 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.8000 Model_1_val:0.5144 Model_2_val:0.5254
Epoch: 0040 Model_1_loss: 0.7045 Model_2_loss: 0.6001 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8500 Model_1_val:0.6580 Model_2_val:0.6570
Epoch: 0060 Model_1_loss: 0.5426 Model_2_loss: 0.4691 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9167 Model_1_val:0.6855 Model_2_val:0.6995
Epoch: 0080 Model_1_loss: 0.3968 Model_2_loss: 0.3210 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9833 Model_1_val:0.7117 Model_2_val:0.7142
Epoch: 0100 Model_1_loss: 0.3521 Model_2_loss: 0.3008 Model_1_trainacc: 0.9333 Model_2_trainacc: 1.0000 Model_1_val:0.7246 Model_2_val:0.7332
Epoch: 0120 Model_1_loss: 0.2890 Model_2_loss: 0.3027 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7283 Model_2_val:0.7376
Epoch: 0140 Model_1_loss: 0.2544 Model_2_loss: 0.2516 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7244 Model_2_val:0.7273
Epoch: 0160 Model_1_loss: 0.2547 Model_2_loss: 0.2323 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7332 Model_2_val:0.7334
Epoch: 0180 Model_1_loss: 0.2102 Model_2_loss: 0.1975 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7341 Model_2_val:0.7250
Epoch: 0200 Model_1_loss: 0.1895 Model_2_loss: 0.1928 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7261 Model_2_val:0.7352
Epoch: 0220 Model_1_loss: 0.2176 Model_2_loss: 0.2454 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7576 Model_2_val:0.7614
Epoch: 0240 Model_1_loss: 0.2178 Model_2_loss: 0.1696 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7503 Model_2_val:0.7596
Epoch: 0260 Model_1_loss: 0.2150 Model_2_loss: 0.1860 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7616 Model_2_val:0.7683
Epoch: 0280 Model_1_loss: 0.1912 Model_2_loss: 0.1678 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7525 Model_2_val:0.7624
Epoch: 0300 Model_1_loss: 0.1979 Model_2_loss: 0.1635 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7523 Model_2_val:0.7636
Epoch: 0320 Model_1_loss: 0.1843 Model_2_loss: 0.1721 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7612 Model_2_val:0.7645
Epoch: 0340 Model_1_loss: 0.1722 Model_2_loss: 0.1501 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7580 Model_2_val:0.7636
Epoch: 0360 Model_1_loss: 0.1580 Model_2_loss: 0.1491 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7546 Model_2_val:0.7597
Epoch: 0380 Model_1_loss: 0.1595 Model_2_loss: 0.1601 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7572 Model_2_val:0.7590
Epoch: 0400 Model_1_loss: 0.1628 Model_2_loss: 0.1709 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7581 Model_2_val:0.7608
Model_one_test:0.7817 Model_two_test:0.7830
added by two output: 0.7825
3
labels of each class :  [20 20 20]
t= [975 975 975]
642100786
Epoch: 0020 Model_1_loss: 1.0353 Model_2_loss: 1.0421 Model_1_trainacc: 0.4833 Model_2_trainacc: 0.5167 Model_1_val:0.4300 Model_2_val:0.4864
Epoch: 0040 Model_1_loss: 0.9160 Model_2_loss: 0.8571 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.8167 Model_1_val:0.5699 Model_2_val:0.6041
Epoch: 0060 Model_1_loss: 0.7249 Model_2_loss: 0.6244 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9167 Model_1_val:0.6585 Model_2_val:0.6876
Epoch: 0080 Model_1_loss: 0.5510 Model_2_loss: 0.5229 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8667 Model_1_val:0.6827 Model_2_val:0.7138
Epoch: 0100 Model_1_loss: 0.3942 Model_2_loss: 0.3957 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9333 Model_1_val:0.7210 Model_2_val:0.7152
Epoch: 0120 Model_1_loss: 0.3170 Model_2_loss: 0.3496 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.7209 Model_2_val:0.7233
Epoch: 0140 Model_1_loss: 0.3118 Model_2_loss: 0.2549 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7351 Model_2_val:0.7290
Epoch: 0160 Model_1_loss: 0.2488 Model_2_loss: 0.2673 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7423 Model_2_val:0.7405
Epoch: 0180 Model_1_loss: 0.2161 Model_2_loss: 0.2455 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7488 Model_2_val:0.7418
Epoch: 0200 Model_1_loss: 0.2071 Model_2_loss: 0.2156 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7361 Model_2_val:0.7400
Epoch: 0220 Model_1_loss: 0.2816 Model_2_loss: 0.2652 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7575 Model_2_val:0.7576
Epoch: 0240 Model_1_loss: 0.2045 Model_2_loss: 0.2544 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7659 Model_2_val:0.7590
Epoch: 0260 Model_1_loss: 0.1741 Model_2_loss: 0.2305 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7648 Model_2_val:0.7618
Epoch: 0280 Model_1_loss: 0.1831 Model_2_loss: 0.2298 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7669 Model_2_val:0.7639
Epoch: 0300 Model_1_loss: 0.1618 Model_2_loss: 0.2004 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7706 Model_2_val:0.7698
Epoch: 0320 Model_1_loss: 0.1800 Model_2_loss: 0.1494 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7716 Model_2_val:0.7670
Epoch: 0340 Model_1_loss: 0.2146 Model_2_loss: 0.1497 Model_1_trainacc: 0.9333 Model_2_trainacc: 1.0000 Model_1_val:0.7808 Model_2_val:0.7673
Epoch: 0360 Model_1_loss: 0.1490 Model_2_loss: 0.1597 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7700 Model_2_val:0.7732
Epoch: 0380 Model_1_loss: 0.1329 Model_2_loss: 0.1271 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7796 Model_2_val:0.7776
Epoch: 0400 Model_1_loss: 0.1514 Model_2_loss: 0.1197 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7749 Model_2_val:0.7777
Model_one_test:0.7977 Model_two_test:0.7957
added by two output: 0.7961
4
labels of each class :  [20 20 20]
t= [975 975 975]
841969949
Epoch: 0020 Model_1_loss: 1.0102 Model_2_loss: 0.9556 Model_1_trainacc: 0.6333 Model_2_trainacc: 0.7667 Model_1_val:0.4769 Model_2_val:0.5349
Epoch: 0040 Model_1_loss: 0.7952 Model_2_loss: 0.7642 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8333 Model_1_val:0.6666 Model_2_val:0.6718
Epoch: 0060 Model_1_loss: 0.5267 Model_2_loss: 0.5219 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.7105 Model_2_val:0.7135
Epoch: 0080 Model_1_loss: 0.4171 Model_2_loss: 0.3498 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9833 Model_1_val:0.7442 Model_2_val:0.7360
Epoch: 0100 Model_1_loss: 0.3162 Model_2_loss: 0.3200 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7548 Model_2_val:0.7502
Epoch: 0120 Model_1_loss: 0.2443 Model_2_loss: 0.3113 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7595 Model_2_val:0.7516
Epoch: 0140 Model_1_loss: 0.2185 Model_2_loss: 0.2132 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7622 Model_2_val:0.7648
Epoch: 0160 Model_1_loss: 0.2017 Model_2_loss: 0.2745 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9333 Model_1_val:0.7673 Model_2_val:0.7687
Epoch: 0180 Model_1_loss: 0.1840 Model_2_loss: 0.2319 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7676 Model_2_val:0.7689
Epoch: 0200 Model_1_loss: 0.1972 Model_2_loss: 0.1595 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7712 Model_2_val:0.7746
Epoch: 0220 Model_1_loss: 0.2034 Model_2_loss: 0.2047 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7738 Model_2_val:0.7740
Epoch: 0240 Model_1_loss: 0.1816 Model_2_loss: 0.2145 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7773 Model_2_val:0.7810
Epoch: 0260 Model_1_loss: 0.1817 Model_2_loss: 0.1584 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7787 Model_2_val:0.7795
Epoch: 0280 Model_1_loss: 0.1515 Model_2_loss: 0.1756 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7819 Model_2_val:0.7887
Epoch: 0300 Model_1_loss: 0.1540 Model_2_loss: 0.1605 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7830 Model_2_val:0.7865
Epoch: 0320 Model_1_loss: 0.1557 Model_2_loss: 0.1597 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7824 Model_2_val:0.7855
Epoch: 0340 Model_1_loss: 0.1194 Model_2_loss: 0.1732 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7892 Model_2_val:0.7898
Epoch: 0360 Model_1_loss: 0.1466 Model_2_loss: 0.1629 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7863 Model_2_val:0.7910
Epoch: 0380 Model_1_loss: 0.1314 Model_2_loss: 0.1648 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7829 Model_2_val:0.7788
Epoch: 0400 Model_1_loss: 0.1291 Model_2_loss: 0.1643 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7873 Model_2_val:0.7902
Model_one_test:0.8072 Model_two_test:0.8117
added by two output: 0.8102
5
labels of each class :  [20 20 20]
t= [975 975 975]
1253568785
Epoch: 0020 Model_1_loss: 0.9425 Model_2_loss: 1.0430 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.5500 Model_1_val:0.6139 Model_2_val:0.5025
Epoch: 0040 Model_1_loss: 0.6545 Model_2_loss: 0.8317 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.7667 Model_1_val:0.6454 Model_2_val:0.6045
Epoch: 0060 Model_1_loss: 0.4923 Model_2_loss: 0.5732 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.6801 Model_2_val:0.6514
Epoch: 0080 Model_1_loss: 0.3569 Model_2_loss: 0.4592 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9333 Model_1_val:0.6974 Model_2_val:0.6901
Epoch: 0100 Model_1_loss: 0.2940 Model_2_loss: 0.3422 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9333 Model_1_val:0.7097 Model_2_val:0.6990
Epoch: 0120 Model_1_loss: 0.2759 Model_2_loss: 0.2534 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7152 Model_2_val:0.7065
Epoch: 0140 Model_1_loss: 0.2006 Model_2_loss: 0.2308 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7186 Model_2_val:0.7177
Epoch: 0160 Model_1_loss: 0.2093 Model_2_loss: 0.2254 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7221 Model_2_val:0.7108
Epoch: 0180 Model_1_loss: 0.1705 Model_2_loss: 0.1668 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7259 Model_2_val:0.7222
Epoch: 0200 Model_1_loss: 0.1626 Model_2_loss: 0.1561 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7168 Model_2_val:0.7227
Epoch: 0220 Model_1_loss: 0.2407 Model_2_loss: 0.2422 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.7419 Model_2_val:0.7369
Epoch: 0240 Model_1_loss: 0.1643 Model_2_loss: 0.1800 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7523 Model_2_val:0.7474
Epoch: 0260 Model_1_loss: 0.1938 Model_2_loss: 0.1564 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7527 Model_2_val:0.7487
Epoch: 0280 Model_1_loss: 0.1834 Model_2_loss: 0.1531 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7509 Model_2_val:0.7630
Epoch: 0300 Model_1_loss: 0.1627 Model_2_loss: 0.1786 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7522 Model_2_val:0.7532
Epoch: 0320 Model_1_loss: 0.1610 Model_2_loss: 0.1642 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7525 Model_2_val:0.7527
Epoch: 0340 Model_1_loss: 0.1431 Model_2_loss: 0.1745 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7531 Model_2_val:0.7502
Epoch: 0360 Model_1_loss: 0.1191 Model_2_loss: 0.1418 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7567 Model_2_val:0.7579
Epoch: 0380 Model_1_loss: 0.1215 Model_2_loss: 0.1217 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7579 Model_2_val:0.7561
Epoch: 0400 Model_1_loss: 0.1130 Model_2_loss: 0.1325 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7516 Model_2_val:0.7552
Model_one_test:0.7748 Model_two_test:0.7718
added by two output: 0.7730
6
labels of each class :  [20 20 20]
t= [975 975 975]
604036910
Epoch: 0020 Model_1_loss: 1.0384 Model_2_loss: 1.0025 Model_1_trainacc: 0.5667 Model_2_trainacc: 0.6000 Model_1_val:0.5068 Model_2_val:0.5090
Epoch: 0040 Model_1_loss: 0.7975 Model_2_loss: 0.8570 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8167 Model_1_val:0.6134 Model_2_val:0.6266
Epoch: 0060 Model_1_loss: 0.6036 Model_2_loss: 0.6389 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8500 Model_1_val:0.7122 Model_2_val:0.6644
Epoch: 0080 Model_1_loss: 0.4287 Model_2_loss: 0.5280 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.8333 Model_1_val:0.7358 Model_2_val:0.7108
Epoch: 0100 Model_1_loss: 0.3253 Model_2_loss: 0.4758 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.8667 Model_1_val:0.7446 Model_2_val:0.7338
Epoch: 0120 Model_1_loss: 0.2830 Model_2_loss: 0.3602 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7579 Model_2_val:0.7340
Epoch: 0140 Model_1_loss: 0.2803 Model_2_loss: 0.3173 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7513 Model_2_val:0.7353
Epoch: 0160 Model_1_loss: 0.2615 Model_2_loss: 0.2519 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7583 Model_2_val:0.7407
Epoch: 0180 Model_1_loss: 0.2044 Model_2_loss: 0.2307 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7532 Model_2_val:0.7468
Epoch: 0200 Model_1_loss: 0.1803 Model_2_loss: 0.2446 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7545 Model_2_val:0.7462
Epoch: 0220 Model_1_loss: 0.2380 Model_2_loss: 0.3241 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7737 Model_2_val:0.7607
Epoch: 0240 Model_1_loss: 0.2204 Model_2_loss: 0.2606 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7755 Model_2_val:0.7643
Epoch: 0260 Model_1_loss: 0.1957 Model_2_loss: 0.2453 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7704 Model_2_val:0.7688
Epoch: 0280 Model_1_loss: 0.2197 Model_2_loss: 0.2038 Model_1_trainacc: 0.9500 Model_2_trainacc: 1.0000 Model_1_val:0.7705 Model_2_val:0.7651
Epoch: 0300 Model_1_loss: 0.1768 Model_2_loss: 0.2382 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7699 Model_2_val:0.7690
Epoch: 0320 Model_1_loss: 0.1829 Model_2_loss: 0.2714 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9333 Model_1_val:0.7698 Model_2_val:0.7636
Epoch: 0340 Model_1_loss: 0.1333 Model_2_loss: 0.1722 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7678 Model_2_val:0.7731
Epoch: 0360 Model_1_loss: 0.1769 Model_2_loss: 0.2040 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7669 Model_2_val:0.7661
Epoch: 0380 Model_1_loss: 0.1457 Model_2_loss: 0.2079 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7671 Model_2_val:0.7708
Epoch: 0400 Model_1_loss: 0.1505 Model_2_loss: 0.1847 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7729 Model_2_val:0.7699
Model_one_test:0.7904 Model_two_test:0.7929
added by two output: 0.7911
7
labels of each class :  [20 20 20]
t= [975 975 975]
584436397
Epoch: 0020 Model_1_loss: 0.9966 Model_2_loss: 0.9982 Model_1_trainacc: 0.6000 Model_2_trainacc: 0.6833 Model_1_val:0.5571 Model_2_val:0.5703
Epoch: 0040 Model_1_loss: 0.7846 Model_2_loss: 0.7994 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8333 Model_1_val:0.6418 Model_2_val:0.6356
Epoch: 0060 Model_1_loss: 0.5652 Model_2_loss: 0.5802 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8833 Model_1_val:0.6791 Model_2_val:0.6751
Epoch: 0080 Model_1_loss: 0.4732 Model_2_loss: 0.4590 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9667 Model_1_val:0.7070 Model_2_val:0.7108
Epoch: 0100 Model_1_loss: 0.3566 Model_2_loss: 0.3565 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7161 Model_2_val:0.7290
Epoch: 0120 Model_1_loss: 0.3276 Model_2_loss: 0.2918 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.7273 Model_2_val:0.7300
Epoch: 0140 Model_1_loss: 0.2632 Model_2_loss: 0.2932 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9167 Model_1_val:0.7250 Model_2_val:0.7369
Epoch: 0160 Model_1_loss: 0.2575 Model_2_loss: 0.2148 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7393 Model_2_val:0.7377
Epoch: 0180 Model_1_loss: 0.2548 Model_2_loss: 0.2102 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7343 Model_2_val:0.7441
Epoch: 0200 Model_1_loss: 0.2114 Model_2_loss: 0.2183 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7386 Model_2_val:0.7443
Epoch: 0220 Model_1_loss: 0.2446 Model_2_loss: 0.2567 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7528 Model_2_val:0.7506
Epoch: 0240 Model_1_loss: 0.1997 Model_2_loss: 0.1942 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7508 Model_2_val:0.7590
Epoch: 0260 Model_1_loss: 0.2094 Model_2_loss: 0.2216 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7557 Model_2_val:0.7568
Epoch: 0280 Model_1_loss: 0.2030 Model_2_loss: 0.1966 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7601 Model_2_val:0.7621
Epoch: 0300 Model_1_loss: 0.1757 Model_2_loss: 0.2285 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7592 Model_2_val:0.7608
Epoch: 0320 Model_1_loss: 0.1924 Model_2_loss: 0.1502 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7645 Model_2_val:0.7636
Epoch: 0340 Model_1_loss: 0.1737 Model_2_loss: 0.1958 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7751 Model_2_val:0.7631
Epoch: 0360 Model_1_loss: 0.1775 Model_2_loss: 0.1910 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7651 Model_2_val:0.7622
Epoch: 0380 Model_1_loss: 0.1227 Model_2_loss: 0.1734 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7523 Model_2_val:0.7726
Epoch: 0400 Model_1_loss: 0.1424 Model_2_loss: 0.1819 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7681 Model_2_val:0.7689
Model_one_test:0.7889 Model_two_test:0.7903
added by two output: 0.7890
8
labels of each class :  [20 20 20]
t= [975 975 975]
1113013745
Epoch: 0020 Model_1_loss: 1.0203 Model_2_loss: 1.0556 Model_1_trainacc: 0.7000 Model_2_trainacc: 0.4667 Model_1_val:0.6282 Model_2_val:0.4022
Epoch: 0040 Model_1_loss: 0.7465 Model_2_loss: 0.9307 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.7667 Model_1_val:0.6893 Model_2_val:0.6228
Epoch: 0060 Model_1_loss: 0.5501 Model_2_loss: 0.7208 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8833 Model_1_val:0.7173 Model_2_val:0.6666
Epoch: 0080 Model_1_loss: 0.3417 Model_2_loss: 0.4898 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.7377 Model_2_val:0.7044
Epoch: 0100 Model_1_loss: 0.2906 Model_2_loss: 0.3754 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.7457 Model_2_val:0.7268
Epoch: 0120 Model_1_loss: 0.2501 Model_2_loss: 0.3000 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7588 Model_2_val:0.7390
Epoch: 0140 Model_1_loss: 0.1952 Model_2_loss: 0.2555 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7598 Model_2_val:0.7452
Epoch: 0160 Model_1_loss: 0.2017 Model_2_loss: 0.1880 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7625 Model_2_val:0.7459
Epoch: 0180 Model_1_loss: 0.1569 Model_2_loss: 0.1907 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7664 Model_2_val:0.7594
Epoch: 0200 Model_1_loss: 0.1646 Model_2_loss: 0.1859 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7639 Model_2_val:0.7600
Epoch: 0220 Model_1_loss: 0.2082 Model_2_loss: 0.2057 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7668 Model_2_val:0.7591
Epoch: 0240 Model_1_loss: 0.1664 Model_2_loss: 0.1757 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7720 Model_2_val:0.7672
Epoch: 0260 Model_1_loss: 0.1745 Model_2_loss: 0.1693 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7676 Model_2_val:0.7635
Epoch: 0280 Model_1_loss: 0.1766 Model_2_loss: 0.2164 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7752 Model_2_val:0.7678
Epoch: 0300 Model_1_loss: 0.1352 Model_2_loss: 0.2105 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7708 Model_2_val:0.7778
Epoch: 0320 Model_1_loss: 0.1232 Model_2_loss: 0.1538 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7745 Model_2_val:0.7764
Epoch: 0340 Model_1_loss: 0.1219 Model_2_loss: 0.1526 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7740 Model_2_val:0.7742
Epoch: 0360 Model_1_loss: 0.1565 Model_2_loss: 0.1367 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7740 Model_2_val:0.7729
Epoch: 0380 Model_1_loss: 0.1155 Model_2_loss: 0.1216 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7779 Model_2_val:0.7732
Epoch: 0400 Model_1_loss: 0.1184 Model_2_loss: 0.1261 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7741 Model_2_val:0.7759
Model_one_test:0.7917 Model_two_test:0.7932
added by two output: 0.7921
9
labels of each class :  [20 20 20]
t= [975 975 975]
909266070
Epoch: 0020 Model_1_loss: 1.0045 Model_2_loss: 0.9858 Model_1_trainacc: 0.6833 Model_2_trainacc: 0.6833 Model_1_val:0.5632 Model_2_val:0.5717
Epoch: 0040 Model_1_loss: 0.8122 Model_2_loss: 0.8037 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8000 Model_1_val:0.6713 Model_2_val:0.6605
Epoch: 0060 Model_1_loss: 0.5962 Model_2_loss: 0.6095 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8667 Model_1_val:0.7365 Model_2_val:0.7041
Epoch: 0080 Model_1_loss: 0.4332 Model_2_loss: 0.4890 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.7485 Model_2_val:0.7354
Epoch: 0100 Model_1_loss: 0.3825 Model_2_loss: 0.4090 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.7502 Model_2_val:0.7426
Epoch: 0120 Model_1_loss: 0.2586 Model_2_loss: 0.3457 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7552 Model_2_val:0.7554
Epoch: 0140 Model_1_loss: 0.2892 Model_2_loss: 0.2748 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7662 Model_2_val:0.7523
Epoch: 0160 Model_1_loss: 0.2311 Model_2_loss: 0.2463 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7576 Model_2_val:0.7542
Epoch: 0180 Model_1_loss: 0.2415 Model_2_loss: 0.2461 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7597 Model_2_val:0.7443
Epoch: 0200 Model_1_loss: 0.2200 Model_2_loss: 0.2855 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7573 Model_2_val:0.7507
Epoch: 0220 Model_1_loss: 0.2508 Model_2_loss: 0.2738 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7674 Model_2_val:0.7690
Epoch: 0240 Model_1_loss: 0.2305 Model_2_loss: 0.2633 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7774 Model_2_val:0.7824
Epoch: 0260 Model_1_loss: 0.2392 Model_2_loss: 0.2169 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7644 Model_2_val:0.7812
Epoch: 0280 Model_1_loss: 0.2103 Model_2_loss: 0.2343 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7725 Model_2_val:0.7808
Epoch: 0300 Model_1_loss: 0.2200 Model_2_loss: 0.2274 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7736 Model_2_val:0.7734
Epoch: 0320 Model_1_loss: 0.2005 Model_2_loss: 0.2095 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7748 Model_2_val:0.7788
Epoch: 0340 Model_1_loss: 0.2139 Model_2_loss: 0.2107 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7837 Model_2_val:0.7844
Epoch: 0360 Model_1_loss: 0.1623 Model_2_loss: 0.1953 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7751 Model_2_val:0.7800
Epoch: 0380 Model_1_loss: 0.1571 Model_2_loss: 0.1527 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7740 Model_2_val:0.7804
Epoch: 0400 Model_1_loss: 0.1832 Model_2_loss: 0.1725 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7782 Model_2_val:0.7799
Model_one_test:0.7889 Model_two_test:0.7996
added by two output: 0.7956
10
labels of each class :  [20 20 20]
t= [975 975 975]
554665081
Epoch: 0020 Model_1_loss: 0.9918 Model_2_loss: 0.9674 Model_1_trainacc: 0.5167 Model_2_trainacc: 0.6500 Model_1_val:0.4474 Model_2_val:0.4838
Epoch: 0040 Model_1_loss: 0.8431 Model_2_loss: 0.7692 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.8333 Model_1_val:0.5820 Model_2_val:0.6101
Epoch: 0060 Model_1_loss: 0.6328 Model_2_loss: 0.6031 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.9167 Model_1_val:0.6467 Model_2_val:0.6618
Epoch: 0080 Model_1_loss: 0.5047 Model_2_loss: 0.4408 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9667 Model_1_val:0.6730 Model_2_val:0.6866
Epoch: 0100 Model_1_loss: 0.3571 Model_2_loss: 0.3054 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6965 Model_2_val:0.7177
Epoch: 0120 Model_1_loss: 0.2825 Model_2_loss: 0.2902 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7018 Model_2_val:0.7261
Epoch: 0140 Model_1_loss: 0.2510 Model_2_loss: 0.2425 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7241 Model_2_val:0.7262
Epoch: 0160 Model_1_loss: 0.2531 Model_2_loss: 0.2140 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7275 Model_2_val:0.7309
Epoch: 0180 Model_1_loss: 0.2212 Model_2_loss: 0.1789 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7340 Model_2_val:0.7358
Epoch: 0200 Model_1_loss: 0.1632 Model_2_loss: 0.1737 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7275 Model_2_val:0.7380
Epoch: 0220 Model_1_loss: 0.2783 Model_2_loss: 0.2295 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7432 Model_2_val:0.7472
Epoch: 0240 Model_1_loss: 0.1458 Model_2_loss: 0.1879 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7515 Model_2_val:0.7534
Epoch: 0260 Model_1_loss: 0.1719 Model_2_loss: 0.1490 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7522 Model_2_val:0.7517
Epoch: 0280 Model_1_loss: 0.1943 Model_2_loss: 0.1450 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7538 Model_2_val:0.7586
Epoch: 0300 Model_1_loss: 0.1380 Model_2_loss: 0.1422 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7540 Model_2_val:0.7572
Epoch: 0320 Model_1_loss: 0.1492 Model_2_loss: 0.1561 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7542 Model_2_val:0.7563
Epoch: 0340 Model_1_loss: 0.1341 Model_2_loss: 0.1372 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7529 Model_2_val:0.7580
Epoch: 0360 Model_1_loss: 0.1318 Model_2_loss: 0.1462 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7580 Model_2_val:0.7592
Epoch: 0380 Model_1_loss: 0.1113 Model_2_loss: 0.1188 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7553 Model_2_val:0.7592
Epoch: 0400 Model_1_loss: 0.1232 Model_2_loss: 0.1313 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7573 Model_2_val:0.7553
Model_one_test:0.7742 Model_two_test:0.7677
added by two output: 0.7717
Model1 Acc: 0.788073 Model2 Acc: 0.789368
Maxacc Mean: 0.790508
[0.7724194482998152, 0.784036321393279, 0.7753405892386516, 0.7789860521055665, 0.780001540983086, 0.7844636490501327, 0.7676116657325908, 0.7666694514691771, 0.7905084294930736]
Maxacc of all experiments: 0.7905084294930736
1
labels of each class :  [20 20 20]
t= [975 975 975]
711031100
Epoch: 0020 Model_1_loss: 1.0129 Model_2_loss: 1.0375 Model_1_trainacc: 0.5667 Model_2_trainacc: 0.7167 Model_1_val:0.5762 Model_2_val:0.5825
Epoch: 0040 Model_1_loss: 0.7954 Model_2_loss: 0.8928 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8167 Model_1_val:0.6954 Model_2_val:0.6653
Epoch: 0060 Model_1_loss: 0.6097 Model_2_loss: 0.7158 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8833 Model_1_val:0.7273 Model_2_val:0.7010
Epoch: 0080 Model_1_loss: 0.4680 Model_2_loss: 0.5442 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8833 Model_1_val:0.7371 Model_2_val:0.7199
Epoch: 0100 Model_1_loss: 0.3432 Model_2_loss: 0.3985 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7428 Model_2_val:0.7301
Epoch: 0120 Model_1_loss: 0.2959 Model_2_loss: 0.3661 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.7417 Model_2_val:0.7316
Epoch: 0140 Model_1_loss: 0.2519 Model_2_loss: 0.3414 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7427 Model_2_val:0.7396
Epoch: 0160 Model_1_loss: 0.2149 Model_2_loss: 0.2704 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7499 Model_2_val:0.7415
Epoch: 0180 Model_1_loss: 0.2168 Model_2_loss: 0.2590 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7489 Model_2_val:0.7396
Epoch: 0200 Model_1_loss: 0.2098 Model_2_loss: 0.2336 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7498 Model_2_val:0.7443
Epoch: 0220 Model_1_loss: 0.2771 Model_2_loss: 0.3475 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9333 Model_1_val:0.7654 Model_2_val:0.7480
Epoch: 0240 Model_1_loss: 0.2251 Model_2_loss: 0.2436 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7753 Model_2_val:0.7661
Epoch: 0260 Model_1_loss: 0.1941 Model_2_loss: 0.2482 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7771 Model_2_val:0.7599
Epoch: 0280 Model_1_loss: 0.2252 Model_2_loss: 0.2158 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7778 Model_2_val:0.7652
Epoch: 0300 Model_1_loss: 0.1904 Model_2_loss: 0.2008 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7804 Model_2_val:0.7660
Epoch: 0320 Model_1_loss: 0.1956 Model_2_loss: 0.2510 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7820 Model_2_val:0.7674
Epoch: 0340 Model_1_loss: 0.1713 Model_2_loss: 0.2089 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7732 Model_2_val:0.7664
Epoch: 0360 Model_1_loss: 0.1569 Model_2_loss: 0.2210 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7813 Model_2_val:0.7790
Epoch: 0380 Model_1_loss: 0.1470 Model_2_loss: 0.1559 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7772 Model_2_val:0.7728
Epoch: 0400 Model_1_loss: 0.1364 Model_2_loss: 0.2276 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9333 Model_1_val:0.7734 Model_2_val:0.7664
Model_one_test:0.7943 Model_two_test:0.7925
added by two output: 0.7936
2
labels of each class :  [20 20 20]
t= [975 975 975]
853964813
Epoch: 0020 Model_1_loss: 1.0063 Model_2_loss: 1.0302 Model_1_trainacc: 0.6167 Model_2_trainacc: 0.5667 Model_1_val:0.5325 Model_2_val:0.4949
Epoch: 0040 Model_1_loss: 0.8013 Model_2_loss: 0.8716 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.7000 Model_1_val:0.5999 Model_2_val:0.5407
Epoch: 0060 Model_1_loss: 0.5899 Model_2_loss: 0.6193 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8500 Model_1_val:0.6732 Model_2_val:0.6408
Epoch: 0080 Model_1_loss: 0.4468 Model_2_loss: 0.4711 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9000 Model_1_val:0.7161 Model_2_val:0.6988
Epoch: 0100 Model_1_loss: 0.3817 Model_2_loss: 0.3478 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9833 Model_1_val:0.7309 Model_2_val:0.7120
Epoch: 0120 Model_1_loss: 0.2833 Model_2_loss: 0.2589 Model_1_trainacc: 0.9500 Model_2_trainacc: 1.0000 Model_1_val:0.7450 Model_2_val:0.7375
Epoch: 0140 Model_1_loss: 0.2390 Model_2_loss: 0.2224 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7559 Model_2_val:0.7497
Epoch: 0160 Model_1_loss: 0.2051 Model_2_loss: 0.2419 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7455 Model_2_val:0.7508
Epoch: 0180 Model_1_loss: 0.2050 Model_2_loss: 0.1968 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7581 Model_2_val:0.7533
Epoch: 0200 Model_1_loss: 0.1649 Model_2_loss: 0.2075 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7573 Model_2_val:0.7519
Epoch: 0220 Model_1_loss: 0.2143 Model_2_loss: 0.2585 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7803 Model_2_val:0.7851
Epoch: 0240 Model_1_loss: 0.1777 Model_2_loss: 0.1939 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7821 Model_2_val:0.7851
Epoch: 0260 Model_1_loss: 0.1698 Model_2_loss: 0.1830 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7819 Model_2_val:0.7819
Epoch: 0280 Model_1_loss: 0.1662 Model_2_loss: 0.1896 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7908 Model_2_val:0.7842
Epoch: 0300 Model_1_loss: 0.1572 Model_2_loss: 0.1520 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7853 Model_2_val:0.7869
Epoch: 0320 Model_1_loss: 0.1511 Model_2_loss: 0.1658 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7866 Model_2_val:0.7871
Epoch: 0340 Model_1_loss: 0.1513 Model_2_loss: 0.1255 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7891 Model_2_val:0.7916
Epoch: 0360 Model_1_loss: 0.1231 Model_2_loss: 0.1285 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7869 Model_2_val:0.7812
Epoch: 0380 Model_1_loss: 0.1145 Model_2_loss: 0.1710 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7898 Model_2_val:0.7835
Epoch: 0400 Model_1_loss: 0.1335 Model_2_loss: 0.1245 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7808 Model_2_val:0.7810
Model_one_test:0.7984 Model_two_test:0.8019
added by two output: 0.7991
3
labels of each class :  [20 20 20]
t= [975 975 975]
702539516
Epoch: 0020 Model_1_loss: 0.9920 Model_2_loss: 1.0513 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.5333 Model_1_val:0.6096 Model_2_val:0.5006
Epoch: 0040 Model_1_loss: 0.7798 Model_2_loss: 0.8703 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8333 Model_1_val:0.6845 Model_2_val:0.6517
Epoch: 0060 Model_1_loss: 0.4711 Model_2_loss: 0.6512 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.8333 Model_1_val:0.7167 Model_2_val:0.6868
Epoch: 0080 Model_1_loss: 0.3507 Model_2_loss: 0.4795 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.7481 Model_2_val:0.7147
Epoch: 0100 Model_1_loss: 0.3250 Model_2_loss: 0.3621 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.7620 Model_2_val:0.7398
Epoch: 0120 Model_1_loss: 0.2066 Model_2_loss: 0.3194 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7689 Model_2_val:0.7473
Epoch: 0140 Model_1_loss: 0.1810 Model_2_loss: 0.2463 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7655 Model_2_val:0.7524
Epoch: 0160 Model_1_loss: 0.1640 Model_2_loss: 0.2087 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7738 Model_2_val:0.7626
Epoch: 0180 Model_1_loss: 0.1513 Model_2_loss: 0.2011 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7655 Model_2_val:0.7647
Epoch: 0200 Model_1_loss: 0.1801 Model_2_loss: 0.1801 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7769 Model_2_val:0.7685
Epoch: 0220 Model_1_loss: 0.1798 Model_2_loss: 0.2452 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7784 Model_2_val:0.7702
Epoch: 0240 Model_1_loss: 0.1680 Model_2_loss: 0.1883 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7811 Model_2_val:0.7726
Epoch: 0260 Model_1_loss: 0.1775 Model_2_loss: 0.1905 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7796 Model_2_val:0.7791
Epoch: 0280 Model_1_loss: 0.1705 Model_2_loss: 0.2079 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7816 Model_2_val:0.7748
Epoch: 0300 Model_1_loss: 0.1605 Model_2_loss: 0.1711 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7801 Model_2_val:0.7768
Epoch: 0320 Model_1_loss: 0.1474 Model_2_loss: 0.1619 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7784 Model_2_val:0.7763
Epoch: 0340 Model_1_loss: 0.1206 Model_2_loss: 0.1624 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7812 Model_2_val:0.7800
Epoch: 0360 Model_1_loss: 0.1186 Model_2_loss: 0.1754 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7806 Model_2_val:0.7709
Epoch: 0380 Model_1_loss: 0.1485 Model_2_loss: 0.1350 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7817 Model_2_val:0.7799
Epoch: 0400 Model_1_loss: 0.1184 Model_2_loss: 0.1405 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7832 Model_2_val:0.7743
Model_one_test:0.7960 Model_two_test:0.7934
added by two output: 0.7952
4
labels of each class :  [20 20 20]
t= [975 975 975]
459744295
Epoch: 0020 Model_1_loss: 1.0464 Model_2_loss: 1.0025 Model_1_trainacc: 0.5500 Model_2_trainacc: 0.6667 Model_1_val:0.4574 Model_2_val:0.4743
Epoch: 0040 Model_1_loss: 0.8484 Model_2_loss: 0.8154 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8000 Model_1_val:0.6268 Model_2_val:0.6488
Epoch: 0060 Model_1_loss: 0.6223 Model_2_loss: 0.5878 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9500 Model_1_val:0.6623 Model_2_val:0.6794
Epoch: 0080 Model_1_loss: 0.4569 Model_2_loss: 0.4461 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.6975 Model_2_val:0.7093
Epoch: 0100 Model_1_loss: 0.3919 Model_2_loss: 0.4148 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.7296 Model_2_val:0.7345
Epoch: 0120 Model_1_loss: 0.3240 Model_2_loss: 0.2861 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7245 Model_2_val:0.7348
Epoch: 0140 Model_1_loss: 0.2265 Model_2_loss: 0.3143 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7401 Model_2_val:0.7413
Epoch: 0160 Model_1_loss: 0.2445 Model_2_loss: 0.3061 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.7517 Model_2_val:0.7441
Epoch: 0180 Model_1_loss: 0.2012 Model_2_loss: 0.2299 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7503 Model_2_val:0.7438
Epoch: 0200 Model_1_loss: 0.1692 Model_2_loss: 0.2068 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7601 Model_2_val:0.7524
Epoch: 0220 Model_1_loss: 0.2601 Model_2_loss: 0.2221 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7636 Model_2_val:0.7561
Epoch: 0240 Model_1_loss: 0.1922 Model_2_loss: 0.1847 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7611 Model_2_val:0.7667
Epoch: 0260 Model_1_loss: 0.1922 Model_2_loss: 0.1604 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7542 Model_2_val:0.7680
Epoch: 0280 Model_1_loss: 0.1848 Model_2_loss: 0.1659 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7608 Model_2_val:0.7751
Epoch: 0300 Model_1_loss: 0.1998 Model_2_loss: 0.2021 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7550 Model_2_val:0.7677
Epoch: 0320 Model_1_loss: 0.1510 Model_2_loss: 0.1662 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7678 Model_2_val:0.7704
Epoch: 0340 Model_1_loss: 0.1563 Model_2_loss: 0.1313 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7656 Model_2_val:0.7749
Epoch: 0360 Model_1_loss: 0.1659 Model_2_loss: 0.1177 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7632 Model_2_val:0.7736
Epoch: 0380 Model_1_loss: 0.1443 Model_2_loss: 0.1655 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7548 Model_2_val:0.7695
Epoch: 0400 Model_1_loss: 0.1428 Model_2_loss: 0.1667 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7648 Model_2_val:0.7822
Model_one_test:0.7879 Model_two_test:0.7961
added by two output: 0.7929
5
labels of each class :  [20 20 20]
t= [975 975 975]
772287808
Epoch: 0020 Model_1_loss: 1.0250 Model_2_loss: 1.0344 Model_1_trainacc: 0.5833 Model_2_trainacc: 0.6333 Model_1_val:0.4936 Model_2_val:0.5196
Epoch: 0040 Model_1_loss: 0.8685 Model_2_loss: 0.8433 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.7667 Model_1_val:0.5876 Model_2_val:0.5926
Epoch: 0060 Model_1_loss: 0.6617 Model_2_loss: 0.6039 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8333 Model_1_val:0.6695 Model_2_val:0.6634
Epoch: 0080 Model_1_loss: 0.4887 Model_2_loss: 0.4505 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9333 Model_1_val:0.7069 Model_2_val:0.7153
Epoch: 0100 Model_1_loss: 0.3718 Model_2_loss: 0.3215 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9667 Model_1_val:0.7365 Model_2_val:0.7432
Epoch: 0120 Model_1_loss: 0.3480 Model_2_loss: 0.3330 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.7479 Model_2_val:0.7416
Epoch: 0140 Model_1_loss: 0.2748 Model_2_loss: 0.2124 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7486 Model_2_val:0.7678
Epoch: 0160 Model_1_loss: 0.2320 Model_2_loss: 0.2255 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7563 Model_2_val:0.7680
Epoch: 0180 Model_1_loss: 0.2011 Model_2_loss: 0.2428 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.7553 Model_2_val:0.7681
Epoch: 0200 Model_1_loss: 0.2013 Model_2_loss: 0.2080 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7558 Model_2_val:0.7693
Epoch: 0220 Model_1_loss: 0.2744 Model_2_loss: 0.2222 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7860 Model_2_val:0.7893
Epoch: 0240 Model_1_loss: 0.2060 Model_2_loss: 0.2007 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7897 Model_2_val:0.7894
Epoch: 0260 Model_1_loss: 0.2077 Model_2_loss: 0.2154 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7928 Model_2_val:0.7876
Epoch: 0280 Model_1_loss: 0.1553 Model_2_loss: 0.1888 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7940 Model_2_val:0.7892
Epoch: 0300 Model_1_loss: 0.1729 Model_2_loss: 0.1776 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7982 Model_2_val:0.7935
Epoch: 0320 Model_1_loss: 0.1412 Model_2_loss: 0.1580 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7973 Model_2_val:0.7897
Epoch: 0340 Model_1_loss: 0.1479 Model_2_loss: 0.1691 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7963 Model_2_val:0.7975
Epoch: 0360 Model_1_loss: 0.1438 Model_2_loss: 0.1705 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7964 Model_2_val:0.8001
Epoch: 0380 Model_1_loss: 0.1380 Model_2_loss: 0.1414 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7985 Model_2_val:0.7920
Epoch: 0400 Model_1_loss: 0.1595 Model_2_loss: 0.1483 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7964 Model_2_val:0.7969
Model_one_test:0.8172 Model_two_test:0.8138
added by two output: 0.8172
6
labels of each class :  [20 20 20]
t= [975 975 975]
680258422
Epoch: 0020 Model_1_loss: 1.0026 Model_2_loss: 1.0177 Model_1_trainacc: 0.6500 Model_2_trainacc: 0.5833 Model_1_val:0.5235 Model_2_val:0.5415
Epoch: 0040 Model_1_loss: 0.8244 Model_2_loss: 0.7957 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8833 Model_1_val:0.6280 Model_2_val:0.6709
Epoch: 0060 Model_1_loss: 0.6320 Model_2_loss: 0.5756 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.9167 Model_1_val:0.6838 Model_2_val:0.7175
Epoch: 0080 Model_1_loss: 0.4748 Model_2_loss: 0.3885 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9833 Model_1_val:0.7146 Model_2_val:0.7333
Epoch: 0100 Model_1_loss: 0.3809 Model_2_loss: 0.3186 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.7206 Model_2_val:0.7502
Epoch: 0120 Model_1_loss: 0.2688 Model_2_loss: 0.2554 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7307 Model_2_val:0.7466
Epoch: 0140 Model_1_loss: 0.2601 Model_2_loss: 0.2419 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7375 Model_2_val:0.7522
Epoch: 0160 Model_1_loss: 0.2364 Model_2_loss: 0.1985 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7451 Model_2_val:0.7534
Epoch: 0180 Model_1_loss: 0.1968 Model_2_loss: 0.1701 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7425 Model_2_val:0.7585
Epoch: 0200 Model_1_loss: 0.2046 Model_2_loss: 0.1904 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7529 Model_2_val:0.7535
Epoch: 0220 Model_1_loss: 0.2062 Model_2_loss: 0.1689 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7514 Model_2_val:0.7585
Epoch: 0240 Model_1_loss: 0.1730 Model_2_loss: 0.1920 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7564 Model_2_val:0.7649
Epoch: 0260 Model_1_loss: 0.1478 Model_2_loss: 0.1899 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7557 Model_2_val:0.7615
Epoch: 0280 Model_1_loss: 0.1985 Model_2_loss: 0.1717 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7639 Model_2_val:0.7611
Epoch: 0300 Model_1_loss: 0.1184 Model_2_loss: 0.1571 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7587 Model_2_val:0.7618
Epoch: 0320 Model_1_loss: 0.1353 Model_2_loss: 0.1450 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7591 Model_2_val:0.7662
Epoch: 0340 Model_1_loss: 0.1557 Model_2_loss: 0.1514 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7600 Model_2_val:0.7627
Epoch: 0360 Model_1_loss: 0.1568 Model_2_loss: 0.1253 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7669 Model_2_val:0.7668
Epoch: 0380 Model_1_loss: 0.1316 Model_2_loss: 0.1326 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7584 Model_2_val:0.7618
Epoch: 0400 Model_1_loss: 0.1781 Model_2_loss: 0.1379 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7641 Model_2_val:0.7654
Model_one_test:0.7798 Model_two_test:0.7840
added by two output: 0.7825
7
labels of each class :  [20 20 20]
t= [975 975 975]
1044795242
Epoch: 0020 Model_1_loss: 1.0296 Model_2_loss: 1.0790 Model_1_trainacc: 0.6500 Model_2_trainacc: 0.4667 Model_1_val:0.4142 Model_2_val:0.5379
Epoch: 0040 Model_1_loss: 0.9188 Model_2_loss: 0.9262 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.8167 Model_1_val:0.6090 Model_2_val:0.6118
Epoch: 0060 Model_1_loss: 0.6806 Model_2_loss: 0.6781 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8833 Model_1_val:0.6572 Model_2_val:0.6740
Epoch: 0080 Model_1_loss: 0.5143 Model_2_loss: 0.4708 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9500 Model_1_val:0.6989 Model_2_val:0.6989
Epoch: 0100 Model_1_loss: 0.3420 Model_2_loss: 0.3388 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7195 Model_2_val:0.7257
Epoch: 0120 Model_1_loss: 0.3103 Model_2_loss: 0.2724 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7255 Model_2_val:0.7250
Epoch: 0140 Model_1_loss: 0.2645 Model_2_loss: 0.2538 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7354 Model_2_val:0.7278
Epoch: 0160 Model_1_loss: 0.2155 Model_2_loss: 0.2083 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7377 Model_2_val:0.7305
Epoch: 0180 Model_1_loss: 0.1596 Model_2_loss: 0.1889 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7341 Model_2_val:0.7313
Epoch: 0200 Model_1_loss: 0.1837 Model_2_loss: 0.2274 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.7423 Model_2_val:0.7404
Epoch: 0220 Model_1_loss: 0.1976 Model_2_loss: 0.2371 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7460 Model_2_val:0.7435
Epoch: 0240 Model_1_loss: 0.1706 Model_2_loss: 0.1920 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7573 Model_2_val:0.7438
Epoch: 0260 Model_1_loss: 0.1920 Model_2_loss: 0.2136 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7549 Model_2_val:0.7461
Epoch: 0280 Model_1_loss: 0.1680 Model_2_loss: 0.1744 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7602 Model_2_val:0.7558
Epoch: 0300 Model_1_loss: 0.1328 Model_2_loss: 0.1422 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7606 Model_2_val:0.7594
Epoch: 0320 Model_1_loss: 0.1393 Model_2_loss: 0.1492 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7529 Model_2_val:0.7565
Epoch: 0340 Model_1_loss: 0.1308 Model_2_loss: 0.1331 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7498 Model_2_val:0.7581
Epoch: 0360 Model_1_loss: 0.1429 Model_2_loss: 0.1426 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7530 Model_2_val:0.7558
Epoch: 0380 Model_1_loss: 0.1259 Model_2_loss: 0.1135 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7533 Model_2_val:0.7460
Epoch: 0400 Model_1_loss: 0.1188 Model_2_loss: 0.1632 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7535 Model_2_val:0.7489
Model_one_test:0.7765 Model_two_test:0.7735
added by two output: 0.7749
8
labels of each class :  [20 20 20]
t= [975 975 975]
641056402
Epoch: 0020 Model_1_loss: 1.0043 Model_2_loss: 0.9881 Model_1_trainacc: 0.5167 Model_2_trainacc: 0.5000 Model_1_val:0.4847 Model_2_val:0.4846
Epoch: 0040 Model_1_loss: 0.8070 Model_2_loss: 0.8059 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8667 Model_1_val:0.6402 Model_2_val:0.5906
Epoch: 0060 Model_1_loss: 0.5943 Model_2_loss: 0.6363 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8333 Model_1_val:0.6853 Model_2_val:0.6403
Epoch: 0080 Model_1_loss: 0.4262 Model_2_loss: 0.4814 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.7061 Model_2_val:0.6866
Epoch: 0100 Model_1_loss: 0.3244 Model_2_loss: 0.3761 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7223 Model_2_val:0.6980
Epoch: 0120 Model_1_loss: 0.2949 Model_2_loss: 0.3382 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.7260 Model_2_val:0.7084
Epoch: 0140 Model_1_loss: 0.2324 Model_2_loss: 0.2807 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7249 Model_2_val:0.7112
Epoch: 0160 Model_1_loss: 0.2469 Model_2_loss: 0.2303 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7362 Model_2_val:0.7189
Epoch: 0180 Model_1_loss: 0.1958 Model_2_loss: 0.1902 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7319 Model_2_val:0.7224
Epoch: 0200 Model_1_loss: 0.1912 Model_2_loss: 0.2161 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7366 Model_2_val:0.7249
Epoch: 0220 Model_1_loss: 0.2472 Model_2_loss: 0.3130 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.7657 Model_2_val:0.7535
Epoch: 0240 Model_1_loss: 0.2219 Model_2_loss: 0.2120 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7688 Model_2_val:0.7609
Epoch: 0260 Model_1_loss: 0.1930 Model_2_loss: 0.1854 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7666 Model_2_val:0.7668
Epoch: 0280 Model_1_loss: 0.1911 Model_2_loss: 0.2025 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7679 Model_2_val:0.7610
Epoch: 0300 Model_1_loss: 0.1902 Model_2_loss: 0.1798 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7618 Model_2_val:0.7619
Epoch: 0320 Model_1_loss: 0.1836 Model_2_loss: 0.1743 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7690 Model_2_val:0.7728
Epoch: 0340 Model_1_loss: 0.1465 Model_2_loss: 0.1972 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7715 Model_2_val:0.7659
Epoch: 0360 Model_1_loss: 0.1787 Model_2_loss: 0.1460 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7724 Model_2_val:0.7674
Epoch: 0380 Model_1_loss: 0.1690 Model_2_loss: 0.1703 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7664 Model_2_val:0.7667
Epoch: 0400 Model_1_loss: 0.1226 Model_2_loss: 0.1548 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7723 Model_2_val:0.7710
Model_one_test:0.7880 Model_two_test:0.7902
added by two output: 0.7896
9
labels of each class :  [20 20 20]
t= [975 975 975]
1133892942
Epoch: 0020 Model_1_loss: 1.0707 Model_2_loss: 1.0000 Model_1_trainacc: 0.5167 Model_2_trainacc: 0.8000 Model_1_val:0.4344 Model_2_val:0.6257
Epoch: 0040 Model_1_loss: 0.9127 Model_2_loss: 0.7787 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.9000 Model_1_val:0.6128 Model_2_val:0.6793
Epoch: 0060 Model_1_loss: 0.7174 Model_2_loss: 0.6185 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8500 Model_1_val:0.6571 Model_2_val:0.7106
Epoch: 0080 Model_1_loss: 0.5850 Model_2_loss: 0.4337 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9833 Model_1_val:0.7053 Model_2_val:0.7306
Epoch: 0100 Model_1_loss: 0.4167 Model_2_loss: 0.3777 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.7370 Model_2_val:0.7493
Epoch: 0120 Model_1_loss: 0.3869 Model_2_loss: 0.3138 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.7417 Model_2_val:0.7583
Epoch: 0140 Model_1_loss: 0.3335 Model_2_loss: 0.2309 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.7517 Model_2_val:0.7641
Epoch: 0160 Model_1_loss: 0.2726 Model_2_loss: 0.2038 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.7585 Model_2_val:0.7727
Epoch: 0180 Model_1_loss: 0.2229 Model_2_loss: 0.2110 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.7615 Model_2_val:0.7744
Epoch: 0200 Model_1_loss: 0.1982 Model_2_loss: 0.1722 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7615 Model_2_val:0.7741
Epoch: 0220 Model_1_loss: 0.2892 Model_2_loss: 0.2105 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9833 Model_1_val:0.7856 Model_2_val:0.7959
Epoch: 0240 Model_1_loss: 0.2087 Model_2_loss: 0.1902 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7883 Model_2_val:0.7910
Epoch: 0260 Model_1_loss: 0.2023 Model_2_loss: 0.2096 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.7921 Model_2_val:0.7927
Epoch: 0280 Model_1_loss: 0.1941 Model_2_loss: 0.1744 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7892 Model_2_val:0.7945
Epoch: 0300 Model_1_loss: 0.1499 Model_2_loss: 0.1602 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7943 Model_2_val:0.7930
Epoch: 0320 Model_1_loss: 0.1690 Model_2_loss: 0.1502 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7909 Model_2_val:0.7976
Epoch: 0340 Model_1_loss: 0.1554 Model_2_loss: 0.1582 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7907 Model_2_val:0.7937
Epoch: 0360 Model_1_loss: 0.1449 Model_2_loss: 0.1931 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7908 Model_2_val:0.7950
Epoch: 0380 Model_1_loss: 0.1499 Model_2_loss: 0.1602 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7877 Model_2_val:0.7911
Epoch: 0400 Model_1_loss: 0.1318 Model_2_loss: 0.1297 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7953 Model_2_val:0.7953
Model_one_test:0.8118 Model_two_test:0.8118
added by two output: 0.8122
10
labels of each class :  [20 20 20]
t= [975 975 975]
339993748
Epoch: 0020 Model_1_loss: 0.9634 Model_2_loss: 0.9675 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.6833 Model_1_val:0.4671 Model_2_val:0.5569
Epoch: 0040 Model_1_loss: 0.7593 Model_2_loss: 0.7895 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8000 Model_1_val:0.6593 Model_2_val:0.6477
Epoch: 0060 Model_1_loss: 0.5004 Model_2_loss: 0.5593 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.8833 Model_1_val:0.7060 Model_2_val:0.7041
Epoch: 0080 Model_1_loss: 0.3627 Model_2_loss: 0.3997 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.7334 Model_2_val:0.7231
Epoch: 0100 Model_1_loss: 0.2777 Model_2_loss: 0.3281 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.7391 Model_2_val:0.7341
Epoch: 0120 Model_1_loss: 0.2365 Model_2_loss: 0.2629 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7421 Model_2_val:0.7349
Epoch: 0140 Model_1_loss: 0.2241 Model_2_loss: 0.2404 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.7467 Model_2_val:0.7413
Epoch: 0160 Model_1_loss: 0.1755 Model_2_loss: 0.2026 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7493 Model_2_val:0.7469
Epoch: 0180 Model_1_loss: 0.1530 Model_2_loss: 0.1779 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7544 Model_2_val:0.7527
Epoch: 0200 Model_1_loss: 0.1625 Model_2_loss: 0.1847 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.7579 Model_2_val:0.7481
Epoch: 0220 Model_1_loss: 0.1751 Model_2_loss: 0.2025 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7570 Model_2_val:0.7613
Epoch: 0240 Model_1_loss: 0.1519 Model_2_loss: 0.1705 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7547 Model_2_val:0.7553
Epoch: 0260 Model_1_loss: 0.1659 Model_2_loss: 0.1689 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7618 Model_2_val:0.7643
Epoch: 0280 Model_1_loss: 0.1773 Model_2_loss: 0.1406 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7614 Model_2_val:0.7627
Epoch: 0300 Model_1_loss: 0.1404 Model_2_loss: 0.1164 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7578 Model_2_val:0.7621
Epoch: 0320 Model_1_loss: 0.1393 Model_2_loss: 0.1251 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7624 Model_2_val:0.7639
Epoch: 0340 Model_1_loss: 0.1299 Model_2_loss: 0.1464 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.7616 Model_2_val:0.7638
Epoch: 0360 Model_1_loss: 0.1272 Model_2_loss: 0.1333 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7563 Model_2_val:0.7618
Epoch: 0380 Model_1_loss: 0.1244 Model_2_loss: 0.1200 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.7592 Model_2_val:0.7639
Epoch: 0400 Model_1_loss: 0.1131 Model_2_loss: 0.1082 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.7673 Model_2_val:0.7685
Model_one_test:0.7810 Model_two_test:0.7823
added by two output: 0.7822
Model1 Acc: 0.793094 Model2 Acc: 0.793945
Maxacc Mean: 0.795030
[0.7724194482998152, 0.784036321393279, 0.7753405892386516, 0.7789860521055665, 0.780001540983086, 0.7844636490501327, 0.7676116657325908, 0.7666694514691771, 0.7905084294930736, 0.7950298642698047]
Maxacc of all experiments: 0.7950298642698047
