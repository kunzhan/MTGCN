citeseer
1
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
318475672
Epoch: 0020 Model_1_loss: 1.7135 Model_2_loss: 1.7437 Model_1_trainacc: 0.4500 Model_2_trainacc: 0.3917 Model_1_val:0.2986 Model_2_val:0.2648
Epoch: 0040 Model_1_loss: 1.4860 Model_2_loss: 1.5941 Model_1_trainacc: 0.7583 Model_2_trainacc: 0.6833 Model_1_val:0.4310 Model_2_val:0.3913
Epoch: 0060 Model_1_loss: 1.1501 Model_2_loss: 1.3398 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8250 Model_1_val:0.5005 Model_2_val:0.4952
Epoch: 0080 Model_1_loss: 0.8704 Model_2_loss: 1.0299 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9083 Model_1_val:0.5572 Model_2_val:0.5162
Epoch: 0100 Model_1_loss: 0.7360 Model_2_loss: 0.7857 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8917 Model_1_val:0.5683 Model_2_val:0.5457
Epoch: 0120 Model_1_loss: 0.5887 Model_2_loss: 0.6252 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5959 Model_2_val:0.5516
Epoch: 0140 Model_1_loss: 0.4923 Model_2_loss: 0.6040 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9250 Model_1_val:0.5811 Model_2_val:0.5726
Epoch: 0160 Model_1_loss: 0.4698 Model_2_loss: 0.4596 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6021 Model_2_val:0.5995
Epoch: 0180 Model_1_loss: 0.4088 Model_2_loss: 0.4043 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.5978 Model_2_val:0.5926
Epoch: 0200 Model_1_loss: 0.3377 Model_2_loss: 0.3865 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6073 Model_2_val:0.6018
Epoch: 0220 Model_1_loss: 0.7271 Model_2_loss: 0.7195 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6532 Model_2_val:0.6286
Epoch: 0240 Model_1_loss: 0.6396 Model_2_loss: 0.6899 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6562 Model_2_val:0.6473
Epoch: 0260 Model_1_loss: 0.6211 Model_2_loss: 0.6542 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6601 Model_2_val:0.6526
Epoch: 0280 Model_1_loss: 0.5733 Model_2_loss: 0.5956 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6627 Model_2_val:0.6660
Epoch: 0300 Model_1_loss: 0.5497 Model_2_loss: 0.5394 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6670 Model_2_val:0.6709
Epoch: 0320 Model_1_loss: 0.5467 Model_2_loss: 0.5595 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6614 Model_2_val:0.6572
Epoch: 0340 Model_1_loss: 0.4762 Model_2_loss: 0.5127 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6601 Model_2_val:0.6601
Epoch: 0360 Model_1_loss: 0.5135 Model_2_loss: 0.5179 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6644 Model_2_val:0.6614
Epoch: 0380 Model_1_loss: 0.4641 Model_2_loss: 0.4406 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6542 Model_2_val:0.6552
Epoch: 0400 Model_1_loss: 0.4440 Model_2_loss: 0.4116 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6568 Model_2_val:0.6676
Model_one_test:0.6775 Model_two_test:0.6804
added by two output: 0.6778
2
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
176846987
Epoch: 0020 Model_1_loss: 1.7248 Model_2_loss: 1.7464 Model_1_trainacc: 0.3667 Model_2_trainacc: 0.3583 Model_1_val:0.2621 Model_2_val:0.2198
Epoch: 0040 Model_1_loss: 1.5754 Model_2_loss: 1.6129 Model_1_trainacc: 0.6583 Model_2_trainacc: 0.7333 Model_1_val:0.4059 Model_2_val:0.4127
Epoch: 0060 Model_1_loss: 1.2733 Model_2_loss: 1.3531 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8167 Model_1_val:0.4972 Model_2_val:0.4462
Epoch: 0080 Model_1_loss: 1.0469 Model_2_loss: 1.1010 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8667 Model_1_val:0.5333 Model_2_val:0.5141
Epoch: 0100 Model_1_loss: 0.8721 Model_2_loss: 0.8845 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9000 Model_1_val:0.5226 Model_2_val:0.5317
Epoch: 0120 Model_1_loss: 0.7253 Model_2_loss: 0.7488 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9250 Model_1_val:0.5698 Model_2_val:0.5541
Epoch: 0140 Model_1_loss: 0.6596 Model_2_loss: 0.6572 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9333 Model_1_val:0.5876 Model_2_val:0.5626
Epoch: 0160 Model_1_loss: 0.5598 Model_2_loss: 0.5654 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.5928 Model_2_val:0.5717
Epoch: 0180 Model_1_loss: 0.4929 Model_2_loss: 0.5135 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.5987 Model_2_val:0.6065
Epoch: 0200 Model_1_loss: 0.4231 Model_2_loss: 0.4462 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5984 Model_2_val:0.5902
Epoch: 0220 Model_1_loss: 0.8218 Model_2_loss: 0.8184 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9250 Model_1_val:0.6598 Model_2_val:0.6631
Epoch: 0240 Model_1_loss: 0.7454 Model_2_loss: 0.7202 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6709 Model_2_val:0.6670
Epoch: 0260 Model_1_loss: 0.6715 Model_2_loss: 0.6653 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6735 Model_2_val:0.6767
Epoch: 0280 Model_1_loss: 0.6333 Model_2_loss: 0.6222 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6852 Model_2_val:0.6767
Epoch: 0300 Model_1_loss: 0.5948 Model_2_loss: 0.5895 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6816 Model_2_val:0.6823
Epoch: 0320 Model_1_loss: 0.6113 Model_2_loss: 0.5288 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6917 Model_2_val:0.6758
Epoch: 0340 Model_1_loss: 0.5546 Model_2_loss: 0.6153 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6937 Model_2_val:0.6719
Epoch: 0360 Model_1_loss: 0.4997 Model_2_loss: 0.5461 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6816 Model_2_val:0.6823
Epoch: 0380 Model_1_loss: 0.5021 Model_2_loss: 0.4778 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6793 Model_2_val:0.6751
Epoch: 0400 Model_1_loss: 0.4732 Model_2_loss: 0.5305 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6823 Model_2_val:0.6634
Model_one_test:0.7054 Model_two_test:0.7015
added by two output: 0.7024
3
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
779212156
Epoch: 0020 Model_1_loss: 1.7183 Model_2_loss: 1.7548 Model_1_trainacc: 0.4333 Model_2_trainacc: 0.2750 Model_1_val:0.2451 Model_2_val:0.2145
Epoch: 0040 Model_1_loss: 1.5695 Model_2_loss: 1.6309 Model_1_trainacc: 0.6500 Model_2_trainacc: 0.5500 Model_1_val:0.4059 Model_2_val:0.3617
Epoch: 0060 Model_1_loss: 1.3007 Model_2_loss: 1.3897 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.7750 Model_1_val:0.4919 Model_2_val:0.4671
Epoch: 0080 Model_1_loss: 1.0608 Model_2_loss: 1.1646 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.7917 Model_1_val:0.5140 Model_2_val:0.5218
Epoch: 0100 Model_1_loss: 0.9072 Model_2_loss: 0.9020 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.9167 Model_1_val:0.5566 Model_2_val:0.5501
Epoch: 0120 Model_1_loss: 0.6894 Model_2_loss: 0.7479 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9000 Model_1_val:0.5459 Model_2_val:0.5544
Epoch: 0140 Model_1_loss: 0.6349 Model_2_loss: 0.6374 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.5527 Model_2_val:0.5736
Epoch: 0160 Model_1_loss: 0.6222 Model_2_loss: 0.5255 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5713 Model_2_val:0.5745
Epoch: 0180 Model_1_loss: 0.5173 Model_2_loss: 0.4561 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5794 Model_2_val:0.6006
Epoch: 0200 Model_1_loss: 0.4619 Model_2_loss: 0.4170 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5911 Model_2_val:0.5986
Epoch: 0220 Model_1_loss: 0.8553 Model_2_loss: 0.7331 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6270 Model_2_val:0.6348
Epoch: 0240 Model_1_loss: 0.7463 Model_2_loss: 0.6923 Model_1_trainacc: 0.9583 Model_2_trainacc: 1.0000 Model_1_val:0.6445 Model_2_val:0.6383
Epoch: 0260 Model_1_loss: 0.7293 Model_2_loss: 0.6562 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6406 Model_2_val:0.6497
Epoch: 0280 Model_1_loss: 0.6552 Model_2_loss: 0.6357 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6478 Model_2_val:0.6562
Epoch: 0300 Model_1_loss: 0.6343 Model_2_loss: 0.6365 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6572 Model_2_val:0.6462
Epoch: 0320 Model_1_loss: 0.6251 Model_2_loss: 0.5788 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6429 Model_2_val:0.6530
Epoch: 0340 Model_1_loss: 0.6193 Model_2_loss: 0.5315 Model_1_trainacc: 0.9417 Model_2_trainacc: 1.0000 Model_1_val:0.6510 Model_2_val:0.6556
Epoch: 0360 Model_1_loss: 0.5950 Model_2_loss: 0.5418 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6507 Model_2_val:0.6523
Epoch: 0380 Model_1_loss: 0.6054 Model_2_loss: 0.5121 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6471 Model_2_val:0.6530
Epoch: 0400 Model_1_loss: 0.5892 Model_2_loss: 0.4862 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6426 Model_2_val:0.6582
Model_one_test:0.6790 Model_two_test:0.6748
added by two output: 0.6768
4
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
951494621
Epoch: 0020 Model_1_loss: 1.7201 Model_2_loss: 1.7057 Model_1_trainacc: 0.5167 Model_2_trainacc: 0.4333 Model_1_val:0.2386 Model_2_val:0.2534
Epoch: 0040 Model_1_loss: 1.5052 Model_2_loss: 1.5154 Model_1_trainacc: 0.7583 Model_2_trainacc: 0.7667 Model_1_val:0.4150 Model_2_val:0.4459
Epoch: 0060 Model_1_loss: 1.1778 Model_2_loss: 1.2553 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8000 Model_1_val:0.4964 Model_2_val:0.4979
Epoch: 0080 Model_1_loss: 0.8861 Model_2_loss: 0.9990 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8750 Model_1_val:0.5131 Model_2_val:0.5099
Epoch: 0100 Model_1_loss: 0.6825 Model_2_loss: 0.8101 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9000 Model_1_val:0.5421 Model_2_val:0.5405
Epoch: 0120 Model_1_loss: 0.6271 Model_2_loss: 0.6801 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.5573 Model_2_val:0.5412
Epoch: 0140 Model_1_loss: 0.6044 Model_2_loss: 0.6496 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9167 Model_1_val:0.5529 Model_2_val:0.5374
Epoch: 0160 Model_1_loss: 0.5067 Model_2_loss: 0.5319 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5557 Model_2_val:0.5529
Epoch: 0180 Model_1_loss: 0.4705 Model_2_loss: 0.4648 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5589 Model_2_val:0.5614
Epoch: 0200 Model_1_loss: 0.4290 Model_2_loss: 0.4521 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5674 Model_2_val:0.5522
Epoch: 0220 Model_1_loss: 0.7861 Model_2_loss: 0.7687 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.6456 Model_2_val:0.6349
Epoch: 0240 Model_1_loss: 0.7595 Model_2_loss: 0.6832 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9667 Model_1_val:0.6608 Model_2_val:0.6538
Epoch: 0260 Model_1_loss: 0.6567 Model_2_loss: 0.6617 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6595 Model_2_val:0.6541
Epoch: 0280 Model_1_loss: 0.6652 Model_2_loss: 0.6134 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9667 Model_1_val:0.6642 Model_2_val:0.6576
Epoch: 0300 Model_1_loss: 0.6330 Model_2_loss: 0.5486 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9917 Model_1_val:0.6482 Model_2_val:0.6617
Epoch: 0320 Model_1_loss: 0.5583 Model_2_loss: 0.5384 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6687 Model_2_val:0.6598
Epoch: 0340 Model_1_loss: 0.5164 Model_2_loss: 0.5452 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6690 Model_2_val:0.6636
Epoch: 0360 Model_1_loss: 0.5614 Model_2_loss: 0.5112 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.6674 Model_2_val:0.6674
Epoch: 0380 Model_1_loss: 0.5521 Model_2_loss: 0.5389 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6661 Model_2_val:0.6620
Epoch: 0400 Model_1_loss: 0.5183 Model_2_loss: 0.4708 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6633 Model_2_val:0.6759
Model_one_test:0.6904 Model_two_test:0.6882
added by two output: 0.6911
5
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
270249028
Epoch: 0020 Model_1_loss: 1.7484 Model_2_loss: 1.7278 Model_1_trainacc: 0.3417 Model_2_trainacc: 0.4667 Model_1_val:0.1972 Model_2_val:0.2120
Epoch: 0040 Model_1_loss: 1.6429 Model_2_loss: 1.5848 Model_1_trainacc: 0.6083 Model_2_trainacc: 0.6833 Model_1_val:0.3445 Model_2_val:0.3652
Epoch: 0060 Model_1_loss: 1.4506 Model_2_loss: 1.3813 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.7500 Model_1_val:0.4533 Model_2_val:0.4145
Epoch: 0080 Model_1_loss: 1.1949 Model_2_loss: 1.1888 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.7750 Model_1_val:0.5082 Model_2_val:0.4579
Epoch: 0100 Model_1_loss: 0.9875 Model_2_loss: 1.0383 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8250 Model_1_val:0.5039 Model_2_val:0.4839
Epoch: 0120 Model_1_loss: 0.8463 Model_2_loss: 0.8555 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9083 Model_1_val:0.5201 Model_2_val:0.5155
Epoch: 0140 Model_1_loss: 0.7136 Model_2_loss: 0.7614 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9167 Model_1_val:0.5135 Model_2_val:0.5138
Epoch: 0160 Model_1_loss: 0.7236 Model_2_loss: 0.6405 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9083 Model_1_val:0.5467 Model_2_val:0.5319
Epoch: 0180 Model_1_loss: 0.5417 Model_2_loss: 0.5253 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5493 Model_2_val:0.5556
Epoch: 0200 Model_1_loss: 0.5372 Model_2_loss: 0.4453 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9583 Model_1_val:0.5454 Model_2_val:0.5825
Epoch: 0220 Model_1_loss: 0.8466 Model_2_loss: 0.8219 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6256 Model_2_val:0.6246
Epoch: 0240 Model_1_loss: 0.8222 Model_2_loss: 0.7079 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6374 Model_2_val:0.6279
Epoch: 0260 Model_1_loss: 0.7476 Model_2_loss: 0.6851 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6450 Model_2_val:0.6335
Epoch: 0280 Model_1_loss: 0.7060 Model_2_loss: 0.6736 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6433 Model_2_val:0.6476
Epoch: 0300 Model_1_loss: 0.6613 Model_2_loss: 0.6030 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6552 Model_2_val:0.6565
Epoch: 0320 Model_1_loss: 0.6294 Model_2_loss: 0.5946 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6506 Model_2_val:0.6450
Epoch: 0340 Model_1_loss: 0.6299 Model_2_loss: 0.5521 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6502 Model_2_val:0.6469
Epoch: 0360 Model_1_loss: 0.5886 Model_2_loss: 0.5128 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.6446 Model_2_val:0.6555
Epoch: 0380 Model_1_loss: 0.5409 Model_2_loss: 0.4899 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6476 Model_2_val:0.6502
Epoch: 0400 Model_1_loss: 0.5542 Model_2_loss: 0.5471 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6394 Model_2_val:0.6496
Model_one_test:0.6716 Model_two_test:0.6765
added by two output: 0.6739
6
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
794082748
Epoch: 0020 Model_1_loss: 1.7442 Model_2_loss: 1.7135 Model_1_trainacc: 0.2833 Model_2_trainacc: 0.4417 Model_1_val:0.2361 Model_2_val:0.2423
Epoch: 0040 Model_1_loss: 1.5678 Model_2_loss: 1.5182 Model_1_trainacc: 0.7250 Model_2_trainacc: 0.7583 Model_1_val:0.3881 Model_2_val:0.4250
Epoch: 0060 Model_1_loss: 1.2562 Model_2_loss: 1.1634 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8583 Model_1_val:0.4883 Model_2_val:0.5114
Epoch: 0080 Model_1_loss: 0.8812 Model_2_loss: 0.8835 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9000 Model_1_val:0.5427 Model_2_val:0.5654
Epoch: 0100 Model_1_loss: 0.7045 Model_2_loss: 0.6671 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9250 Model_1_val:0.5836 Model_2_val:0.5776
Epoch: 0120 Model_1_loss: 0.5127 Model_2_loss: 0.5663 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6063 Model_2_val:0.5994
Epoch: 0140 Model_1_loss: 0.4862 Model_2_loss: 0.5266 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6139 Model_2_val:0.5964
Epoch: 0160 Model_1_loss: 0.3931 Model_2_loss: 0.4414 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6152 Model_2_val:0.6136
Epoch: 0180 Model_1_loss: 0.3974 Model_2_loss: 0.4354 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6215 Model_2_val:0.6139
Epoch: 0200 Model_1_loss: 0.3304 Model_2_loss: 0.3605 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6218 Model_2_val:0.6268
Epoch: 0220 Model_1_loss: 0.6740 Model_2_loss: 0.6842 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6736 Model_2_val:0.6660
Epoch: 0240 Model_1_loss: 0.5545 Model_2_loss: 0.6474 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6934 Model_2_val:0.6884
Epoch: 0260 Model_1_loss: 0.5875 Model_2_loss: 0.5921 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6815 Model_2_val:0.6805
Epoch: 0280 Model_1_loss: 0.5342 Model_2_loss: 0.5546 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6851 Model_2_val:0.6894
Epoch: 0300 Model_1_loss: 0.5312 Model_2_loss: 0.5319 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6845 Model_2_val:0.6841
Epoch: 0320 Model_1_loss: 0.4697 Model_2_loss: 0.5483 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6858 Model_2_val:0.6874
Epoch: 0340 Model_1_loss: 0.4857 Model_2_loss: 0.4877 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6917 Model_2_val:0.6848
Epoch: 0360 Model_1_loss: 0.4648 Model_2_loss: 0.4549 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6785 Model_2_val:0.6891
Epoch: 0380 Model_1_loss: 0.4840 Model_2_loss: 0.4427 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6719 Model_2_val:0.6868
Epoch: 0400 Model_1_loss: 0.4549 Model_2_loss: 0.4188 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6871 Model_2_val:0.6878
Model_one_test:0.7112 Model_two_test:0.7082
added by two output: 0.7089
7
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
813128449
Epoch: 0020 Model_1_loss: 1.6815 Model_2_loss: 1.7213 Model_1_trainacc: 0.5167 Model_2_trainacc: 0.4167 Model_1_val:0.2269 Model_2_val:0.3246
Epoch: 0040 Model_1_loss: 1.4598 Model_2_loss: 1.5510 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.7500 Model_1_val:0.4531 Model_2_val:0.4295
Epoch: 0060 Model_1_loss: 1.1326 Model_2_loss: 1.1828 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8667 Model_1_val:0.5157 Model_2_val:0.4885
Epoch: 0080 Model_1_loss: 0.8181 Model_2_loss: 0.9039 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9000 Model_1_val:0.5502 Model_2_val:0.5525
Epoch: 0100 Model_1_loss: 0.6468 Model_2_loss: 0.7507 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9167 Model_1_val:0.5813 Model_2_val:0.5485
Epoch: 0120 Model_1_loss: 0.5626 Model_2_loss: 0.6001 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9250 Model_1_val:0.5548 Model_2_val:0.5711
Epoch: 0140 Model_1_loss: 0.5043 Model_2_loss: 0.5019 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5889 Model_2_val:0.5872
Epoch: 0160 Model_1_loss: 0.4304 Model_2_loss: 0.4359 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.5807 Model_2_val:0.6020
Epoch: 0180 Model_1_loss: 0.4228 Model_2_loss: 0.4114 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.5964 Model_2_val:0.6056
Epoch: 0200 Model_1_loss: 0.4052 Model_2_loss: 0.4048 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.5993 Model_2_val:0.5925
Epoch: 0220 Model_1_loss: 0.6789 Model_2_loss: 0.6853 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6580 Model_2_val:0.6449
Epoch: 0240 Model_1_loss: 0.6891 Model_2_loss: 0.6705 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6630 Model_2_val:0.6505
Epoch: 0260 Model_1_loss: 0.5826 Model_2_loss: 0.6012 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6708 Model_2_val:0.6587
Epoch: 0280 Model_1_loss: 0.5588 Model_2_loss: 0.5907 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6656 Model_2_val:0.6590
Epoch: 0300 Model_1_loss: 0.5314 Model_2_loss: 0.5540 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6689 Model_2_val:0.6505
Epoch: 0320 Model_1_loss: 0.5411 Model_2_loss: 0.5073 Model_1_trainacc: 0.9583 Model_2_trainacc: 1.0000 Model_1_val:0.6620 Model_2_val:0.6600
Epoch: 0340 Model_1_loss: 0.5134 Model_2_loss: 0.5033 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6652 Model_2_val:0.6528
Epoch: 0360 Model_1_loss: 0.5089 Model_2_loss: 0.4702 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6574 Model_2_val:0.6600
Epoch: 0380 Model_1_loss: 0.4694 Model_2_loss: 0.4971 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6698 Model_2_val:0.6574
Epoch: 0400 Model_1_loss: 0.4404 Model_2_loss: 0.4840 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6774 Model_2_val:0.6646
Model_one_test:0.6911 Model_two_test:0.6872
added by two output: 0.6895
8
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
86249924
Epoch: 0020 Model_1_loss: 1.7302 Model_2_loss: 1.7114 Model_1_trainacc: 0.3833 Model_2_trainacc: 0.4833 Model_1_val:0.2276 Model_2_val:0.3047
Epoch: 0040 Model_1_loss: 1.5771 Model_2_loss: 1.5280 Model_1_trainacc: 0.6583 Model_2_trainacc: 0.7750 Model_1_val:0.4015 Model_2_val:0.4359
Epoch: 0060 Model_1_loss: 1.2749 Model_2_loss: 1.2310 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8750 Model_1_val:0.5021 Model_2_val:0.5098
Epoch: 0080 Model_1_loss: 0.9658 Model_2_loss: 0.9307 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8750 Model_1_val:0.5497 Model_2_val:0.5230
Epoch: 0100 Model_1_loss: 0.7611 Model_2_loss: 0.7110 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.5638 Model_2_val:0.5567
Epoch: 0120 Model_1_loss: 0.6499 Model_2_loss: 0.6009 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.5770 Model_2_val:0.5522
Epoch: 0140 Model_1_loss: 0.5457 Model_2_loss: 0.5428 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5821 Model_2_val:0.5853
Epoch: 0160 Model_1_loss: 0.4611 Model_2_loss: 0.5242 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9417 Model_1_val:0.5709 Model_2_val:0.5818
Epoch: 0180 Model_1_loss: 0.4631 Model_2_loss: 0.4386 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5786 Model_2_val:0.5779
Epoch: 0200 Model_1_loss: 0.4322 Model_2_loss: 0.3736 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5747 Model_2_val:0.5802
Epoch: 0220 Model_1_loss: 0.7506 Model_2_loss: 0.6800 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6432 Model_2_val:0.6516
Epoch: 0240 Model_1_loss: 0.6691 Model_2_loss: 0.6470 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6545 Model_2_val:0.6561
Epoch: 0260 Model_1_loss: 0.6074 Model_2_loss: 0.5679 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6509 Model_2_val:0.6557
Epoch: 0280 Model_1_loss: 0.5836 Model_2_loss: 0.5578 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6551 Model_2_val:0.6609
Epoch: 0300 Model_1_loss: 0.5364 Model_2_loss: 0.5235 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6599 Model_2_val:0.6564
Epoch: 0320 Model_1_loss: 0.5436 Model_2_loss: 0.5151 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6570 Model_2_val:0.6686
Epoch: 0340 Model_1_loss: 0.5007 Model_2_loss: 0.4451 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6525 Model_2_val:0.6663
Epoch: 0360 Model_1_loss: 0.4523 Model_2_loss: 0.4358 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6561 Model_2_val:0.6702
Epoch: 0380 Model_1_loss: 0.4661 Model_2_loss: 0.4596 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6583 Model_2_val:0.6663
Epoch: 0400 Model_1_loss: 0.4691 Model_2_loss: 0.4424 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6506 Model_2_val:0.6606
Model_one_test:0.6789 Model_two_test:0.6831
added by two output: 0.6795
9
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1092219554
Epoch: 0020 Model_1_loss: 1.7389 Model_2_loss: 1.7258 Model_1_trainacc: 0.4000 Model_2_trainacc: 0.5417 Model_1_val:0.2903 Model_2_val:0.3601
Epoch: 0040 Model_1_loss: 1.5818 Model_2_loss: 1.5078 Model_1_trainacc: 0.7250 Model_2_trainacc: 0.8250 Model_1_val:0.3578 Model_2_val:0.4847
Epoch: 0060 Model_1_loss: 1.3313 Model_2_loss: 1.1727 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8917 Model_1_val:0.4959 Model_2_val:0.5213
Epoch: 0080 Model_1_loss: 1.0825 Model_2_loss: 0.8460 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9250 Model_1_val:0.5127 Model_2_val:0.5493
Epoch: 0100 Model_1_loss: 0.8270 Model_2_loss: 0.6414 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.5657 Model_2_val:0.5756
Epoch: 0120 Model_1_loss: 0.7245 Model_2_loss: 0.5431 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9500 Model_1_val:0.5644 Model_2_val:0.5799
Epoch: 0140 Model_1_loss: 0.6215 Model_2_loss: 0.5036 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5918 Model_2_val:0.6129
Epoch: 0160 Model_1_loss: 0.4772 Model_2_loss: 0.4297 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.5888 Model_2_val:0.6066
Epoch: 0180 Model_1_loss: 0.4709 Model_2_loss: 0.3840 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6000 Model_2_val:0.6023
Epoch: 0200 Model_1_loss: 0.4341 Model_2_loss: 0.3862 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6033 Model_2_val:0.6066
Epoch: 0220 Model_1_loss: 0.7172 Model_2_loss: 0.6834 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6603 Model_2_val:0.6718
Epoch: 0240 Model_1_loss: 0.6533 Model_2_loss: 0.6613 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.6636 Model_2_val:0.6751
Epoch: 0260 Model_1_loss: 0.5988 Model_2_loss: 0.6336 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6787 Model_2_val:0.6610
Epoch: 0280 Model_1_loss: 0.6659 Model_2_loss: 0.5799 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6715 Model_2_val:0.6778
Epoch: 0300 Model_1_loss: 0.6090 Model_2_loss: 0.5671 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6685 Model_2_val:0.6731
Epoch: 0320 Model_1_loss: 0.5957 Model_2_loss: 0.5172 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6745 Model_2_val:0.6712
Epoch: 0340 Model_1_loss: 0.5115 Model_2_loss: 0.5071 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6692 Model_2_val:0.6629
Epoch: 0360 Model_1_loss: 0.5532 Model_2_loss: 0.5295 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6643 Model_2_val:0.6699
Epoch: 0380 Model_1_loss: 0.5153 Model_2_loss: 0.4541 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6689 Model_2_val:0.6675
Epoch: 0400 Model_1_loss: 0.5113 Model_2_loss: 0.4973 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6685 Model_2_val:0.6695
Model_one_test:0.6982 Model_two_test:0.6952
added by two output: 0.6965
10
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1027070516
Epoch: 0020 Model_1_loss: 1.7186 Model_2_loss: 1.7379 Model_1_trainacc: 0.5417 Model_2_trainacc: 0.3167 Model_1_val:0.2945 Model_2_val:0.2285
Epoch: 0040 Model_1_loss: 1.5544 Model_2_loss: 1.5901 Model_1_trainacc: 0.7083 Model_2_trainacc: 0.6833 Model_1_val:0.4198 Model_2_val:0.3777
Epoch: 0060 Model_1_loss: 1.2311 Model_2_loss: 1.2882 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8583 Model_1_val:0.4658 Model_2_val:0.4970
Epoch: 0080 Model_1_loss: 0.9363 Model_2_loss: 0.9492 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9250 Model_1_val:0.5174 Model_2_val:0.5322
Epoch: 0100 Model_1_loss: 0.7808 Model_2_loss: 0.7468 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5135 Model_2_val:0.5381
Epoch: 0120 Model_1_loss: 0.6299 Model_2_loss: 0.6362 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.5460 Model_2_val:0.5579
Epoch: 0140 Model_1_loss: 0.5495 Model_2_loss: 0.5480 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5444 Model_2_val:0.5828
Epoch: 0160 Model_1_loss: 0.4930 Model_2_loss: 0.4636 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.5822 Model_2_val:0.5776
Epoch: 0180 Model_1_loss: 0.3699 Model_2_loss: 0.3795 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.5842 Model_2_val:0.5996
Epoch: 0200 Model_1_loss: 0.3727 Model_2_loss: 0.4176 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.5934 Model_2_val:0.5740
Epoch: 0220 Model_1_loss: 0.7083 Model_2_loss: 0.7132 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6308 Model_2_val:0.6394
Epoch: 0240 Model_1_loss: 0.6571 Model_2_loss: 0.6484 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6341 Model_2_val:0.6377
Epoch: 0260 Model_1_loss: 0.5916 Model_2_loss: 0.6066 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6558 Model_2_val:0.6525
Epoch: 0280 Model_1_loss: 0.5685 Model_2_loss: 0.5557 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6433 Model_2_val:0.6473
Epoch: 0300 Model_1_loss: 0.5121 Model_2_loss: 0.5676 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6456 Model_2_val:0.6667
Epoch: 0320 Model_1_loss: 0.5091 Model_2_loss: 0.5152 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6492 Model_2_val:0.6538
Epoch: 0340 Model_1_loss: 0.4761 Model_2_loss: 0.4766 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6532 Model_2_val:0.6581
Epoch: 0360 Model_1_loss: 0.4817 Model_2_loss: 0.4816 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6515 Model_2_val:0.6637
Epoch: 0380 Model_1_loss: 0.4415 Model_2_loss: 0.4944 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6561 Model_2_val:0.6588
Epoch: 0400 Model_1_loss: 0.4281 Model_2_loss: 0.4994 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6611 Model_2_val:0.6561
Model_one_test:0.6828 Model_two_test:0.6795
added by two output: 0.6818
11
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
38966526
Epoch: 0020 Model_1_loss: 1.7302 Model_2_loss: 1.7125 Model_1_trainacc: 0.4833 Model_2_trainacc: 0.4083 Model_1_val:0.2582 Model_2_val:0.3032
Epoch: 0040 Model_1_loss: 1.5607 Model_2_loss: 1.4924 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7583 Model_1_val:0.4272 Model_2_val:0.4165
Epoch: 0060 Model_1_loss: 1.2668 Model_2_loss: 1.1844 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8500 Model_1_val:0.5109 Model_2_val:0.5090
Epoch: 0080 Model_1_loss: 0.9740 Model_2_loss: 0.9323 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8500 Model_1_val:0.5698 Model_2_val:0.5484
Epoch: 0100 Model_1_loss: 0.8287 Model_2_loss: 0.7438 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9083 Model_1_val:0.5861 Model_2_val:0.5835
Epoch: 0120 Model_1_loss: 0.6522 Model_2_loss: 0.6108 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.6053 Model_2_val:0.5852
Epoch: 0140 Model_1_loss: 0.5344 Model_2_loss: 0.5437 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.5982 Model_2_val:0.5946
Epoch: 0160 Model_1_loss: 0.5139 Model_2_loss: 0.5588 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9083 Model_1_val:0.6073 Model_2_val:0.6005
Epoch: 0180 Model_1_loss: 0.4560 Model_2_loss: 0.4329 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6145 Model_2_val:0.6021
Epoch: 0200 Model_1_loss: 0.4075 Model_2_loss: 0.4020 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6128 Model_2_val:0.6086
Epoch: 0220 Model_1_loss: 0.7922 Model_2_loss: 0.7940 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6649 Model_2_val:0.6744
Epoch: 0240 Model_1_loss: 0.7238 Model_2_loss: 0.7340 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6711 Model_2_val:0.6822
Epoch: 0260 Model_1_loss: 0.6544 Model_2_loss: 0.6827 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6714 Model_2_val:0.6649
Epoch: 0280 Model_1_loss: 0.5924 Model_2_loss: 0.5997 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6744 Model_2_val:0.6747
Epoch: 0300 Model_1_loss: 0.5772 Model_2_loss: 0.6084 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6802 Model_2_val:0.6740
Epoch: 0320 Model_1_loss: 0.5363 Model_2_loss: 0.5965 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6796 Model_2_val:0.6734
Epoch: 0340 Model_1_loss: 0.5406 Model_2_loss: 0.5622 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6747 Model_2_val:0.6832
Epoch: 0360 Model_1_loss: 0.5236 Model_2_loss: 0.5348 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6754 Model_2_val:0.6698
Epoch: 0380 Model_1_loss: 0.4858 Model_2_loss: 0.5224 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6806 Model_2_val:0.6770
Epoch: 0400 Model_1_loss: 0.4797 Model_2_loss: 0.4811 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6802 Model_2_val:0.6714
Model_one_test:0.7056 Model_two_test:0.6991
added by two output: 0.7007
12
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
587981
Epoch: 0020 Model_1_loss: 1.7030 Model_2_loss: 1.7245 Model_1_trainacc: 0.4167 Model_2_trainacc: 0.4000 Model_1_val:0.2367 Model_2_val:0.2312
Epoch: 0040 Model_1_loss: 1.5851 Model_2_loss: 1.5484 Model_1_trainacc: 0.6083 Model_2_trainacc: 0.6833 Model_1_val:0.3929 Model_2_val:0.4056
Epoch: 0060 Model_1_loss: 1.3652 Model_2_loss: 1.2251 Model_1_trainacc: 0.7417 Model_2_trainacc: 0.8750 Model_1_val:0.4591 Model_2_val:0.4724
Epoch: 0080 Model_1_loss: 1.0591 Model_2_loss: 1.0020 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8917 Model_1_val:0.4992 Model_2_val:0.5347
Epoch: 0100 Model_1_loss: 0.8597 Model_2_loss: 0.7324 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9250 Model_1_val:0.5249 Model_2_val:0.5504
Epoch: 0120 Model_1_loss: 0.7045 Model_2_loss: 0.5640 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5442 Model_2_val:0.5683
Epoch: 0140 Model_1_loss: 0.5799 Model_2_loss: 0.4643 Model_1_trainacc: 0.9417 Model_2_trainacc: 1.0000 Model_1_val:0.5595 Model_2_val:0.5843
Epoch: 0160 Model_1_loss: 0.5627 Model_2_loss: 0.4796 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9917 Model_1_val:0.5566 Model_2_val:0.6136
Epoch: 0180 Model_1_loss: 0.5344 Model_2_loss: 0.3970 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5634 Model_2_val:0.6074
Epoch: 0200 Model_1_loss: 0.4041 Model_2_loss: 0.3371 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.5778 Model_2_val:0.6022
Epoch: 0220 Model_1_loss: 0.7664 Model_2_loss: 0.6453 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6528 Model_2_val:0.6651
Epoch: 0240 Model_1_loss: 0.6086 Model_2_loss: 0.5773 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6691 Model_2_val:0.6834
Epoch: 0260 Model_1_loss: 0.6293 Model_2_loss: 0.5838 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6625 Model_2_val:0.6779
Epoch: 0280 Model_1_loss: 0.5947 Model_2_loss: 0.5536 Model_1_trainacc: 0.9583 Model_2_trainacc: 1.0000 Model_1_val:0.6697 Model_2_val:0.6811
Epoch: 0300 Model_1_loss: 0.5934 Model_2_loss: 0.5000 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6733 Model_2_val:0.6883
Epoch: 0320 Model_1_loss: 0.6070 Model_2_loss: 0.4764 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6766 Model_2_val:0.6717
Epoch: 0340 Model_1_loss: 0.4987 Model_2_loss: 0.4636 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6801 Model_2_val:0.6704
Epoch: 0360 Model_1_loss: 0.5120 Model_2_loss: 0.5125 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6736 Model_2_val:0.6782
Epoch: 0380 Model_1_loss: 0.4911 Model_2_loss: 0.4649 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6746 Model_2_val:0.6854
Epoch: 0400 Model_1_loss: 0.4684 Model_2_loss: 0.4377 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6814 Model_2_val:0.6837
Model_one_test:0.7069 Model_two_test:0.7046
added by two output: 0.7056
13
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1562229140
Epoch: 0020 Model_1_loss: 1.7340 Model_2_loss: 1.7067 Model_1_trainacc: 0.4083 Model_2_trainacc: 0.4000 Model_1_val:0.2772 Model_2_val:0.2497
Epoch: 0040 Model_1_loss: 1.5359 Model_2_loss: 1.4999 Model_1_trainacc: 0.7250 Model_2_trainacc: 0.7750 Model_1_val:0.4219 Model_2_val:0.4510
Epoch: 0060 Model_1_loss: 1.2470 Model_2_loss: 1.1891 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8250 Model_1_val:0.4876 Model_2_val:0.5107
Epoch: 0080 Model_1_loss: 0.9540 Model_2_loss: 0.8988 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8917 Model_1_val:0.5263 Model_2_val:0.5710
Epoch: 0100 Model_1_loss: 0.7573 Model_2_loss: 0.7746 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9167 Model_1_val:0.5503 Model_2_val:0.5744
Epoch: 0120 Model_1_loss: 0.6538 Model_2_loss: 0.6295 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9250 Model_1_val:0.5744 Model_2_val:0.5856
Epoch: 0140 Model_1_loss: 0.5604 Model_2_loss: 0.5866 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.5784 Model_2_val:0.5862
Epoch: 0160 Model_1_loss: 0.4711 Model_2_loss: 0.5144 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9250 Model_1_val:0.5778 Model_2_val:0.5856
Epoch: 0180 Model_1_loss: 0.4782 Model_2_loss: 0.4946 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5835 Model_2_val:0.5784
Epoch: 0200 Model_1_loss: 0.4554 Model_2_loss: 0.4747 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5893 Model_2_val:0.6015
Epoch: 0220 Model_1_loss: 0.7633 Model_2_loss: 0.7197 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6489 Model_2_val:0.6438
Epoch: 0240 Model_1_loss: 0.6802 Model_2_loss: 0.7264 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6540 Model_2_val:0.6537
Epoch: 0260 Model_1_loss: 0.6766 Model_2_loss: 0.6563 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6672 Model_2_val:0.6655
Epoch: 0280 Model_1_loss: 0.6055 Model_2_loss: 0.5918 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6601 Model_2_val:0.6533
Epoch: 0300 Model_1_loss: 0.5818 Model_2_loss: 0.5814 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6720 Model_2_val:0.6594
Epoch: 0320 Model_1_loss: 0.5114 Model_2_loss: 0.5563 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6577 Model_2_val:0.6666
Epoch: 0340 Model_1_loss: 0.5362 Model_2_loss: 0.5448 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6516 Model_2_val:0.6676
Epoch: 0360 Model_1_loss: 0.4925 Model_2_loss: 0.4950 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6655 Model_2_val:0.6649
Epoch: 0380 Model_1_loss: 0.5224 Model_2_loss: 0.5090 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6666 Model_2_val:0.6666
Epoch: 0400 Model_1_loss: 0.4900 Model_2_loss: 0.4994 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6611 Model_2_val:0.6615
Model_one_test:0.6920 Model_two_test:0.6913
added by two output: 0.6923
14
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
621336989
Epoch: 0020 Model_1_loss: 1.7542 Model_2_loss: 1.7110 Model_1_trainacc: 0.3750 Model_2_trainacc: 0.4000 Model_1_val:0.2649 Model_2_val:0.2592
Epoch: 0040 Model_1_loss: 1.6316 Model_2_loss: 1.4837 Model_1_trainacc: 0.6167 Model_2_trainacc: 0.7500 Model_1_val:0.3913 Model_2_val:0.4449
Epoch: 0060 Model_1_loss: 1.3383 Model_2_loss: 1.1640 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8917 Model_1_val:0.4732 Model_2_val:0.5082
Epoch: 0080 Model_1_loss: 1.0315 Model_2_loss: 0.8447 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9250 Model_1_val:0.5258 Model_2_val:0.5561
Epoch: 0100 Model_1_loss: 0.8560 Model_2_loss: 0.6633 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9667 Model_1_val:0.5514 Model_2_val:0.5687
Epoch: 0120 Model_1_loss: 0.7006 Model_2_loss: 0.5508 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9833 Model_1_val:0.5617 Model_2_val:0.5820
Epoch: 0140 Model_1_loss: 0.5525 Model_2_loss: 0.5058 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.5800 Model_2_val:0.5920
Epoch: 0160 Model_1_loss: 0.5899 Model_2_loss: 0.4617 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.5667 Model_2_val:0.5880
Epoch: 0180 Model_1_loss: 0.4794 Model_2_loss: 0.3891 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5734 Model_2_val:0.5983
Epoch: 0200 Model_1_loss: 0.4331 Model_2_loss: 0.3410 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.5810 Model_2_val:0.5970
Epoch: 0220 Model_1_loss: 0.7609 Model_2_loss: 0.7240 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6286 Model_2_val:0.6539
Epoch: 0240 Model_1_loss: 0.6568 Model_2_loss: 0.6306 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6479 Model_2_val:0.6659
Epoch: 0260 Model_1_loss: 0.6717 Model_2_loss: 0.6112 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6459 Model_2_val:0.6712
Epoch: 0280 Model_1_loss: 0.6160 Model_2_loss: 0.5612 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6626 Model_2_val:0.6619
Epoch: 0300 Model_1_loss: 0.5938 Model_2_loss: 0.4949 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6549 Model_2_val:0.6616
Epoch: 0320 Model_1_loss: 0.5405 Model_2_loss: 0.4571 Model_1_trainacc: 0.9583 Model_2_trainacc: 1.0000 Model_1_val:0.6592 Model_2_val:0.6662
Epoch: 0340 Model_1_loss: 0.5341 Model_2_loss: 0.4432 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6596 Model_2_val:0.6735
Epoch: 0360 Model_1_loss: 0.5311 Model_2_loss: 0.4357 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6566 Model_2_val:0.6639
Epoch: 0380 Model_1_loss: 0.5234 Model_2_loss: 0.4358 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6572 Model_2_val:0.6709
Epoch: 0400 Model_1_loss: 0.5044 Model_2_loss: 0.4386 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6652 Model_2_val:0.6586
Model_one_test:0.6908 Model_two_test:0.6872
added by two output: 0.6895
15
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
868045830
Epoch: 0020 Model_1_loss: 1.7227 Model_2_loss: 1.7134 Model_1_trainacc: 0.3000 Model_2_trainacc: 0.3000 Model_1_val:0.2268 Model_2_val:0.2510
Epoch: 0040 Model_1_loss: 1.5902 Model_2_loss: 1.5206 Model_1_trainacc: 0.6833 Model_2_trainacc: 0.7333 Model_1_val:0.3820 Model_2_val:0.4594
Epoch: 0060 Model_1_loss: 1.3589 Model_2_loss: 1.2180 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8417 Model_1_val:0.4626 Model_2_val:0.5019
Epoch: 0080 Model_1_loss: 1.0645 Model_2_loss: 0.9486 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9083 Model_1_val:0.5048 Model_2_val:0.5168
Epoch: 0100 Model_1_loss: 0.8484 Model_2_loss: 0.7804 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9167 Model_1_val:0.5311 Model_2_val:0.5266
Epoch: 0120 Model_1_loss: 0.6873 Model_2_loss: 0.6489 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5466 Model_2_val:0.5470
Epoch: 0140 Model_1_loss: 0.6145 Model_2_loss: 0.6428 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9250 Model_1_val:0.5555 Model_2_val:0.5603
Epoch: 0160 Model_1_loss: 0.5451 Model_2_loss: 0.5307 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.5733 Model_2_val:0.5625
Epoch: 0180 Model_1_loss: 0.4914 Model_2_loss: 0.4604 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.5673 Model_2_val:0.5707
Epoch: 0200 Model_1_loss: 0.4902 Model_2_loss: 0.4749 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.5869 Model_2_val:0.5698
Epoch: 0220 Model_1_loss: 0.8149 Model_2_loss: 0.7967 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6634 Model_2_val:0.6361
Epoch: 0240 Model_1_loss: 0.6933 Model_2_loss: 0.7926 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6672 Model_2_val:0.6675
Epoch: 0260 Model_1_loss: 0.6387 Model_2_loss: 0.6914 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6780 Model_2_val:0.6656
Epoch: 0280 Model_1_loss: 0.6194 Model_2_loss: 0.7033 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6831 Model_2_val:0.6732
Epoch: 0300 Model_1_loss: 0.5832 Model_2_loss: 0.6224 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6891 Model_2_val:0.6726
Epoch: 0320 Model_1_loss: 0.6224 Model_2_loss: 0.6410 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6846 Model_2_val:0.6631
Epoch: 0340 Model_1_loss: 0.5772 Model_2_loss: 0.5806 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6875 Model_2_val:0.6675
Epoch: 0360 Model_1_loss: 0.4884 Model_2_loss: 0.5964 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6957 Model_2_val:0.6707
Epoch: 0380 Model_1_loss: 0.4873 Model_2_loss: 0.5715 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6907 Model_2_val:0.6748
Epoch: 0400 Model_1_loss: 0.5046 Model_2_loss: 0.5979 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6837 Model_2_val:0.6666
Model_one_test:0.7034 Model_two_test:0.7075
added by two output: 0.7075
16
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1525638245
Epoch: 0020 Model_1_loss: 1.6951 Model_2_loss: 1.7253 Model_1_trainacc: 0.5833 Model_2_trainacc: 0.3917 Model_1_val:0.3603 Model_2_val:0.2650
Epoch: 0040 Model_1_loss: 1.4782 Model_2_loss: 1.5242 Model_1_trainacc: 0.7583 Model_2_trainacc: 0.8167 Model_1_val:0.4657 Model_2_val:0.4818
Epoch: 0060 Model_1_loss: 1.1623 Model_2_loss: 1.2072 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8583 Model_1_val:0.5504 Model_2_val:0.4989
Epoch: 0080 Model_1_loss: 0.8723 Model_2_loss: 0.9200 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9000 Model_1_val:0.5846 Model_2_val:0.5589
Epoch: 0100 Model_1_loss: 0.7388 Model_2_loss: 0.7083 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5967 Model_2_val:0.5961
Epoch: 0120 Model_1_loss: 0.6456 Model_2_loss: 0.6215 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.6089 Model_2_val:0.6076
Epoch: 0140 Model_1_loss: 0.5442 Model_2_loss: 0.5345 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.6099 Model_2_val:0.6066
Epoch: 0160 Model_1_loss: 0.5099 Model_2_loss: 0.4630 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.6217 Model_2_val:0.6128
Epoch: 0180 Model_1_loss: 0.4574 Model_2_loss: 0.4592 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6263 Model_2_val:0.6223
Epoch: 0200 Model_1_loss: 0.4454 Model_2_loss: 0.4154 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6289 Model_2_val:0.6220
Epoch: 0220 Model_1_loss: 0.7059 Model_2_loss: 0.7038 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6801 Model_2_val:0.6673
Epoch: 0240 Model_1_loss: 0.6670 Model_2_loss: 0.6822 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6768 Model_2_val:0.6778
Epoch: 0260 Model_1_loss: 0.6267 Model_2_loss: 0.6196 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6788 Model_2_val:0.6690
Epoch: 0280 Model_1_loss: 0.5963 Model_2_loss: 0.5924 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6808 Model_2_val:0.6660
Epoch: 0300 Model_1_loss: 0.5716 Model_2_loss: 0.5884 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6706 Model_2_val:0.6742
Epoch: 0320 Model_1_loss: 0.5934 Model_2_loss: 0.6120 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6736 Model_2_val:0.6683
Epoch: 0340 Model_1_loss: 0.5184 Model_2_loss: 0.5466 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6785 Model_2_val:0.6617
Epoch: 0360 Model_1_loss: 0.5687 Model_2_loss: 0.5763 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6650 Model_2_val:0.6634
Epoch: 0380 Model_1_loss: 0.5103 Model_2_loss: 0.4922 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6706 Model_2_val:0.6650
Epoch: 0400 Model_1_loss: 0.4816 Model_2_loss: 0.5512 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6811 Model_2_val:0.6670
Model_one_test:0.6900 Model_two_test:0.6877
added by two output: 0.6883
17
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1406750122
Epoch: 0020 Model_1_loss: 1.7335 Model_2_loss: 1.7274 Model_1_trainacc: 0.4167 Model_2_trainacc: 0.4333 Model_1_val:0.2440 Model_2_val:0.2674
Epoch: 0040 Model_1_loss: 1.5888 Model_2_loss: 1.5656 Model_1_trainacc: 0.6500 Model_2_trainacc: 0.7333 Model_1_val:0.4046 Model_2_val:0.4453
Epoch: 0060 Model_1_loss: 1.3772 Model_2_loss: 1.2834 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.7917 Model_1_val:0.4575 Model_2_val:0.4642
Epoch: 0080 Model_1_loss: 1.0978 Model_2_loss: 0.9522 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8833 Model_1_val:0.5117 Model_2_val:0.5327
Epoch: 0100 Model_1_loss: 0.8243 Model_2_loss: 0.7993 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8917 Model_1_val:0.5351 Model_2_val:0.5391
Epoch: 0120 Model_1_loss: 0.7283 Model_2_loss: 0.6645 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9250 Model_1_val:0.5547 Model_2_val:0.5751
Epoch: 0140 Model_1_loss: 0.6040 Model_2_loss: 0.5575 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5717 Model_2_val:0.5822
Epoch: 0160 Model_1_loss: 0.4826 Model_2_loss: 0.5127 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9417 Model_1_val:0.5585 Model_2_val:0.5832
Epoch: 0180 Model_1_loss: 0.4588 Model_2_loss: 0.4314 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9833 Model_1_val:0.5693 Model_2_val:0.5910
Epoch: 0200 Model_1_loss: 0.4348 Model_2_loss: 0.4509 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5795 Model_2_val:0.5893
Epoch: 0220 Model_1_loss: 0.7516 Model_2_loss: 0.7672 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6618 Model_2_val:0.6547
Epoch: 0240 Model_1_loss: 0.7296 Model_2_loss: 0.6617 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9333 Model_1_val:0.6611 Model_2_val:0.6672
Epoch: 0260 Model_1_loss: 0.6877 Model_2_loss: 0.6589 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6615 Model_2_val:0.6699
Epoch: 0280 Model_1_loss: 0.6592 Model_2_loss: 0.6065 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6750 Model_2_val:0.6740
Epoch: 0300 Model_1_loss: 0.6305 Model_2_loss: 0.6079 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6703 Model_2_val:0.6808
Epoch: 0320 Model_1_loss: 0.5934 Model_2_loss: 0.6082 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6747 Model_2_val:0.6757
Epoch: 0340 Model_1_loss: 0.5454 Model_2_loss: 0.5434 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6750 Model_2_val:0.6757
Epoch: 0360 Model_1_loss: 0.5195 Model_2_loss: 0.5265 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6869 Model_2_val:0.6764
Epoch: 0380 Model_1_loss: 0.5585 Model_2_loss: 0.5042 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6804 Model_2_val:0.6811
Epoch: 0400 Model_1_loss: 0.4678 Model_2_loss: 0.4742 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6771 Model_2_val:0.6808
Model_one_test:0.7072 Model_two_test:0.7055
added by two output: 0.7045
18
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1557748000
Epoch: 0020 Model_1_loss: 1.6657 Model_2_loss: 1.7388 Model_1_trainacc: 0.6333 Model_2_trainacc: 0.3917 Model_1_val:0.2955 Model_2_val:0.2866
Epoch: 0040 Model_1_loss: 1.3830 Model_2_loss: 1.5401 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.7250 Model_1_val:0.4774 Model_2_val:0.4471
Epoch: 0060 Model_1_loss: 1.1039 Model_2_loss: 1.1890 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8833 Model_1_val:0.5402 Model_2_val:0.5356
Epoch: 0080 Model_1_loss: 0.7955 Model_2_loss: 0.8498 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9083 Model_1_val:0.5455 Model_2_val:0.6027
Epoch: 0100 Model_1_loss: 0.6633 Model_2_loss: 0.6564 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5918 Model_2_val:0.5874
Epoch: 0120 Model_1_loss: 0.5221 Model_2_loss: 0.5279 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5928 Model_2_val:0.6031
Epoch: 0140 Model_1_loss: 0.5017 Model_2_loss: 0.4552 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5991 Model_2_val:0.6110
Epoch: 0160 Model_1_loss: 0.4187 Model_2_loss: 0.4377 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.5981 Model_2_val:0.6346
Epoch: 0180 Model_1_loss: 0.3430 Model_2_loss: 0.3679 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6170 Model_2_val:0.6263
Epoch: 0200 Model_1_loss: 0.3288 Model_2_loss: 0.3450 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6177 Model_2_val:0.6439
Epoch: 0220 Model_1_loss: 0.6590 Model_2_loss: 0.6429 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6622 Model_2_val:0.6739
Epoch: 0240 Model_1_loss: 0.5727 Model_2_loss: 0.5882 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6639 Model_2_val:0.6785
Epoch: 0260 Model_1_loss: 0.5639 Model_2_loss: 0.5579 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6712 Model_2_val:0.6732
Epoch: 0280 Model_1_loss: 0.5058 Model_2_loss: 0.4996 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6752 Model_2_val:0.6725
Epoch: 0300 Model_1_loss: 0.5251 Model_2_loss: 0.5558 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6722 Model_2_val:0.6725
Epoch: 0320 Model_1_loss: 0.4894 Model_2_loss: 0.5615 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6692 Model_2_val:0.6725
Epoch: 0340 Model_1_loss: 0.4473 Model_2_loss: 0.4751 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6569 Model_2_val:0.6742
Epoch: 0360 Model_1_loss: 0.4288 Model_2_loss: 0.4644 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6719 Model_2_val:0.6732
Epoch: 0380 Model_1_loss: 0.4651 Model_2_loss: 0.4789 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6639 Model_2_val:0.6636
Epoch: 0400 Model_1_loss: 0.4080 Model_2_loss: 0.4593 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6679 Model_2_val:0.6672
Model_one_test:0.6922 Model_two_test:0.6918
added by two output: 0.6908
19
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1364714213
Epoch: 0020 Model_1_loss: 1.7106 Model_2_loss: 1.7418 Model_1_trainacc: 0.3833 Model_2_trainacc: 0.3000 Model_1_val:0.2635 Model_2_val:0.2394
Epoch: 0040 Model_1_loss: 1.5057 Model_2_loss: 1.5494 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.7167 Model_1_val:0.4332 Model_2_val:0.3662
Epoch: 0060 Model_1_loss: 1.1847 Model_2_loss: 1.3205 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.7917 Model_1_val:0.4818 Model_2_val:0.4600
Epoch: 0080 Model_1_loss: 0.9644 Model_2_loss: 1.0696 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8167 Model_1_val:0.5253 Model_2_val:0.5060
Epoch: 0100 Model_1_loss: 0.7667 Model_2_loss: 0.8053 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9083 Model_1_val:0.5369 Model_2_val:0.5366
Epoch: 0120 Model_1_loss: 0.6154 Model_2_loss: 0.6636 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5682 Model_2_val:0.5519
Epoch: 0140 Model_1_loss: 0.5561 Model_2_loss: 0.6726 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5757 Model_2_val:0.5651
Epoch: 0160 Model_1_loss: 0.4620 Model_2_loss: 0.5442 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.5600 Model_2_val:0.5845
Epoch: 0180 Model_1_loss: 0.4457 Model_2_loss: 0.5193 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.5593 Model_2_val:0.5947
Epoch: 0200 Model_1_loss: 0.3968 Model_2_loss: 0.4864 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.5716 Model_2_val:0.5760
Epoch: 0220 Model_1_loss: 0.7526 Model_2_loss: 0.8063 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6549 Model_2_val:0.6396
Epoch: 0240 Model_1_loss: 0.6663 Model_2_loss: 0.6988 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6603 Model_2_val:0.6579
Epoch: 0260 Model_1_loss: 0.6424 Model_2_loss: 0.6808 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6549 Model_2_val:0.6586
Epoch: 0280 Model_1_loss: 0.6071 Model_2_loss: 0.6469 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6539 Model_2_val:0.6576
Epoch: 0300 Model_1_loss: 0.5633 Model_2_loss: 0.6059 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6637 Model_2_val:0.6525
Epoch: 0320 Model_1_loss: 0.5050 Model_2_loss: 0.5499 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6644 Model_2_val:0.6726
Epoch: 0340 Model_1_loss: 0.5292 Model_2_loss: 0.5992 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9500 Model_1_val:0.6579 Model_2_val:0.6664
Epoch: 0360 Model_1_loss: 0.4743 Model_2_loss: 0.5652 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9500 Model_1_val:0.6596 Model_2_val:0.6573
Epoch: 0380 Model_1_loss: 0.5032 Model_2_loss: 0.4843 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6634 Model_2_val:0.6729
Epoch: 0400 Model_1_loss: 0.4428 Model_2_loss: 0.5261 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9583 Model_1_val:0.6624 Model_2_val:0.6528
Model_one_test:0.6845 Model_two_test:0.6811
added by two output: 0.6817
20
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
80930649
Epoch: 0020 Model_1_loss: 1.7018 Model_2_loss: 1.7299 Model_1_trainacc: 0.3083 Model_2_trainacc: 0.2917 Model_1_val:0.2380 Model_2_val:0.2211
Epoch: 0040 Model_1_loss: 1.5085 Model_2_loss: 1.5656 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7083 Model_1_val:0.3682 Model_2_val:0.4003
Epoch: 0060 Model_1_loss: 1.2775 Model_2_loss: 1.2643 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8333 Model_1_val:0.4539 Model_2_val:0.4786
Epoch: 0080 Model_1_loss: 0.9871 Model_2_loss: 0.9483 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8917 Model_1_val:0.5097 Model_2_val:0.5078
Epoch: 0100 Model_1_loss: 0.7607 Model_2_loss: 0.7931 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9000 Model_1_val:0.5062 Model_2_val:0.5438
Epoch: 0120 Model_1_loss: 0.5883 Model_2_loss: 0.6505 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9167 Model_1_val:0.5594 Model_2_val:0.5692
Epoch: 0140 Model_1_loss: 0.5577 Model_2_loss: 0.5388 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.5679 Model_2_val:0.5773
Epoch: 0160 Model_1_loss: 0.4500 Model_2_loss: 0.4866 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5844 Model_2_val:0.5834
Epoch: 0180 Model_1_loss: 0.4361 Model_2_loss: 0.4602 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.5718 Model_2_val:0.5893
Epoch: 0200 Model_1_loss: 0.3756 Model_2_loss: 0.4354 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.5779 Model_2_val:0.5838
Epoch: 0220 Model_1_loss: 0.7327 Model_2_loss: 0.7400 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6562 Model_2_val:0.6604
Epoch: 0240 Model_1_loss: 0.6465 Model_2_loss: 0.7113 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6682 Model_2_val:0.6623
Epoch: 0260 Model_1_loss: 0.6144 Model_2_loss: 0.6715 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6711 Model_2_val:0.6685
Epoch: 0280 Model_1_loss: 0.5277 Model_2_loss: 0.6394 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6692 Model_2_val:0.6565
Epoch: 0300 Model_1_loss: 0.5491 Model_2_loss: 0.5372 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6773 Model_2_val:0.6640
Epoch: 0320 Model_1_loss: 0.4752 Model_2_loss: 0.5638 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6695 Model_2_val:0.6607
Epoch: 0340 Model_1_loss: 0.5203 Model_2_loss: 0.5127 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6701 Model_2_val:0.6760
Epoch: 0360 Model_1_loss: 0.4827 Model_2_loss: 0.5518 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6841 Model_2_val:0.6692
Epoch: 0380 Model_1_loss: 0.4765 Model_2_loss: 0.4870 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6727 Model_2_val:0.6747
Epoch: 0400 Model_1_loss: 0.4699 Model_2_loss: 0.4556 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6646 Model_2_val:0.6640
Model_one_test:0.7019 Model_two_test:0.6990
added by two output: 0.6997
21
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
774842302
Epoch: 0020 Model_1_loss: 1.7283 Model_2_loss: 1.6926 Model_1_trainacc: 0.4333 Model_2_trainacc: 0.5333 Model_1_val:0.2706 Model_2_val:0.3044
Epoch: 0040 Model_1_loss: 1.5964 Model_2_loss: 1.4664 Model_1_trainacc: 0.6333 Model_2_trainacc: 0.8500 Model_1_val:0.3982 Model_2_val:0.4336
Epoch: 0060 Model_1_loss: 1.3267 Model_2_loss: 1.1285 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.9333 Model_1_val:0.4536 Model_2_val:0.5166
Epoch: 0080 Model_1_loss: 1.0741 Model_2_loss: 0.8484 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.9500 Model_1_val:0.4923 Model_2_val:0.5530
Epoch: 0100 Model_1_loss: 0.8895 Model_2_loss: 0.6370 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9667 Model_1_val:0.5179 Model_2_val:0.5763
Epoch: 0120 Model_1_loss: 0.6900 Model_2_loss: 0.5449 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5330 Model_2_val:0.6054
Epoch: 0140 Model_1_loss: 0.6127 Model_2_loss: 0.4511 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5356 Model_2_val:0.6005
Epoch: 0160 Model_1_loss: 0.5849 Model_2_loss: 0.4332 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9917 Model_1_val:0.5294 Model_2_val:0.6117
Epoch: 0180 Model_1_loss: 0.5250 Model_2_loss: 0.3429 Model_1_trainacc: 0.9417 Model_2_trainacc: 1.0000 Model_1_val:0.5576 Model_2_val:0.6146
Epoch: 0200 Model_1_loss: 0.5563 Model_2_loss: 0.3240 Model_1_trainacc: 0.9250 Model_2_trainacc: 1.0000 Model_1_val:0.5661 Model_2_val:0.6166
Epoch: 0220 Model_1_loss: 0.9372 Model_2_loss: 0.7330 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9833 Model_1_val:0.6363 Model_2_val:0.6530
Epoch: 0240 Model_1_loss: 0.8648 Model_2_loss: 0.6452 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6353 Model_2_val:0.6776
Epoch: 0260 Model_1_loss: 0.7541 Model_2_loss: 0.6251 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6376 Model_2_val:0.6642
Epoch: 0280 Model_1_loss: 0.7732 Model_2_loss: 0.6011 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.6386 Model_2_val:0.6724
Epoch: 0300 Model_1_loss: 0.6402 Model_2_loss: 0.5664 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6494 Model_2_val:0.6671
Epoch: 0320 Model_1_loss: 0.6588 Model_2_loss: 0.5587 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6415 Model_2_val:0.6615
Epoch: 0340 Model_1_loss: 0.5942 Model_2_loss: 0.4913 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6471 Model_2_val:0.6645
Epoch: 0360 Model_1_loss: 0.6249 Model_2_loss: 0.4792 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6523 Model_2_val:0.6599
Epoch: 0380 Model_1_loss: 0.5843 Model_2_loss: 0.4897 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6504 Model_2_val:0.6645
Epoch: 0400 Model_1_loss: 0.5319 Model_2_loss: 0.4390 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6474 Model_2_val:0.6648
Model_one_test:0.6848 Model_two_test:0.6822
added by two output: 0.6828
22
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1044295956
Epoch: 0020 Model_1_loss: 1.6978 Model_2_loss: 1.7282 Model_1_trainacc: 0.4167 Model_2_trainacc: 0.3917 Model_1_val:0.2669 Model_2_val:0.1657
Epoch: 0040 Model_1_loss: 1.4740 Model_2_loss: 1.5593 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.7167 Model_1_val:0.4227 Model_2_val:0.3576
Epoch: 0060 Model_1_loss: 1.1726 Model_2_loss: 1.3088 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8000 Model_1_val:0.4862 Model_2_val:0.4322
Epoch: 0080 Model_1_loss: 0.9087 Model_2_loss: 1.0797 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8583 Model_1_val:0.5408 Model_2_val:0.4916
Epoch: 0100 Model_1_loss: 0.7146 Model_2_loss: 0.8760 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9000 Model_1_val:0.5496 Model_2_val:0.5118
Epoch: 0120 Model_1_loss: 0.5813 Model_2_loss: 0.7623 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.5870 Model_2_val:0.5169
Epoch: 0140 Model_1_loss: 0.5195 Model_2_loss: 0.6041 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9250 Model_1_val:0.5746 Model_2_val:0.5455
Epoch: 0160 Model_1_loss: 0.4549 Model_2_loss: 0.5435 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9000 Model_1_val:0.5725 Model_2_val:0.5408
Epoch: 0180 Model_1_loss: 0.3967 Model_2_loss: 0.4725 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.5881 Model_2_val:0.5425
Epoch: 0200 Model_1_loss: 0.4027 Model_2_loss: 0.4196 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.5725 Model_2_val:0.5351
Epoch: 0220 Model_1_loss: 0.7424 Model_2_loss: 0.7947 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.6265 Model_2_val:0.6306
Epoch: 0240 Model_1_loss: 0.7007 Model_2_loss: 0.6967 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6353 Model_2_val:0.6447
Epoch: 0260 Model_1_loss: 0.6454 Model_2_loss: 0.6368 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6417 Model_2_val:0.6538
Epoch: 0280 Model_1_loss: 0.6070 Model_2_loss: 0.6262 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6451 Model_2_val:0.6603
Epoch: 0300 Model_1_loss: 0.5217 Model_2_loss: 0.5794 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6532 Model_2_val:0.6528
Epoch: 0320 Model_1_loss: 0.5309 Model_2_loss: 0.5380 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6508 Model_2_val:0.6538
Epoch: 0340 Model_1_loss: 0.5188 Model_2_loss: 0.5411 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6609 Model_2_val:0.6660
Epoch: 0360 Model_1_loss: 0.4992 Model_2_loss: 0.4791 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6522 Model_2_val:0.6596
Epoch: 0380 Model_1_loss: 0.4562 Model_2_loss: 0.5346 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9583 Model_1_val:0.6491 Model_2_val:0.6535
Epoch: 0400 Model_1_loss: 0.4431 Model_2_loss: 0.4819 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6582 Model_2_val:0.6576
Model_one_test:0.6754 Model_two_test:0.6795
added by two output: 0.6785
23
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
115282561
Epoch: 0020 Model_1_loss: 1.7316 Model_2_loss: 1.7176 Model_1_trainacc: 0.4083 Model_2_trainacc: 0.4167 Model_1_val:0.2372 Model_2_val:0.2496
Epoch: 0040 Model_1_loss: 1.6099 Model_2_loss: 1.5299 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7167 Model_1_val:0.4062 Model_2_val:0.3827
Epoch: 0060 Model_1_loss: 1.3770 Model_2_loss: 1.2461 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8917 Model_1_val:0.4450 Model_2_val:0.4460
Epoch: 0080 Model_1_loss: 1.1056 Model_2_loss: 0.9838 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8917 Model_1_val:0.5077 Model_2_val:0.5109
Epoch: 0100 Model_1_loss: 0.8551 Model_2_loss: 0.7712 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9333 Model_1_val:0.5240 Model_2_val:0.5560
Epoch: 0120 Model_1_loss: 0.7148 Model_2_loss: 0.6073 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5364 Model_2_val:0.5579
Epoch: 0140 Model_1_loss: 0.6405 Model_2_loss: 0.5839 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5299 Model_2_val:0.5804
Epoch: 0160 Model_1_loss: 0.5742 Model_2_loss: 0.4903 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.5700 Model_2_val:0.5931
Epoch: 0180 Model_1_loss: 0.5328 Model_2_loss: 0.4023 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.5703 Model_2_val:0.5804
Epoch: 0200 Model_1_loss: 0.5308 Model_2_loss: 0.4174 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5896 Model_2_val:0.5752
Epoch: 0220 Model_1_loss: 0.8907 Model_2_loss: 0.7289 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6271 Model_2_val:0.6427
Epoch: 0240 Model_1_loss: 0.7655 Model_2_loss: 0.7711 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6496 Model_2_val:0.6502
Epoch: 0260 Model_1_loss: 0.7082 Model_2_loss: 0.6311 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6405 Model_2_val:0.6483
Epoch: 0280 Model_1_loss: 0.6712 Model_2_loss: 0.5969 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6411 Model_2_val:0.6525
Epoch: 0300 Model_1_loss: 0.6137 Model_2_loss: 0.5792 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6457 Model_2_val:0.6577
Epoch: 0320 Model_1_loss: 0.6241 Model_2_loss: 0.5512 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6483 Model_2_val:0.6568
Epoch: 0340 Model_1_loss: 0.5733 Model_2_loss: 0.5433 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6388 Model_2_val:0.6653
Epoch: 0360 Model_1_loss: 0.5220 Model_2_loss: 0.5429 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.6538 Model_2_val:0.6705
Epoch: 0380 Model_1_loss: 0.5248 Model_2_loss: 0.5055 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6594 Model_2_val:0.6597
Epoch: 0400 Model_1_loss: 0.5887 Model_2_loss: 0.4816 Model_1_trainacc: 0.9583 Model_2_trainacc: 1.0000 Model_1_val:0.6512 Model_2_val:0.6633
Model_one_test:0.6819 Model_two_test:0.6780
added by two output: 0.6812
24
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
659422848
Epoch: 0020 Model_1_loss: 1.7299 Model_2_loss: 1.7083 Model_1_trainacc: 0.4750 Model_2_trainacc: 0.4750 Model_1_val:0.3148 Model_2_val:0.2502
Epoch: 0040 Model_1_loss: 1.5520 Model_2_loss: 1.4937 Model_1_trainacc: 0.6333 Model_2_trainacc: 0.8250 Model_1_val:0.4003 Model_2_val:0.3950
Epoch: 0060 Model_1_loss: 1.2778 Model_2_loss: 1.1913 Model_1_trainacc: 0.7583 Model_2_trainacc: 0.8833 Model_1_val:0.4720 Model_2_val:0.4992
Epoch: 0080 Model_1_loss: 0.9860 Model_2_loss: 0.8869 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.5116 Model_2_val:0.5303
Epoch: 0100 Model_1_loss: 0.8059 Model_2_loss: 0.6937 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9500 Model_1_val:0.5208 Model_2_val:0.5490
Epoch: 0120 Model_1_loss: 0.7366 Model_2_loss: 0.6032 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9417 Model_1_val:0.5378 Model_2_val:0.5699
Epoch: 0140 Model_1_loss: 0.6005 Model_2_loss: 0.5233 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5562 Model_2_val:0.5755
Epoch: 0160 Model_1_loss: 0.5795 Model_2_loss: 0.4575 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9667 Model_1_val:0.5532 Model_2_val:0.5670
Epoch: 0180 Model_1_loss: 0.5313 Model_2_loss: 0.3713 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.5667 Model_2_val:0.5794
Epoch: 0200 Model_1_loss: 0.4463 Model_2_loss: 0.3671 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.5545 Model_2_val:0.5863
Epoch: 0220 Model_1_loss: 0.8529 Model_2_loss: 0.6825 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6292 Model_2_val:0.6571
Epoch: 0240 Model_1_loss: 0.7410 Model_2_loss: 0.6801 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6443 Model_2_val:0.6492
Epoch: 0260 Model_1_loss: 0.7698 Model_2_loss: 0.6462 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6495 Model_2_val:0.6607
Epoch: 0280 Model_1_loss: 0.7043 Model_2_loss: 0.6135 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6459 Model_2_val:0.6554
Epoch: 0300 Model_1_loss: 0.6931 Model_2_loss: 0.6011 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.6325 Model_2_val:0.6603
Epoch: 0320 Model_1_loss: 0.7003 Model_2_loss: 0.5737 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.6381 Model_2_val:0.6561
Epoch: 0340 Model_1_loss: 0.6195 Model_2_loss: 0.5140 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6410 Model_2_val:0.6639
Epoch: 0360 Model_1_loss: 0.6447 Model_2_loss: 0.5323 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.6315 Model_2_val:0.6603
Epoch: 0380 Model_1_loss: 0.6549 Model_2_loss: 0.5153 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.6404 Model_2_val:0.6682
Epoch: 0400 Model_1_loss: 0.5162 Model_2_loss: 0.5061 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6433 Model_2_val:0.6594
Model_one_test:0.6725 Model_two_test:0.6793
added by two output: 0.6761
25
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1557050566
Epoch: 0020 Model_1_loss: 1.7324 Model_2_loss: 1.7597 Model_1_trainacc: 0.4417 Model_2_trainacc: 0.2000 Model_1_val:0.3269 Model_2_val:0.1646
Epoch: 0040 Model_1_loss: 1.5557 Model_2_loss: 1.6786 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.5750 Model_1_val:0.4524 Model_2_val:0.3533
Epoch: 0060 Model_1_loss: 1.2416 Model_2_loss: 1.5097 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.7083 Model_1_val:0.5316 Model_2_val:0.4413
Epoch: 0080 Model_1_loss: 0.9614 Model_2_loss: 1.3460 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.7583 Model_1_val:0.5639 Model_2_val:0.4775
Epoch: 0100 Model_1_loss: 0.7408 Model_2_loss: 1.1140 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.8667 Model_1_val:0.5851 Model_2_val:0.5000
Epoch: 0120 Model_1_loss: 0.6687 Model_2_loss: 0.9998 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8417 Model_1_val:0.6023 Model_2_val:0.5153
Epoch: 0140 Model_1_loss: 0.5494 Model_2_loss: 0.8656 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.8583 Model_1_val:0.6023 Model_2_val:0.5355
Epoch: 0160 Model_1_loss: 0.4647 Model_2_loss: 0.7192 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9167 Model_1_val:0.6245 Model_2_val:0.5420
Epoch: 0180 Model_1_loss: 0.3986 Model_2_loss: 0.6763 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.8833 Model_1_val:0.6287 Model_2_val:0.5499
Epoch: 0200 Model_1_loss: 0.3481 Model_2_loss: 0.5681 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9250 Model_1_val:0.6320 Model_2_val:0.5610
Epoch: 0220 Model_1_loss: 0.7637 Model_2_loss: 0.8733 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6757 Model_2_val:0.6490
Epoch: 0240 Model_1_loss: 0.6903 Model_2_loss: 0.7594 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6900 Model_2_val:0.6581
Epoch: 0260 Model_1_loss: 0.5964 Model_2_loss: 0.7805 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9417 Model_1_val:0.6877 Model_2_val:0.6698
Epoch: 0280 Model_1_loss: 0.6076 Model_2_loss: 0.7496 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.6894 Model_2_val:0.6734
Epoch: 0300 Model_1_loss: 0.5982 Model_2_loss: 0.6400 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6920 Model_2_val:0.6767
Epoch: 0320 Model_1_loss: 0.5316 Model_2_loss: 0.6489 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6923 Model_2_val:0.6763
Epoch: 0340 Model_1_loss: 0.5503 Model_2_loss: 0.5856 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6900 Model_2_val:0.6721
Epoch: 0360 Model_1_loss: 0.5056 Model_2_loss: 0.5598 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6975 Model_2_val:0.6871
Epoch: 0380 Model_1_loss: 0.4513 Model_2_loss: 0.5584 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6965 Model_2_val:0.6799
Epoch: 0400 Model_1_loss: 0.4789 Model_2_loss: 0.5736 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6917 Model_2_val:0.6757
Model_one_test:0.7086 Model_two_test:0.7138
added by two output: 0.7109
26
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
456340504
Epoch: 0020 Model_1_loss: 1.7574 Model_2_loss: 1.7164 Model_1_trainacc: 0.3583 Model_2_trainacc: 0.4833 Model_1_val:0.2674 Model_2_val:0.3474
Epoch: 0040 Model_1_loss: 1.6336 Model_2_loss: 1.5228 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.7250 Model_1_val:0.4073 Model_2_val:0.4840
Epoch: 0060 Model_1_loss: 1.4383 Model_2_loss: 1.2167 Model_1_trainacc: 0.7583 Model_2_trainacc: 0.8417 Model_1_val:0.4377 Model_2_val:0.5150
Epoch: 0080 Model_1_loss: 1.1528 Model_2_loss: 0.9624 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.9000 Model_1_val:0.4767 Model_2_val:0.5580
Epoch: 0100 Model_1_loss: 0.9782 Model_2_loss: 0.7614 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9083 Model_1_val:0.4906 Model_2_val:0.5461
Epoch: 0120 Model_1_loss: 0.7872 Model_2_loss: 0.6424 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9417 Model_1_val:0.5124 Model_2_val:0.5580
Epoch: 0140 Model_1_loss: 0.6564 Model_2_loss: 0.5835 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.5428 Model_2_val:0.5527
Epoch: 0160 Model_1_loss: 0.5943 Model_2_loss: 0.4926 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5531 Model_2_val:0.5745
Epoch: 0180 Model_1_loss: 0.5242 Model_2_loss: 0.4559 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5683 Model_2_val:0.5739
Epoch: 0200 Model_1_loss: 0.5376 Model_2_loss: 0.3973 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9917 Model_1_val:0.5679 Model_2_val:0.5884
Epoch: 0220 Model_1_loss: 0.8251 Model_2_loss: 0.8155 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6400 Model_2_val:0.6354
Epoch: 0240 Model_1_loss: 0.7755 Model_2_loss: 0.6868 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6509 Model_2_val:0.6651
Epoch: 0260 Model_1_loss: 0.6931 Model_2_loss: 0.6566 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6555 Model_2_val:0.6655
Epoch: 0280 Model_1_loss: 0.7114 Model_2_loss: 0.6113 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.6602 Model_2_val:0.6731
Epoch: 0300 Model_1_loss: 0.6468 Model_2_loss: 0.6031 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6542 Model_2_val:0.6711
Epoch: 0320 Model_1_loss: 0.6215 Model_2_loss: 0.5546 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6631 Model_2_val:0.6668
Epoch: 0340 Model_1_loss: 0.5840 Model_2_loss: 0.4873 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6529 Model_2_val:0.6727
Epoch: 0360 Model_1_loss: 0.5355 Model_2_loss: 0.5071 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6645 Model_2_val:0.6684
Epoch: 0380 Model_1_loss: 0.4820 Model_2_loss: 0.4556 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6641 Model_2_val:0.6737
Epoch: 0400 Model_1_loss: 0.5308 Model_2_loss: 0.4437 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6559 Model_2_val:0.6707
Model_one_test:0.6902 Model_two_test:0.6939
added by two output: 0.6916
27
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
48114088
Epoch: 0020 Model_1_loss: 1.7108 Model_2_loss: 1.6811 Model_1_trainacc: 0.4500 Model_2_trainacc: 0.4750 Model_1_val:0.2957 Model_2_val:0.2986
Epoch: 0040 Model_1_loss: 1.4951 Model_2_loss: 1.4888 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.7417 Model_1_val:0.4502 Model_2_val:0.4378
Epoch: 0060 Model_1_loss: 1.1613 Model_2_loss: 1.2248 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8417 Model_1_val:0.5296 Model_2_val:0.5060
Epoch: 0080 Model_1_loss: 0.9414 Model_2_loss: 0.9257 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9083 Model_1_val:0.5724 Model_2_val:0.5609
Epoch: 0100 Model_1_loss: 0.7540 Model_2_loss: 0.7352 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9500 Model_1_val:0.5893 Model_2_val:0.5622
Epoch: 0120 Model_1_loss: 0.6056 Model_2_loss: 0.6393 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.6014 Model_2_val:0.6112
Epoch: 0140 Model_1_loss: 0.5149 Model_2_loss: 0.5052 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6188 Model_2_val:0.6125
Epoch: 0160 Model_1_loss: 0.4986 Model_2_loss: 0.5285 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.6259 Model_2_val:0.6047
Epoch: 0180 Model_1_loss: 0.4392 Model_2_loss: 0.4379 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6331 Model_2_val:0.6152
Epoch: 0200 Model_1_loss: 0.4209 Model_2_loss: 0.4103 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6269 Model_2_val:0.6116
Epoch: 0220 Model_1_loss: 0.7512 Model_2_loss: 0.6813 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6694 Model_2_val:0.6691
Epoch: 0240 Model_1_loss: 0.6384 Model_2_loss: 0.6491 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6766 Model_2_val:0.6733
Epoch: 0260 Model_1_loss: 0.5979 Model_2_loss: 0.6071 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6939 Model_2_val:0.6733
Epoch: 0280 Model_1_loss: 0.5841 Model_2_loss: 0.6066 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6851 Model_2_val:0.6655
Epoch: 0300 Model_1_loss: 0.5456 Model_2_loss: 0.5872 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6854 Model_2_val:0.6743
Epoch: 0320 Model_1_loss: 0.5136 Model_2_loss: 0.6120 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.6861 Model_2_val:0.6681
Epoch: 0340 Model_1_loss: 0.5112 Model_2_loss: 0.5778 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6684 Model_2_val:0.6658
Epoch: 0360 Model_1_loss: 0.4990 Model_2_loss: 0.4668 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6821 Model_2_val:0.6828
Epoch: 0380 Model_1_loss: 0.4797 Model_2_loss: 0.4732 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6811 Model_2_val:0.6678
Epoch: 0400 Model_1_loss: 0.4337 Model_2_loss: 0.4891 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6740 Model_2_val:0.6782
Model_one_test:0.6998 Model_two_test:0.6994
added by two output: 0.7021
28
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
754007471
Epoch: 0020 Model_1_loss: 1.7407 Model_2_loss: 1.6885 Model_1_trainacc: 0.4167 Model_2_trainacc: 0.4167 Model_1_val:0.2874 Model_2_val:0.2414
Epoch: 0040 Model_1_loss: 1.5732 Model_2_loss: 1.4955 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.6833 Model_1_val:0.4222 Model_2_val:0.4288
Epoch: 0060 Model_1_loss: 1.3360 Model_2_loss: 1.1790 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.8250 Model_1_val:0.4653 Model_2_val:0.5054
Epoch: 0080 Model_1_loss: 1.0632 Model_2_loss: 0.8735 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8917 Model_1_val:0.5110 Model_2_val:0.5594
Epoch: 0100 Model_1_loss: 0.8358 Model_2_loss: 0.7272 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8917 Model_1_val:0.5403 Model_2_val:0.5617
Epoch: 0120 Model_1_loss: 0.7486 Model_2_loss: 0.6139 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9083 Model_1_val:0.5554 Model_2_val:0.5824
Epoch: 0140 Model_1_loss: 0.6531 Model_2_loss: 0.5337 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5804 Model_2_val:0.5712
Epoch: 0160 Model_1_loss: 0.5744 Model_2_loss: 0.4626 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9583 Model_1_val:0.5640 Model_2_val:0.5725
Epoch: 0180 Model_1_loss: 0.5624 Model_2_loss: 0.4347 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9667 Model_1_val:0.5719 Model_2_val:0.5893
Epoch: 0200 Model_1_loss: 0.4849 Model_2_loss: 0.3970 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5834 Model_2_val:0.5893
Epoch: 0220 Model_1_loss: 0.8305 Model_2_loss: 0.7587 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6557 Model_2_val:0.6550
Epoch: 0240 Model_1_loss: 0.6895 Model_2_loss: 0.6980 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6481 Model_2_val:0.6554
Epoch: 0260 Model_1_loss: 0.6592 Model_2_loss: 0.6723 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6567 Model_2_val:0.6610
Epoch: 0280 Model_1_loss: 0.6287 Model_2_loss: 0.6285 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.6643 Model_2_val:0.6606
Epoch: 0300 Model_1_loss: 0.5975 Model_2_loss: 0.6092 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6557 Model_2_val:0.6544
Epoch: 0320 Model_1_loss: 0.5346 Model_2_loss: 0.5376 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6715 Model_2_val:0.6564
Epoch: 0340 Model_1_loss: 0.5314 Model_2_loss: 0.4778 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9833 Model_1_val:0.6557 Model_2_val:0.6626
Epoch: 0360 Model_1_loss: 0.5257 Model_2_loss: 0.5127 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6662 Model_2_val:0.6541
Epoch: 0380 Model_1_loss: 0.4706 Model_2_loss: 0.4912 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6583 Model_2_val:0.6580
Epoch: 0400 Model_1_loss: 0.5097 Model_2_loss: 0.4921 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6468 Model_2_val:0.6524
Model_one_test:0.6827 Model_two_test:0.6758
added by two output: 0.6768
29
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1515294089
Epoch: 0020 Model_1_loss: 1.7008 Model_2_loss: 1.7597 Model_1_trainacc: 0.4500 Model_2_trainacc: 0.4417 Model_1_val:0.3275 Model_2_val:0.2540
Epoch: 0040 Model_1_loss: 1.4901 Model_2_loss: 1.6356 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.7833 Model_1_val:0.4670 Model_2_val:0.4248
Epoch: 0060 Model_1_loss: 1.1839 Model_2_loss: 1.3336 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8250 Model_1_val:0.5139 Model_2_val:0.4960
Epoch: 0080 Model_1_loss: 0.9375 Model_2_loss: 1.0270 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8333 Model_1_val:0.5303 Model_2_val:0.5366
Epoch: 0100 Model_1_loss: 0.7949 Model_2_loss: 0.8523 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9083 Model_1_val:0.5455 Model_2_val:0.5267
Epoch: 0120 Model_1_loss: 0.6498 Model_2_loss: 0.7451 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9000 Model_1_val:0.5584 Model_2_val:0.5594
Epoch: 0140 Model_1_loss: 0.5593 Model_2_loss: 0.5581 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.5772 Model_2_val:0.5699
Epoch: 0160 Model_1_loss: 0.5304 Model_2_loss: 0.5012 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9833 Model_1_val:0.5663 Model_2_val:0.5745
Epoch: 0180 Model_1_loss: 0.4990 Model_2_loss: 0.4809 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5693 Model_2_val:0.5881
Epoch: 0200 Model_1_loss: 0.4403 Model_2_loss: 0.4464 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5798 Model_2_val:0.5877
Epoch: 0220 Model_1_loss: 0.7820 Model_2_loss: 0.8240 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6514 Model_2_val:0.6649
Epoch: 0240 Model_1_loss: 0.7084 Model_2_loss: 0.7125 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6639 Model_2_val:0.6797
Epoch: 0260 Model_1_loss: 0.6466 Model_2_loss: 0.7096 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6755 Model_2_val:0.6761
Epoch: 0280 Model_1_loss: 0.6285 Model_2_loss: 0.5889 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6692 Model_2_val:0.6784
Epoch: 0300 Model_1_loss: 0.6100 Model_2_loss: 0.5761 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6679 Model_2_val:0.6781
Epoch: 0320 Model_1_loss: 0.5960 Model_2_loss: 0.6160 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6672 Model_2_val:0.6830
Epoch: 0340 Model_1_loss: 0.5871 Model_2_loss: 0.5717 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6784 Model_2_val:0.6847
Epoch: 0360 Model_1_loss: 0.5607 Model_2_loss: 0.5319 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6758 Model_2_val:0.6824
Epoch: 0380 Model_1_loss: 0.5456 Model_2_loss: 0.5310 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6821 Model_2_val:0.6778
Epoch: 0400 Model_1_loss: 0.5043 Model_2_loss: 0.5448 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6814 Model_2_val:0.6741
Model_one_test:0.7002 Model_two_test:0.7065
added by two output: 0.7051
30
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
84734359
Epoch: 0020 Model_1_loss: 1.7161 Model_2_loss: 1.7557 Model_1_trainacc: 0.5000 Model_2_trainacc: 0.3917 Model_1_val:0.3178 Model_2_val:0.1873
Epoch: 0040 Model_1_loss: 1.5200 Model_2_loss: 1.6024 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.6917 Model_1_val:0.4725 Model_2_val:0.3439
Epoch: 0060 Model_1_loss: 1.2054 Model_2_loss: 1.3501 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.7583 Model_1_val:0.4873 Model_2_val:0.4596
Epoch: 0080 Model_1_loss: 0.9224 Model_2_loss: 1.0366 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9000 Model_1_val:0.5269 Model_2_val:0.4939
Epoch: 0100 Model_1_loss: 0.7438 Model_2_loss: 0.8796 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9083 Model_1_val:0.5486 Model_2_val:0.5134
Epoch: 0120 Model_1_loss: 0.6466 Model_2_loss: 0.7098 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9083 Model_1_val:0.5661 Model_2_val:0.5424
Epoch: 0140 Model_1_loss: 0.5871 Model_2_loss: 0.7011 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8667 Model_1_val:0.5608 Model_2_val:0.5338
Epoch: 0160 Model_1_loss: 0.5162 Model_2_loss: 0.5775 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9167 Model_1_val:0.5664 Model_2_val:0.5437
Epoch: 0180 Model_1_loss: 0.4697 Model_2_loss: 0.5296 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9250 Model_1_val:0.5892 Model_2_val:0.5730
Epoch: 0200 Model_1_loss: 0.4308 Model_2_loss: 0.4713 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5783 Model_2_val:0.5720
Epoch: 0220 Model_1_loss: 0.7305 Model_2_loss: 0.8706 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6320 Model_2_val:0.6172
Epoch: 0240 Model_1_loss: 0.7459 Model_2_loss: 0.7497 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6466 Model_2_val:0.6393
Epoch: 0260 Model_1_loss: 0.6848 Model_2_loss: 0.7527 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6459 Model_2_val:0.6449
Epoch: 0280 Model_1_loss: 0.6471 Model_2_loss: 0.6538 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6456 Model_2_val:0.6330
Epoch: 0300 Model_1_loss: 0.5714 Model_2_loss: 0.6340 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6571 Model_2_val:0.6423
Epoch: 0320 Model_1_loss: 0.6329 Model_2_loss: 0.6884 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.6416 Model_2_val:0.6413
Epoch: 0340 Model_1_loss: 0.5923 Model_2_loss: 0.5705 Model_1_trainacc: 0.9500 Model_2_trainacc: 1.0000 Model_1_val:0.6548 Model_2_val:0.6564
Epoch: 0360 Model_1_loss: 0.5511 Model_2_loss: 0.5894 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6449 Model_2_val:0.6429
Epoch: 0380 Model_1_loss: 0.5526 Model_2_loss: 0.5475 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6469 Model_2_val:0.6637
Epoch: 0400 Model_1_loss: 0.5226 Model_2_loss: 0.5757 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6604 Model_2_val:0.6469
Model_one_test:0.6729 Model_two_test:0.6742
added by two output: 0.6742
Model1 Acc: 0.690986 Model2 Acc: 0.690402
Maxacc Mean: 0.692437
[0.6924372651610259]
Maxacc of all experiments: 0.6924372651610259
1
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
882584290
Epoch: 0020 Model_1_loss: 1.7295 Model_2_loss: 1.7278 Model_1_trainacc: 0.3667 Model_2_trainacc: 0.3667 Model_1_val:0.2552 Model_2_val:0.2392
Epoch: 0040 Model_1_loss: 1.5361 Model_2_loss: 1.5437 Model_1_trainacc: 0.6917 Model_2_trainacc: 0.7917 Model_1_val:0.4787 Model_2_val:0.4173
Epoch: 0060 Model_1_loss: 1.2445 Model_2_loss: 1.2319 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.8667 Model_1_val:0.4954 Model_2_val:0.4823
Epoch: 0080 Model_1_loss: 0.9464 Model_2_loss: 0.9398 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.9000 Model_1_val:0.5283 Model_2_val:0.5334
Epoch: 0100 Model_1_loss: 0.7915 Model_2_loss: 0.7158 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9583 Model_1_val:0.5603 Model_2_val:0.5427
Epoch: 0120 Model_1_loss: 0.6209 Model_2_loss: 0.5459 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.5657 Model_2_val:0.5814
Epoch: 0140 Model_1_loss: 0.5097 Model_2_loss: 0.5100 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5830 Model_2_val:0.5785
Epoch: 0160 Model_1_loss: 0.5151 Model_2_loss: 0.4959 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9417 Model_1_val:0.5945 Model_2_val:0.5763
Epoch: 0180 Model_1_loss: 0.4463 Model_2_loss: 0.4412 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.5776 Model_2_val:0.6003
Epoch: 0200 Model_1_loss: 0.4337 Model_2_loss: 0.4058 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5907 Model_2_val:0.5836
Epoch: 0220 Model_1_loss: 0.7583 Model_2_loss: 0.7245 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6553 Model_2_val:0.6505
Epoch: 0240 Model_1_loss: 0.6702 Model_2_loss: 0.6927 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6700 Model_2_val:0.6559
Epoch: 0260 Model_1_loss: 0.6172 Model_2_loss: 0.5844 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6617 Model_2_val:0.6652
Epoch: 0280 Model_1_loss: 0.6056 Model_2_loss: 0.6278 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.6636 Model_2_val:0.6553
Epoch: 0300 Model_1_loss: 0.5760 Model_2_loss: 0.5752 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6690 Model_2_val:0.6629
Epoch: 0320 Model_1_loss: 0.5805 Model_2_loss: 0.5340 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6674 Model_2_val:0.6594
Epoch: 0340 Model_1_loss: 0.5207 Model_2_loss: 0.5558 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6655 Model_2_val:0.6617
Epoch: 0360 Model_1_loss: 0.5146 Model_2_loss: 0.5152 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6572 Model_2_val:0.6562
Epoch: 0380 Model_1_loss: 0.5112 Model_2_loss: 0.5152 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6594 Model_2_val:0.6572
Epoch: 0400 Model_1_loss: 0.4967 Model_2_loss: 0.4943 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6649 Model_2_val:0.6690
Model_one_test:0.6837 Model_two_test:0.6828
added by two output: 0.6818
2
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
217973773
Epoch: 0020 Model_1_loss: 1.7374 Model_2_loss: 1.7224 Model_1_trainacc: 0.4667 Model_2_trainacc: 0.3500 Model_1_val:0.2597 Model_2_val:0.1953
Epoch: 0040 Model_1_loss: 1.5887 Model_2_loss: 1.5232 Model_1_trainacc: 0.6417 Model_2_trainacc: 0.8000 Model_1_val:0.3566 Model_2_val:0.4452
Epoch: 0060 Model_1_loss: 1.2962 Model_2_loss: 1.2030 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8583 Model_1_val:0.4380 Model_2_val:0.5041
Epoch: 0080 Model_1_loss: 1.0353 Model_2_loss: 0.8868 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9000 Model_1_val:0.5028 Model_2_val:0.5345
Epoch: 0100 Model_1_loss: 0.8331 Model_2_loss: 0.7226 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9417 Model_1_val:0.5375 Model_2_val:0.5496
Epoch: 0120 Model_1_loss: 0.6765 Model_2_loss: 0.5971 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5352 Model_2_val:0.5702
Epoch: 0140 Model_1_loss: 0.5941 Model_2_loss: 0.5291 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5653 Model_2_val:0.5751
Epoch: 0160 Model_1_loss: 0.4811 Model_2_loss: 0.4851 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5757 Model_2_val:0.5833
Epoch: 0180 Model_1_loss: 0.4434 Model_2_loss: 0.4541 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.5836 Model_2_val:0.5927
Epoch: 0200 Model_1_loss: 0.4843 Model_2_loss: 0.3955 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5770 Model_2_val:0.5908
Epoch: 0220 Model_1_loss: 0.7743 Model_2_loss: 0.7586 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6385 Model_2_val:0.6425
Epoch: 0240 Model_1_loss: 0.6858 Model_2_loss: 0.6775 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6588 Model_2_val:0.6634
Epoch: 0260 Model_1_loss: 0.6302 Model_2_loss: 0.5919 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6506 Model_2_val:0.6529
Epoch: 0280 Model_1_loss: 0.6401 Model_2_loss: 0.5850 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6654 Model_2_val:0.6657
Epoch: 0300 Model_1_loss: 0.5557 Model_2_loss: 0.5801 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6601 Model_2_val:0.6608
Epoch: 0320 Model_1_loss: 0.5811 Model_2_loss: 0.5342 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6523 Model_2_val:0.6618
Epoch: 0340 Model_1_loss: 0.5593 Model_2_loss: 0.5275 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6519 Model_2_val:0.6562
Epoch: 0360 Model_1_loss: 0.5216 Model_2_loss: 0.4824 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6621 Model_2_val:0.6686
Epoch: 0380 Model_1_loss: 0.4800 Model_2_loss: 0.4875 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6663 Model_2_val:0.6654
Epoch: 0400 Model_1_loss: 0.4064 Model_2_loss: 0.4221 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6575 Model_2_val:0.6667
Model_one_test:0.6843 Model_two_test:0.6860
added by two output: 0.6853
3
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1565039850
Epoch: 0020 Model_1_loss: 1.6996 Model_2_loss: 1.6759 Model_1_trainacc: 0.5917 Model_2_trainacc: 0.4167 Model_1_val:0.3148 Model_2_val:0.3090
Epoch: 0040 Model_1_loss: 1.4838 Model_2_loss: 1.4101 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.7917 Model_1_val:0.4780 Model_2_val:0.4738
Epoch: 0060 Model_1_loss: 1.1477 Model_2_loss: 1.0871 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8833 Model_1_val:0.4770 Model_2_val:0.5179
Epoch: 0080 Model_1_loss: 0.8915 Model_2_loss: 0.8367 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9167 Model_1_val:0.5240 Model_2_val:0.5459
Epoch: 0100 Model_1_loss: 0.7351 Model_2_loss: 0.6076 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.5594 Model_2_val:0.5919
Epoch: 0120 Model_1_loss: 0.5720 Model_2_loss: 0.5424 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.5745 Model_2_val:0.5964
Epoch: 0140 Model_1_loss: 0.5310 Model_2_loss: 0.4866 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5945 Model_2_val:0.5771
Epoch: 0160 Model_1_loss: 0.4605 Model_2_loss: 0.4498 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5983 Model_2_val:0.5803
Epoch: 0180 Model_1_loss: 0.4426 Model_2_loss: 0.4495 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5903 Model_2_val:0.5916
Epoch: 0200 Model_1_loss: 0.4065 Model_2_loss: 0.3614 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6054 Model_2_val:0.5970
Epoch: 0220 Model_1_loss: 0.7309 Model_2_loss: 0.6831 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6518 Model_2_val:0.6366
Epoch: 0240 Model_1_loss: 0.6399 Model_2_loss: 0.6421 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6524 Model_2_val:0.6553
Epoch: 0260 Model_1_loss: 0.6014 Model_2_loss: 0.6317 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6572 Model_2_val:0.6608
Epoch: 0280 Model_1_loss: 0.5633 Model_2_loss: 0.5729 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6701 Model_2_val:0.6617
Epoch: 0300 Model_1_loss: 0.5879 Model_2_loss: 0.5663 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9750 Model_1_val:0.6662 Model_2_val:0.6659
Epoch: 0320 Model_1_loss: 0.5187 Model_2_loss: 0.5352 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6662 Model_2_val:0.6601
Epoch: 0340 Model_1_loss: 0.5545 Model_2_loss: 0.5045 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6537 Model_2_val:0.6559
Epoch: 0360 Model_1_loss: 0.5345 Model_2_loss: 0.5083 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6659 Model_2_val:0.6678
Epoch: 0380 Model_1_loss: 0.4510 Model_2_loss: 0.4499 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6637 Model_2_val:0.6543
Epoch: 0400 Model_1_loss: 0.5048 Model_2_loss: 0.4700 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6662 Model_2_val:0.6598
Model_one_test:0.6846 Model_two_test:0.6846
added by two output: 0.6855
4
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1198645696
Epoch: 0020 Model_1_loss: 1.7269 Model_2_loss: 1.6972 Model_1_trainacc: 0.3500 Model_2_trainacc: 0.5083 Model_1_val:0.2619 Model_2_val:0.3034
Epoch: 0040 Model_1_loss: 1.5329 Model_2_loss: 1.4924 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.7667 Model_1_val:0.4395 Model_2_val:0.5080
Epoch: 0060 Model_1_loss: 1.2729 Model_2_loss: 1.1739 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8667 Model_1_val:0.4801 Model_2_val:0.5544
Epoch: 0080 Model_1_loss: 0.9952 Model_2_loss: 0.8323 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.9250 Model_1_val:0.5364 Model_2_val:0.5814
Epoch: 0100 Model_1_loss: 0.8143 Model_2_loss: 0.6482 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9667 Model_1_val:0.5444 Model_2_val:0.5843
Epoch: 0120 Model_1_loss: 0.6632 Model_2_loss: 0.5651 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9833 Model_1_val:0.5537 Model_2_val:0.6088
Epoch: 0140 Model_1_loss: 0.5929 Model_2_loss: 0.4743 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5692 Model_2_val:0.5991
Epoch: 0160 Model_1_loss: 0.5030 Model_2_loss: 0.4800 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.5672 Model_2_val:0.6123
Epoch: 0180 Model_1_loss: 0.4314 Model_2_loss: 0.4004 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6020 Model_2_val:0.6023
Epoch: 0200 Model_1_loss: 0.3736 Model_2_loss: 0.3645 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6007 Model_2_val:0.6190
Epoch: 0220 Model_1_loss: 0.6838 Model_2_loss: 0.6782 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6647 Model_2_val:0.6718
Epoch: 0240 Model_1_loss: 0.5942 Model_2_loss: 0.6034 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6805 Model_2_val:0.6818
Epoch: 0260 Model_1_loss: 0.6187 Model_2_loss: 0.5766 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6782 Model_2_val:0.6692
Epoch: 0280 Model_1_loss: 0.5429 Model_2_loss: 0.5549 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6757 Model_2_val:0.6805
Epoch: 0300 Model_1_loss: 0.5081 Model_2_loss: 0.5012 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6734 Model_2_val:0.6657
Epoch: 0320 Model_1_loss: 0.4617 Model_2_loss: 0.5039 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6821 Model_2_val:0.6754
Epoch: 0340 Model_1_loss: 0.4962 Model_2_loss: 0.5061 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6779 Model_2_val:0.6763
Epoch: 0360 Model_1_loss: 0.4631 Model_2_loss: 0.4462 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6869 Model_2_val:0.6644
Epoch: 0380 Model_1_loss: 0.4474 Model_2_loss: 0.4265 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6702 Model_2_val:0.6792
Epoch: 0400 Model_1_loss: 0.4850 Model_2_loss: 0.4506 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6792 Model_2_val:0.6725
Model_one_test:0.7030 Model_two_test:0.6950
added by two output: 0.7008
5
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1417123138
Epoch: 0020 Model_1_loss: 1.7453 Model_2_loss: 1.7253 Model_1_trainacc: 0.2500 Model_2_trainacc: 0.4083 Model_1_val:0.1807 Model_2_val:0.2595
Epoch: 0040 Model_1_loss: 1.5902 Model_2_loss: 1.5382 Model_1_trainacc: 0.7083 Model_2_trainacc: 0.7167 Model_1_val:0.3698 Model_2_val:0.4530
Epoch: 0060 Model_1_loss: 1.3714 Model_2_loss: 1.2418 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.8167 Model_1_val:0.4456 Model_2_val:0.5107
Epoch: 0080 Model_1_loss: 1.1407 Model_2_loss: 0.9732 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8750 Model_1_val:0.4900 Model_2_val:0.5397
Epoch: 0100 Model_1_loss: 0.8436 Model_2_loss: 0.7437 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9500 Model_1_val:0.5263 Model_2_val:0.5566
Epoch: 0120 Model_1_loss: 0.7234 Model_2_loss: 0.5995 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9667 Model_1_val:0.5588 Model_2_val:0.5824
Epoch: 0140 Model_1_loss: 0.6380 Model_2_loss: 0.5014 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.5671 Model_2_val:0.5974
Epoch: 0160 Model_1_loss: 0.5888 Model_2_loss: 0.4816 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5808 Model_2_val:0.6054
Epoch: 0180 Model_1_loss: 0.5385 Model_2_loss: 0.3831 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5674 Model_2_val:0.6114
Epoch: 0200 Model_1_loss: 0.4541 Model_2_loss: 0.3437 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.5626 Model_2_val:0.6095
Epoch: 0220 Model_1_loss: 0.7866 Model_2_loss: 0.6824 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6465 Model_2_val:0.6650
Epoch: 0240 Model_1_loss: 0.6896 Model_2_loss: 0.6675 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6500 Model_2_val:0.6745
Epoch: 0260 Model_1_loss: 0.7231 Model_2_loss: 0.6653 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6474 Model_2_val:0.6736
Epoch: 0280 Model_1_loss: 0.6856 Model_2_loss: 0.5935 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6567 Model_2_val:0.6755
Epoch: 0300 Model_1_loss: 0.5773 Model_2_loss: 0.5526 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6554 Model_2_val:0.6678
Epoch: 0320 Model_1_loss: 0.5381 Model_2_loss: 0.5212 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6573 Model_2_val:0.6637
Epoch: 0340 Model_1_loss: 0.5491 Model_2_loss: 0.5207 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6580 Model_2_val:0.6720
Epoch: 0360 Model_1_loss: 0.4828 Model_2_loss: 0.5018 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6627 Model_2_val:0.6650
Epoch: 0380 Model_1_loss: 0.4404 Model_2_loss: 0.4327 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6640 Model_2_val:0.6736
Epoch: 0400 Model_1_loss: 0.4441 Model_2_loss: 0.4584 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6519 Model_2_val:0.6662
Model_one_test:0.6911 Model_two_test:0.6908
added by two output: 0.6905
6
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
85101831
Epoch: 0020 Model_1_loss: 1.6951 Model_2_loss: 1.7411 Model_1_trainacc: 0.5000 Model_2_trainacc: 0.3417 Model_1_val:0.2492 Model_2_val:0.2624
Epoch: 0040 Model_1_loss: 1.4848 Model_2_loss: 1.6163 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.6583 Model_1_val:0.4024 Model_2_val:0.3604
Epoch: 0060 Model_1_loss: 1.1828 Model_2_loss: 1.3637 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.7750 Model_1_val:0.4745 Model_2_val:0.4441
Epoch: 0080 Model_1_loss: 0.9100 Model_2_loss: 1.1240 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8500 Model_1_val:0.5195 Model_2_val:0.4825
Epoch: 0100 Model_1_loss: 0.6951 Model_2_loss: 0.9125 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.8833 Model_1_val:0.5460 Model_2_val:0.5063
Epoch: 0120 Model_1_loss: 0.6085 Model_2_loss: 0.7649 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8750 Model_1_val:0.5705 Model_2_val:0.5258
Epoch: 0140 Model_1_loss: 0.5971 Model_2_loss: 0.6867 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9000 Model_1_val:0.5652 Model_2_val:0.5490
Epoch: 0160 Model_1_loss: 0.4603 Model_2_loss: 0.6053 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9250 Model_1_val:0.5768 Model_2_val:0.5407
Epoch: 0180 Model_1_loss: 0.4406 Model_2_loss: 0.4965 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9250 Model_1_val:0.5490 Model_2_val:0.5516
Epoch: 0200 Model_1_loss: 0.4461 Model_2_loss: 0.4801 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.5831 Model_2_val:0.5510
Epoch: 0220 Model_1_loss: 0.8551 Model_2_loss: 0.8498 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6264 Model_2_val:0.6214
Epoch: 0240 Model_1_loss: 0.7347 Model_2_loss: 0.7856 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6410 Model_2_val:0.6479
Epoch: 0260 Model_1_loss: 0.7323 Model_2_loss: 0.6490 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6509 Model_2_val:0.6466
Epoch: 0280 Model_1_loss: 0.7167 Model_2_loss: 0.6757 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6489 Model_2_val:0.6509
Epoch: 0300 Model_1_loss: 0.6464 Model_2_loss: 0.6332 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6575 Model_2_val:0.6608
Epoch: 0320 Model_1_loss: 0.6569 Model_2_loss: 0.5768 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6446 Model_2_val:0.6645
Epoch: 0340 Model_1_loss: 0.6442 Model_2_loss: 0.6165 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.6482 Model_2_val:0.6552
Epoch: 0360 Model_1_loss: 0.5386 Model_2_loss: 0.5960 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6476 Model_2_val:0.6529
Epoch: 0380 Model_1_loss: 0.5347 Model_2_loss: 0.5155 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6482 Model_2_val:0.6512
Epoch: 0400 Model_1_loss: 0.4927 Model_2_loss: 0.5601 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6585 Model_2_val:0.6671
Model_one_test:0.6837 Model_two_test:0.6817
added by two output: 0.6820
7
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1011777157
Epoch: 0020 Model_1_loss: 1.6771 Model_2_loss: 1.7123 Model_1_trainacc: 0.6250 Model_2_trainacc: 0.4833 Model_1_val:0.3800 Model_2_val:0.2813
Epoch: 0040 Model_1_loss: 1.4384 Model_2_loss: 1.5032 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.7667 Model_1_val:0.4770 Model_2_val:0.4947
Epoch: 0060 Model_1_loss: 1.1078 Model_2_loss: 1.1180 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8917 Model_1_val:0.5160 Model_2_val:0.5343
Epoch: 0080 Model_1_loss: 0.8000 Model_2_loss: 0.7966 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.5459 Model_2_val:0.5459
Epoch: 0100 Model_1_loss: 0.6203 Model_2_loss: 0.6205 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5917 Model_2_val:0.5778
Epoch: 0120 Model_1_loss: 0.5375 Model_2_loss: 0.5298 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.5820 Model_2_val:0.5756
Epoch: 0140 Model_1_loss: 0.4284 Model_2_loss: 0.4409 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.5804 Model_2_val:0.5907
Epoch: 0160 Model_1_loss: 0.3927 Model_2_loss: 0.4108 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.5869 Model_2_val:0.5968
Epoch: 0180 Model_1_loss: 0.3605 Model_2_loss: 0.3612 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.6084 Model_2_val:0.5949
Epoch: 0200 Model_1_loss: 0.3002 Model_2_loss: 0.3277 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.5891 Model_2_val:0.5920
Epoch: 0220 Model_1_loss: 0.6355 Model_2_loss: 0.6066 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6413 Model_2_val:0.6536
Epoch: 0240 Model_1_loss: 0.5646 Model_2_loss: 0.5732 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6626 Model_2_val:0.6581
Epoch: 0260 Model_1_loss: 0.5243 Model_2_loss: 0.5626 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6529 Model_2_val:0.6610
Epoch: 0280 Model_1_loss: 0.5204 Model_2_loss: 0.5152 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6584 Model_2_val:0.6671
Epoch: 0300 Model_1_loss: 0.5136 Model_2_loss: 0.4769 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6661 Model_2_val:0.6590
Epoch: 0320 Model_1_loss: 0.4781 Model_2_loss: 0.4680 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6665 Model_2_val:0.6500
Epoch: 0340 Model_1_loss: 0.4288 Model_2_loss: 0.4159 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6700 Model_2_val:0.6616
Epoch: 0360 Model_1_loss: 0.4121 Model_2_loss: 0.4807 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6661 Model_2_val:0.6629
Epoch: 0380 Model_1_loss: 0.4474 Model_2_loss: 0.4007 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6652 Model_2_val:0.6706
Epoch: 0400 Model_1_loss: 0.3878 Model_2_loss: 0.3785 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6706 Model_2_val:0.6610
Model_one_test:0.6897 Model_two_test:0.6938
added by two output: 0.6922
8
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1109791553
Epoch: 0020 Model_1_loss: 1.6964 Model_2_loss: 1.7235 Model_1_trainacc: 0.4917 Model_2_trainacc: 0.3750 Model_1_val:0.3152 Model_2_val:0.2362
Epoch: 0040 Model_1_loss: 1.5144 Model_2_loss: 1.5535 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.6583 Model_1_val:0.4279 Model_2_val:0.3711
Epoch: 0060 Model_1_loss: 1.2590 Model_2_loss: 1.2569 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8833 Model_1_val:0.5016 Model_2_val:0.4784
Epoch: 0080 Model_1_loss: 0.9653 Model_2_loss: 0.9836 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8750 Model_1_val:0.5343 Model_2_val:0.5114
Epoch: 0100 Model_1_loss: 0.7986 Model_2_loss: 0.7893 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9167 Model_1_val:0.5578 Model_2_val:0.5171
Epoch: 0120 Model_1_loss: 0.6854 Model_2_loss: 0.7196 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8833 Model_1_val:0.5686 Model_2_val:0.5397
Epoch: 0140 Model_1_loss: 0.5541 Model_2_loss: 0.6535 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9083 Model_1_val:0.5689 Model_2_val:0.5454
Epoch: 0160 Model_1_loss: 0.5583 Model_2_loss: 0.6195 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8667 Model_1_val:0.5737 Model_2_val:0.5492
Epoch: 0180 Model_1_loss: 0.4664 Model_2_loss: 0.5079 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.5803 Model_2_val:0.5651
Epoch: 0200 Model_1_loss: 0.4141 Model_2_loss: 0.4577 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9333 Model_1_val:0.5889 Model_2_val:0.5559
Epoch: 0220 Model_1_loss: 0.7900 Model_2_loss: 0.8462 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.6492 Model_2_val:0.6333
Epoch: 0240 Model_1_loss: 0.7081 Model_2_loss: 0.7710 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.6562 Model_2_val:0.6495
Epoch: 0260 Model_1_loss: 0.6611 Model_2_loss: 0.6498 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6695 Model_2_val:0.6444
Epoch: 0280 Model_1_loss: 0.6355 Model_2_loss: 0.6806 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6673 Model_2_val:0.6537
Epoch: 0300 Model_1_loss: 0.5960 Model_2_loss: 0.6008 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.6625 Model_2_val:0.6524
Epoch: 0320 Model_1_loss: 0.5800 Model_2_loss: 0.6064 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6717 Model_2_val:0.6530
Epoch: 0340 Model_1_loss: 0.5180 Model_2_loss: 0.5538 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.6686 Model_2_val:0.6613
Epoch: 0360 Model_1_loss: 0.5324 Model_2_loss: 0.5787 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6686 Model_2_val:0.6562
Epoch: 0380 Model_1_loss: 0.5414 Model_2_loss: 0.5768 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6613 Model_2_val:0.6616
Epoch: 0400 Model_1_loss: 0.5394 Model_2_loss: 0.5031 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.6683 Model_2_val:0.6663
Model_one_test:0.6883 Model_two_test:0.6854
added by two output: 0.6892
9
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
299247100
Epoch: 0020 Model_1_loss: 1.7169 Model_2_loss: 1.7295 Model_1_trainacc: 0.4833 Model_2_trainacc: 0.4417 Model_1_val:0.2568 Model_2_val:0.1982
Epoch: 0040 Model_1_loss: 1.5070 Model_2_loss: 1.5452 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8250 Model_1_val:0.4055 Model_2_val:0.4084
Epoch: 0060 Model_1_loss: 1.2644 Model_2_loss: 1.2975 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8917 Model_1_val:0.4964 Model_2_val:0.4791
Epoch: 0080 Model_1_loss: 0.9819 Model_2_loss: 1.0343 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8833 Model_1_val:0.5346 Model_2_val:0.5365
Epoch: 0100 Model_1_loss: 0.7532 Model_2_loss: 0.8424 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8750 Model_1_val:0.5518 Model_2_val:0.5492
Epoch: 0120 Model_1_loss: 0.7106 Model_2_loss: 0.6834 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9250 Model_1_val:0.5531 Model_2_val:0.5492
Epoch: 0140 Model_1_loss: 0.5797 Model_2_loss: 0.5722 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.5707 Model_2_val:0.5694
Epoch: 0160 Model_1_loss: 0.5228 Model_2_loss: 0.5400 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9250 Model_1_val:0.5874 Model_2_val:0.5831
Epoch: 0180 Model_1_loss: 0.4700 Model_2_loss: 0.5170 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9167 Model_1_val:0.5629 Model_2_val:0.5825
Epoch: 0200 Model_1_loss: 0.4399 Model_2_loss: 0.4254 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.5746 Model_2_val:0.5727
Epoch: 0220 Model_1_loss: 0.7925 Model_2_loss: 0.8235 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6418 Model_2_val:0.6362
Epoch: 0240 Model_1_loss: 0.7443 Model_2_loss: 0.7822 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6623 Model_2_val:0.6516
Epoch: 0260 Model_1_loss: 0.6827 Model_2_loss: 0.6820 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6503 Model_2_val:0.6636
Epoch: 0280 Model_1_loss: 0.6742 Model_2_loss: 0.6513 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.6620 Model_2_val:0.6512
Epoch: 0300 Model_1_loss: 0.6052 Model_2_loss: 0.5952 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6630 Model_2_val:0.6643
Epoch: 0320 Model_1_loss: 0.6081 Model_2_loss: 0.5924 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6545 Model_2_val:0.6594
Epoch: 0340 Model_1_loss: 0.5694 Model_2_loss: 0.5407 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6744 Model_2_val:0.6581
Epoch: 0360 Model_1_loss: 0.5953 Model_2_loss: 0.5786 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6604 Model_2_val:0.6669
Epoch: 0380 Model_1_loss: 0.5469 Model_2_loss: 0.5307 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6519 Model_2_val:0.6607
Epoch: 0400 Model_1_loss: 0.5258 Model_2_loss: 0.4835 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6640 Model_2_val:0.6568
Model_one_test:0.6920 Model_two_test:0.6861
added by two output: 0.6887
10
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1178669953
Epoch: 0020 Model_1_loss: 1.7283 Model_2_loss: 1.6996 Model_1_trainacc: 0.4000 Model_2_trainacc: 0.4167 Model_1_val:0.2763 Model_2_val:0.2430
Epoch: 0040 Model_1_loss: 1.5649 Model_2_loss: 1.4516 Model_1_trainacc: 0.6417 Model_2_trainacc: 0.8167 Model_1_val:0.3705 Model_2_val:0.4368
Epoch: 0060 Model_1_loss: 1.2483 Model_2_loss: 1.1690 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8833 Model_1_val:0.4835 Model_2_val:0.4906
Epoch: 0080 Model_1_loss: 0.8983 Model_2_loss: 0.8719 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9583 Model_1_val:0.5107 Model_2_val:0.5277
Epoch: 0100 Model_1_loss: 0.7528 Model_2_loss: 0.7745 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9000 Model_1_val:0.5501 Model_2_val:0.5616
Epoch: 0120 Model_1_loss: 0.6517 Model_2_loss: 0.6410 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9083 Model_1_val:0.5636 Model_2_val:0.5642
Epoch: 0140 Model_1_loss: 0.5438 Model_2_loss: 0.5561 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9083 Model_1_val:0.5735 Model_2_val:0.5828
Epoch: 0160 Model_1_loss: 0.4613 Model_2_loss: 0.5067 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5732 Model_2_val:0.5834
Epoch: 0180 Model_1_loss: 0.4936 Model_2_loss: 0.5026 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9250 Model_1_val:0.5773 Model_2_val:0.5879
Epoch: 0200 Model_1_loss: 0.4440 Model_2_loss: 0.3982 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5985 Model_2_val:0.5901
Epoch: 0220 Model_1_loss: 0.8161 Model_2_loss: 0.8094 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.6622 Model_2_val:0.6724
Epoch: 0240 Model_1_loss: 0.7305 Model_2_loss: 0.6708 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.6756 Model_2_val:0.6795
Epoch: 0260 Model_1_loss: 0.6899 Model_2_loss: 0.6255 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6795 Model_2_val:0.6852
Epoch: 0280 Model_1_loss: 0.7041 Model_2_loss: 0.6502 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.6888 Model_2_val:0.6888
Epoch: 0300 Model_1_loss: 0.5990 Model_2_loss: 0.6337 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6779 Model_2_val:0.6772
Epoch: 0320 Model_1_loss: 0.6081 Model_2_loss: 0.6143 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6721 Model_2_val:0.6872
Epoch: 0340 Model_1_loss: 0.6185 Model_2_loss: 0.5925 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.6888 Model_2_val:0.6862
Epoch: 0360 Model_1_loss: 0.5646 Model_2_loss: 0.5715 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6910 Model_2_val:0.6920
Epoch: 0380 Model_1_loss: 0.5522 Model_2_loss: 0.5431 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.6913 Model_2_val:0.6852
Epoch: 0400 Model_1_loss: 0.5285 Model_2_loss: 0.5606 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.6814 Model_2_val:0.6776
Model_one_test:0.7134 Model_two_test:0.7112
added by two output: 0.7144
11
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
775604402
Epoch: 0020 Model_1_loss: 1.7324 Model_2_loss: 1.7194 Model_1_trainacc: 0.4583 Model_2_trainacc: 0.4500 Model_1_val:0.2929 Model_2_val:0.2324
Epoch: 0040 Model_1_loss: 1.5612 Model_2_loss: 1.5165 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7417 Model_1_val:0.4552 Model_2_val:0.4229
Epoch: 0060 Model_1_loss: 1.2687 Model_2_loss: 1.2194 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8250 Model_1_val:0.4798 Model_2_val:0.5259
Epoch: 0080 Model_1_loss: 1.0055 Model_2_loss: 0.9450 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8833 Model_1_val:0.4917 Model_2_val:0.5467
Epoch: 0100 Model_1_loss: 0.8219 Model_2_loss: 0.7427 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9250 Model_1_val:0.5307 Model_2_val:0.5743
Epoch: 0120 Model_1_loss: 0.6824 Model_2_loss: 0.6383 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9167 Model_1_val:0.5304 Model_2_val:0.5698
Epoch: 0140 Model_1_loss: 0.5814 Model_2_loss: 0.5741 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5448 Model_2_val:0.5871
Epoch: 0160 Model_1_loss: 0.5327 Model_2_loss: 0.5264 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5695 Model_2_val:0.5861
Epoch: 0180 Model_1_loss: 0.5271 Model_2_loss: 0.4644 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.5592 Model_2_val:0.5944
Epoch: 0200 Model_1_loss: 0.4735 Model_2_loss: 0.4769 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.5752 Model_2_val:0.5919
Epoch: 0220 Model_1_loss: 0.7978 Model_2_loss: 0.7412 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6501 Model_2_val:0.6533
Epoch: 0240 Model_1_loss: 0.7227 Model_2_loss: 0.7101 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6649 Model_2_val:0.6543
Epoch: 0260 Model_1_loss: 0.6698 Model_2_loss: 0.6975 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6549 Model_2_val:0.6607
Epoch: 0280 Model_1_loss: 0.6190 Model_2_loss: 0.7068 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6552 Model_2_val:0.6607
Epoch: 0300 Model_1_loss: 0.6364 Model_2_loss: 0.6472 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6629 Model_2_val:0.6799
Epoch: 0320 Model_1_loss: 0.6120 Model_2_loss: 0.5787 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6559 Model_2_val:0.6677
Epoch: 0340 Model_1_loss: 0.5929 Model_2_loss: 0.5466 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6639 Model_2_val:0.6735
Epoch: 0360 Model_1_loss: 0.5725 Model_2_loss: 0.5196 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6613 Model_2_val:0.6706
Epoch: 0380 Model_1_loss: 0.5392 Model_2_loss: 0.4957 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6706 Model_2_val:0.6655
Epoch: 0400 Model_1_loss: 0.5709 Model_2_loss: 0.5061 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6633 Model_2_val:0.6633
Model_one_test:0.6911 Model_two_test:0.6927
added by two output: 0.6937
12
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1336291489
Epoch: 0020 Model_1_loss: 1.7357 Model_2_loss: 1.7274 Model_1_trainacc: 0.3250 Model_2_trainacc: 0.3833 Model_1_val:0.2277 Model_2_val:0.1681
Epoch: 0040 Model_1_loss: 1.5485 Model_2_loss: 1.6146 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.6167 Model_1_val:0.4035 Model_2_val:0.3439
Epoch: 0060 Model_1_loss: 1.2696 Model_2_loss: 1.3394 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.7917 Model_1_val:0.4935 Model_2_val:0.4671
Epoch: 0080 Model_1_loss: 1.0147 Model_2_loss: 1.0656 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8667 Model_1_val:0.5558 Model_2_val:0.5300
Epoch: 0100 Model_1_loss: 0.8000 Model_2_loss: 0.7826 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8917 Model_1_val:0.5674 Model_2_val:0.5748
Epoch: 0120 Model_1_loss: 0.6706 Model_2_loss: 0.6872 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9167 Model_1_val:0.5681 Model_2_val:0.5739
Epoch: 0140 Model_1_loss: 0.5833 Model_2_loss: 0.6407 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9250 Model_1_val:0.6000 Model_2_val:0.5719
Epoch: 0160 Model_1_loss: 0.5623 Model_2_loss: 0.5115 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9417 Model_1_val:0.6081 Model_2_val:0.5990
Epoch: 0180 Model_1_loss: 0.4553 Model_2_loss: 0.4466 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6145 Model_2_val:0.6016
Epoch: 0200 Model_1_loss: 0.4307 Model_2_loss: 0.4042 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6019 Model_2_val:0.6094
Epoch: 0220 Model_1_loss: 0.7640 Model_2_loss: 0.7388 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6545 Model_2_val:0.6626
Epoch: 0240 Model_1_loss: 0.7137 Model_2_loss: 0.6727 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6661 Model_2_val:0.6652
Epoch: 0260 Model_1_loss: 0.7329 Model_2_loss: 0.6409 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6597 Model_2_val:0.6600
Epoch: 0280 Model_1_loss: 0.6128 Model_2_loss: 0.6409 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9500 Model_1_val:0.6655 Model_2_val:0.6565
Epoch: 0300 Model_1_loss: 0.5863 Model_2_loss: 0.5671 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6668 Model_2_val:0.6590
Epoch: 0320 Model_1_loss: 0.5597 Model_2_loss: 0.5717 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6600 Model_2_val:0.6697
Epoch: 0340 Model_1_loss: 0.5800 Model_2_loss: 0.5579 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6645 Model_2_val:0.6616
Epoch: 0360 Model_1_loss: 0.5484 Model_2_loss: 0.5437 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6671 Model_2_val:0.6674
Epoch: 0380 Model_1_loss: 0.5072 Model_2_loss: 0.4910 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6648 Model_2_val:0.6616
Epoch: 0400 Model_1_loss: 0.5415 Model_2_loss: 0.4922 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6603 Model_2_val:0.6671
Model_one_test:0.6855 Model_two_test:0.6929
added by two output: 0.6916
13
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1049152855
Epoch: 0020 Model_1_loss: 1.7117 Model_2_loss: 1.7185 Model_1_trainacc: 0.4583 Model_2_trainacc: 0.3750 Model_1_val:0.2388 Model_2_val:0.2062
Epoch: 0040 Model_1_loss: 1.5450 Model_2_loss: 1.4667 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.7917 Model_1_val:0.4261 Model_2_val:0.4264
Epoch: 0060 Model_1_loss: 1.3006 Model_2_loss: 1.1590 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8917 Model_1_val:0.4706 Model_2_val:0.4919
Epoch: 0080 Model_1_loss: 1.0593 Model_2_loss: 0.9376 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8917 Model_1_val:0.5257 Model_2_val:0.5423
Epoch: 0100 Model_1_loss: 0.8527 Model_2_loss: 0.6897 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9250 Model_1_val:0.5277 Model_2_val:0.5626
Epoch: 0120 Model_1_loss: 0.7179 Model_2_loss: 0.6542 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9417 Model_1_val:0.5357 Model_2_val:0.5699
Epoch: 0140 Model_1_loss: 0.6159 Model_2_loss: 0.5143 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5616 Model_2_val:0.5842
Epoch: 0160 Model_1_loss: 0.5784 Model_2_loss: 0.4750 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9250 Model_1_val:0.5789 Model_2_val:0.5878
Epoch: 0180 Model_1_loss: 0.4707 Model_2_loss: 0.4321 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5865 Model_2_val:0.6068
Epoch: 0200 Model_1_loss: 0.4712 Model_2_loss: 0.3615 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.5609 Model_2_val:0.6028
Epoch: 0220 Model_1_loss: 0.8569 Model_2_loss: 0.6671 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6347 Model_2_val:0.6493
Epoch: 0240 Model_1_loss: 0.6954 Model_2_loss: 0.6453 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6443 Model_2_val:0.6556
Epoch: 0260 Model_1_loss: 0.7045 Model_2_loss: 0.6057 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6426 Model_2_val:0.6669
Epoch: 0280 Model_1_loss: 0.6329 Model_2_loss: 0.5616 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6370 Model_2_val:0.6546
Epoch: 0300 Model_1_loss: 0.6139 Model_2_loss: 0.5668 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6450 Model_2_val:0.6490
Epoch: 0320 Model_1_loss: 0.6014 Model_2_loss: 0.5358 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6413 Model_2_val:0.6622
Epoch: 0340 Model_1_loss: 0.5789 Model_2_loss: 0.5156 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6446 Model_2_val:0.6566
Epoch: 0360 Model_1_loss: 0.5263 Model_2_loss: 0.4705 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6486 Model_2_val:0.6559
Epoch: 0380 Model_1_loss: 0.5706 Model_2_loss: 0.4717 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6430 Model_2_val:0.6529
Epoch: 0400 Model_1_loss: 0.5679 Model_2_loss: 0.4757 Model_1_trainacc: 0.9583 Model_2_trainacc: 1.0000 Model_1_val:0.6473 Model_2_val:0.6533
Model_one_test:0.6762 Model_two_test:0.6729
added by two output: 0.6735
14
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1020597728
Epoch: 0020 Model_1_loss: 1.7236 Model_2_loss: 1.7216 Model_1_trainacc: 0.5083 Model_2_trainacc: 0.4333 Model_1_val:0.3066 Model_2_val:0.2595
Epoch: 0040 Model_1_loss: 1.5149 Model_2_loss: 1.5332 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.7250 Model_1_val:0.4193 Model_2_val:0.3706
Epoch: 0060 Model_1_loss: 1.2841 Model_2_loss: 1.2742 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.8583 Model_1_val:0.4584 Model_2_val:0.4264
Epoch: 0080 Model_1_loss: 1.0125 Model_2_loss: 0.9912 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9000 Model_1_val:0.5158 Model_2_val:0.4774
Epoch: 0100 Model_1_loss: 0.7554 Model_2_loss: 0.7805 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9417 Model_1_val:0.5316 Model_2_val:0.5355
Epoch: 0120 Model_1_loss: 0.6172 Model_2_loss: 0.7016 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9000 Model_1_val:0.5355 Model_2_val:0.5445
Epoch: 0140 Model_1_loss: 0.5567 Model_2_loss: 0.6208 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9167 Model_1_val:0.5710 Model_2_val:0.5407
Epoch: 0160 Model_1_loss: 0.4749 Model_2_loss: 0.5125 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5755 Model_2_val:0.5671
Epoch: 0180 Model_1_loss: 0.4129 Model_2_loss: 0.5218 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9167 Model_1_val:0.5713 Model_2_val:0.5600
Epoch: 0200 Model_1_loss: 0.3895 Model_2_loss: 0.4378 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9417 Model_1_val:0.5723 Model_2_val:0.5778
Epoch: 0220 Model_1_loss: 0.7654 Model_2_loss: 0.8281 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9333 Model_1_val:0.6453 Model_2_val:0.6562
Epoch: 0240 Model_1_loss: 0.7403 Model_2_loss: 0.7414 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6701 Model_2_val:0.6598
Epoch: 0260 Model_1_loss: 0.7472 Model_2_loss: 0.6265 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6666 Model_2_val:0.6682
Epoch: 0280 Model_1_loss: 0.6527 Model_2_loss: 0.6542 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6791 Model_2_val:0.6711
Epoch: 0300 Model_1_loss: 0.5968 Model_2_loss: 0.5990 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6714 Model_2_val:0.6656
Epoch: 0320 Model_1_loss: 0.5850 Model_2_loss: 0.5315 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6791 Model_2_val:0.6643
Epoch: 0340 Model_1_loss: 0.5836 Model_2_loss: 0.5457 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6730 Model_2_val:0.6762
Epoch: 0360 Model_1_loss: 0.5916 Model_2_loss: 0.5390 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6772 Model_2_val:0.6704
Epoch: 0380 Model_1_loss: 0.5259 Model_2_loss: 0.4882 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6775 Model_2_val:0.6798
Epoch: 0400 Model_1_loss: 0.5350 Model_2_loss: 0.4912 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.6772 Model_2_val:0.6769
Model_one_test:0.7008 Model_two_test:0.6995
added by two output: 0.7008
15
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
105184199
Epoch: 0020 Model_1_loss: 1.7010 Model_2_loss: 1.7087 Model_1_trainacc: 0.6250 Model_2_trainacc: 0.4667 Model_1_val:0.3047 Model_2_val:0.2113
Epoch: 0040 Model_1_loss: 1.4881 Model_2_loss: 1.4934 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8250 Model_1_val:0.4521 Model_2_val:0.4551
Epoch: 0060 Model_1_loss: 1.2621 Model_2_loss: 1.1990 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8500 Model_1_val:0.4936 Model_2_val:0.5413
Epoch: 0080 Model_1_loss: 1.0072 Model_2_loss: 0.8557 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9083 Model_1_val:0.5242 Model_2_val:0.5601
Epoch: 0100 Model_1_loss: 0.8247 Model_2_loss: 0.7250 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9250 Model_1_val:0.5502 Model_2_val:0.5791
Epoch: 0120 Model_1_loss: 0.7032 Model_2_loss: 0.5731 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9583 Model_1_val:0.5703 Model_2_val:0.5864
Epoch: 0140 Model_1_loss: 0.6172 Model_2_loss: 0.4939 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9667 Model_1_val:0.5686 Model_2_val:0.6064
Epoch: 0160 Model_1_loss: 0.5420 Model_2_loss: 0.4138 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5788 Model_2_val:0.6018
Epoch: 0180 Model_1_loss: 0.4642 Model_2_loss: 0.3911 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.5755 Model_2_val:0.5999
Epoch: 0200 Model_1_loss: 0.4711 Model_2_loss: 0.3932 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.5907 Model_2_val:0.6028
Epoch: 0220 Model_1_loss: 0.7243 Model_2_loss: 0.6382 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6630 Model_2_val:0.6834
Epoch: 0240 Model_1_loss: 0.6644 Model_2_loss: 0.5995 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6739 Model_2_val:0.6736
Epoch: 0260 Model_1_loss: 0.6262 Model_2_loss: 0.5566 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6736 Model_2_val:0.6752
Epoch: 0280 Model_1_loss: 0.6143 Model_2_loss: 0.5551 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6795 Model_2_val:0.6811
Epoch: 0300 Model_1_loss: 0.5715 Model_2_loss: 0.5418 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6700 Model_2_val:0.6841
Epoch: 0320 Model_1_loss: 0.5378 Model_2_loss: 0.5239 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6700 Model_2_val:0.6729
Epoch: 0340 Model_1_loss: 0.4504 Model_2_loss: 0.4876 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6772 Model_2_val:0.6805
Epoch: 0360 Model_1_loss: 0.4765 Model_2_loss: 0.4558 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6739 Model_2_val:0.6765
Epoch: 0380 Model_1_loss: 0.5313 Model_2_loss: 0.4219 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6637 Model_2_val:0.6736
Epoch: 0400 Model_1_loss: 0.4921 Model_2_loss: 0.4330 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6594 Model_2_val:0.6742
Model_one_test:0.6877 Model_two_test:0.6940
added by two output: 0.6910
16
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
477984420
Epoch: 0020 Model_1_loss: 1.7259 Model_2_loss: 1.6770 Model_1_trainacc: 0.3917 Model_2_trainacc: 0.5750 Model_1_val:0.2337 Model_2_val:0.3509
Epoch: 0040 Model_1_loss: 1.5663 Model_2_loss: 1.4449 Model_1_trainacc: 0.7250 Model_2_trainacc: 0.7833 Model_1_val:0.3997 Model_2_val:0.4494
Epoch: 0060 Model_1_loss: 1.3115 Model_2_loss: 1.1585 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8083 Model_1_val:0.4812 Model_2_val:0.4943
Epoch: 0080 Model_1_loss: 0.9563 Model_2_loss: 0.8823 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9333 Model_1_val:0.5178 Model_2_val:0.5113
Epoch: 0100 Model_1_loss: 0.7829 Model_2_loss: 0.7216 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.5283 Model_2_val:0.5378
Epoch: 0120 Model_1_loss: 0.6145 Model_2_loss: 0.6165 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.5764 Model_2_val:0.5345
Epoch: 0140 Model_1_loss: 0.4970 Model_2_loss: 0.5631 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.5938 Model_2_val:0.5408
Epoch: 0160 Model_1_loss: 0.4361 Model_2_loss: 0.4230 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.5928 Model_2_val:0.5804
Epoch: 0180 Model_1_loss: 0.3795 Model_2_loss: 0.3629 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6003 Model_2_val:0.5836
Epoch: 0200 Model_1_loss: 0.3252 Model_2_loss: 0.3637 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6036 Model_2_val:0.5800
Epoch: 0220 Model_1_loss: 0.6699 Model_2_loss: 0.6548 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6507 Model_2_val:0.6347
Epoch: 0240 Model_1_loss: 0.5813 Model_2_loss: 0.6363 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9583 Model_1_val:0.6668 Model_2_val:0.6563
Epoch: 0260 Model_1_loss: 0.5929 Model_2_loss: 0.5904 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6648 Model_2_val:0.6517
Epoch: 0280 Model_1_loss: 0.5450 Model_2_loss: 0.5309 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6678 Model_2_val:0.6507
Epoch: 0300 Model_1_loss: 0.4937 Model_2_loss: 0.4898 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6596 Model_2_val:0.6671
Epoch: 0320 Model_1_loss: 0.4766 Model_2_loss: 0.5021 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6645 Model_2_val:0.6596
Epoch: 0340 Model_1_loss: 0.4920 Model_2_loss: 0.4306 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6583 Model_2_val:0.6556
Epoch: 0360 Model_1_loss: 0.4464 Model_2_loss: 0.4081 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6615 Model_2_val:0.6550
Epoch: 0380 Model_1_loss: 0.4120 Model_2_loss: 0.4499 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6602 Model_2_val:0.6511
Epoch: 0400 Model_1_loss: 0.4512 Model_2_loss: 0.4257 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6691 Model_2_val:0.6700
Model_one_test:0.6848 Model_two_test:0.6782
added by two output: 0.6822
17
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1004759534
Epoch: 0020 Model_1_loss: 1.7423 Model_2_loss: 1.7224 Model_1_trainacc: 0.2500 Model_2_trainacc: 0.3167 Model_1_val:0.2015 Model_2_val:0.2610
Epoch: 0040 Model_1_loss: 1.5702 Model_2_loss: 1.5483 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.7167 Model_1_val:0.4088 Model_2_val:0.4187
Epoch: 0060 Model_1_loss: 1.2334 Model_2_loss: 1.3195 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.7583 Model_1_val:0.5092 Model_2_val:0.5108
Epoch: 0080 Model_1_loss: 0.9226 Model_2_loss: 1.0340 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8500 Model_1_val:0.5658 Model_2_val:0.5443
Epoch: 0100 Model_1_loss: 0.7206 Model_2_loss: 0.8012 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9000 Model_1_val:0.5887 Model_2_val:0.5681
Epoch: 0120 Model_1_loss: 0.6345 Model_2_loss: 0.6175 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5948 Model_2_val:0.5932
Epoch: 0140 Model_1_loss: 0.5535 Model_2_loss: 0.5564 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.6106 Model_2_val:0.6109
Epoch: 0160 Model_1_loss: 0.5169 Model_2_loss: 0.5213 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.6077 Model_2_val:0.6012
Epoch: 0180 Model_1_loss: 0.4646 Model_2_loss: 0.4549 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9250 Model_1_val:0.6077 Model_2_val:0.6231
Epoch: 0200 Model_1_loss: 0.3966 Model_2_loss: 0.3877 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6276 Model_2_val:0.6118
Epoch: 0220 Model_1_loss: 0.7545 Model_2_loss: 0.7397 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6685 Model_2_val:0.6630
Epoch: 0240 Model_1_loss: 0.6855 Model_2_loss: 0.7216 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6711 Model_2_val:0.6682
Epoch: 0260 Model_1_loss: 0.6804 Model_2_loss: 0.6460 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6650 Model_2_val:0.6672
Epoch: 0280 Model_1_loss: 0.6565 Model_2_loss: 0.6219 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6640 Model_2_val:0.6588
Epoch: 0300 Model_1_loss: 0.5958 Model_2_loss: 0.6204 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9333 Model_1_val:0.6695 Model_2_val:0.6688
Epoch: 0320 Model_1_loss: 0.5813 Model_2_loss: 0.5458 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6678 Model_2_val:0.6608
Epoch: 0340 Model_1_loss: 0.5614 Model_2_loss: 0.5483 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6740 Model_2_val:0.6659
Epoch: 0360 Model_1_loss: 0.4769 Model_2_loss: 0.5029 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6701 Model_2_val:0.6743
Epoch: 0380 Model_1_loss: 0.5535 Model_2_loss: 0.5075 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6727 Model_2_val:0.6746
Epoch: 0400 Model_1_loss: 0.5110 Model_2_loss: 0.5049 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6682 Model_2_val:0.6788
Model_one_test:0.6926 Model_two_test:0.6971
added by two output: 0.6955
18
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
552847908
Epoch: 0020 Model_1_loss: 1.7762 Model_2_loss: 1.7116 Model_1_trainacc: 0.2917 Model_2_trainacc: 0.4667 Model_1_val:0.1498 Model_2_val:0.2643
Epoch: 0040 Model_1_loss: 1.6805 Model_2_loss: 1.5376 Model_1_trainacc: 0.6167 Model_2_trainacc: 0.7333 Model_1_val:0.2946 Model_2_val:0.4268
Epoch: 0060 Model_1_loss: 1.5012 Model_2_loss: 1.2250 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.8583 Model_1_val:0.3945 Model_2_val:0.4985
Epoch: 0080 Model_1_loss: 1.2489 Model_2_loss: 0.9356 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8750 Model_1_val:0.4763 Model_2_val:0.5569
Epoch: 0100 Model_1_loss: 1.0625 Model_2_loss: 0.7757 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.9000 Model_1_val:0.4943 Model_2_val:0.5667
Epoch: 0120 Model_1_loss: 0.8780 Model_2_loss: 0.6778 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9083 Model_1_val:0.5083 Model_2_val:0.5781
Epoch: 0140 Model_1_loss: 0.8217 Model_2_loss: 0.6140 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.9417 Model_1_val:0.5178 Model_2_val:0.5742
Epoch: 0160 Model_1_loss: 0.6446 Model_2_loss: 0.5052 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9167 Model_1_val:0.5387 Model_2_val:0.5879
Epoch: 0180 Model_1_loss: 0.6170 Model_2_loss: 0.4850 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9333 Model_1_val:0.5429 Model_2_val:0.5980
Epoch: 0200 Model_1_loss: 0.5856 Model_2_loss: 0.4692 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.5514 Model_2_val:0.5948
Epoch: 0220 Model_1_loss: 0.9556 Model_2_loss: 0.8099 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.6388 Model_2_val:0.6489
Epoch: 0240 Model_1_loss: 0.8616 Model_2_loss: 0.7406 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.6509 Model_2_val:0.6656
Epoch: 0260 Model_1_loss: 0.7924 Model_2_loss: 0.7115 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.6460 Model_2_val:0.6620
Epoch: 0280 Model_1_loss: 0.6968 Model_2_loss: 0.6312 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6587 Model_2_val:0.6711
Epoch: 0300 Model_1_loss: 0.7050 Model_2_loss: 0.5934 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.6597 Model_2_val:0.6649
Epoch: 0320 Model_1_loss: 0.6525 Model_2_loss: 0.6278 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6591 Model_2_val:0.6646
Epoch: 0340 Model_1_loss: 0.6135 Model_2_loss: 0.5392 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9833 Model_1_val:0.6656 Model_2_val:0.6649
Epoch: 0360 Model_1_loss: 0.6311 Model_2_loss: 0.5356 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6613 Model_2_val:0.6695
Epoch: 0380 Model_1_loss: 0.5956 Model_2_loss: 0.5289 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.6682 Model_2_val:0.6581
Epoch: 0400 Model_1_loss: 0.5600 Model_2_loss: 0.5556 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6545 Model_2_val:0.6610
Model_one_test:0.6907 Model_two_test:0.6832
added by two output: 0.6845
19
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
190623460
Epoch: 0020 Model_1_loss: 1.7067 Model_2_loss: 1.7105 Model_1_trainacc: 0.3083 Model_2_trainacc: 0.3417 Model_1_val:0.2214 Model_2_val:0.2331
Epoch: 0040 Model_1_loss: 1.5214 Model_2_loss: 1.5082 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.7667 Model_1_val:0.4483 Model_2_val:0.4969
Epoch: 0060 Model_1_loss: 1.2522 Model_2_loss: 1.1939 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8667 Model_1_val:0.4865 Model_2_val:0.5266
Epoch: 0080 Model_1_loss: 0.9693 Model_2_loss: 0.9148 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9250 Model_1_val:0.5223 Model_2_val:0.5416
Epoch: 0100 Model_1_loss: 0.7535 Model_2_loss: 0.6963 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.5602 Model_2_val:0.5644
Epoch: 0120 Model_1_loss: 0.6895 Model_2_loss: 0.5802 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9417 Model_1_val:0.5657 Model_2_val:0.5973
Epoch: 0140 Model_1_loss: 0.5736 Model_2_loss: 0.4880 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.5719 Model_2_val:0.5908
Epoch: 0160 Model_1_loss: 0.4667 Model_2_loss: 0.4450 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5993 Model_2_val:0.6153
Epoch: 0180 Model_1_loss: 0.4356 Model_2_loss: 0.4206 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5872 Model_2_val:0.6009
Epoch: 0200 Model_1_loss: 0.3750 Model_2_loss: 0.3599 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6087 Model_2_val:0.6113
Epoch: 0220 Model_1_loss: 0.7057 Model_2_loss: 0.7000 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6730 Model_2_val:0.6710
Epoch: 0240 Model_1_loss: 0.6521 Model_2_loss: 0.6950 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6687 Model_2_val:0.6762
Epoch: 0260 Model_1_loss: 0.6212 Model_2_loss: 0.5841 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6824 Model_2_val:0.6785
Epoch: 0280 Model_1_loss: 0.5972 Model_2_loss: 0.5441 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6762 Model_2_val:0.6792
Epoch: 0300 Model_1_loss: 0.5275 Model_2_loss: 0.5151 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6814 Model_2_val:0.6808
Epoch: 0320 Model_1_loss: 0.4507 Model_2_loss: 0.5488 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6814 Model_2_val:0.6762
Epoch: 0340 Model_1_loss: 0.4649 Model_2_loss: 0.5161 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6805 Model_2_val:0.6762
Epoch: 0360 Model_1_loss: 0.4569 Model_2_loss: 0.4585 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6814 Model_2_val:0.6854
Epoch: 0380 Model_1_loss: 0.4495 Model_2_loss: 0.4620 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6837 Model_2_val:0.6814
Epoch: 0400 Model_1_loss: 0.4383 Model_2_loss: 0.4710 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6906 Model_2_val:0.6857
Model_one_test:0.7092 Model_two_test:0.7069
added by two output: 0.7085
20
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
282552495
Epoch: 0020 Model_1_loss: 1.7198 Model_2_loss: 1.7249 Model_1_trainacc: 0.4333 Model_2_trainacc: 0.4500 Model_1_val:0.2545 Model_2_val:0.2790
Epoch: 0040 Model_1_loss: 1.5529 Model_2_loss: 1.5176 Model_1_trainacc: 0.7083 Model_2_trainacc: 0.8083 Model_1_val:0.4176 Model_2_val:0.4548
Epoch: 0060 Model_1_loss: 1.3232 Model_2_loss: 1.1941 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8250 Model_1_val:0.4672 Model_2_val:0.5005
Epoch: 0080 Model_1_loss: 1.0787 Model_2_loss: 0.9462 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9250 Model_1_val:0.5148 Model_2_val:0.5576
Epoch: 0100 Model_1_loss: 0.8957 Model_2_loss: 0.7677 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9083 Model_1_val:0.5436 Model_2_val:0.5762
Epoch: 0120 Model_1_loss: 0.7343 Model_2_loss: 0.6538 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9417 Model_1_val:0.5664 Model_2_val:0.5821
Epoch: 0140 Model_1_loss: 0.6169 Model_2_loss: 0.5611 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9417 Model_1_val:0.5615 Model_2_val:0.5837
Epoch: 0160 Model_1_loss: 0.5434 Model_2_loss: 0.4477 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.5824 Model_2_val:0.5918
Epoch: 0180 Model_1_loss: 0.4543 Model_2_loss: 0.4478 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9750 Model_1_val:0.5886 Model_2_val:0.5948
Epoch: 0200 Model_1_loss: 0.4373 Model_2_loss: 0.4154 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6000 Model_2_val:0.6082
Epoch: 0220 Model_1_loss: 0.7656 Model_2_loss: 0.7355 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6502 Model_2_val:0.6613
Epoch: 0240 Model_1_loss: 0.7393 Model_2_loss: 0.6658 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6659 Model_2_val:0.6724
Epoch: 0260 Model_1_loss: 0.6691 Model_2_loss: 0.6307 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6656 Model_2_val:0.6679
Epoch: 0280 Model_1_loss: 0.6984 Model_2_loss: 0.5997 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.6685 Model_2_val:0.6728
Epoch: 0300 Model_1_loss: 0.6190 Model_2_loss: 0.5282 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6626 Model_2_val:0.6741
Epoch: 0320 Model_1_loss: 0.5784 Model_2_loss: 0.5292 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6604 Model_2_val:0.6705
Epoch: 0340 Model_1_loss: 0.5495 Model_2_loss: 0.5580 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6656 Model_2_val:0.6682
Epoch: 0360 Model_1_loss: 0.5562 Model_2_loss: 0.4879 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6613 Model_2_val:0.6591
Epoch: 0380 Model_1_loss: 0.5072 Model_2_loss: 0.4665 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6662 Model_2_val:0.6666
Epoch: 0400 Model_1_loss: 0.4984 Model_2_loss: 0.4638 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6630 Model_2_val:0.6737
Model_one_test:0.6884 Model_two_test:0.6910
added by two output: 0.6904
21
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
525389455
Epoch: 0020 Model_1_loss: 1.6983 Model_2_loss: 1.7081 Model_1_trainacc: 0.4583 Model_2_trainacc: 0.4083 Model_1_val:0.2985 Model_2_val:0.2902
Epoch: 0040 Model_1_loss: 1.4841 Model_2_loss: 1.4960 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.7583 Model_1_val:0.4557 Model_2_val:0.4457
Epoch: 0060 Model_1_loss: 1.1649 Model_2_loss: 1.1758 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8583 Model_1_val:0.5232 Model_2_val:0.5268
Epoch: 0080 Model_1_loss: 0.9455 Model_2_loss: 0.9135 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9167 Model_1_val:0.5553 Model_2_val:0.5745
Epoch: 0100 Model_1_loss: 0.7095 Model_2_loss: 0.7157 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9250 Model_1_val:0.5688 Model_2_val:0.5834
Epoch: 0120 Model_1_loss: 0.6248 Model_2_loss: 0.5760 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9333 Model_1_val:0.6036 Model_2_val:0.5953
Epoch: 0140 Model_1_loss: 0.5494 Model_2_loss: 0.5388 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.6099 Model_2_val:0.6122
Epoch: 0160 Model_1_loss: 0.4561 Model_2_loss: 0.5098 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.5983 Model_2_val:0.5923
Epoch: 0180 Model_1_loss: 0.4503 Model_2_loss: 0.4365 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.5989 Model_2_val:0.6089
Epoch: 0200 Model_1_loss: 0.4164 Model_2_loss: 0.3932 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.6257 Model_2_val:0.6191
Epoch: 0220 Model_1_loss: 0.7391 Model_2_loss: 0.7003 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.6704 Model_2_val:0.6549
Epoch: 0240 Model_1_loss: 0.6798 Model_2_loss: 0.6818 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.6803 Model_2_val:0.6661
Epoch: 0260 Model_1_loss: 0.6618 Model_2_loss: 0.6414 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6787 Model_2_val:0.6750
Epoch: 0280 Model_1_loss: 0.6186 Model_2_loss: 0.5777 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6701 Model_2_val:0.6777
Epoch: 0300 Model_1_loss: 0.5834 Model_2_loss: 0.5784 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6671 Model_2_val:0.6747
Epoch: 0320 Model_1_loss: 0.5505 Model_2_loss: 0.5538 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.6757 Model_2_val:0.6734
Epoch: 0340 Model_1_loss: 0.5577 Model_2_loss: 0.5128 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.6817 Model_2_val:0.6651
Epoch: 0360 Model_1_loss: 0.5114 Model_2_loss: 0.5436 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.6731 Model_2_val:0.6784
Epoch: 0380 Model_1_loss: 0.5553 Model_2_loss: 0.5311 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6794 Model_2_val:0.6737
Epoch: 0400 Model_1_loss: 0.5106 Model_2_loss: 0.4843 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6790 Model_2_val:0.6777
Model_one_test:0.7012 Model_two_test:0.6929
added by two output: 0.6962
22
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
857315760
Epoch: 0020 Model_1_loss: 1.7134 Model_2_loss: 1.7364 Model_1_trainacc: 0.4333 Model_2_trainacc: 0.2667 Model_1_val:0.2265 Model_2_val:0.2103
Epoch: 0040 Model_1_loss: 1.5090 Model_2_loss: 1.6117 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.6917 Model_1_val:0.4626 Model_2_val:0.4051
Epoch: 0060 Model_1_loss: 1.1753 Model_2_loss: 1.3243 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8083 Model_1_val:0.5142 Model_2_val:0.4924
Epoch: 0080 Model_1_loss: 0.9195 Model_2_loss: 1.0853 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8417 Model_1_val:0.5582 Model_2_val:0.5413
Epoch: 0100 Model_1_loss: 0.7184 Model_2_loss: 0.7670 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9000 Model_1_val:0.5764 Model_2_val:0.5526
Epoch: 0120 Model_1_loss: 0.6186 Model_2_loss: 0.6388 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5982 Model_2_val:0.5651
Epoch: 0140 Model_1_loss: 0.5248 Model_2_loss: 0.5586 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.6042 Model_2_val:0.5866
Epoch: 0160 Model_1_loss: 0.5003 Model_2_loss: 0.5174 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.5999 Model_2_val:0.5982
Epoch: 0180 Model_1_loss: 0.4067 Model_2_loss: 0.4901 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6276 Model_2_val:0.5989
Epoch: 0200 Model_1_loss: 0.3965 Model_2_loss: 0.4585 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6071 Model_2_val:0.6154
Epoch: 0220 Model_1_loss: 0.7317 Model_2_loss: 0.7456 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6663 Model_2_val:0.6644
Epoch: 0240 Model_1_loss: 0.6235 Model_2_loss: 0.6932 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6733 Model_2_val:0.6574
Epoch: 0260 Model_1_loss: 0.5895 Model_2_loss: 0.6135 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6746 Model_2_val:0.6822
Epoch: 0280 Model_1_loss: 0.5340 Model_2_loss: 0.5519 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6815 Model_2_val:0.6700
Epoch: 0300 Model_1_loss: 0.5380 Model_2_loss: 0.5831 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6716 Model_2_val:0.6753
Epoch: 0320 Model_1_loss: 0.5355 Model_2_loss: 0.5437 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6782 Model_2_val:0.6766
Epoch: 0340 Model_1_loss: 0.4775 Model_2_loss: 0.4984 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6640 Model_2_val:0.6667
Epoch: 0360 Model_1_loss: 0.4300 Model_2_loss: 0.4770 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6716 Model_2_val:0.6733
Epoch: 0380 Model_1_loss: 0.4656 Model_2_loss: 0.4607 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6796 Model_2_val:0.6802
Epoch: 0400 Model_1_loss: 0.4519 Model_2_loss: 0.4724 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6693 Model_2_val:0.6739
Model_one_test:0.6938 Model_two_test:0.6971
added by two output: 0.6938
23
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
317557461
Epoch: 0020 Model_1_loss: 1.7233 Model_2_loss: 1.7310 Model_1_trainacc: 0.3917 Model_2_trainacc: 0.3250 Model_1_val:0.2970 Model_2_val:0.2225
Epoch: 0040 Model_1_loss: 1.5442 Model_2_loss: 1.5792 Model_1_trainacc: 0.7083 Model_2_trainacc: 0.6833 Model_1_val:0.4287 Model_2_val:0.3635
Epoch: 0060 Model_1_loss: 1.2301 Model_2_loss: 1.2911 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8000 Model_1_val:0.5022 Model_2_val:0.4434
Epoch: 0080 Model_1_loss: 0.9336 Model_2_loss: 0.9801 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8833 Model_1_val:0.5566 Model_2_val:0.5176
Epoch: 0100 Model_1_loss: 0.7571 Model_2_loss: 0.7788 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9000 Model_1_val:0.5777 Model_2_val:0.5409
Epoch: 0120 Model_1_loss: 0.6443 Model_2_loss: 0.6570 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9250 Model_1_val:0.5790 Model_2_val:0.5703
Epoch: 0140 Model_1_loss: 0.5426 Model_2_loss: 0.5897 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.5857 Model_2_val:0.5697
Epoch: 0160 Model_1_loss: 0.5269 Model_2_loss: 0.4641 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.5863 Model_2_val:0.5751
Epoch: 0180 Model_1_loss: 0.4549 Model_2_loss: 0.4060 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.5822 Model_2_val:0.5866
Epoch: 0200 Model_1_loss: 0.4099 Model_2_loss: 0.3584 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.5818 Model_2_val:0.5981
Epoch: 0220 Model_1_loss: 0.7176 Model_2_loss: 0.7312 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6512 Model_2_val:0.6416
Epoch: 0240 Model_1_loss: 0.6743 Model_2_loss: 0.6540 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6653 Model_2_val:0.6618
Epoch: 0260 Model_1_loss: 0.6186 Model_2_loss: 0.6168 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6579 Model_2_val:0.6637
Epoch: 0280 Model_1_loss: 0.5708 Model_2_loss: 0.5629 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6515 Model_2_val:0.6582
Epoch: 0300 Model_1_loss: 0.5230 Model_2_loss: 0.5424 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6621 Model_2_val:0.6678
Epoch: 0320 Model_1_loss: 0.5026 Model_2_loss: 0.4910 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6637 Model_2_val:0.6624
Epoch: 0340 Model_1_loss: 0.4637 Model_2_loss: 0.4880 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6630 Model_2_val:0.6547
Epoch: 0360 Model_1_loss: 0.4373 Model_2_loss: 0.4559 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6576 Model_2_val:0.6669
Epoch: 0380 Model_1_loss: 0.4751 Model_2_loss: 0.4389 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6688 Model_2_val:0.6525
Epoch: 0400 Model_1_loss: 0.4614 Model_2_loss: 0.4755 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6618 Model_2_val:0.6640
Model_one_test:0.6803 Model_two_test:0.6835
added by two output: 0.6819
24
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1262048452
Epoch: 0020 Model_1_loss: 1.7409 Model_2_loss: 1.7240 Model_1_trainacc: 0.2917 Model_2_trainacc: 0.5333 Model_1_val:0.2483 Model_2_val:0.3015
Epoch: 0040 Model_1_loss: 1.6023 Model_2_loss: 1.5015 Model_1_trainacc: 0.6417 Model_2_trainacc: 0.7833 Model_1_val:0.3770 Model_2_val:0.4744
Epoch: 0060 Model_1_loss: 1.3709 Model_2_loss: 1.1873 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8750 Model_1_val:0.4838 Model_2_val:0.5270
Epoch: 0080 Model_1_loss: 1.0637 Model_2_loss: 0.9049 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9000 Model_1_val:0.5162 Model_2_val:0.5495
Epoch: 0100 Model_1_loss: 0.8553 Model_2_loss: 0.6886 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9833 Model_1_val:0.5750 Model_2_val:0.5746
Epoch: 0120 Model_1_loss: 0.6694 Model_2_loss: 0.5935 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5841 Model_2_val:0.5965
Epoch: 0140 Model_1_loss: 0.5646 Model_2_loss: 0.4972 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.5893 Model_2_val:0.5965
Epoch: 0160 Model_1_loss: 0.4720 Model_2_loss: 0.4365 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6106 Model_2_val:0.5959
Epoch: 0180 Model_1_loss: 0.3894 Model_2_loss: 0.3838 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6233 Model_2_val:0.5910
Epoch: 0200 Model_1_loss: 0.3576 Model_2_loss: 0.3308 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6194 Model_2_val:0.6037
Epoch: 0220 Model_1_loss: 0.6665 Model_2_loss: 0.7009 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6501 Model_2_val:0.6645
Epoch: 0240 Model_1_loss: 0.6135 Model_2_loss: 0.6441 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6779 Model_2_val:0.6678
Epoch: 0260 Model_1_loss: 0.5571 Model_2_loss: 0.6016 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6580 Model_2_val:0.6612
Epoch: 0280 Model_1_loss: 0.5361 Model_2_loss: 0.6122 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6704 Model_2_val:0.6772
Epoch: 0300 Model_1_loss: 0.5366 Model_2_loss: 0.5420 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6759 Model_2_val:0.6566
Epoch: 0320 Model_1_loss: 0.5396 Model_2_loss: 0.5538 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6632 Model_2_val:0.6717
Epoch: 0340 Model_1_loss: 0.5314 Model_2_loss: 0.5115 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6606 Model_2_val:0.6713
Epoch: 0360 Model_1_loss: 0.5203 Model_2_loss: 0.5509 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6782 Model_2_val:0.6668
Epoch: 0380 Model_1_loss: 0.4982 Model_2_loss: 0.4794 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6651 Model_2_val:0.6691
Epoch: 0400 Model_1_loss: 0.4707 Model_2_loss: 0.4891 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6759 Model_2_val:0.6645
Model_one_test:0.6926 Model_two_test:0.6939
added by two output: 0.6936
25
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
908444167
Epoch: 0020 Model_1_loss: 1.7067 Model_2_loss: 1.7158 Model_1_trainacc: 0.5000 Model_2_trainacc: 0.4500 Model_1_val:0.3156 Model_2_val:0.2427
Epoch: 0040 Model_1_loss: 1.5593 Model_2_loss: 1.5373 Model_1_trainacc: 0.6417 Model_2_trainacc: 0.7833 Model_1_val:0.4039 Model_2_val:0.4014
Epoch: 0060 Model_1_loss: 1.2949 Model_2_loss: 1.2865 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8333 Model_1_val:0.5080 Model_2_val:0.4673
Epoch: 0080 Model_1_loss: 0.9751 Model_2_loss: 0.9833 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8917 Model_1_val:0.5497 Model_2_val:0.5178
Epoch: 0100 Model_1_loss: 0.7624 Model_2_loss: 0.8159 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8750 Model_1_val:0.5421 Model_2_val:0.5538
Epoch: 0120 Model_1_loss: 0.6916 Model_2_loss: 0.6591 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.5636 Model_2_val:0.5431
Epoch: 0140 Model_1_loss: 0.6117 Model_2_loss: 0.6161 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9417 Model_1_val:0.5674 Model_2_val:0.5724
Epoch: 0160 Model_1_loss: 0.4987 Model_2_loss: 0.5210 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9167 Model_1_val:0.5778 Model_2_val:0.5869
Epoch: 0180 Model_1_loss: 0.4795 Model_2_loss: 0.4785 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.6046 Model_2_val:0.5658
Epoch: 0200 Model_1_loss: 0.4107 Model_2_loss: 0.4066 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5677 Model_2_val:0.5645
Epoch: 0220 Model_1_loss: 0.7673 Model_2_loss: 0.7390 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6321 Model_2_val:0.6409
Epoch: 0240 Model_1_loss: 0.6993 Model_2_loss: 0.8005 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9333 Model_1_val:0.6406 Model_2_val:0.6456
Epoch: 0260 Model_1_loss: 0.6432 Model_2_loss: 0.6495 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6453 Model_2_val:0.6472
Epoch: 0280 Model_1_loss: 0.6238 Model_2_loss: 0.6321 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6551 Model_2_val:0.6314
Epoch: 0300 Model_1_loss: 0.5742 Model_2_loss: 0.5587 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6444 Model_2_val:0.6541
Epoch: 0320 Model_1_loss: 0.6224 Model_2_loss: 0.5655 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.6422 Model_2_val:0.6491
Epoch: 0340 Model_1_loss: 0.4985 Model_2_loss: 0.5120 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6472 Model_2_val:0.6482
Epoch: 0360 Model_1_loss: 0.5253 Model_2_loss: 0.5440 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6428 Model_2_val:0.6478
Epoch: 0380 Model_1_loss: 0.4843 Model_2_loss: 0.5352 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6516 Model_2_val:0.6447
Epoch: 0400 Model_1_loss: 0.4480 Model_2_loss: 0.4906 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6434 Model_2_val:0.6485
Model_one_test:0.6680 Model_two_test:0.6655
added by two output: 0.6674
26
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
252453680
Epoch: 0020 Model_1_loss: 1.6907 Model_2_loss: 1.7319 Model_1_trainacc: 0.5667 Model_2_trainacc: 0.4083 Model_1_val:0.3278 Model_2_val:0.2283
Epoch: 0040 Model_1_loss: 1.4494 Model_2_loss: 1.5846 Model_1_trainacc: 0.7417 Model_2_trainacc: 0.6833 Model_1_val:0.4808 Model_2_val:0.4482
Epoch: 0060 Model_1_loss: 1.1361 Model_2_loss: 1.3041 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8333 Model_1_val:0.5302 Model_2_val:0.4884
Epoch: 0080 Model_1_loss: 0.8572 Model_2_loss: 1.0224 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8917 Model_1_val:0.5883 Model_2_val:0.5315
Epoch: 0100 Model_1_loss: 0.6886 Model_2_loss: 0.9122 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.8083 Model_1_val:0.5753 Model_2_val:0.5468
Epoch: 0120 Model_1_loss: 0.5778 Model_2_loss: 0.6951 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9250 Model_1_val:0.5949 Model_2_val:0.5491
Epoch: 0140 Model_1_loss: 0.5095 Model_2_loss: 0.6151 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9250 Model_1_val:0.5972 Model_2_val:0.5690
Epoch: 0160 Model_1_loss: 0.4788 Model_2_loss: 0.5303 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6072 Model_2_val:0.5810
Epoch: 0180 Model_1_loss: 0.4437 Model_2_loss: 0.4821 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.6005 Model_2_val:0.5849
Epoch: 0200 Model_1_loss: 0.4040 Model_2_loss: 0.4393 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.5982 Model_2_val:0.5959
Epoch: 0220 Model_1_loss: 0.7778 Model_2_loss: 0.8282 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6583 Model_2_val:0.6516
Epoch: 0240 Model_1_loss: 0.6879 Model_2_loss: 0.7770 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6702 Model_2_val:0.6666
Epoch: 0260 Model_1_loss: 0.6775 Model_2_loss: 0.7126 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6739 Model_2_val:0.6662
Epoch: 0280 Model_1_loss: 0.6758 Model_2_loss: 0.7265 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9333 Model_1_val:0.6729 Model_2_val:0.6729
Epoch: 0300 Model_1_loss: 0.6262 Model_2_loss: 0.6601 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6745 Model_2_val:0.6642
Epoch: 0320 Model_1_loss: 0.5670 Model_2_loss: 0.5991 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6739 Model_2_val:0.6652
Epoch: 0340 Model_1_loss: 0.5644 Model_2_loss: 0.5709 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6768 Model_2_val:0.6802
Epoch: 0360 Model_1_loss: 0.5187 Model_2_loss: 0.6053 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6825 Model_2_val:0.6719
Epoch: 0380 Model_1_loss: 0.4890 Model_2_loss: 0.5041 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6765 Model_2_val:0.6752
Epoch: 0400 Model_1_loss: 0.5275 Model_2_loss: 0.5273 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6722 Model_2_val:0.6695
Model_one_test:0.6991 Model_two_test:0.7007
added by two output: 0.6997
27
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1283782287
Epoch: 0020 Model_1_loss: 1.7239 Model_2_loss: 1.7203 Model_1_trainacc: 0.4500 Model_2_trainacc: 0.4417 Model_1_val:0.2823 Model_2_val:0.2715
Epoch: 0040 Model_1_loss: 1.5953 Model_2_loss: 1.5302 Model_1_trainacc: 0.7417 Model_2_trainacc: 0.7250 Model_1_val:0.4235 Model_2_val:0.3932
Epoch: 0060 Model_1_loss: 1.2679 Model_2_loss: 1.2859 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.7750 Model_1_val:0.4883 Model_2_val:0.4622
Epoch: 0080 Model_1_loss: 0.9720 Model_2_loss: 0.9385 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8750 Model_1_val:0.5126 Model_2_val:0.5238
Epoch: 0100 Model_1_loss: 0.7605 Model_2_loss: 0.7221 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8917 Model_1_val:0.5394 Model_2_val:0.5439
Epoch: 0120 Model_1_loss: 0.5828 Model_2_loss: 0.6556 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5628 Model_2_val:0.5698
Epoch: 0140 Model_1_loss: 0.5234 Model_2_loss: 0.5825 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9250 Model_1_val:0.5605 Model_2_val:0.5628
Epoch: 0160 Model_1_loss: 0.4868 Model_2_loss: 0.5194 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5826 Model_2_val:0.5794
Epoch: 0180 Model_1_loss: 0.3698 Model_2_loss: 0.4520 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6097 Model_2_val:0.5822
Epoch: 0200 Model_1_loss: 0.3661 Model_2_loss: 0.4327 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6100 Model_2_val:0.5822
Epoch: 0220 Model_1_loss: 0.7319 Model_2_loss: 0.8167 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6672 Model_2_val:0.6634
Epoch: 0240 Model_1_loss: 0.6692 Model_2_loss: 0.6517 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6675 Model_2_val:0.6691
Epoch: 0260 Model_1_loss: 0.6119 Model_2_loss: 0.6483 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6707 Model_2_val:0.6656
Epoch: 0280 Model_1_loss: 0.5886 Model_2_loss: 0.6453 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6714 Model_2_val:0.6729
Epoch: 0300 Model_1_loss: 0.5988 Model_2_loss: 0.5804 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6755 Model_2_val:0.6701
Epoch: 0320 Model_1_loss: 0.5365 Model_2_loss: 0.5484 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6669 Model_2_val:0.6781
Epoch: 0340 Model_1_loss: 0.5013 Model_2_loss: 0.5347 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6729 Model_2_val:0.6870
Epoch: 0360 Model_1_loss: 0.4844 Model_2_loss: 0.5410 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6643 Model_2_val:0.6758
Epoch: 0380 Model_1_loss: 0.4606 Model_2_loss: 0.5002 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6761 Model_2_val:0.6749
Epoch: 0400 Model_1_loss: 0.4922 Model_2_loss: 0.5124 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6742 Model_2_val:0.6720
Model_one_test:0.6937 Model_two_test:0.6902
added by two output: 0.6915
28
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1321594318
Epoch: 0020 Model_1_loss: 1.6984 Model_2_loss: 1.7338 Model_1_trainacc: 0.4333 Model_2_trainacc: 0.4083 Model_1_val:0.3121 Model_2_val:0.2704
Epoch: 0040 Model_1_loss: 1.4659 Model_2_loss: 1.5591 Model_1_trainacc: 0.7583 Model_2_trainacc: 0.6833 Model_1_val:0.4172 Model_2_val:0.4029
Epoch: 0060 Model_1_loss: 1.1778 Model_2_loss: 1.3020 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.7917 Model_1_val:0.4614 Model_2_val:0.4745
Epoch: 0080 Model_1_loss: 0.9253 Model_2_loss: 1.0737 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8000 Model_1_val:0.5334 Model_2_val:0.5096
Epoch: 0100 Model_1_loss: 0.7792 Model_2_loss: 0.8152 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8750 Model_1_val:0.5438 Model_2_val:0.5220
Epoch: 0120 Model_1_loss: 0.6798 Model_2_loss: 0.6630 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9333 Model_1_val:0.5685 Model_2_val:0.5473
Epoch: 0140 Model_1_loss: 0.5900 Model_2_loss: 0.6172 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5734 Model_2_val:0.5639
Epoch: 0160 Model_1_loss: 0.4768 Model_2_loss: 0.5653 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.5815 Model_2_val:0.5665
Epoch: 0180 Model_1_loss: 0.4839 Model_2_loss: 0.4896 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5994 Model_2_val:0.5786
Epoch: 0200 Model_1_loss: 0.4231 Model_2_loss: 0.4008 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.5848 Model_2_val:0.5607
Epoch: 0220 Model_1_loss: 0.7875 Model_2_loss: 0.7524 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6593 Model_2_val:0.6704
Epoch: 0240 Model_1_loss: 0.6993 Model_2_loss: 0.6976 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6606 Model_2_val:0.6625
Epoch: 0260 Model_1_loss: 0.6712 Model_2_loss: 0.6791 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.6691 Model_2_val:0.6691
Epoch: 0280 Model_1_loss: 0.6184 Model_2_loss: 0.6145 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.6599 Model_2_val:0.6661
Epoch: 0300 Model_1_loss: 0.6183 Model_2_loss: 0.6511 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.6658 Model_2_val:0.6573
Epoch: 0320 Model_1_loss: 0.5591 Model_2_loss: 0.5791 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6648 Model_2_val:0.6687
Epoch: 0340 Model_1_loss: 0.5712 Model_2_loss: 0.6012 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6661 Model_2_val:0.6687
Epoch: 0360 Model_1_loss: 0.5063 Model_2_loss: 0.5126 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6635 Model_2_val:0.6752
Epoch: 0380 Model_1_loss: 0.5286 Model_2_loss: 0.5493 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.6739 Model_2_val:0.6684
Epoch: 0400 Model_1_loss: 0.4973 Model_2_loss: 0.4916 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6730 Model_2_val:0.6658
Model_one_test:0.7003 Model_two_test:0.6974
added by two output: 0.7003
29
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1453811112
Epoch: 0020 Model_1_loss: 1.7409 Model_2_loss: 1.7341 Model_1_trainacc: 0.3833 Model_2_trainacc: 0.3750 Model_1_val:0.2439 Model_2_val:0.2215
Epoch: 0040 Model_1_loss: 1.6150 Model_2_loss: 1.5644 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7333 Model_1_val:0.3393 Model_2_val:0.4195
Epoch: 0060 Model_1_loss: 1.3453 Model_2_loss: 1.2958 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8417 Model_1_val:0.4201 Model_2_val:0.5068
Epoch: 0080 Model_1_loss: 1.0338 Model_2_loss: 1.0281 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8833 Model_1_val:0.5453 Model_2_val:0.5149
Epoch: 0100 Model_1_loss: 0.7465 Model_2_loss: 0.7827 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9250 Model_1_val:0.5634 Model_2_val:0.5702
Epoch: 0120 Model_1_loss: 0.7258 Model_2_loss: 0.6609 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9250 Model_1_val:0.5909 Model_2_val:0.5414
Epoch: 0140 Model_1_loss: 0.6130 Model_2_loss: 0.5725 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.5831 Model_2_val:0.5828
Epoch: 0160 Model_1_loss: 0.5157 Model_2_loss: 0.5018 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6174 Model_2_val:0.5857
Epoch: 0180 Model_1_loss: 0.4237 Model_2_loss: 0.4381 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6038 Model_2_val:0.5857
Epoch: 0200 Model_1_loss: 0.3917 Model_2_loss: 0.4017 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6258 Model_2_val:0.5918
Epoch: 0220 Model_1_loss: 0.7029 Model_2_loss: 0.6908 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6591 Model_2_val:0.6698
Epoch: 0240 Model_1_loss: 0.6646 Model_2_loss: 0.6584 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6740 Model_2_val:0.6717
Epoch: 0260 Model_1_loss: 0.5995 Model_2_loss: 0.5900 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6766 Model_2_val:0.6779
Epoch: 0280 Model_1_loss: 0.6086 Model_2_loss: 0.5529 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6769 Model_2_val:0.6734
Epoch: 0300 Model_1_loss: 0.5567 Model_2_loss: 0.5343 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6721 Model_2_val:0.6721
Epoch: 0320 Model_1_loss: 0.5609 Model_2_loss: 0.5342 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6750 Model_2_val:0.6834
Epoch: 0340 Model_1_loss: 0.4995 Model_2_loss: 0.4779 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6721 Model_2_val:0.6724
Epoch: 0360 Model_1_loss: 0.4786 Model_2_loss: 0.4732 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6685 Model_2_val:0.6863
Epoch: 0380 Model_1_loss: 0.4686 Model_2_loss: 0.4572 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6850 Model_2_val:0.6753
Epoch: 0400 Model_1_loss: 0.4350 Model_2_loss: 0.4055 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6843 Model_2_val:0.6795
Model_one_test:0.7002 Model_two_test:0.6986
added by two output: 0.6986
30
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1233606675
Epoch: 0020 Model_1_loss: 1.7253 Model_2_loss: 1.7124 Model_1_trainacc: 0.4083 Model_2_trainacc: 0.4500 Model_1_val:0.2603 Model_2_val:0.3031
Epoch: 0040 Model_1_loss: 1.5929 Model_2_loss: 1.4971 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.8083 Model_1_val:0.3826 Model_2_val:0.4245
Epoch: 0060 Model_1_loss: 1.2818 Model_2_loss: 1.2008 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8250 Model_1_val:0.5249 Model_2_val:0.5075
Epoch: 0080 Model_1_loss: 0.9596 Model_2_loss: 0.9529 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9083 Model_1_val:0.5435 Model_2_val:0.5396
Epoch: 0100 Model_1_loss: 0.7164 Model_2_loss: 0.6932 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9417 Model_1_val:0.5680 Model_2_val:0.5687
Epoch: 0120 Model_1_loss: 0.5989 Model_2_loss: 0.5846 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5958 Model_2_val:0.5831
Epoch: 0140 Model_1_loss: 0.4754 Model_2_loss: 0.4263 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.5818 Model_2_val:0.5991
Epoch: 0160 Model_1_loss: 0.4049 Model_2_loss: 0.4368 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9417 Model_1_val:0.5850 Model_2_val:0.6128
Epoch: 0180 Model_1_loss: 0.3907 Model_2_loss: 0.3745 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.5997 Model_2_val:0.5840
Epoch: 0200 Model_1_loss: 0.4122 Model_2_loss: 0.3414 Model_1_trainacc: 0.9417 Model_2_trainacc: 1.0000 Model_1_val:0.6135 Model_2_val:0.6056
Epoch: 0220 Model_1_loss: 0.6089 Model_2_loss: 0.6953 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6566 Model_2_val:0.6687
Epoch: 0240 Model_1_loss: 0.5738 Model_2_loss: 0.5880 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6586 Model_2_val:0.6776
Epoch: 0260 Model_1_loss: 0.5606 Model_2_loss: 0.5685 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6576 Model_2_val:0.6596
Epoch: 0280 Model_1_loss: 0.5149 Model_2_loss: 0.4916 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6606 Model_2_val:0.6625
Epoch: 0300 Model_1_loss: 0.5471 Model_2_loss: 0.5363 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6691 Model_2_val:0.6700
Epoch: 0320 Model_1_loss: 0.5149 Model_2_loss: 0.4887 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6700 Model_2_val:0.6629
Epoch: 0340 Model_1_loss: 0.5217 Model_2_loss: 0.4724 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6691 Model_2_val:0.6723
Epoch: 0360 Model_1_loss: 0.4775 Model_2_loss: 0.4405 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6583 Model_2_val:0.6779
Epoch: 0380 Model_1_loss: 0.4445 Model_2_loss: 0.4306 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6704 Model_2_val:0.6700
Epoch: 0400 Model_1_loss: 0.5007 Model_2_loss: 0.4159 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6547 Model_2_val:0.6707
Model_one_test:0.6929 Model_two_test:0.6936
added by two output: 0.6920
Model1 Acc: 0.691426 Model2 Acc: 0.690635
Maxacc Mean: 0.692704
[0.6924372651610259, 0.6927043179398544]
Maxacc of all experiments: 0.6927043179398544
1
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1240967399
Epoch: 0020 Model_1_loss: 1.7214 Model_2_loss: 1.7299 Model_1_trainacc: 0.5250 Model_2_trainacc: 0.5167 Model_1_val:0.2992 Model_2_val:0.3375
Epoch: 0040 Model_1_loss: 1.5494 Model_2_loss: 1.5640 Model_1_trainacc: 0.6583 Model_2_trainacc: 0.7750 Model_1_val:0.3933 Model_2_val:0.4260
Epoch: 0060 Model_1_loss: 1.2712 Model_2_loss: 1.2550 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8500 Model_1_val:0.4875 Model_2_val:0.4766
Epoch: 0080 Model_1_loss: 1.0125 Model_2_loss: 0.9369 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9000 Model_1_val:0.5234 Model_2_val:0.5433
Epoch: 0100 Model_1_loss: 0.7912 Model_2_loss: 0.7331 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.5353 Model_2_val:0.5535
Epoch: 0120 Model_1_loss: 0.6445 Model_2_loss: 0.6329 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.5746 Model_2_val:0.5627
Epoch: 0140 Model_1_loss: 0.5986 Model_2_loss: 0.5039 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.5674 Model_2_val:0.5852
Epoch: 0160 Model_1_loss: 0.5489 Model_2_loss: 0.5190 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5651 Model_2_val:0.5908
Epoch: 0180 Model_1_loss: 0.5022 Model_2_loss: 0.4024 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.5845 Model_2_val:0.5829
Epoch: 0200 Model_1_loss: 0.4796 Model_2_loss: 0.3715 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5845 Model_2_val:0.6004
Epoch: 0220 Model_1_loss: 0.8422 Model_2_loss: 0.7276 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6618 Model_2_val:0.6608
Epoch: 0240 Model_1_loss: 0.6975 Model_2_loss: 0.6529 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6631 Model_2_val:0.6740
Epoch: 0260 Model_1_loss: 0.7236 Model_2_loss: 0.5496 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9917 Model_1_val:0.6602 Model_2_val:0.6691
Epoch: 0280 Model_1_loss: 0.6460 Model_2_loss: 0.5736 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6641 Model_2_val:0.6704
Epoch: 0300 Model_1_loss: 0.5439 Model_2_loss: 0.5506 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6668 Model_2_val:0.6681
Epoch: 0320 Model_1_loss: 0.5554 Model_2_loss: 0.5427 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6681 Model_2_val:0.6803
Epoch: 0340 Model_1_loss: 0.5257 Model_2_loss: 0.4806 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6767 Model_2_val:0.6839
Epoch: 0360 Model_1_loss: 0.4749 Model_2_loss: 0.4586 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6707 Model_2_val:0.6823
Epoch: 0380 Model_1_loss: 0.4633 Model_2_loss: 0.4737 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6754 Model_2_val:0.6803
Epoch: 0400 Model_1_loss: 0.4551 Model_2_loss: 0.4516 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6856 Model_2_val:0.6773
Model_one_test:0.6991 Model_two_test:0.6995
added by two output: 0.6982
2
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1357846707
Epoch: 0020 Model_1_loss: 1.7060 Model_2_loss: 1.7268 Model_1_trainacc: 0.4333 Model_2_trainacc: 0.4583 Model_1_val:0.2559 Model_2_val:0.2996
Epoch: 0040 Model_1_loss: 1.4846 Model_2_loss: 1.5620 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.6750 Model_1_val:0.4377 Model_2_val:0.4393
Epoch: 0060 Model_1_loss: 1.1424 Model_2_loss: 1.2582 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8083 Model_1_val:0.5137 Model_2_val:0.4963
Epoch: 0080 Model_1_loss: 0.8283 Model_2_loss: 0.9704 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8750 Model_1_val:0.5548 Model_2_val:0.5319
Epoch: 0100 Model_1_loss: 0.6819 Model_2_loss: 0.7290 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5807 Model_2_val:0.5357
Epoch: 0120 Model_1_loss: 0.5811 Model_2_loss: 0.6061 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5827 Model_2_val:0.5542
Epoch: 0140 Model_1_loss: 0.4563 Model_2_loss: 0.5609 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9333 Model_1_val:0.5823 Model_2_val:0.5694
Epoch: 0160 Model_1_loss: 0.4196 Model_2_loss: 0.4653 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6001 Model_2_val:0.5730
Epoch: 0180 Model_1_loss: 0.3633 Model_2_loss: 0.4370 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.5982 Model_2_val:0.5794
Epoch: 0200 Model_1_loss: 0.3956 Model_2_loss: 0.4034 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6082 Model_2_val:0.5885
Epoch: 0220 Model_1_loss: 0.6733 Model_2_loss: 0.7332 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6629 Model_2_val:0.6519
Epoch: 0240 Model_1_loss: 0.5966 Model_2_loss: 0.6923 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6658 Model_2_val:0.6500
Epoch: 0260 Model_1_loss: 0.5918 Model_2_loss: 0.6126 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6697 Model_2_val:0.6532
Epoch: 0280 Model_1_loss: 0.5410 Model_2_loss: 0.5694 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6668 Model_2_val:0.6820
Epoch: 0300 Model_1_loss: 0.5263 Model_2_loss: 0.5952 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6729 Model_2_val:0.6610
Epoch: 0320 Model_1_loss: 0.5174 Model_2_loss: 0.5109 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6690 Model_2_val:0.6561
Epoch: 0340 Model_1_loss: 0.5110 Model_2_loss: 0.5656 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6810 Model_2_val:0.6736
Epoch: 0360 Model_1_loss: 0.4605 Model_2_loss: 0.5270 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9333 Model_1_val:0.6665 Model_2_val:0.6742
Epoch: 0380 Model_1_loss: 0.4692 Model_2_loss: 0.4790 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6661 Model_2_val:0.6639
Epoch: 0400 Model_1_loss: 0.4580 Model_2_loss: 0.5068 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6726 Model_2_val:0.6655
Model_one_test:0.6943 Model_two_test:0.6914
added by two output: 0.6917
3
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
975727906
Epoch: 0020 Model_1_loss: 1.6876 Model_2_loss: 1.7338 Model_1_trainacc: 0.5333 Model_2_trainacc: 0.5417 Model_1_val:0.2933 Model_2_val:0.3175
Epoch: 0040 Model_1_loss: 1.4729 Model_2_loss: 1.5574 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.7583 Model_1_val:0.4743 Model_2_val:0.4538
Epoch: 0060 Model_1_loss: 1.1581 Model_2_loss: 1.3031 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8000 Model_1_val:0.5294 Model_2_val:0.4955
Epoch: 0080 Model_1_loss: 0.8764 Model_2_loss: 0.9582 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8833 Model_1_val:0.5547 Model_2_val:0.5536
Epoch: 0100 Model_1_loss: 0.7052 Model_2_loss: 0.7362 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9333 Model_1_val:0.5718 Model_2_val:0.5789
Epoch: 0120 Model_1_loss: 0.6000 Model_2_loss: 0.5794 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5883 Model_2_val:0.5890
Epoch: 0140 Model_1_loss: 0.5126 Model_2_loss: 0.4790 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.5954 Model_2_val:0.5839
Epoch: 0160 Model_1_loss: 0.4930 Model_2_loss: 0.4623 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5809 Model_2_val:0.6128
Epoch: 0180 Model_1_loss: 0.4654 Model_2_loss: 0.4186 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.5859 Model_2_val:0.5943
Epoch: 0200 Model_1_loss: 0.3808 Model_2_loss: 0.4144 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.5910 Model_2_val:0.6048
Epoch: 0220 Model_1_loss: 0.7976 Model_2_loss: 0.7178 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6347 Model_2_val:0.6509
Epoch: 0240 Model_1_loss: 0.7170 Model_2_loss: 0.6263 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6421 Model_2_val:0.6495
Epoch: 0260 Model_1_loss: 0.6902 Model_2_loss: 0.6113 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6616 Model_2_val:0.6744
Epoch: 0280 Model_1_loss: 0.6231 Model_2_loss: 0.5990 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6472 Model_2_val:0.6589
Epoch: 0300 Model_1_loss: 0.6193 Model_2_loss: 0.5793 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6441 Model_2_val:0.6572
Epoch: 0320 Model_1_loss: 0.6080 Model_2_loss: 0.5419 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6583 Model_2_val:0.6727
Epoch: 0340 Model_1_loss: 0.6000 Model_2_loss: 0.5203 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6630 Model_2_val:0.6572
Epoch: 0360 Model_1_loss: 0.5973 Model_2_loss: 0.5270 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6593 Model_2_val:0.6636
Epoch: 0380 Model_1_loss: 0.5181 Model_2_loss: 0.5115 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9833 Model_1_val:0.6552 Model_2_val:0.6613
Epoch: 0400 Model_1_loss: 0.5432 Model_2_loss: 0.4787 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6542 Model_2_val:0.6502
Model_one_test:0.6811 Model_two_test:0.6761
added by two output: 0.6798
4
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1144293125
Epoch: 0020 Model_1_loss: 1.6948 Model_2_loss: 1.7322 Model_1_trainacc: 0.4917 Model_2_trainacc: 0.3250 Model_1_val:0.2447 Model_2_val:0.2054
Epoch: 0040 Model_1_loss: 1.4918 Model_2_loss: 1.5891 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.6417 Model_1_val:0.4485 Model_2_val:0.3980
Epoch: 0060 Model_1_loss: 1.2405 Model_2_loss: 1.2905 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8750 Model_1_val:0.4869 Model_2_val:0.5074
Epoch: 0080 Model_1_loss: 0.9438 Model_2_loss: 1.0081 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9167 Model_1_val:0.5013 Model_2_val:0.5093
Epoch: 0100 Model_1_loss: 0.7756 Model_2_loss: 0.7406 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5438 Model_2_val:0.5480
Epoch: 0120 Model_1_loss: 0.6040 Model_2_loss: 0.6556 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9250 Model_1_val:0.5678 Model_2_val:0.5774
Epoch: 0140 Model_1_loss: 0.5704 Model_2_loss: 0.5457 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.5704 Model_2_val:0.5822
Epoch: 0160 Model_1_loss: 0.4868 Model_2_loss: 0.5340 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.5861 Model_2_val:0.5909
Epoch: 0180 Model_1_loss: 0.4450 Model_2_loss: 0.4720 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6052 Model_2_val:0.6011
Epoch: 0200 Model_1_loss: 0.4360 Model_2_loss: 0.4187 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.5889 Model_2_val:0.6059
Epoch: 0220 Model_1_loss: 0.6472 Model_2_loss: 0.7305 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6715 Model_2_val:0.6587
Epoch: 0240 Model_1_loss: 0.6687 Model_2_loss: 0.6771 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6676 Model_2_val:0.6692
Epoch: 0260 Model_1_loss: 0.5992 Model_2_loss: 0.6993 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6708 Model_2_val:0.6801
Epoch: 0280 Model_1_loss: 0.5846 Model_2_loss: 0.6394 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6740 Model_2_val:0.6702
Epoch: 0300 Model_1_loss: 0.5366 Model_2_loss: 0.5906 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6820 Model_2_val:0.6721
Epoch: 0320 Model_1_loss: 0.5585 Model_2_loss: 0.5567 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6811 Model_2_val:0.6596
Epoch: 0340 Model_1_loss: 0.4923 Model_2_loss: 0.5243 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6791 Model_2_val:0.6628
Epoch: 0360 Model_1_loss: 0.5045 Model_2_loss: 0.5199 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6855 Model_2_val:0.6833
Epoch: 0380 Model_1_loss: 0.4506 Model_2_loss: 0.4293 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6811 Model_2_val:0.6782
Epoch: 0400 Model_1_loss: 0.4753 Model_2_loss: 0.4419 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6750 Model_2_val:0.6772
Model_one_test:0.7047 Model_two_test:0.7009
added by two output: 0.7028
5
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
758834090
Epoch: 0020 Model_1_loss: 1.7144 Model_2_loss: 1.7302 Model_1_trainacc: 0.4833 Model_2_trainacc: 0.4417 Model_1_val:0.3091 Model_2_val:0.2127
Epoch: 0040 Model_1_loss: 1.5171 Model_2_loss: 1.6163 Model_1_trainacc: 0.6583 Model_2_trainacc: 0.6833 Model_1_val:0.4456 Model_2_val:0.3913
Epoch: 0060 Model_1_loss: 1.2047 Model_2_loss: 1.3250 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8083 Model_1_val:0.4998 Model_2_val:0.4604
Epoch: 0080 Model_1_loss: 0.9409 Model_2_loss: 1.0438 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8917 Model_1_val:0.5467 Model_2_val:0.5079
Epoch: 0100 Model_1_loss: 0.7878 Model_2_loss: 0.8546 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8667 Model_1_val:0.5699 Model_2_val:0.5672
Epoch: 0120 Model_1_loss: 0.6403 Model_2_loss: 0.7260 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8833 Model_1_val:0.5608 Model_2_val:0.5659
Epoch: 0140 Model_1_loss: 0.5849 Model_2_loss: 0.6119 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9083 Model_1_val:0.5656 Model_2_val:0.5844
Epoch: 0160 Model_1_loss: 0.5024 Model_2_loss: 0.5351 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5888 Model_2_val:0.5915
Epoch: 0180 Model_1_loss: 0.4713 Model_2_loss: 0.4574 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.5807 Model_2_val:0.6057
Epoch: 0200 Model_1_loss: 0.4688 Model_2_loss: 0.4719 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9250 Model_1_val:0.5780 Model_2_val:0.5969
Epoch: 0220 Model_1_loss: 0.7394 Model_2_loss: 0.7592 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6505 Model_2_val:0.6522
Epoch: 0240 Model_1_loss: 0.6778 Model_2_loss: 0.6708 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6367 Model_2_val:0.6502
Epoch: 0260 Model_1_loss: 0.6645 Model_2_loss: 0.6360 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.6397 Model_2_val:0.6576
Epoch: 0280 Model_1_loss: 0.5994 Model_2_loss: 0.6002 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6582 Model_2_val:0.6545
Epoch: 0300 Model_1_loss: 0.6387 Model_2_loss: 0.5698 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.6515 Model_2_val:0.6650
Epoch: 0320 Model_1_loss: 0.5660 Model_2_loss: 0.5481 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6613 Model_2_val:0.6535
Epoch: 0340 Model_1_loss: 0.5888 Model_2_loss: 0.4638 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6502 Model_2_val:0.6653
Epoch: 0360 Model_1_loss: 0.5046 Model_2_loss: 0.5228 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6613 Model_2_val:0.6626
Epoch: 0380 Model_1_loss: 0.4836 Model_2_loss: 0.4973 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6593 Model_2_val:0.6663
Epoch: 0400 Model_1_loss: 0.4773 Model_2_loss: 0.4801 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6653 Model_2_val:0.6495
Model_one_test:0.6781 Model_two_test:0.6842
added by two output: 0.6822
6
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
287547533
Epoch: 0020 Model_1_loss: 1.6946 Model_2_loss: 1.7599 Model_1_trainacc: 0.4417 Model_2_trainacc: 0.3250 Model_1_val:0.2861 Model_2_val:0.2139
Epoch: 0040 Model_1_loss: 1.4897 Model_2_loss: 1.6536 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.6417 Model_1_val:0.4702 Model_2_val:0.4017
Epoch: 0060 Model_1_loss: 1.1890 Model_2_loss: 1.3630 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8750 Model_1_val:0.5195 Model_2_val:0.5169
Epoch: 0080 Model_1_loss: 0.8999 Model_2_loss: 1.0323 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8917 Model_1_val:0.5401 Model_2_val:0.5576
Epoch: 0100 Model_1_loss: 0.6817 Model_2_loss: 0.7540 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9333 Model_1_val:0.5762 Model_2_val:0.5795
Epoch: 0120 Model_1_loss: 0.5784 Model_2_loss: 0.6328 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.5762 Model_2_val:0.5983
Epoch: 0140 Model_1_loss: 0.4900 Model_2_loss: 0.5507 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9333 Model_1_val:0.5791 Model_2_val:0.5901
Epoch: 0160 Model_1_loss: 0.4616 Model_2_loss: 0.4846 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.5940 Model_2_val:0.6053
Epoch: 0180 Model_1_loss: 0.4282 Model_2_loss: 0.4046 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.6113 Model_2_val:0.6013
Epoch: 0200 Model_1_loss: 0.3766 Model_2_loss: 0.3665 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.5944 Model_2_val:0.6050
Epoch: 0220 Model_1_loss: 0.6862 Model_2_loss: 0.7148 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6523 Model_2_val:0.6699
Epoch: 0240 Model_1_loss: 0.6944 Model_2_loss: 0.6914 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6702 Model_2_val:0.6765
Epoch: 0260 Model_1_loss: 0.6146 Model_2_loss: 0.6289 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6695 Model_2_val:0.6639
Epoch: 0280 Model_1_loss: 0.5664 Model_2_loss: 0.5830 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6831 Model_2_val:0.6755
Epoch: 0300 Model_1_loss: 0.5097 Model_2_loss: 0.5484 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6758 Model_2_val:0.6808
Epoch: 0320 Model_1_loss: 0.5076 Model_2_loss: 0.5587 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6606 Model_2_val:0.6589
Epoch: 0340 Model_1_loss: 0.5130 Model_2_loss: 0.4615 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6692 Model_2_val:0.6695
Epoch: 0360 Model_1_loss: 0.5248 Model_2_loss: 0.4821 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6639 Model_2_val:0.6632
Epoch: 0380 Model_1_loss: 0.4491 Model_2_loss: 0.4785 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6576 Model_2_val:0.6765
Epoch: 0400 Model_1_loss: 0.4790 Model_2_loss: 0.5194 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6649 Model_2_val:0.6632
Model_one_test:0.6838 Model_two_test:0.6891
added by two output: 0.6854
7
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
371753607
Epoch: 0020 Model_1_loss: 1.7348 Model_2_loss: 1.7323 Model_1_trainacc: 0.5000 Model_2_trainacc: 0.4083 Model_1_val:0.3183 Model_2_val:0.2574
Epoch: 0040 Model_1_loss: 1.5949 Model_2_loss: 1.5358 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7833 Model_1_val:0.4361 Model_2_val:0.4194
Epoch: 0060 Model_1_loss: 1.3066 Model_2_loss: 1.2099 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.9000 Model_1_val:0.4730 Model_2_val:0.5115
Epoch: 0080 Model_1_loss: 0.9870 Model_2_loss: 0.9656 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8667 Model_1_val:0.5257 Model_2_val:0.5467
Epoch: 0100 Model_1_loss: 0.7919 Model_2_loss: 0.7331 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9083 Model_1_val:0.5178 Model_2_val:0.5504
Epoch: 0120 Model_1_loss: 0.6534 Model_2_loss: 0.6191 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5444 Model_2_val:0.5602
Epoch: 0140 Model_1_loss: 0.5726 Model_2_loss: 0.5747 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9000 Model_1_val:0.5652 Model_2_val:0.5658
Epoch: 0160 Model_1_loss: 0.4745 Model_2_loss: 0.5036 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5869 Model_2_val:0.5737
Epoch: 0180 Model_1_loss: 0.4607 Model_2_loss: 0.4542 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5899 Model_2_val:0.5833
Epoch: 0200 Model_1_loss: 0.4235 Model_2_loss: 0.4632 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.5813 Model_2_val:0.5843
Epoch: 0220 Model_1_loss: 0.7309 Model_2_loss: 0.6988 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6320 Model_2_val:0.6429
Epoch: 0240 Model_1_loss: 0.6779 Model_2_loss: 0.6835 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6448 Model_2_val:0.6478
Epoch: 0260 Model_1_loss: 0.6158 Model_2_loss: 0.7168 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6271 Model_2_val:0.6412
Epoch: 0280 Model_1_loss: 0.5609 Model_2_loss: 0.5967 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6406 Model_2_val:0.6442
Epoch: 0300 Model_1_loss: 0.5463 Model_2_loss: 0.5745 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6429 Model_2_val:0.6356
Epoch: 0320 Model_1_loss: 0.5226 Model_2_loss: 0.5433 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6363 Model_2_val:0.6544
Epoch: 0340 Model_1_loss: 0.5691 Model_2_loss: 0.5653 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6346 Model_2_val:0.6359
Epoch: 0360 Model_1_loss: 0.4905 Model_2_loss: 0.5706 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.6406 Model_2_val:0.6448
Epoch: 0380 Model_1_loss: 0.4852 Model_2_loss: 0.5465 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9417 Model_1_val:0.6412 Model_2_val:0.6491
Epoch: 0400 Model_1_loss: 0.4604 Model_2_loss: 0.5394 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6527 Model_2_val:0.6468
Model_one_test:0.6646 Model_two_test:0.6685
added by two output: 0.6652
8
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
599714321
Epoch: 0020 Model_1_loss: 1.7042 Model_2_loss: 1.7225 Model_1_trainacc: 0.4500 Model_2_trainacc: 0.4167 Model_1_val:0.2070 Model_2_val:0.3173
Epoch: 0040 Model_1_loss: 1.5136 Model_2_loss: 1.5211 Model_1_trainacc: 0.7000 Model_2_trainacc: 0.7333 Model_1_val:0.4332 Model_2_val:0.4364
Epoch: 0060 Model_1_loss: 1.1806 Model_2_loss: 1.1936 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8250 Model_1_val:0.5104 Model_2_val:0.4925
Epoch: 0080 Model_1_loss: 0.9016 Model_2_loss: 0.9178 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8750 Model_1_val:0.5594 Model_2_val:0.5571
Epoch: 0100 Model_1_loss: 0.6979 Model_2_loss: 0.7597 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9083 Model_1_val:0.5805 Model_2_val:0.5591
Epoch: 0120 Model_1_loss: 0.6297 Model_2_loss: 0.6399 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9000 Model_1_val:0.6022 Model_2_val:0.5685
Epoch: 0140 Model_1_loss: 0.5617 Model_2_loss: 0.6062 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9167 Model_1_val:0.6025 Model_2_val:0.5772
Epoch: 0160 Model_1_loss: 0.4589 Model_2_loss: 0.5101 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.6129 Model_2_val:0.6025
Epoch: 0180 Model_1_loss: 0.4427 Model_2_loss: 0.4772 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.5993 Model_2_val:0.5951
Epoch: 0200 Model_1_loss: 0.4186 Model_2_loss: 0.4300 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9333 Model_1_val:0.6129 Model_2_val:0.5983
Epoch: 0220 Model_1_loss: 0.7587 Model_2_loss: 0.8086 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6658 Model_2_val:0.6593
Epoch: 0240 Model_1_loss: 0.6588 Model_2_loss: 0.7027 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6655 Model_2_val:0.6616
Epoch: 0260 Model_1_loss: 0.6609 Model_2_loss: 0.6696 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6726 Model_2_val:0.6655
Epoch: 0280 Model_1_loss: 0.5964 Model_2_loss: 0.6170 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6616 Model_2_val:0.6525
Epoch: 0300 Model_1_loss: 0.5865 Model_2_loss: 0.5890 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6684 Model_2_val:0.6626
Epoch: 0320 Model_1_loss: 0.5319 Model_2_loss: 0.6032 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6661 Model_2_val:0.6629
Epoch: 0340 Model_1_loss: 0.4945 Model_2_loss: 0.5467 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6697 Model_2_val:0.6694
Epoch: 0360 Model_1_loss: 0.5406 Model_2_loss: 0.5441 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6593 Model_2_val:0.6574
Epoch: 0380 Model_1_loss: 0.4793 Model_2_loss: 0.5030 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6729 Model_2_val:0.6551
Epoch: 0400 Model_1_loss: 0.5261 Model_2_loss: 0.5030 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9750 Model_1_val:0.6716 Model_2_val:0.6522
Model_one_test:0.6788 Model_two_test:0.6853
added by two output: 0.6836
9
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1255693446
Epoch: 0020 Model_1_loss: 1.7163 Model_2_loss: 1.7263 Model_1_trainacc: 0.4250 Model_2_trainacc: 0.3750 Model_1_val:0.3197 Model_2_val:0.2338
Epoch: 0040 Model_1_loss: 1.5128 Model_2_loss: 1.5405 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.6167 Model_1_val:0.4335 Model_2_val:0.3964
Epoch: 0060 Model_1_loss: 1.3048 Model_2_loss: 1.2235 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.8833 Model_1_val:0.4628 Model_2_val:0.4933
Epoch: 0080 Model_1_loss: 0.9875 Model_2_loss: 0.9553 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9250 Model_1_val:0.5161 Model_2_val:0.5294
Epoch: 0100 Model_1_loss: 0.8170 Model_2_loss: 0.7086 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9417 Model_1_val:0.5102 Model_2_val:0.5372
Epoch: 0120 Model_1_loss: 0.6995 Model_2_loss: 0.6453 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.5528 Model_2_val:0.5522
Epoch: 0140 Model_1_loss: 0.5599 Model_2_loss: 0.5993 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.5486 Model_2_val:0.5613
Epoch: 0160 Model_1_loss: 0.5311 Model_2_loss: 0.5417 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9333 Model_1_val:0.5655 Model_2_val:0.5880
Epoch: 0180 Model_1_loss: 0.4929 Model_2_loss: 0.4056 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5597 Model_2_val:0.5665
Epoch: 0200 Model_1_loss: 0.4483 Model_2_loss: 0.3906 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.5763 Model_2_val:0.5844
Epoch: 0220 Model_1_loss: 0.8008 Model_2_loss: 0.7941 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.6426 Model_2_val:0.6491
Epoch: 0240 Model_1_loss: 0.7610 Model_2_loss: 0.6977 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6543 Model_2_val:0.6706
Epoch: 0260 Model_1_loss: 0.6314 Model_2_loss: 0.6983 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6618 Model_2_val:0.6663
Epoch: 0280 Model_1_loss: 0.6604 Model_2_loss: 0.6185 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6605 Model_2_val:0.6741
Epoch: 0300 Model_1_loss: 0.6401 Model_2_loss: 0.6011 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6598 Model_2_val:0.6715
Epoch: 0320 Model_1_loss: 0.5737 Model_2_loss: 0.5561 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6546 Model_2_val:0.6725
Epoch: 0340 Model_1_loss: 0.5289 Model_2_loss: 0.5384 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6611 Model_2_val:0.6722
Epoch: 0360 Model_1_loss: 0.5557 Model_2_loss: 0.5037 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6621 Model_2_val:0.6706
Epoch: 0380 Model_1_loss: 0.5191 Model_2_loss: 0.5215 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6657 Model_2_val:0.6663
Epoch: 0400 Model_1_loss: 0.4901 Model_2_loss: 0.4785 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6686 Model_2_val:0.6618
Model_one_test:0.6875 Model_two_test:0.6881
added by two output: 0.6865
10
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1019165782
Epoch: 0020 Model_1_loss: 1.7151 Model_2_loss: 1.7430 Model_1_trainacc: 0.5833 Model_2_trainacc: 0.3417 Model_1_val:0.3258 Model_2_val:0.1784
Epoch: 0040 Model_1_loss: 1.5400 Model_2_loss: 1.5776 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.6833 Model_1_val:0.3776 Model_2_val:0.4306
Epoch: 0060 Model_1_loss: 1.2434 Model_2_loss: 1.3026 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.7917 Model_1_val:0.4400 Model_2_val:0.4847
Epoch: 0080 Model_1_loss: 0.9820 Model_2_loss: 1.0186 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9083 Model_1_val:0.5032 Model_2_val:0.5284
Epoch: 0100 Model_1_loss: 0.7760 Model_2_loss: 0.8271 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9000 Model_1_val:0.5479 Model_2_val:0.5405
Epoch: 0120 Model_1_loss: 0.6820 Model_2_loss: 0.7559 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9083 Model_1_val:0.5653 Model_2_val:0.5502
Epoch: 0140 Model_1_loss: 0.5824 Model_2_loss: 0.6059 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9000 Model_1_val:0.5663 Model_2_val:0.5485
Epoch: 0160 Model_1_loss: 0.5569 Model_2_loss: 0.5247 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5781 Model_2_val:0.5821
Epoch: 0180 Model_1_loss: 0.4668 Model_2_loss: 0.5153 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.5596 Model_2_val:0.5660
Epoch: 0200 Model_1_loss: 0.3848 Model_2_loss: 0.4988 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9250 Model_1_val:0.5761 Model_2_val:0.5687
Epoch: 0220 Model_1_loss: 0.7944 Model_2_loss: 0.8214 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6523 Model_2_val:0.6409
Epoch: 0240 Model_1_loss: 0.7608 Model_2_loss: 0.7840 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9333 Model_1_val:0.6849 Model_2_val:0.6607
Epoch: 0260 Model_1_loss: 0.7043 Model_2_loss: 0.6977 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6698 Model_2_val:0.6698
Epoch: 0280 Model_1_loss: 0.6775 Model_2_loss: 0.6961 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6738 Model_2_val:0.6802
Epoch: 0300 Model_1_loss: 0.6452 Model_2_loss: 0.6644 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6708 Model_2_val:0.6802
Epoch: 0320 Model_1_loss: 0.5878 Model_2_loss: 0.6081 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6799 Model_2_val:0.6789
Epoch: 0340 Model_1_loss: 0.6064 Model_2_loss: 0.5907 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6832 Model_2_val:0.6772
Epoch: 0360 Model_1_loss: 0.5399 Model_2_loss: 0.5648 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6779 Model_2_val:0.6701
Epoch: 0380 Model_1_loss: 0.5194 Model_2_loss: 0.5656 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6732 Model_2_val:0.6732
Epoch: 0400 Model_1_loss: 0.4648 Model_2_loss: 0.4782 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6886 Model_2_val:0.6742
Model_one_test:0.7051 Model_two_test:0.7088
added by two output: 0.7084
11
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
673293719
Epoch: 0020 Model_1_loss: 1.7168 Model_2_loss: 1.7164 Model_1_trainacc: 0.4500 Model_2_trainacc: 0.4000 Model_1_val:0.2993 Model_2_val:0.2564
Epoch: 0040 Model_1_loss: 1.5444 Model_2_loss: 1.5668 Model_1_trainacc: 0.7250 Model_2_trainacc: 0.6583 Model_1_val:0.4235 Model_2_val:0.4111
Epoch: 0060 Model_1_loss: 1.2765 Model_2_loss: 1.3157 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8083 Model_1_val:0.4911 Model_2_val:0.4948
Epoch: 0080 Model_1_loss: 0.9627 Model_2_loss: 1.1276 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8500 Model_1_val:0.5142 Model_2_val:0.4998
Epoch: 0100 Model_1_loss: 0.7777 Model_2_loss: 0.8396 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8917 Model_1_val:0.5547 Model_2_val:0.5336
Epoch: 0120 Model_1_loss: 0.6956 Model_2_loss: 0.6902 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9250 Model_1_val:0.5792 Model_2_val:0.5604
Epoch: 0140 Model_1_loss: 0.6336 Model_2_loss: 0.5994 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9250 Model_1_val:0.5728 Model_2_val:0.5641
Epoch: 0160 Model_1_loss: 0.5023 Model_2_loss: 0.5080 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5832 Model_2_val:0.6009
Epoch: 0180 Model_1_loss: 0.4867 Model_2_loss: 0.4224 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5979 Model_2_val:0.6096
Epoch: 0200 Model_1_loss: 0.4141 Model_2_loss: 0.4290 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6237 Model_2_val:0.6106
Epoch: 0220 Model_1_loss: 0.7848 Model_2_loss: 0.7473 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6649 Model_2_val:0.6615
Epoch: 0240 Model_1_loss: 0.7235 Model_2_loss: 0.7330 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6515 Model_2_val:0.6682
Epoch: 0260 Model_1_loss: 0.6691 Model_2_loss: 0.6183 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6662 Model_2_val:0.6615
Epoch: 0280 Model_1_loss: 0.6197 Model_2_loss: 0.6561 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6743 Model_2_val:0.6736
Epoch: 0300 Model_1_loss: 0.5767 Model_2_loss: 0.5675 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6699 Model_2_val:0.6672
Epoch: 0320 Model_1_loss: 0.5534 Model_2_loss: 0.5516 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6716 Model_2_val:0.6726
Epoch: 0340 Model_1_loss: 0.5177 Model_2_loss: 0.5669 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6826 Model_2_val:0.6662
Epoch: 0360 Model_1_loss: 0.4665 Model_2_loss: 0.5626 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6810 Model_2_val:0.6666
Epoch: 0380 Model_1_loss: 0.4773 Model_2_loss: 0.5322 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6706 Model_2_val:0.6736
Epoch: 0400 Model_1_loss: 0.4351 Model_2_loss: 0.4843 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6769 Model_2_val:0.6652
Model_one_test:0.6970 Model_two_test:0.6970
added by two output: 0.6974
12
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
804357187
Epoch: 0020 Model_1_loss: 1.6624 Model_2_loss: 1.7355 Model_1_trainacc: 0.5333 Model_2_trainacc: 0.4750 Model_1_val:0.3264 Model_2_val:0.2454
Epoch: 0040 Model_1_loss: 1.4207 Model_2_loss: 1.5922 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.7500 Model_1_val:0.4790 Model_2_val:0.3671
Epoch: 0060 Model_1_loss: 1.1510 Model_2_loss: 1.3242 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8000 Model_1_val:0.5405 Model_2_val:0.4152
Epoch: 0080 Model_1_loss: 0.8423 Model_2_loss: 1.0344 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9083 Model_1_val:0.5698 Model_2_val:0.4884
Epoch: 0100 Model_1_loss: 0.6598 Model_2_loss: 0.7753 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5630 Model_2_val:0.5246
Epoch: 0120 Model_1_loss: 0.5323 Model_2_loss: 0.6497 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.5714 Model_2_val:0.5425
Epoch: 0140 Model_1_loss: 0.4636 Model_2_loss: 0.5369 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.5900 Model_2_val:0.5591
Epoch: 0160 Model_1_loss: 0.4200 Model_2_loss: 0.5210 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.5923 Model_2_val:0.5783
Epoch: 0180 Model_1_loss: 0.3872 Model_2_loss: 0.4267 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.5818 Model_2_val:0.5698
Epoch: 0200 Model_1_loss: 0.3762 Model_2_loss: 0.4185 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.5831 Model_2_val:0.5773
Epoch: 0220 Model_1_loss: 0.7000 Model_2_loss: 0.6774 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6482 Model_2_val:0.6616
Epoch: 0240 Model_1_loss: 0.6373 Model_2_loss: 0.6287 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6642 Model_2_val:0.6554
Epoch: 0260 Model_1_loss: 0.5982 Model_2_loss: 0.5727 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6707 Model_2_val:0.6700
Epoch: 0280 Model_1_loss: 0.5500 Model_2_loss: 0.5887 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6661 Model_2_val:0.6655
Epoch: 0300 Model_1_loss: 0.5655 Model_2_loss: 0.5506 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6590 Model_2_val:0.6664
Epoch: 0320 Model_1_loss: 0.5297 Model_2_loss: 0.4684 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6632 Model_2_val:0.6801
Epoch: 0340 Model_1_loss: 0.4966 Model_2_loss: 0.4641 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6694 Model_2_val:0.6648
Epoch: 0360 Model_1_loss: 0.5003 Model_2_loss: 0.4708 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6622 Model_2_val:0.6658
Epoch: 0380 Model_1_loss: 0.4567 Model_2_loss: 0.4728 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6609 Model_2_val:0.6697
Epoch: 0400 Model_1_loss: 0.4579 Model_2_loss: 0.4145 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6733 Model_2_val:0.6596
Model_one_test:0.6863 Model_two_test:0.6905
added by two output: 0.6886
13
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1081138222
Epoch: 0020 Model_1_loss: 1.7170 Model_2_loss: 1.7215 Model_1_trainacc: 0.3500 Model_2_trainacc: 0.4250 Model_1_val:0.2376 Model_2_val:0.2575
Epoch: 0040 Model_1_loss: 1.5501 Model_2_loss: 1.5447 Model_1_trainacc: 0.6167 Model_2_trainacc: 0.7167 Model_1_val:0.3799 Model_2_val:0.3985
Epoch: 0060 Model_1_loss: 1.2330 Model_2_loss: 1.2602 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8250 Model_1_val:0.4909 Model_2_val:0.4886
Epoch: 0080 Model_1_loss: 0.9284 Model_2_loss: 0.9774 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8833 Model_1_val:0.5323 Model_2_val:0.5062
Epoch: 0100 Model_1_loss: 0.7640 Model_2_loss: 0.7490 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.5418 Model_2_val:0.5522
Epoch: 0120 Model_1_loss: 0.6516 Model_2_loss: 0.6460 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.5751 Model_2_val:0.5728
Epoch: 0140 Model_1_loss: 0.5728 Model_2_loss: 0.5277 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9750 Model_1_val:0.5868 Model_2_val:0.5767
Epoch: 0160 Model_1_loss: 0.5017 Model_2_loss: 0.4772 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.5855 Model_2_val:0.5826
Epoch: 0180 Model_1_loss: 0.4522 Model_2_loss: 0.4514 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5917 Model_2_val:0.5816
Epoch: 0200 Model_1_loss: 0.4146 Model_2_loss: 0.4094 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5911 Model_2_val:0.5888
Epoch: 0220 Model_1_loss: 0.7605 Model_2_loss: 0.7204 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6443 Model_2_val:0.6407
Epoch: 0240 Model_1_loss: 0.6736 Model_2_loss: 0.6256 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6482 Model_2_val:0.6557
Epoch: 0260 Model_1_loss: 0.5981 Model_2_loss: 0.6117 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6413 Model_2_val:0.6599
Epoch: 0280 Model_1_loss: 0.5973 Model_2_loss: 0.6108 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6560 Model_2_val:0.6550
Epoch: 0300 Model_1_loss: 0.5595 Model_2_loss: 0.5660 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6537 Model_2_val:0.6554
Epoch: 0320 Model_1_loss: 0.4967 Model_2_loss: 0.5233 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6537 Model_2_val:0.6589
Epoch: 0340 Model_1_loss: 0.4986 Model_2_loss: 0.4854 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6550 Model_2_val:0.6488
Epoch: 0360 Model_1_loss: 0.4618 Model_2_loss: 0.4863 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6550 Model_2_val:0.6524
Epoch: 0380 Model_1_loss: 0.4606 Model_2_loss: 0.4281 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6583 Model_2_val:0.6563
Epoch: 0400 Model_1_loss: 0.4306 Model_2_loss: 0.4739 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6485 Model_2_val:0.6573
Model_one_test:0.6769 Model_two_test:0.6792
added by two output: 0.6779
14
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
863120287
Epoch: 0020 Model_1_loss: 1.7164 Model_2_loss: 1.7145 Model_1_trainacc: 0.3750 Model_2_trainacc: 0.4250 Model_1_val:0.2417 Model_2_val:0.2339
Epoch: 0040 Model_1_loss: 1.5239 Model_2_loss: 1.5248 Model_1_trainacc: 0.7000 Model_2_trainacc: 0.7917 Model_1_val:0.4160 Model_2_val:0.4062
Epoch: 0060 Model_1_loss: 1.1855 Model_2_loss: 1.2151 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8833 Model_1_val:0.4966 Model_2_val:0.4913
Epoch: 0080 Model_1_loss: 0.9346 Model_2_loss: 0.9400 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9000 Model_1_val:0.5306 Model_2_val:0.5427
Epoch: 0100 Model_1_loss: 0.7003 Model_2_loss: 0.7133 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.5434 Model_2_val:0.5817
Epoch: 0120 Model_1_loss: 0.5612 Model_2_loss: 0.6041 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9250 Model_1_val:0.5798 Model_2_val:0.5788
Epoch: 0140 Model_1_loss: 0.5052 Model_2_loss: 0.5403 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9417 Model_1_val:0.5889 Model_2_val:0.5873
Epoch: 0160 Model_1_loss: 0.4095 Model_2_loss: 0.4364 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.5899 Model_2_val:0.6014
Epoch: 0180 Model_1_loss: 0.4236 Model_2_loss: 0.3902 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.5997 Model_2_val:0.6083
Epoch: 0200 Model_1_loss: 0.3742 Model_2_loss: 0.3594 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6001 Model_2_val:0.6102
Epoch: 0220 Model_1_loss: 0.6595 Model_2_loss: 0.6173 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6482 Model_2_val:0.6636
Epoch: 0240 Model_1_loss: 0.6000 Model_2_loss: 0.5742 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6587 Model_2_val:0.6554
Epoch: 0260 Model_1_loss: 0.5490 Model_2_loss: 0.5247 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6594 Model_2_val:0.6718
Epoch: 0280 Model_1_loss: 0.5421 Model_2_loss: 0.5142 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6518 Model_2_val:0.6698
Epoch: 0300 Model_1_loss: 0.5031 Model_2_loss: 0.4795 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6603 Model_2_val:0.6666
Epoch: 0320 Model_1_loss: 0.4854 Model_2_loss: 0.4802 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6525 Model_2_val:0.6652
Epoch: 0340 Model_1_loss: 0.4785 Model_2_loss: 0.4050 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6603 Model_2_val:0.6652
Epoch: 0360 Model_1_loss: 0.4722 Model_2_loss: 0.4030 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6626 Model_2_val:0.6721
Epoch: 0380 Model_1_loss: 0.4252 Model_2_loss: 0.3879 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6715 Model_2_val:0.6689
Epoch: 0400 Model_1_loss: 0.3910 Model_2_loss: 0.3925 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6597 Model_2_val:0.6731
Model_one_test:0.6872 Model_two_test:0.6888
added by two output: 0.6869
15
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
439868659
Epoch: 0020 Model_1_loss: 1.6920 Model_2_loss: 1.7387 Model_1_trainacc: 0.5167 Model_2_trainacc: 0.2417 Model_1_val:0.3437 Model_2_val:0.1797
Epoch: 0040 Model_1_loss: 1.5233 Model_2_loss: 1.6130 Model_1_trainacc: 0.7083 Model_2_trainacc: 0.6750 Model_1_val:0.3981 Model_2_val:0.3564
Epoch: 0060 Model_1_loss: 1.2469 Model_2_loss: 1.3477 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8167 Model_1_val:0.4886 Model_2_val:0.4222
Epoch: 0080 Model_1_loss: 0.8954 Model_2_loss: 1.0673 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8417 Model_1_val:0.5407 Model_2_val:0.5194
Epoch: 0100 Model_1_loss: 0.7212 Model_2_loss: 0.8093 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8667 Model_1_val:0.5718 Model_2_val:0.5267
Epoch: 0120 Model_1_loss: 0.6539 Model_2_loss: 0.7237 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9167 Model_1_val:0.5805 Model_2_val:0.5645
Epoch: 0140 Model_1_loss: 0.5450 Model_2_loss: 0.6025 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5688 Model_2_val:0.5638
Epoch: 0160 Model_1_loss: 0.5009 Model_2_loss: 0.5110 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5828 Model_2_val:0.5842
Epoch: 0180 Model_1_loss: 0.4641 Model_2_loss: 0.5216 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9250 Model_1_val:0.5982 Model_2_val:0.5718
Epoch: 0200 Model_1_loss: 0.3897 Model_2_loss: 0.4585 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.6092 Model_2_val:0.5939
Epoch: 0220 Model_1_loss: 0.7434 Model_2_loss: 0.8661 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.6663 Model_2_val:0.6543
Epoch: 0240 Model_1_loss: 0.6968 Model_2_loss: 0.6985 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.6710 Model_2_val:0.6723
Epoch: 0260 Model_1_loss: 0.6279 Model_2_loss: 0.6994 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6740 Model_2_val:0.6687
Epoch: 0280 Model_1_loss: 0.6438 Model_2_loss: 0.6673 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6747 Model_2_val:0.6723
Epoch: 0300 Model_1_loss: 0.5918 Model_2_loss: 0.6519 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.6740 Model_2_val:0.6764
Epoch: 0320 Model_1_loss: 0.5809 Model_2_loss: 0.6484 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6787 Model_2_val:0.6713
Epoch: 0340 Model_1_loss: 0.5037 Model_2_loss: 0.5600 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6800 Model_2_val:0.6723
Epoch: 0360 Model_1_loss: 0.5386 Model_2_loss: 0.5571 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6830 Model_2_val:0.6764
Epoch: 0380 Model_1_loss: 0.4962 Model_2_loss: 0.5501 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6777 Model_2_val:0.6723
Epoch: 0400 Model_1_loss: 0.5010 Model_2_loss: 0.5159 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6780 Model_2_val:0.6713
Model_one_test:0.6987 Model_two_test:0.6977
added by two output: 0.7017
16
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
440535468
Epoch: 0020 Model_1_loss: 1.7350 Model_2_loss: 1.7090 Model_1_trainacc: 0.3417 Model_2_trainacc: 0.3333 Model_1_val:0.1890 Model_2_val:0.2629
Epoch: 0040 Model_1_loss: 1.5895 Model_2_loss: 1.5352 Model_1_trainacc: 0.7083 Model_2_trainacc: 0.7000 Model_1_val:0.3996 Model_2_val:0.4430
Epoch: 0060 Model_1_loss: 1.2433 Model_2_loss: 1.2188 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8750 Model_1_val:0.4739 Model_2_val:0.4956
Epoch: 0080 Model_1_loss: 0.9356 Model_2_loss: 0.9814 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9000 Model_1_val:0.5146 Model_2_val:0.5002
Epoch: 0100 Model_1_loss: 0.7298 Model_2_loss: 0.7880 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9000 Model_1_val:0.5389 Model_2_val:0.5340
Epoch: 0120 Model_1_loss: 0.6109 Model_2_loss: 0.6458 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9333 Model_1_val:0.5514 Model_2_val:0.5462
Epoch: 0140 Model_1_loss: 0.5093 Model_2_loss: 0.6061 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9250 Model_1_val:0.5748 Model_2_val:0.5518
Epoch: 0160 Model_1_loss: 0.4468 Model_2_loss: 0.5676 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.5685 Model_2_val:0.5491
Epoch: 0180 Model_1_loss: 0.4490 Model_2_loss: 0.4694 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.5734 Model_2_val:0.5718
Epoch: 0200 Model_1_loss: 0.3664 Model_2_loss: 0.4531 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.5771 Model_2_val:0.5685
Epoch: 0220 Model_1_loss: 0.7472 Model_2_loss: 0.8015 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6379 Model_2_val:0.6385
Epoch: 0240 Model_1_loss: 0.6640 Model_2_loss: 0.7037 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6507 Model_2_val:0.6556
Epoch: 0260 Model_1_loss: 0.6022 Model_2_loss: 0.6772 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6678 Model_2_val:0.6464
Epoch: 0280 Model_1_loss: 0.6075 Model_2_loss: 0.6245 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6523 Model_2_val:0.6503
Epoch: 0300 Model_1_loss: 0.5606 Model_2_loss: 0.5945 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6753 Model_2_val:0.6540
Epoch: 0320 Model_1_loss: 0.5050 Model_2_loss: 0.5212 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6664 Model_2_val:0.6691
Epoch: 0340 Model_1_loss: 0.5382 Model_2_loss: 0.5691 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6622 Model_2_val:0.6622
Epoch: 0360 Model_1_loss: 0.4883 Model_2_loss: 0.5282 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6661 Model_2_val:0.6586
Epoch: 0380 Model_1_loss: 0.4557 Model_2_loss: 0.4869 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6710 Model_2_val:0.6533
Epoch: 0400 Model_1_loss: 0.4753 Model_2_loss: 0.4597 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6691 Model_2_val:0.6645
Model_one_test:0.6914 Model_two_test:0.6914
added by two output: 0.6918
17
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
69752506
Epoch: 0020 Model_1_loss: 1.6921 Model_2_loss: 1.7180 Model_1_trainacc: 0.5417 Model_2_trainacc: 0.4250 Model_1_val:0.2426 Model_2_val:0.3156
Epoch: 0040 Model_1_loss: 1.4064 Model_2_loss: 1.5567 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.7250 Model_1_val:0.4560 Model_2_val:0.4739
Epoch: 0060 Model_1_loss: 1.0704 Model_2_loss: 1.2936 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8000 Model_1_val:0.5221 Model_2_val:0.5091
Epoch: 0080 Model_1_loss: 0.8560 Model_2_loss: 1.0281 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8833 Model_1_val:0.5516 Model_2_val:0.5247
Epoch: 0100 Model_1_loss: 0.6975 Model_2_loss: 0.8460 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8750 Model_1_val:0.5782 Model_2_val:0.5529
Epoch: 0120 Model_1_loss: 0.6002 Model_2_loss: 0.7169 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9417 Model_1_val:0.5808 Model_2_val:0.5586
Epoch: 0140 Model_1_loss: 0.4995 Model_2_loss: 0.6016 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9250 Model_1_val:0.6024 Model_2_val:0.5669
Epoch: 0160 Model_1_loss: 0.4987 Model_2_loss: 0.5379 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.6034 Model_2_val:0.5765
Epoch: 0180 Model_1_loss: 0.4389 Model_2_loss: 0.5079 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.6057 Model_2_val:0.5838
Epoch: 0200 Model_1_loss: 0.4357 Model_2_loss: 0.4141 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6067 Model_2_val:0.5974
Epoch: 0220 Model_1_loss: 0.7496 Model_2_loss: 0.7698 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6651 Model_2_val:0.6598
Epoch: 0240 Model_1_loss: 0.6754 Model_2_loss: 0.7211 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6890 Model_2_val:0.6761
Epoch: 0260 Model_1_loss: 0.6257 Model_2_loss: 0.7197 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.6860 Model_2_val:0.6721
Epoch: 0280 Model_1_loss: 0.5955 Model_2_loss: 0.6471 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6880 Model_2_val:0.6801
Epoch: 0300 Model_1_loss: 0.5574 Model_2_loss: 0.5558 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6757 Model_2_val:0.6847
Epoch: 0320 Model_1_loss: 0.5826 Model_2_loss: 0.5950 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6817 Model_2_val:0.6714
Epoch: 0340 Model_1_loss: 0.5536 Model_2_loss: 0.6057 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6817 Model_2_val:0.6731
Epoch: 0360 Model_1_loss: 0.5081 Model_2_loss: 0.5132 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6781 Model_2_val:0.6737
Epoch: 0380 Model_1_loss: 0.5063 Model_2_loss: 0.4982 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6711 Model_2_val:0.6774
Epoch: 0400 Model_1_loss: 0.5035 Model_2_loss: 0.4887 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6734 Model_2_val:0.6734
Model_one_test:0.7076 Model_two_test:0.7076
added by two output: 0.7073
18
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
298960446
Epoch: 0020 Model_1_loss: 1.7089 Model_2_loss: 1.6955 Model_1_trainacc: 0.3917 Model_2_trainacc: 0.4917 Model_1_val:0.2667 Model_2_val:0.2970
Epoch: 0040 Model_1_loss: 1.5320 Model_2_loss: 1.4450 Model_1_trainacc: 0.6750 Model_2_trainacc: 0.8583 Model_1_val:0.3745 Model_2_val:0.4591
Epoch: 0060 Model_1_loss: 1.2496 Model_2_loss: 1.1381 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8333 Model_1_val:0.4842 Model_2_val:0.4891
Epoch: 0080 Model_1_loss: 0.9867 Model_2_loss: 0.9017 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8917 Model_1_val:0.5067 Model_2_val:0.5389
Epoch: 0100 Model_1_loss: 0.7052 Model_2_loss: 0.7453 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8583 Model_1_val:0.5523 Model_2_val:0.5396
Epoch: 0120 Model_1_loss: 0.6580 Model_2_loss: 0.5947 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.5376 Model_2_val:0.5806
Epoch: 0140 Model_1_loss: 0.5628 Model_2_loss: 0.5728 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.5646 Model_2_val:0.5552
Epoch: 0160 Model_1_loss: 0.5724 Model_2_loss: 0.4968 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9583 Model_1_val:0.5571 Model_2_val:0.5767
Epoch: 0180 Model_1_loss: 0.4768 Model_2_loss: 0.3946 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5695 Model_2_val:0.5881
Epoch: 0200 Model_1_loss: 0.4049 Model_2_loss: 0.4225 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5734 Model_2_val:0.5838
Epoch: 0220 Model_1_loss: 0.7478 Model_2_loss: 0.7387 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6447 Model_2_val:0.6666
Epoch: 0240 Model_1_loss: 0.6735 Model_2_loss: 0.6812 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6509 Model_2_val:0.6633
Epoch: 0260 Model_1_loss: 0.6838 Model_2_loss: 0.6519 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.6617 Model_2_val:0.6594
Epoch: 0280 Model_1_loss: 0.6052 Model_2_loss: 0.6060 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6740 Model_2_val:0.6737
Epoch: 0300 Model_1_loss: 0.5560 Model_2_loss: 0.5280 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6653 Model_2_val:0.6688
Epoch: 0320 Model_1_loss: 0.6140 Model_2_loss: 0.5475 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6555 Model_2_val:0.6695
Epoch: 0340 Model_1_loss: 0.5447 Model_2_loss: 0.4870 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6718 Model_2_val:0.6669
Epoch: 0360 Model_1_loss: 0.5750 Model_2_loss: 0.5109 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6633 Model_2_val:0.6692
Epoch: 0380 Model_1_loss: 0.4950 Model_2_loss: 0.4948 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6724 Model_2_val:0.6646
Epoch: 0400 Model_1_loss: 0.4777 Model_2_loss: 0.4675 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6731 Model_2_val:0.6773
Model_one_test:0.6916 Model_two_test:0.6871
added by two output: 0.6897
19
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
148579665
Epoch: 0020 Model_1_loss: 1.6988 Model_2_loss: 1.7212 Model_1_trainacc: 0.6000 Model_2_trainacc: 0.3667 Model_1_val:0.3092 Model_2_val:0.2218
Epoch: 0040 Model_1_loss: 1.4635 Model_2_loss: 1.5239 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.6917 Model_1_val:0.4144 Model_2_val:0.3595
Epoch: 0060 Model_1_loss: 1.0978 Model_2_loss: 1.1830 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9167 Model_1_val:0.4767 Model_2_val:0.4864
Epoch: 0080 Model_1_loss: 0.8498 Model_2_loss: 0.8825 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5320 Model_2_val:0.5397
Epoch: 0100 Model_1_loss: 0.7087 Model_2_loss: 0.7032 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9167 Model_1_val:0.5534 Model_2_val:0.5534
Epoch: 0120 Model_1_loss: 0.5656 Model_2_loss: 0.5765 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.5591 Model_2_val:0.5621
Epoch: 0140 Model_1_loss: 0.4919 Model_2_loss: 0.5145 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.5896 Model_2_val:0.5755
Epoch: 0160 Model_1_loss: 0.3751 Model_2_loss: 0.4327 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.5762 Model_2_val:0.5742
Epoch: 0180 Model_1_loss: 0.4257 Model_2_loss: 0.3428 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.5876 Model_2_val:0.5608
Epoch: 0200 Model_1_loss: 0.3467 Model_2_loss: 0.3824 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.5869 Model_2_val:0.5605
Epoch: 0220 Model_1_loss: 0.6860 Model_2_loss: 0.6732 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6439 Model_2_val:0.6362
Epoch: 0240 Model_1_loss: 0.6446 Model_2_loss: 0.6147 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6405 Model_2_val:0.6446
Epoch: 0260 Model_1_loss: 0.5742 Model_2_loss: 0.5965 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6429 Model_2_val:0.6459
Epoch: 0280 Model_1_loss: 0.5451 Model_2_loss: 0.5362 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6486 Model_2_val:0.6446
Epoch: 0300 Model_1_loss: 0.5322 Model_2_loss: 0.5164 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6580 Model_2_val:0.6436
Epoch: 0320 Model_1_loss: 0.4992 Model_2_loss: 0.5017 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6469 Model_2_val:0.6456
Epoch: 0340 Model_1_loss: 0.4918 Model_2_loss: 0.4809 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6533 Model_2_val:0.6459
Epoch: 0360 Model_1_loss: 0.4460 Model_2_loss: 0.4287 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6583 Model_2_val:0.6486
Epoch: 0380 Model_1_loss: 0.4392 Model_2_loss: 0.4515 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6415 Model_2_val:0.6539
Epoch: 0400 Model_1_loss: 0.4490 Model_2_loss: 0.4283 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6446 Model_2_val:0.6466
Model_one_test:0.6707 Model_two_test:0.6704
added by two output: 0.6747
20
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
168322011
Epoch: 0020 Model_1_loss: 1.7210 Model_2_loss: 1.7398 Model_1_trainacc: 0.5167 Model_2_trainacc: 0.4167 Model_1_val:0.2525 Model_2_val:0.2575
Epoch: 0040 Model_1_loss: 1.5265 Model_2_loss: 1.5624 Model_1_trainacc: 0.7583 Model_2_trainacc: 0.8167 Model_1_val:0.3732 Model_2_val:0.4415
Epoch: 0060 Model_1_loss: 1.1788 Model_2_loss: 1.2191 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8417 Model_1_val:0.4779 Model_2_val:0.4699
Epoch: 0080 Model_1_loss: 0.8714 Model_2_loss: 0.8919 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9167 Model_1_val:0.5421 Model_2_val:0.5291
Epoch: 0100 Model_1_loss: 0.6812 Model_2_loss: 0.7425 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9167 Model_1_val:0.5789 Model_2_val:0.5615
Epoch: 0120 Model_1_loss: 0.5731 Model_2_loss: 0.6017 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9250 Model_1_val:0.6020 Model_2_val:0.5719
Epoch: 0140 Model_1_loss: 0.4672 Model_2_loss: 0.5316 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6033 Model_2_val:0.5823
Epoch: 0160 Model_1_loss: 0.3932 Model_2_loss: 0.4794 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6107 Model_2_val:0.5920
Epoch: 0180 Model_1_loss: 0.4268 Model_2_loss: 0.4167 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6070 Model_2_val:0.6094
Epoch: 0200 Model_1_loss: 0.3461 Model_2_loss: 0.3854 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6197 Model_2_val:0.6060
Epoch: 0220 Model_1_loss: 0.7276 Model_2_loss: 0.7356 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6686 Model_2_val:0.6545
Epoch: 0240 Model_1_loss: 0.6067 Model_2_loss: 0.6596 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6806 Model_2_val:0.6669
Epoch: 0260 Model_1_loss: 0.6144 Model_2_loss: 0.6071 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6696 Model_2_val:0.6753
Epoch: 0280 Model_1_loss: 0.5561 Model_2_loss: 0.6060 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6779 Model_2_val:0.6732
Epoch: 0300 Model_1_loss: 0.5488 Model_2_loss: 0.5700 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6766 Model_2_val:0.6719
Epoch: 0320 Model_1_loss: 0.5301 Model_2_loss: 0.5523 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6799 Model_2_val:0.6722
Epoch: 0340 Model_1_loss: 0.4683 Model_2_loss: 0.5292 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6756 Model_2_val:0.6749
Epoch: 0360 Model_1_loss: 0.5006 Model_2_loss: 0.4946 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6766 Model_2_val:0.6736
Epoch: 0380 Model_1_loss: 0.4281 Model_2_loss: 0.5017 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6719 Model_2_val:0.6689
Epoch: 0400 Model_1_loss: 0.4475 Model_2_loss: 0.4871 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6803 Model_2_val:0.6716
Model_one_test:0.6943 Model_two_test:0.6983
added by two output: 0.6970
21
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
599004294
Epoch: 0020 Model_1_loss: 1.7146 Model_2_loss: 1.6878 Model_1_trainacc: 0.3583 Model_2_trainacc: 0.4833 Model_1_val:0.2274 Model_2_val:0.2827
Epoch: 0040 Model_1_loss: 1.5491 Model_2_loss: 1.4631 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.7667 Model_1_val:0.3972 Model_2_val:0.4307
Epoch: 0060 Model_1_loss: 1.2572 Model_2_loss: 1.1397 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.8667 Model_1_val:0.4671 Model_2_val:0.4932
Epoch: 0080 Model_1_loss: 0.9309 Model_2_loss: 0.8954 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9167 Model_1_val:0.5104 Model_2_val:0.5151
Epoch: 0100 Model_1_loss: 0.8009 Model_2_loss: 0.7104 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9583 Model_1_val:0.5405 Model_2_val:0.5591
Epoch: 0120 Model_1_loss: 0.6586 Model_2_loss: 0.6004 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5601 Model_2_val:0.5607
Epoch: 0140 Model_1_loss: 0.5280 Model_2_loss: 0.5608 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.5727 Model_2_val:0.5614
Epoch: 0160 Model_1_loss: 0.4526 Model_2_loss: 0.4701 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.5475 Model_2_val:0.5670
Epoch: 0180 Model_1_loss: 0.4424 Model_2_loss: 0.4176 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.5554 Model_2_val:0.5760
Epoch: 0200 Model_1_loss: 0.3935 Model_2_loss: 0.3491 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.5803 Model_2_val:0.5962
Epoch: 0220 Model_1_loss: 0.7356 Model_2_loss: 0.6622 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6660 Model_2_val:0.6395
Epoch: 0240 Model_1_loss: 0.7137 Model_2_loss: 0.6443 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6501 Model_2_val:0.6567
Epoch: 0260 Model_1_loss: 0.6641 Model_2_loss: 0.5843 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6723 Model_2_val:0.6730
Epoch: 0280 Model_1_loss: 0.6347 Model_2_loss: 0.5466 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6696 Model_2_val:0.6663
Epoch: 0300 Model_1_loss: 0.5510 Model_2_loss: 0.5233 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6696 Model_2_val:0.6720
Epoch: 0320 Model_1_loss: 0.5561 Model_2_loss: 0.5014 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6710 Model_2_val:0.6703
Epoch: 0340 Model_1_loss: 0.5603 Model_2_loss: 0.5197 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6835 Model_2_val:0.6773
Epoch: 0360 Model_1_loss: 0.5433 Model_2_loss: 0.5187 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6736 Model_2_val:0.6845
Epoch: 0380 Model_1_loss: 0.4607 Model_2_loss: 0.4488 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6763 Model_2_val:0.6776
Epoch: 0400 Model_1_loss: 0.4592 Model_2_loss: 0.4575 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6779 Model_2_val:0.6826
Model_one_test:0.6994 Model_two_test:0.7011
added by two output: 0.7014
22
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
738237612
Epoch: 0020 Model_1_loss: 1.6548 Model_2_loss: 1.7234 Model_1_trainacc: 0.6167 Model_2_trainacc: 0.2833 Model_1_val:0.3448 Model_2_val:0.2164
Epoch: 0040 Model_1_loss: 1.3700 Model_2_loss: 1.5330 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.7833 Model_1_val:0.5184 Model_2_val:0.4767
Epoch: 0060 Model_1_loss: 1.0086 Model_2_loss: 1.2187 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.8917 Model_1_val:0.5527 Model_2_val:0.5928
Epoch: 0080 Model_1_loss: 0.7615 Model_2_loss: 0.9098 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9000 Model_1_val:0.5931 Model_2_val:0.5779
Epoch: 0100 Model_1_loss: 0.5689 Model_2_loss: 0.7096 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9417 Model_1_val:0.5980 Model_2_val:0.5915
Epoch: 0120 Model_1_loss: 0.5162 Model_2_loss: 0.5706 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6190 Model_2_val:0.5902
Epoch: 0140 Model_1_loss: 0.4487 Model_2_loss: 0.5148 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6216 Model_2_val:0.6074
Epoch: 0160 Model_1_loss: 0.4060 Model_2_loss: 0.4539 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6206 Model_2_val:0.6213
Epoch: 0180 Model_1_loss: 0.3666 Model_2_loss: 0.3692 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6245 Model_2_val:0.6009
Epoch: 0200 Model_1_loss: 0.3684 Model_2_loss: 0.3802 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6384 Model_2_val:0.6248
Epoch: 0220 Model_1_loss: 0.6407 Model_2_loss: 0.6418 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6876 Model_2_val:0.6679
Epoch: 0240 Model_1_loss: 0.5411 Model_2_loss: 0.6100 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6876 Model_2_val:0.6730
Epoch: 0260 Model_1_loss: 0.5378 Model_2_loss: 0.6008 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6847 Model_2_val:0.6659
Epoch: 0280 Model_1_loss: 0.5060 Model_2_loss: 0.5728 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6776 Model_2_val:0.6763
Epoch: 0300 Model_1_loss: 0.5089 Model_2_loss: 0.5152 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6776 Model_2_val:0.6876
Epoch: 0320 Model_1_loss: 0.4860 Model_2_loss: 0.5092 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6763 Model_2_val:0.6717
Epoch: 0340 Model_1_loss: 0.4616 Model_2_loss: 0.4955 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6818 Model_2_val:0.6772
Epoch: 0360 Model_1_loss: 0.4388 Model_2_loss: 0.4888 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6805 Model_2_val:0.6724
Epoch: 0380 Model_1_loss: 0.4227 Model_2_loss: 0.4078 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6801 Model_2_val:0.6840
Epoch: 0400 Model_1_loss: 0.4162 Model_2_loss: 0.4415 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6785 Model_2_val:0.6759
Model_one_test:0.7099 Model_two_test:0.7041
added by two output: 0.7063
23
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
924591364
Epoch: 0020 Model_1_loss: 1.7149 Model_2_loss: 1.7168 Model_1_trainacc: 0.4083 Model_2_trainacc: 0.4250 Model_1_val:0.2535 Model_2_val:0.2977
Epoch: 0040 Model_1_loss: 1.5348 Model_2_loss: 1.5206 Model_1_trainacc: 0.7583 Model_2_trainacc: 0.7250 Model_1_val:0.4349 Model_2_val:0.5012
Epoch: 0060 Model_1_loss: 1.2766 Model_2_loss: 1.2319 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8583 Model_1_val:0.4978 Model_2_val:0.5440
Epoch: 0080 Model_1_loss: 0.9856 Model_2_loss: 0.9286 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9417 Model_1_val:0.5274 Model_2_val:0.5668
Epoch: 0100 Model_1_loss: 0.7819 Model_2_loss: 0.6949 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.5518 Model_2_val:0.5793
Epoch: 0120 Model_1_loss: 0.6665 Model_2_loss: 0.6544 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.5790 Model_2_val:0.5844
Epoch: 0140 Model_1_loss: 0.5988 Model_2_loss: 0.5738 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9167 Model_1_val:0.5827 Model_2_val:0.5977
Epoch: 0160 Model_1_loss: 0.5426 Model_2_loss: 0.4659 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5912 Model_2_val:0.6041
Epoch: 0180 Model_1_loss: 0.4848 Model_2_loss: 0.4005 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5943 Model_2_val:0.6106
Epoch: 0200 Model_1_loss: 0.4210 Model_2_loss: 0.4259 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5906 Model_2_val:0.6198
Epoch: 0220 Model_1_loss: 0.7137 Model_2_loss: 0.7411 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6667 Model_2_val:0.6626
Epoch: 0240 Model_1_loss: 0.6829 Model_2_loss: 0.6068 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6721 Model_2_val:0.6721
Epoch: 0260 Model_1_loss: 0.6262 Model_2_loss: 0.6927 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6697 Model_2_val:0.6765
Epoch: 0280 Model_1_loss: 0.5960 Model_2_loss: 0.5843 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6792 Model_2_val:0.6633
Epoch: 0300 Model_1_loss: 0.5562 Model_2_loss: 0.5495 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6731 Model_2_val:0.6775
Epoch: 0320 Model_1_loss: 0.4896 Model_2_loss: 0.5226 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6731 Model_2_val:0.6667
Epoch: 0340 Model_1_loss: 0.4790 Model_2_loss: 0.4810 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6758 Model_2_val:0.6697
Epoch: 0360 Model_1_loss: 0.4804 Model_2_loss: 0.4989 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6731 Model_2_val:0.6653
Epoch: 0380 Model_1_loss: 0.5008 Model_2_loss: 0.4627 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6527 Model_2_val:0.6718
Epoch: 0400 Model_1_loss: 0.4471 Model_2_loss: 0.4615 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6707 Model_2_val:0.6718
Model_one_test:0.6888 Model_two_test:0.6881
added by two output: 0.6884
24
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
927758507
Epoch: 0020 Model_1_loss: 1.7243 Model_2_loss: 1.7249 Model_1_trainacc: 0.3750 Model_2_trainacc: 0.4167 Model_1_val:0.2868 Model_2_val:0.2605
Epoch: 0040 Model_1_loss: 1.5767 Model_2_loss: 1.5522 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.6750 Model_1_val:0.4527 Model_2_val:0.4497
Epoch: 0060 Model_1_loss: 1.3036 Model_2_loss: 1.2263 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8583 Model_1_val:0.4837 Model_2_val:0.5223
Epoch: 0080 Model_1_loss: 1.0303 Model_2_loss: 0.9243 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8667 Model_1_val:0.5167 Model_2_val:0.5453
Epoch: 0100 Model_1_loss: 0.8860 Model_2_loss: 0.7466 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8667 Model_1_val:0.5186 Model_2_val:0.5826
Epoch: 0120 Model_1_loss: 0.7574 Model_2_loss: 0.6399 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9500 Model_1_val:0.5549 Model_2_val:0.5767
Epoch: 0140 Model_1_loss: 0.6027 Model_2_loss: 0.5174 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9333 Model_1_val:0.5720 Model_2_val:0.5987
Epoch: 0160 Model_1_loss: 0.5169 Model_2_loss: 0.4374 Model_1_trainacc: 0.9583 Model_2_trainacc: 1.0000 Model_1_val:0.5790 Model_2_val:0.5938
Epoch: 0180 Model_1_loss: 0.4530 Model_2_loss: 0.4508 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5922 Model_2_val:0.5747
Epoch: 0200 Model_1_loss: 0.4126 Model_2_loss: 0.3935 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5823 Model_2_val:0.5905
Epoch: 0220 Model_1_loss: 0.7957 Model_2_loss: 0.7082 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.6502 Model_2_val:0.6466
Epoch: 0240 Model_1_loss: 0.6657 Model_2_loss: 0.6748 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6479 Model_2_val:0.6485
Epoch: 0260 Model_1_loss: 0.6095 Model_2_loss: 0.6252 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6499 Model_2_val:0.6489
Epoch: 0280 Model_1_loss: 0.6585 Model_2_loss: 0.6213 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6505 Model_2_val:0.6396
Epoch: 0300 Model_1_loss: 0.5436 Model_2_loss: 0.5409 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6531 Model_2_val:0.6383
Epoch: 0320 Model_1_loss: 0.5642 Model_2_loss: 0.5625 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6525 Model_2_val:0.6588
Epoch: 0340 Model_1_loss: 0.5295 Model_2_loss: 0.5277 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6611 Model_2_val:0.6413
Epoch: 0360 Model_1_loss: 0.4789 Model_2_loss: 0.5039 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6489 Model_2_val:0.6489
Epoch: 0380 Model_1_loss: 0.4772 Model_2_loss: 0.4871 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6446 Model_2_val:0.6522
Epoch: 0400 Model_1_loss: 0.5008 Model_2_loss: 0.4701 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6436 Model_2_val:0.6522
Model_one_test:0.6719 Model_two_test:0.6677
added by two output: 0.6703
25
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1207813382
Epoch: 0020 Model_1_loss: 1.7216 Model_2_loss: 1.6980 Model_1_trainacc: 0.4500 Model_2_trainacc: 0.3917 Model_1_val:0.2463 Model_2_val:0.3105
Epoch: 0040 Model_1_loss: 1.5503 Model_2_loss: 1.5086 Model_1_trainacc: 0.6750 Model_2_trainacc: 0.7000 Model_1_val:0.4308 Model_2_val:0.4350
Epoch: 0060 Model_1_loss: 1.2146 Model_2_loss: 1.2316 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8333 Model_1_val:0.5015 Model_2_val:0.5119
Epoch: 0080 Model_1_loss: 0.9460 Model_2_loss: 0.9456 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8833 Model_1_val:0.5438 Model_2_val:0.5428
Epoch: 0100 Model_1_loss: 0.6861 Model_2_loss: 0.8114 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.8917 Model_1_val:0.5347 Model_2_val:0.5458
Epoch: 0120 Model_1_loss: 0.6154 Model_2_loss: 0.6594 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.5621 Model_2_val:0.5725
Epoch: 0140 Model_1_loss: 0.5009 Model_2_loss: 0.5824 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9250 Model_1_val:0.5816 Model_2_val:0.5582
Epoch: 0160 Model_1_loss: 0.4964 Model_2_loss: 0.5593 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5852 Model_2_val:0.5650
Epoch: 0180 Model_1_loss: 0.4356 Model_2_loss: 0.4792 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9500 Model_1_val:0.5787 Model_2_val:0.5810
Epoch: 0200 Model_1_loss: 0.3709 Model_2_loss: 0.4571 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.5780 Model_2_val:0.5611
Epoch: 0220 Model_1_loss: 0.7559 Model_2_loss: 0.8522 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9250 Model_1_val:0.6403 Model_2_val:0.6439
Epoch: 0240 Model_1_loss: 0.7100 Model_2_loss: 0.7637 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6540 Model_2_val:0.6579
Epoch: 0260 Model_1_loss: 0.6107 Model_2_loss: 0.6647 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6706 Model_2_val:0.6595
Epoch: 0280 Model_1_loss: 0.6012 Model_2_loss: 0.6570 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6663 Model_2_val:0.6543
Epoch: 0300 Model_1_loss: 0.5812 Model_2_loss: 0.5716 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6650 Model_2_val:0.6628
Epoch: 0320 Model_1_loss: 0.5557 Model_2_loss: 0.5409 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6601 Model_2_val:0.6641
Epoch: 0340 Model_1_loss: 0.5337 Model_2_loss: 0.5916 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6514 Model_2_val:0.6618
Epoch: 0360 Model_1_loss: 0.5390 Model_2_loss: 0.5038 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6605 Model_2_val:0.6588
Epoch: 0380 Model_1_loss: 0.5158 Model_2_loss: 0.4666 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6572 Model_2_val:0.6686
Epoch: 0400 Model_1_loss: 0.4801 Model_2_loss: 0.4675 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6527 Model_2_val:0.6637
Model_one_test:0.6817 Model_two_test:0.6843
added by two output: 0.6833
26
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
600233106
Epoch: 0020 Model_1_loss: 1.6946 Model_2_loss: 1.7241 Model_1_trainacc: 0.5167 Model_2_trainacc: 0.4833 Model_1_val:0.3026 Model_2_val:0.2780
Epoch: 0040 Model_1_loss: 1.4365 Model_2_loss: 1.5730 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.6750 Model_1_val:0.4566 Model_2_val:0.4100
Epoch: 0060 Model_1_loss: 1.0852 Model_2_loss: 1.2579 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8417 Model_1_val:0.5217 Model_2_val:0.4877
Epoch: 0080 Model_1_loss: 0.7837 Model_2_loss: 0.9609 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9083 Model_1_val:0.5751 Model_2_val:0.5495
Epoch: 0100 Model_1_loss: 0.5990 Model_2_loss: 0.7005 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5822 Model_2_val:0.5951
Epoch: 0120 Model_1_loss: 0.5272 Model_2_loss: 0.6384 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6139 Model_2_val:0.6042
Epoch: 0140 Model_1_loss: 0.4760 Model_2_loss: 0.4997 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6172 Model_2_val:0.6204
Epoch: 0160 Model_1_loss: 0.4177 Model_2_loss: 0.4126 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6194 Model_2_val:0.6142
Epoch: 0180 Model_1_loss: 0.3930 Model_2_loss: 0.4569 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6146 Model_2_val:0.6123
Epoch: 0200 Model_1_loss: 0.3972 Model_2_loss: 0.3606 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9417 Model_1_val:0.6259 Model_2_val:0.6220
Epoch: 0220 Model_1_loss: 0.6733 Model_2_loss: 0.6807 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6780 Model_2_val:0.6803
Epoch: 0240 Model_1_loss: 0.5965 Model_2_loss: 0.6587 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6841 Model_2_val:0.6757
Epoch: 0260 Model_1_loss: 0.5590 Model_2_loss: 0.6151 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6816 Model_2_val:0.6786
Epoch: 0280 Model_1_loss: 0.5510 Model_2_loss: 0.5386 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6822 Model_2_val:0.6722
Epoch: 0300 Model_1_loss: 0.5025 Model_2_loss: 0.5185 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6647 Model_2_val:0.6686
Epoch: 0320 Model_1_loss: 0.5076 Model_2_loss: 0.5106 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6689 Model_2_val:0.6812
Epoch: 0340 Model_1_loss: 0.4781 Model_2_loss: 0.5054 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6790 Model_2_val:0.6722
Epoch: 0360 Model_1_loss: 0.4460 Model_2_loss: 0.4517 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6757 Model_2_val:0.6699
Epoch: 0380 Model_1_loss: 0.4185 Model_2_loss: 0.4199 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6786 Model_2_val:0.6764
Epoch: 0400 Model_1_loss: 0.3835 Model_2_loss: 0.4314 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6773 Model_2_val:0.6803
Model_one_test:0.6974 Model_two_test:0.6909
added by two output: 0.6955
27
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1313605564
Epoch: 0020 Model_1_loss: 1.7163 Model_2_loss: 1.7120 Model_1_trainacc: 0.4167 Model_2_trainacc: 0.4583 Model_1_val:0.2578 Model_2_val:0.2888
Epoch: 0040 Model_1_loss: 1.5063 Model_2_loss: 1.5106 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.7250 Model_1_val:0.4500 Model_2_val:0.3941
Epoch: 0060 Model_1_loss: 1.2032 Model_2_loss: 1.1988 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8250 Model_1_val:0.4837 Model_2_val:0.5003
Epoch: 0080 Model_1_loss: 0.8899 Model_2_loss: 0.8889 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8667 Model_1_val:0.5266 Model_2_val:0.5390
Epoch: 0100 Model_1_loss: 0.7493 Model_2_loss: 0.7532 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9000 Model_1_val:0.5526 Model_2_val:0.5576
Epoch: 0120 Model_1_loss: 0.6373 Model_2_loss: 0.6367 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5656 Model_2_val:0.5783
Epoch: 0140 Model_1_loss: 0.6209 Model_2_loss: 0.5628 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8833 Model_1_val:0.5753 Model_2_val:0.6029
Epoch: 0160 Model_1_loss: 0.5368 Model_2_loss: 0.4972 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.5730 Model_2_val:0.5989
Epoch: 0180 Model_1_loss: 0.4648 Model_2_loss: 0.4421 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5759 Model_2_val:0.6056
Epoch: 0200 Model_1_loss: 0.4919 Model_2_loss: 0.4256 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9417 Model_1_val:0.5806 Model_2_val:0.5936
Epoch: 0220 Model_1_loss: 0.8115 Model_2_loss: 0.7592 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9417 Model_1_val:0.6356 Model_2_val:0.6509
Epoch: 0240 Model_1_loss: 0.7279 Model_2_loss: 0.6861 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6312 Model_2_val:0.6426
Epoch: 0260 Model_1_loss: 0.6761 Model_2_loss: 0.7281 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.6462 Model_2_val:0.6512
Epoch: 0280 Model_1_loss: 0.6801 Model_2_loss: 0.6827 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.6492 Model_2_val:0.6499
Epoch: 0300 Model_1_loss: 0.6784 Model_2_loss: 0.6372 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9917 Model_1_val:0.6432 Model_2_val:0.6426
Epoch: 0320 Model_1_loss: 0.6341 Model_2_loss: 0.6161 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9250 Model_1_val:0.6446 Model_2_val:0.6522
Epoch: 0340 Model_1_loss: 0.5844 Model_2_loss: 0.5931 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6469 Model_2_val:0.6539
Epoch: 0360 Model_1_loss: 0.5698 Model_2_loss: 0.5622 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6479 Model_2_val:0.6479
Epoch: 0380 Model_1_loss: 0.5379 Model_2_loss: 0.5571 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6346 Model_2_val:0.6542
Epoch: 0400 Model_1_loss: 0.6117 Model_2_loss: 0.5349 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6489 Model_2_val:0.6546
Model_one_test:0.6769 Model_two_test:0.6772
added by two output: 0.6759
28
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1368054024
Epoch: 0020 Model_1_loss: 1.7208 Model_2_loss: 1.7349 Model_1_trainacc: 0.4250 Model_2_trainacc: 0.4250 Model_1_val:0.2651 Model_2_val:0.2984
Epoch: 0040 Model_1_loss: 1.5377 Model_2_loss: 1.5422 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7167 Model_1_val:0.3898 Model_2_val:0.3819
Epoch: 0060 Model_1_loss: 1.3211 Model_2_loss: 1.2318 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.9083 Model_1_val:0.4495 Model_2_val:0.5213
Epoch: 0080 Model_1_loss: 1.0075 Model_2_loss: 0.9302 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9167 Model_1_val:0.5052 Model_2_val:0.5491
Epoch: 0100 Model_1_loss: 0.7918 Model_2_loss: 0.7002 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9083 Model_1_val:0.5295 Model_2_val:0.5701
Epoch: 0120 Model_1_loss: 0.6901 Model_2_loss: 0.6258 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9417 Model_1_val:0.5742 Model_2_val:0.5903
Epoch: 0140 Model_1_loss: 0.6061 Model_2_loss: 0.5102 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.5828 Model_2_val:0.6068
Epoch: 0160 Model_1_loss: 0.5239 Model_2_loss: 0.4345 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9583 Model_1_val:0.5962 Model_2_val:0.6116
Epoch: 0180 Model_1_loss: 0.4492 Model_2_loss: 0.4511 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.5962 Model_2_val:0.6168
Epoch: 0200 Model_1_loss: 0.4418 Model_2_loss: 0.3523 Model_1_trainacc: 0.9583 Model_2_trainacc: 1.0000 Model_1_val:0.5917 Model_2_val:0.6284
Epoch: 0220 Model_1_loss: 0.7412 Model_2_loss: 0.7857 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6569 Model_2_val:0.6748
Epoch: 0240 Model_1_loss: 0.6740 Model_2_loss: 0.6882 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6672 Model_2_val:0.6920
Epoch: 0260 Model_1_loss: 0.6047 Model_2_loss: 0.5724 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6813 Model_2_val:0.6834
Epoch: 0280 Model_1_loss: 0.6078 Model_2_loss: 0.6141 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6817 Model_2_val:0.6909
Epoch: 0300 Model_1_loss: 0.5939 Model_2_loss: 0.5648 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6782 Model_2_val:0.6885
Epoch: 0320 Model_1_loss: 0.5986 Model_2_loss: 0.5296 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6851 Model_2_val:0.6872
Epoch: 0340 Model_1_loss: 0.5320 Model_2_loss: 0.5246 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6837 Model_2_val:0.6851
Epoch: 0360 Model_1_loss: 0.5139 Model_2_loss: 0.5123 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6848 Model_2_val:0.6834
Epoch: 0380 Model_1_loss: 0.5054 Model_2_loss: 0.4890 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6745 Model_2_val:0.6882
Epoch: 0400 Model_1_loss: 0.4902 Model_2_loss: 0.4459 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6868 Model_2_val:0.6830
Model_one_test:0.7088 Model_two_test:0.7105
added by two output: 0.7091
29
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1507985074
Epoch: 0020 Model_1_loss: 1.7199 Model_2_loss: 1.7194 Model_1_trainacc: 0.3833 Model_2_trainacc: 0.4667 Model_1_val:0.2435 Model_2_val:0.2689
Epoch: 0040 Model_1_loss: 1.5556 Model_2_loss: 1.5231 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.7750 Model_1_val:0.4266 Model_2_val:0.4341
Epoch: 0060 Model_1_loss: 1.2893 Model_2_loss: 1.2492 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8333 Model_1_val:0.5011 Model_2_val:0.5085
Epoch: 0080 Model_1_loss: 0.9485 Model_2_loss: 1.0030 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9167 Model_1_val:0.5559 Model_2_val:0.5579
Epoch: 0100 Model_1_loss: 0.6551 Model_2_loss: 0.7944 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9167 Model_1_val:0.5688 Model_2_val:0.5798
Epoch: 0120 Model_1_loss: 0.6127 Model_2_loss: 0.6879 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.6021 Model_2_val:0.5866
Epoch: 0140 Model_1_loss: 0.5085 Model_2_loss: 0.5901 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6069 Model_2_val:0.5956
Epoch: 0160 Model_1_loss: 0.4262 Model_2_loss: 0.5261 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6127 Model_2_val:0.5992
Epoch: 0180 Model_1_loss: 0.4135 Model_2_loss: 0.4293 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6185 Model_2_val:0.6056
Epoch: 0200 Model_1_loss: 0.3253 Model_2_loss: 0.4013 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6143 Model_2_val:0.6082
Epoch: 0220 Model_1_loss: 0.6757 Model_2_loss: 0.7175 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6717 Model_2_val:0.6704
Epoch: 0240 Model_1_loss: 0.5845 Model_2_loss: 0.6544 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6833 Model_2_val:0.6746
Epoch: 0260 Model_1_loss: 0.5627 Model_2_loss: 0.5908 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6853 Model_2_val:0.6833
Epoch: 0280 Model_1_loss: 0.5547 Model_2_loss: 0.5997 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6885 Model_2_val:0.6830
Epoch: 0300 Model_1_loss: 0.5344 Model_2_loss: 0.5686 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6891 Model_2_val:0.6798
Epoch: 0320 Model_1_loss: 0.4939 Model_2_loss: 0.5312 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6862 Model_2_val:0.6753
Epoch: 0340 Model_1_loss: 0.4494 Model_2_loss: 0.5084 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6862 Model_2_val:0.6882
Epoch: 0360 Model_1_loss: 0.4463 Model_2_loss: 0.5194 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6772 Model_2_val:0.6727
Epoch: 0380 Model_1_loss: 0.4414 Model_2_loss: 0.4653 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6898 Model_2_val:0.6785
Epoch: 0400 Model_1_loss: 0.4773 Model_2_loss: 0.4817 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6846 Model_2_val:0.6830
Model_one_test:0.7027 Model_two_test:0.7043
added by two output: 0.7043
30
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1475248933
Epoch: 0020 Model_1_loss: 1.7257 Model_2_loss: 1.7155 Model_1_trainacc: 0.3917 Model_2_trainacc: 0.5000 Model_1_val:0.1990 Model_2_val:0.3562
Epoch: 0040 Model_1_loss: 1.5686 Model_2_loss: 1.4921 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.7667 Model_1_val:0.3675 Model_2_val:0.4947
Epoch: 0060 Model_1_loss: 1.3212 Model_2_loss: 1.1280 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9000 Model_1_val:0.4481 Model_2_val:0.5301
Epoch: 0080 Model_1_loss: 0.9926 Model_2_loss: 0.8422 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9167 Model_1_val:0.5396 Model_2_val:0.5553
Epoch: 0100 Model_1_loss: 0.7996 Model_2_loss: 0.6715 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9583 Model_1_val:0.5335 Model_2_val:0.5777
Epoch: 0120 Model_1_loss: 0.6582 Model_2_loss: 0.5843 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.5726 Model_2_val:0.5781
Epoch: 0140 Model_1_loss: 0.5741 Model_2_loss: 0.4503 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9833 Model_1_val:0.5965 Model_2_val:0.5948
Epoch: 0160 Model_1_loss: 0.5609 Model_2_loss: 0.4409 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.5849 Model_2_val:0.5876
Epoch: 0180 Model_1_loss: 0.5037 Model_2_loss: 0.3971 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9917 Model_1_val:0.5774 Model_2_val:0.5951
Epoch: 0200 Model_1_loss: 0.3973 Model_2_loss: 0.3404 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6084 Model_2_val:0.5999
Epoch: 0220 Model_1_loss: 0.7177 Model_2_loss: 0.6737 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6536 Model_2_val:0.6632
Epoch: 0240 Model_1_loss: 0.7098 Model_2_loss: 0.6605 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6686 Model_2_val:0.6693
Epoch: 0260 Model_1_loss: 0.6075 Model_2_loss: 0.5925 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6662 Model_2_val:0.6597
Epoch: 0280 Model_1_loss: 0.6000 Model_2_loss: 0.5804 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.6727 Model_2_val:0.6774
Epoch: 0300 Model_1_loss: 0.6262 Model_2_loss: 0.5121 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6649 Model_2_val:0.6757
Epoch: 0320 Model_1_loss: 0.5706 Model_2_loss: 0.5307 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6730 Model_2_val:0.6842
Epoch: 0340 Model_1_loss: 0.5111 Model_2_loss: 0.4770 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6632 Model_2_val:0.6754
Epoch: 0360 Model_1_loss: 0.5306 Model_2_loss: 0.5016 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6768 Model_2_val:0.6754
Epoch: 0380 Model_1_loss: 0.5436 Model_2_loss: 0.4732 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6744 Model_2_val:0.6751
Epoch: 0400 Model_1_loss: 0.4792 Model_2_loss: 0.4353 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6737 Model_2_val:0.6832
Model_one_test:0.7060 Model_two_test:0.7064
added by two output: 0.7040
Model1 Acc: 0.690745 Model2 Acc: 0.691144
Maxacc Mean: 0.692309
[0.6924372651610259, 0.6927043179398544, 0.6923088360447857]
Maxacc of all experiments: 0.6927043179398544
1
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
49353024
Epoch: 0020 Model_1_loss: 1.6959 Model_2_loss: 1.6990 Model_1_trainacc: 0.6000 Model_2_trainacc: 0.4250 Model_1_val:0.3179 Model_2_val:0.2907
Epoch: 0040 Model_1_loss: 1.4793 Model_2_loss: 1.4500 Model_1_trainacc: 0.7083 Model_2_trainacc: 0.7583 Model_1_val:0.4411 Model_2_val:0.4375
Epoch: 0060 Model_1_loss: 1.1919 Model_2_loss: 1.1436 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8583 Model_1_val:0.4928 Model_2_val:0.5219
Epoch: 0080 Model_1_loss: 0.8932 Model_2_loss: 0.8298 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.5307 Model_2_val:0.5566
Epoch: 0100 Model_1_loss: 0.6880 Model_2_loss: 0.6886 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5530 Model_2_val:0.5772
Epoch: 0120 Model_1_loss: 0.6004 Model_2_loss: 0.6022 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9083 Model_1_val:0.5615 Model_2_val:0.5670
Epoch: 0140 Model_1_loss: 0.5588 Model_2_loss: 0.5128 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5687 Model_2_val:0.5713
Epoch: 0160 Model_1_loss: 0.4855 Model_2_loss: 0.4435 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.5824 Model_2_val:0.5935
Epoch: 0180 Model_1_loss: 0.4330 Model_2_loss: 0.4662 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5925 Model_2_val:0.5958
Epoch: 0200 Model_1_loss: 0.3534 Model_2_loss: 0.3550 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.5860 Model_2_val:0.5978
Epoch: 0220 Model_1_loss: 0.6670 Model_2_loss: 0.6759 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6625 Model_2_val:0.6491
Epoch: 0240 Model_1_loss: 0.5940 Model_2_loss: 0.6128 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6609 Model_2_val:0.6488
Epoch: 0260 Model_1_loss: 0.5476 Model_2_loss: 0.5879 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6707 Model_2_val:0.6553
Epoch: 0280 Model_1_loss: 0.5274 Model_2_loss: 0.5124 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6622 Model_2_val:0.6586
Epoch: 0300 Model_1_loss: 0.5061 Model_2_loss: 0.4875 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6714 Model_2_val:0.6602
Epoch: 0320 Model_1_loss: 0.4778 Model_2_loss: 0.4779 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6720 Model_2_val:0.6599
Epoch: 0340 Model_1_loss: 0.4608 Model_2_loss: 0.4825 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6638 Model_2_val:0.6570
Epoch: 0360 Model_1_loss: 0.4551 Model_2_loss: 0.4894 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6599 Model_2_val:0.6596
Epoch: 0380 Model_1_loss: 0.4324 Model_2_loss: 0.4311 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6661 Model_2_val:0.6606
Epoch: 0400 Model_1_loss: 0.4233 Model_2_loss: 0.4177 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6668 Model_2_val:0.6638
Model_one_test:0.6851 Model_two_test:0.6828
added by two output: 0.6854
2
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1403145989
Epoch: 0020 Model_1_loss: 1.7274 Model_2_loss: 1.7407 Model_1_trainacc: 0.4167 Model_2_trainacc: 0.4083 Model_1_val:0.2617 Model_2_val:0.3085
Epoch: 0040 Model_1_loss: 1.5512 Model_2_loss: 1.5626 Model_1_trainacc: 0.7083 Model_2_trainacc: 0.6667 Model_1_val:0.3819 Model_2_val:0.4478
Epoch: 0060 Model_1_loss: 1.2704 Model_2_loss: 1.2249 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8750 Model_1_val:0.4808 Model_2_val:0.5362
Epoch: 0080 Model_1_loss: 0.9442 Model_2_loss: 0.8685 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.5375 Model_2_val:0.5549
Epoch: 0100 Model_1_loss: 0.7481 Model_2_loss: 0.6434 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9417 Model_1_val:0.5680 Model_2_val:0.5860
Epoch: 0120 Model_1_loss: 0.6030 Model_2_loss: 0.5748 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.5821 Model_2_val:0.5837
Epoch: 0140 Model_1_loss: 0.4944 Model_2_loss: 0.4737 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5876 Model_2_val:0.5781
Epoch: 0160 Model_1_loss: 0.5100 Model_2_loss: 0.4666 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6010 Model_2_val:0.5912
Epoch: 0180 Model_1_loss: 0.4184 Model_2_loss: 0.4254 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5991 Model_2_val:0.5971
Epoch: 0200 Model_1_loss: 0.3546 Model_2_loss: 0.3812 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6030 Model_2_val:0.6001
Epoch: 0220 Model_1_loss: 0.6643 Model_2_loss: 0.7211 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6669 Model_2_val:0.6548
Epoch: 0240 Model_1_loss: 0.6251 Model_2_loss: 0.6313 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6803 Model_2_val:0.6692
Epoch: 0260 Model_1_loss: 0.5614 Model_2_loss: 0.5662 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6777 Model_2_val:0.6813
Epoch: 0280 Model_1_loss: 0.5686 Model_2_loss: 0.5828 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6823 Model_2_val:0.6715
Epoch: 0300 Model_1_loss: 0.5717 Model_2_loss: 0.5380 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6734 Model_2_val:0.6783
Epoch: 0320 Model_1_loss: 0.5020 Model_2_loss: 0.5331 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6820 Model_2_val:0.6747
Epoch: 0340 Model_1_loss: 0.4902 Model_2_loss: 0.5046 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6757 Model_2_val:0.6774
Epoch: 0360 Model_1_loss: 0.5263 Model_2_loss: 0.4957 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6698 Model_2_val:0.6813
Epoch: 0380 Model_1_loss: 0.5189 Model_2_loss: 0.4973 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6738 Model_2_val:0.6797
Epoch: 0400 Model_1_loss: 0.4907 Model_2_loss: 0.4590 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6764 Model_2_val:0.6793
Model_one_test:0.7000 Model_two_test:0.7003
added by two output: 0.6990
3
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1402801186
Epoch: 0020 Model_1_loss: 1.7251 Model_2_loss: 1.7338 Model_1_trainacc: 0.4083 Model_2_trainacc: 0.3667 Model_1_val:0.3058 Model_2_val:0.2068
Epoch: 0040 Model_1_loss: 1.5678 Model_2_loss: 1.5971 Model_1_trainacc: 0.6750 Model_2_trainacc: 0.7083 Model_1_val:0.3878 Model_2_val:0.3856
Epoch: 0060 Model_1_loss: 1.2935 Model_2_loss: 1.3369 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8000 Model_1_val:0.4972 Model_2_val:0.4814
Epoch: 0080 Model_1_loss: 0.9902 Model_2_loss: 1.0658 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8750 Model_1_val:0.5299 Model_2_val:0.5344
Epoch: 0100 Model_1_loss: 0.8105 Model_2_loss: 0.8176 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8917 Model_1_val:0.5539 Model_2_val:0.5712
Epoch: 0120 Model_1_loss: 0.6793 Model_2_loss: 0.7047 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9167 Model_1_val:0.5848 Model_2_val:0.5851
Epoch: 0140 Model_1_loss: 0.6158 Model_2_loss: 0.6284 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9167 Model_1_val:0.5965 Model_2_val:0.5996
Epoch: 0160 Model_1_loss: 0.5839 Model_2_loss: 0.5120 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9417 Model_1_val:0.5883 Model_2_val:0.6053
Epoch: 0180 Model_1_loss: 0.5065 Model_2_loss: 0.4979 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9250 Model_1_val:0.6050 Model_2_val:0.6009
Epoch: 0200 Model_1_loss: 0.4111 Model_2_loss: 0.4225 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.6006 Model_2_val:0.6107
Epoch: 0220 Model_1_loss: 0.7541 Model_2_loss: 0.8002 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.6724 Model_2_val:0.6740
Epoch: 0240 Model_1_loss: 0.6753 Model_2_loss: 0.7663 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9250 Model_1_val:0.6765 Model_2_val:0.6791
Epoch: 0260 Model_1_loss: 0.6529 Model_2_loss: 0.6948 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.6778 Model_2_val:0.6803
Epoch: 0280 Model_1_loss: 0.6066 Model_2_loss: 0.6415 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6813 Model_2_val:0.6806
Epoch: 0300 Model_1_loss: 0.6002 Model_2_loss: 0.6316 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.6810 Model_2_val:0.6639
Epoch: 0320 Model_1_loss: 0.5608 Model_2_loss: 0.6201 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6769 Model_2_val:0.6687
Epoch: 0340 Model_1_loss: 0.5873 Model_2_loss: 0.6376 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.6788 Model_2_val:0.6765
Epoch: 0360 Model_1_loss: 0.5755 Model_2_loss: 0.5582 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.6825 Model_2_val:0.6800
Epoch: 0380 Model_1_loss: 0.5818 Model_2_loss: 0.5736 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6803 Model_2_val:0.6898
Epoch: 0400 Model_1_loss: 0.5071 Model_2_loss: 0.5723 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9167 Model_1_val:0.6759 Model_2_val:0.6750
Model_one_test:0.7018 Model_two_test:0.6974
added by two output: 0.6999
4
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
704798412
Epoch: 0020 Model_1_loss: 1.7275 Model_2_loss: 1.7384 Model_1_trainacc: 0.3667 Model_2_trainacc: 0.6167 Model_1_val:0.2397 Model_2_val:0.4073
Epoch: 0040 Model_1_loss: 1.5617 Model_2_loss: 1.5911 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.7083 Model_1_val:0.3993 Model_2_val:0.4308
Epoch: 0060 Model_1_loss: 1.3299 Model_2_loss: 1.3263 Model_1_trainacc: 0.7583 Model_2_trainacc: 0.8000 Model_1_val:0.4790 Model_2_val:0.4774
Epoch: 0080 Model_1_loss: 1.0611 Model_2_loss: 1.0214 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8917 Model_1_val:0.4938 Model_2_val:0.5005
Epoch: 0100 Model_1_loss: 0.9033 Model_2_loss: 0.8949 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8667 Model_1_val:0.5216 Model_2_val:0.5337
Epoch: 0120 Model_1_loss: 0.7914 Model_2_loss: 0.7465 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8667 Model_1_val:0.5488 Model_2_val:0.5414
Epoch: 0140 Model_1_loss: 0.6759 Model_2_loss: 0.6635 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.5669 Model_2_val:0.5417
Epoch: 0160 Model_1_loss: 0.6101 Model_2_loss: 0.5976 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5592 Model_2_val:0.5722
Epoch: 0180 Model_1_loss: 0.5376 Model_2_loss: 0.5480 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9167 Model_1_val:0.5830 Model_2_val:0.5836
Epoch: 0200 Model_1_loss: 0.4661 Model_2_loss: 0.4528 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5873 Model_2_val:0.5914
Epoch: 0220 Model_1_loss: 0.8662 Model_2_loss: 0.8596 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.6517 Model_2_val:0.6554
Epoch: 0240 Model_1_loss: 0.8038 Model_2_loss: 0.7050 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6561 Model_2_val:0.6839
Epoch: 0260 Model_1_loss: 0.7587 Model_2_loss: 0.6566 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6668 Model_2_val:0.6685
Epoch: 0280 Model_1_loss: 0.7375 Model_2_loss: 0.6537 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.6711 Model_2_val:0.6862
Epoch: 0300 Model_1_loss: 0.7328 Model_2_loss: 0.6450 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6624 Model_2_val:0.6688
Epoch: 0320 Model_1_loss: 0.7033 Model_2_loss: 0.5380 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.6584 Model_2_val:0.6782
Epoch: 0340 Model_1_loss: 0.6472 Model_2_loss: 0.5722 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6628 Model_2_val:0.6799
Epoch: 0360 Model_1_loss: 0.6126 Model_2_loss: 0.5187 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6705 Model_2_val:0.6815
Epoch: 0380 Model_1_loss: 0.6188 Model_2_loss: 0.5353 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6711 Model_2_val:0.6725
Epoch: 0400 Model_1_loss: 0.5920 Model_2_loss: 0.5262 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6648 Model_2_val:0.6685
Model_one_test:0.6963 Model_two_test:0.7077
added by two output: 0.6966
5
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1093534340
Epoch: 0020 Model_1_loss: 1.7109 Model_2_loss: 1.7256 Model_1_trainacc: 0.4833 Model_2_trainacc: 0.3833 Model_1_val:0.2853 Model_2_val:0.2537
Epoch: 0040 Model_1_loss: 1.5253 Model_2_loss: 1.5365 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.7250 Model_1_val:0.4382 Model_2_val:0.4135
Epoch: 0060 Model_1_loss: 1.2484 Model_2_loss: 1.2113 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9000 Model_1_val:0.5183 Model_2_val:0.5002
Epoch: 0080 Model_1_loss: 0.9506 Model_2_loss: 1.0005 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8750 Model_1_val:0.5516 Model_2_val:0.5311
Epoch: 0100 Model_1_loss: 0.8121 Model_2_loss: 0.7533 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9333 Model_1_val:0.5921 Model_2_val:0.5634
Epoch: 0120 Model_1_loss: 0.6744 Model_2_loss: 0.7042 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9083 Model_1_val:0.5727 Model_2_val:0.5717
Epoch: 0140 Model_1_loss: 0.5678 Model_2_loss: 0.6247 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.5928 Model_2_val:0.5707
Epoch: 0160 Model_1_loss: 0.4752 Model_2_loss: 0.4744 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6115 Model_2_val:0.5786
Epoch: 0180 Model_1_loss: 0.4424 Model_2_loss: 0.4791 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6030 Model_2_val:0.5997
Epoch: 0200 Model_1_loss: 0.4119 Model_2_loss: 0.4381 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6135 Model_2_val:0.5944
Epoch: 0220 Model_1_loss: 0.7185 Model_2_loss: 0.7372 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6695 Model_2_val:0.6465
Epoch: 0240 Model_1_loss: 0.6984 Model_2_loss: 0.7101 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6636 Model_2_val:0.6563
Epoch: 0260 Model_1_loss: 0.6296 Model_2_loss: 0.6841 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6725 Model_2_val:0.6563
Epoch: 0280 Model_1_loss: 0.6003 Model_2_loss: 0.6204 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6643 Model_2_val:0.6619
Epoch: 0300 Model_1_loss: 0.5665 Model_2_loss: 0.5846 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6764 Model_2_val:0.6619
Epoch: 0320 Model_1_loss: 0.5622 Model_2_loss: 0.5588 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6639 Model_2_val:0.6583
Epoch: 0340 Model_1_loss: 0.5020 Model_2_loss: 0.5224 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6643 Model_2_val:0.6540
Epoch: 0360 Model_1_loss: 0.5063 Model_2_loss: 0.4924 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6741 Model_2_val:0.6596
Epoch: 0380 Model_1_loss: 0.5065 Model_2_loss: 0.4744 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6662 Model_2_val:0.6537
Epoch: 0400 Model_1_loss: 0.4945 Model_2_loss: 0.4746 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6692 Model_2_val:0.6652
Model_one_test:0.6890 Model_two_test:0.6906
added by two output: 0.6909
6
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1137888577
Epoch: 0020 Model_1_loss: 1.7187 Model_2_loss: 1.7458 Model_1_trainacc: 0.4750 Model_2_trainacc: 0.3583 Model_1_val:0.3005 Model_2_val:0.2434
Epoch: 0040 Model_1_loss: 1.5261 Model_2_loss: 1.5642 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7250 Model_1_val:0.4348 Model_2_val:0.4072
Epoch: 0060 Model_1_loss: 1.2150 Model_2_loss: 1.2526 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8083 Model_1_val:0.5113 Model_2_val:0.4688
Epoch: 0080 Model_1_loss: 0.9189 Model_2_loss: 0.9343 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9083 Model_1_val:0.5316 Model_2_val:0.5249
Epoch: 0100 Model_1_loss: 0.7350 Model_2_loss: 0.7391 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.5382 Model_2_val:0.5545
Epoch: 0120 Model_1_loss: 0.6348 Model_2_loss: 0.6420 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5545 Model_2_val:0.5525
Epoch: 0140 Model_1_loss: 0.5948 Model_2_loss: 0.5429 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5492 Model_2_val:0.5708
Epoch: 0160 Model_1_loss: 0.4902 Model_2_loss: 0.4988 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.5662 Model_2_val:0.5721
Epoch: 0180 Model_1_loss: 0.5097 Model_2_loss: 0.4430 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.5655 Model_2_val:0.5791
Epoch: 0200 Model_1_loss: 0.4948 Model_2_loss: 0.4168 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9583 Model_1_val:0.5751 Model_2_val:0.5898
Epoch: 0220 Model_1_loss: 0.7953 Model_2_loss: 0.7402 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9667 Model_1_val:0.6483 Model_2_val:0.6307
Epoch: 0240 Model_1_loss: 0.6889 Model_2_loss: 0.7307 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6496 Model_2_val:0.6386
Epoch: 0260 Model_1_loss: 0.6571 Model_2_loss: 0.6961 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6459 Model_2_val:0.6336
Epoch: 0280 Model_1_loss: 0.6139 Model_2_loss: 0.6918 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6426 Model_2_val:0.6466
Epoch: 0300 Model_1_loss: 0.5727 Model_2_loss: 0.5837 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6446 Model_2_val:0.6420
Epoch: 0320 Model_1_loss: 0.5949 Model_2_loss: 0.5857 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6476 Model_2_val:0.6499
Epoch: 0340 Model_1_loss: 0.5476 Model_2_loss: 0.6094 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6509 Model_2_val:0.6533
Epoch: 0360 Model_1_loss: 0.4878 Model_2_loss: 0.5629 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6572 Model_2_val:0.6410
Epoch: 0380 Model_1_loss: 0.4962 Model_2_loss: 0.4606 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6496 Model_2_val:0.6433
Epoch: 0400 Model_1_loss: 0.5512 Model_2_loss: 0.5107 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6479 Model_2_val:0.6453
Model_one_test:0.6772 Model_two_test:0.6679
added by two output: 0.6679
7
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1543335484
Epoch: 0020 Model_1_loss: 1.7173 Model_2_loss: 1.7148 Model_1_trainacc: 0.4750 Model_2_trainacc: 0.4250 Model_1_val:0.3072 Model_2_val:0.2692
Epoch: 0040 Model_1_loss: 1.5292 Model_2_loss: 1.5440 Model_1_trainacc: 0.7250 Model_2_trainacc: 0.6417 Model_1_val:0.4213 Model_2_val:0.4020
Epoch: 0060 Model_1_loss: 1.2260 Model_2_loss: 1.2810 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.7667 Model_1_val:0.5000 Model_2_val:0.4581
Epoch: 0080 Model_1_loss: 0.9577 Model_2_loss: 1.0788 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.7833 Model_1_val:0.5338 Model_2_val:0.4716
Epoch: 0100 Model_1_loss: 0.7476 Model_2_loss: 0.8761 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8917 Model_1_val:0.5548 Model_2_val:0.5029
Epoch: 0120 Model_1_loss: 0.6615 Model_2_loss: 0.7799 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8667 Model_1_val:0.5554 Model_2_val:0.5132
Epoch: 0140 Model_1_loss: 0.5867 Model_2_loss: 0.6804 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8667 Model_1_val:0.5732 Model_2_val:0.5271
Epoch: 0160 Model_1_loss: 0.5533 Model_2_loss: 0.6183 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9167 Model_1_val:0.5780 Model_2_val:0.5303
Epoch: 0180 Model_1_loss: 0.4960 Model_2_loss: 0.5614 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5819 Model_2_val:0.5245
Epoch: 0200 Model_1_loss: 0.4522 Model_2_loss: 0.5637 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.5783 Model_2_val:0.5529
Epoch: 0220 Model_1_loss: 0.7959 Model_2_loss: 0.8772 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9167 Model_1_val:0.6476 Model_2_val:0.6235
Epoch: 0240 Model_1_loss: 0.7274 Model_2_loss: 0.7996 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6615 Model_2_val:0.6457
Epoch: 0260 Model_1_loss: 0.6890 Model_2_loss: 0.7662 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6596 Model_2_val:0.6476
Epoch: 0280 Model_1_loss: 0.7023 Model_2_loss: 0.7273 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.6734 Model_2_val:0.6576
Epoch: 0300 Model_1_loss: 0.6523 Model_2_loss: 0.6926 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.6799 Model_2_val:0.6583
Epoch: 0320 Model_1_loss: 0.5826 Model_2_loss: 0.7154 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.6683 Model_2_val:0.6618
Epoch: 0340 Model_1_loss: 0.5845 Model_2_loss: 0.6464 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6718 Model_2_val:0.6599
Epoch: 0360 Model_1_loss: 0.6272 Model_2_loss: 0.5983 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.6731 Model_2_val:0.6673
Epoch: 0380 Model_1_loss: 0.5720 Model_2_loss: 0.6202 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.6728 Model_2_val:0.6615
Epoch: 0400 Model_1_loss: 0.5688 Model_2_loss: 0.6073 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6712 Model_2_val:0.6641
Model_one_test:0.6979 Model_two_test:0.6947
added by two output: 0.6937
8
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1014185432
Epoch: 0020 Model_1_loss: 1.7156 Model_2_loss: 1.6981 Model_1_trainacc: 0.5417 Model_2_trainacc: 0.5917 Model_1_val:0.3062 Model_2_val:0.3068
Epoch: 0040 Model_1_loss: 1.5336 Model_2_loss: 1.5063 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.7917 Model_1_val:0.4450 Model_2_val:0.4623
Epoch: 0060 Model_1_loss: 1.2278 Model_2_loss: 1.1979 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9250 Model_1_val:0.4971 Model_2_val:0.4961
Epoch: 0080 Model_1_loss: 0.8949 Model_2_loss: 0.9467 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9333 Model_1_val:0.5370 Model_2_val:0.5072
Epoch: 0100 Model_1_loss: 0.7373 Model_2_loss: 0.7612 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9000 Model_1_val:0.5678 Model_2_val:0.5380
Epoch: 0120 Model_1_loss: 0.5782 Model_2_loss: 0.5882 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.5475 Model_2_val:0.5219
Epoch: 0140 Model_1_loss: 0.5094 Model_2_loss: 0.5684 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.5619 Model_2_val:0.5458
Epoch: 0160 Model_1_loss: 0.4598 Model_2_loss: 0.5411 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.5825 Model_2_val:0.5524
Epoch: 0180 Model_1_loss: 0.4270 Model_2_loss: 0.4608 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.5825 Model_2_val:0.5576
Epoch: 0200 Model_1_loss: 0.4340 Model_2_loss: 0.4204 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5747 Model_2_val:0.5566
Epoch: 0220 Model_1_loss: 0.7076 Model_2_loss: 0.7854 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6487 Model_2_val:0.6395
Epoch: 0240 Model_1_loss: 0.7079 Model_2_loss: 0.6888 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6588 Model_2_val:0.6490
Epoch: 0260 Model_1_loss: 0.6588 Model_2_loss: 0.7067 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6591 Model_2_val:0.6506
Epoch: 0280 Model_1_loss: 0.6942 Model_2_loss: 0.6831 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6529 Model_2_val:0.6434
Epoch: 0300 Model_1_loss: 0.5871 Model_2_loss: 0.5801 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6634 Model_2_val:0.6657
Epoch: 0320 Model_1_loss: 0.5418 Model_2_loss: 0.5978 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6722 Model_2_val:0.6532
Epoch: 0340 Model_1_loss: 0.4944 Model_2_loss: 0.5362 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6663 Model_2_val:0.6621
Epoch: 0360 Model_1_loss: 0.4874 Model_2_loss: 0.5050 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6601 Model_2_val:0.6493
Epoch: 0380 Model_1_loss: 0.4549 Model_2_loss: 0.5002 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6680 Model_2_val:0.6428
Epoch: 0400 Model_1_loss: 0.4950 Model_2_loss: 0.4391 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6709 Model_2_val:0.6660
Model_one_test:0.6912 Model_two_test:0.6893
added by two output: 0.6886
9
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
146878119
Epoch: 0020 Model_1_loss: 1.7003 Model_2_loss: 1.7291 Model_1_trainacc: 0.5250 Model_2_trainacc: 0.4583 Model_1_val:0.2687 Model_2_val:0.2683
Epoch: 0040 Model_1_loss: 1.5123 Model_2_loss: 1.5583 Model_1_trainacc: 0.7583 Model_2_trainacc: 0.6583 Model_1_val:0.4397 Model_2_val:0.4206
Epoch: 0060 Model_1_loss: 1.1450 Model_2_loss: 1.2480 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8000 Model_1_val:0.5215 Model_2_val:0.4960
Epoch: 0080 Model_1_loss: 0.8617 Model_2_loss: 0.9455 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8833 Model_1_val:0.5438 Model_2_val:0.5341
Epoch: 0100 Model_1_loss: 0.6637 Model_2_loss: 0.8135 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8833 Model_1_val:0.5590 Model_2_val:0.5357
Epoch: 0120 Model_1_loss: 0.5531 Model_2_loss: 0.6460 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.5839 Model_2_val:0.5829
Epoch: 0140 Model_1_loss: 0.4810 Model_2_loss: 0.5745 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9250 Model_1_val:0.5706 Model_2_val:0.5778
Epoch: 0160 Model_1_loss: 0.4445 Model_2_loss: 0.5575 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.5936 Model_2_val:0.5978
Epoch: 0180 Model_1_loss: 0.4094 Model_2_loss: 0.4793 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6043 Model_2_val:0.5852
Epoch: 0200 Model_1_loss: 0.3809 Model_2_loss: 0.4048 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6075 Model_2_val:0.5807
Epoch: 0220 Model_1_loss: 0.7404 Model_2_loss: 0.8022 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6469 Model_2_val:0.6482
Epoch: 0240 Model_1_loss: 0.6788 Model_2_loss: 0.7211 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6683 Model_2_val:0.6547
Epoch: 0260 Model_1_loss: 0.6438 Model_2_loss: 0.7313 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6722 Model_2_val:0.6550
Epoch: 0280 Model_1_loss: 0.6670 Model_2_loss: 0.6523 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.6722 Model_2_val:0.6693
Epoch: 0300 Model_1_loss: 0.5867 Model_2_loss: 0.6151 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6631 Model_2_val:0.6660
Epoch: 0320 Model_1_loss: 0.5592 Model_2_loss: 0.6054 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6670 Model_2_val:0.6696
Epoch: 0340 Model_1_loss: 0.5391 Model_2_loss: 0.5884 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6712 Model_2_val:0.6770
Epoch: 0360 Model_1_loss: 0.5525 Model_2_loss: 0.5879 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6731 Model_2_val:0.6576
Epoch: 0380 Model_1_loss: 0.5344 Model_2_loss: 0.5689 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6777 Model_2_val:0.6715
Epoch: 0400 Model_1_loss: 0.4579 Model_2_loss: 0.5521 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6757 Model_2_val:0.6605
Model_one_test:0.6938 Model_two_test:0.6951
added by two output: 0.6948
10
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
515080117
Epoch: 0020 Model_1_loss: 1.7120 Model_2_loss: 1.7261 Model_1_trainacc: 0.6000 Model_2_trainacc: 0.4583 Model_1_val:0.2999 Model_2_val:0.2980
Epoch: 0040 Model_1_loss: 1.5371 Model_2_loss: 1.5193 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.8000 Model_1_val:0.4662 Model_2_val:0.4630
Epoch: 0060 Model_1_loss: 1.2462 Model_2_loss: 1.1970 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8750 Model_1_val:0.5071 Model_2_val:0.5303
Epoch: 0080 Model_1_loss: 0.8925 Model_2_loss: 0.9302 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9000 Model_1_val:0.5567 Model_2_val:0.5499
Epoch: 0100 Model_1_loss: 0.7046 Model_2_loss: 0.6866 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.5867 Model_2_val:0.5838
Epoch: 0120 Model_1_loss: 0.5697 Model_2_loss: 0.6743 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9333 Model_1_val:0.6037 Model_2_val:0.5950
Epoch: 0140 Model_1_loss: 0.4703 Model_2_loss: 0.5294 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9167 Model_1_val:0.6137 Model_2_val:0.5999
Epoch: 0160 Model_1_loss: 0.4548 Model_2_loss: 0.4479 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6137 Model_2_val:0.6140
Epoch: 0180 Model_1_loss: 0.4071 Model_2_loss: 0.3879 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6163 Model_2_val:0.6095
Epoch: 0200 Model_1_loss: 0.3771 Model_2_loss: 0.3827 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6053 Model_2_val:0.6095
Epoch: 0220 Model_1_loss: 0.6465 Model_2_loss: 0.6991 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6762 Model_2_val:0.6585
Epoch: 0240 Model_1_loss: 0.5914 Model_2_loss: 0.6363 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6727 Model_2_val:0.6714
Epoch: 0260 Model_1_loss: 0.5870 Model_2_loss: 0.6236 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6730 Model_2_val:0.6649
Epoch: 0280 Model_1_loss: 0.5725 Model_2_loss: 0.5924 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6836 Model_2_val:0.6778
Epoch: 0300 Model_1_loss: 0.5372 Model_2_loss: 0.5380 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6843 Model_2_val:0.6791
Epoch: 0320 Model_1_loss: 0.4980 Model_2_loss: 0.5405 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6736 Model_2_val:0.6775
Epoch: 0340 Model_1_loss: 0.5164 Model_2_loss: 0.5199 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6778 Model_2_val:0.6749
Epoch: 0360 Model_1_loss: 0.4718 Model_2_loss: 0.5170 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6727 Model_2_val:0.6688
Epoch: 0380 Model_1_loss: 0.4715 Model_2_loss: 0.5110 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6772 Model_2_val:0.6769
Epoch: 0400 Model_1_loss: 0.4366 Model_2_loss: 0.4528 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6817 Model_2_val:0.6736
Model_one_test:0.6959 Model_two_test:0.6991
added by two output: 0.6981
11
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1190611966
Epoch: 0020 Model_1_loss: 1.7026 Model_2_loss: 1.7268 Model_1_trainacc: 0.5083 Model_2_trainacc: 0.4833 Model_1_val:0.3220 Model_2_val:0.2593
Epoch: 0040 Model_1_loss: 1.4616 Model_2_loss: 1.5203 Model_1_trainacc: 0.7583 Model_2_trainacc: 0.7750 Model_1_val:0.4628 Model_2_val:0.4372
Epoch: 0060 Model_1_loss: 1.1668 Model_2_loss: 1.1940 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8500 Model_1_val:0.5254 Model_2_val:0.5189
Epoch: 0080 Model_1_loss: 0.8684 Model_2_loss: 0.8703 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9083 Model_1_val:0.5556 Model_2_val:0.5658
Epoch: 0100 Model_1_loss: 0.7044 Model_2_loss: 0.6720 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9167 Model_1_val:0.5655 Model_2_val:0.5783
Epoch: 0120 Model_1_loss: 0.5720 Model_2_loss: 0.5935 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5829 Model_2_val:0.5875
Epoch: 0140 Model_1_loss: 0.4757 Model_2_loss: 0.4672 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6009 Model_2_val:0.6095
Epoch: 0160 Model_1_loss: 0.4535 Model_2_loss: 0.4773 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6062 Model_2_val:0.6075
Epoch: 0180 Model_1_loss: 0.4044 Model_2_loss: 0.4643 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6124 Model_2_val:0.6134
Epoch: 0200 Model_1_loss: 0.3680 Model_2_loss: 0.4076 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6117 Model_2_val:0.6091
Epoch: 0220 Model_1_loss: 0.6503 Model_2_loss: 0.7143 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6636 Model_2_val:0.6672
Epoch: 0240 Model_1_loss: 0.6164 Model_2_loss: 0.6567 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6712 Model_2_val:0.6610
Epoch: 0260 Model_1_loss: 0.5850 Model_2_loss: 0.5690 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6692 Model_2_val:0.6672
Epoch: 0280 Model_1_loss: 0.5631 Model_2_loss: 0.5803 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6646 Model_2_val:0.6712
Epoch: 0300 Model_1_loss: 0.5438 Model_2_loss: 0.5642 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6751 Model_2_val:0.6692
Epoch: 0320 Model_1_loss: 0.4818 Model_2_loss: 0.5246 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6698 Model_2_val:0.6741
Epoch: 0340 Model_1_loss: 0.4502 Model_2_loss: 0.5259 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6734 Model_2_val:0.6616
Epoch: 0360 Model_1_loss: 0.4854 Model_2_loss: 0.4548 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6728 Model_2_val:0.6738
Epoch: 0380 Model_1_loss: 0.4379 Model_2_loss: 0.4609 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6689 Model_2_val:0.6613
Epoch: 0400 Model_1_loss: 0.4255 Model_2_loss: 0.4313 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6738 Model_2_val:0.6767
Model_one_test:0.6961 Model_two_test:0.6951
added by two output: 0.6945
12
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
477646943
Epoch: 0020 Model_1_loss: 1.7393 Model_2_loss: 1.7289 Model_1_trainacc: 0.4000 Model_2_trainacc: 0.3750 Model_1_val:0.2269 Model_2_val:0.2760
Epoch: 0040 Model_1_loss: 1.5835 Model_2_loss: 1.5242 Model_1_trainacc: 0.7000 Model_2_trainacc: 0.8083 Model_1_val:0.3638 Model_2_val:0.4096
Epoch: 0060 Model_1_loss: 1.3435 Model_2_loss: 1.2369 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8750 Model_1_val:0.4502 Model_2_val:0.4915
Epoch: 0080 Model_1_loss: 1.0365 Model_2_loss: 0.8876 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9167 Model_1_val:0.4954 Model_2_val:0.5085
Epoch: 0100 Model_1_loss: 0.8319 Model_2_loss: 0.7009 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9500 Model_1_val:0.5062 Model_2_val:0.5455
Epoch: 0120 Model_1_loss: 0.7087 Model_2_loss: 0.5318 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9583 Model_1_val:0.5154 Model_2_val:0.5458
Epoch: 0140 Model_1_loss: 0.5730 Model_2_loss: 0.4770 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.5426 Model_2_val:0.5711
Epoch: 0160 Model_1_loss: 0.5502 Model_2_loss: 0.4075 Model_1_trainacc: 0.9083 Model_2_trainacc: 1.0000 Model_1_val:0.5367 Model_2_val:0.5655
Epoch: 0180 Model_1_loss: 0.4407 Model_2_loss: 0.3780 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.5445 Model_2_val:0.5629
Epoch: 0200 Model_1_loss: 0.4319 Model_2_loss: 0.3908 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9833 Model_1_val:0.5616 Model_2_val:0.5874
Epoch: 0220 Model_1_loss: 0.7599 Model_2_loss: 0.7463 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6189 Model_2_val:0.6398
Epoch: 0240 Model_1_loss: 0.6959 Model_2_loss: 0.6716 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6385 Model_2_val:0.6549
Epoch: 0260 Model_1_loss: 0.6602 Model_2_loss: 0.6011 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6467 Model_2_val:0.6487
Epoch: 0280 Model_1_loss: 0.6149 Model_2_loss: 0.6128 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6559 Model_2_val:0.6451
Epoch: 0300 Model_1_loss: 0.6041 Model_2_loss: 0.6009 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6431 Model_2_val:0.6496
Epoch: 0320 Model_1_loss: 0.5931 Model_2_loss: 0.5648 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6624 Model_2_val:0.6572
Epoch: 0340 Model_1_loss: 0.5257 Model_2_loss: 0.5600 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6388 Model_2_val:0.6480
Epoch: 0360 Model_1_loss: 0.5486 Model_2_loss: 0.5331 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6568 Model_2_val:0.6506
Epoch: 0380 Model_1_loss: 0.4988 Model_2_loss: 0.5178 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6604 Model_2_val:0.6477
Epoch: 0400 Model_1_loss: 0.5194 Model_2_loss: 0.4801 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6460 Model_2_val:0.6585
Model_one_test:0.6765 Model_two_test:0.6742
added by two output: 0.6726
13
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
811600738
Epoch: 0020 Model_1_loss: 1.7202 Model_2_loss: 1.7265 Model_1_trainacc: 0.3917 Model_2_trainacc: 0.4583 Model_1_val:0.2990 Model_2_val:0.2694
Epoch: 0040 Model_1_loss: 1.5244 Model_2_loss: 1.4956 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.7583 Model_1_val:0.4306 Model_2_val:0.4192
Epoch: 0060 Model_1_loss: 1.2165 Model_2_loss: 1.1307 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8500 Model_1_val:0.4696 Model_2_val:0.5219
Epoch: 0080 Model_1_loss: 0.8981 Model_2_loss: 0.8700 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.5512 Model_2_val:0.5509
Epoch: 0100 Model_1_loss: 0.7821 Model_2_loss: 0.6879 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9250 Model_1_val:0.5655 Model_2_val:0.5717
Epoch: 0120 Model_1_loss: 0.6044 Model_2_loss: 0.5674 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.6019 Model_2_val:0.5801
Epoch: 0140 Model_1_loss: 0.5339 Model_2_loss: 0.4938 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9417 Model_1_val:0.5964 Model_2_val:0.5954
Epoch: 0160 Model_1_loss: 0.4738 Model_2_loss: 0.4679 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6094 Model_2_val:0.6048
Epoch: 0180 Model_1_loss: 0.4513 Model_2_loss: 0.4499 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6009 Model_2_val:0.6139
Epoch: 0200 Model_1_loss: 0.3982 Model_2_loss: 0.3712 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.6110 Model_2_val:0.6159
Epoch: 0220 Model_1_loss: 0.6510 Model_2_loss: 0.7293 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6708 Model_2_val:0.6815
Epoch: 0240 Model_1_loss: 0.6451 Model_2_loss: 0.6253 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6779 Model_2_val:0.6835
Epoch: 0260 Model_1_loss: 0.6025 Model_2_loss: 0.6213 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6835 Model_2_val:0.6835
Epoch: 0280 Model_1_loss: 0.5417 Model_2_loss: 0.6086 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6809 Model_2_val:0.6692
Epoch: 0300 Model_1_loss: 0.5038 Model_2_loss: 0.5730 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6766 Model_2_val:0.6779
Epoch: 0320 Model_1_loss: 0.4809 Model_2_loss: 0.4973 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6844 Model_2_val:0.6835
Epoch: 0340 Model_1_loss: 0.4843 Model_2_loss: 0.5041 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6786 Model_2_val:0.6701
Epoch: 0360 Model_1_loss: 0.4615 Model_2_loss: 0.5165 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6812 Model_2_val:0.6698
Epoch: 0380 Model_1_loss: 0.5036 Model_2_loss: 0.5043 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6789 Model_2_val:0.6753
Epoch: 0400 Model_1_loss: 0.4236 Model_2_loss: 0.4821 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6802 Model_2_val:0.6731
Model_one_test:0.7043 Model_two_test:0.6919
added by two output: 0.6968
14
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
633885813
Epoch: 0020 Model_1_loss: 1.6727 Model_2_loss: 1.7489 Model_1_trainacc: 0.5250 Model_2_trainacc: 0.3417 Model_1_val:0.3179 Model_2_val:0.2392
Epoch: 0040 Model_1_loss: 1.4282 Model_2_loss: 1.6343 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.6417 Model_1_val:0.4771 Model_2_val:0.3469
Epoch: 0060 Model_1_loss: 1.1257 Model_2_loss: 1.3995 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8417 Model_1_val:0.5548 Model_2_val:0.4317
Epoch: 0080 Model_1_loss: 0.8623 Model_2_loss: 1.0523 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8417 Model_1_val:0.5680 Model_2_val:0.5158
Epoch: 0100 Model_1_loss: 0.7067 Model_2_loss: 0.7900 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9250 Model_1_val:0.5867 Model_2_val:0.5477
Epoch: 0120 Model_1_loss: 0.6007 Model_2_loss: 0.6864 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5964 Model_2_val:0.5664
Epoch: 0140 Model_1_loss: 0.5159 Model_2_loss: 0.5803 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.6103 Model_2_val:0.5854
Epoch: 0160 Model_1_loss: 0.4321 Model_2_loss: 0.4886 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.5796 Model_2_val:0.5809
Epoch: 0180 Model_1_loss: 0.4255 Model_2_loss: 0.4600 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.5945 Model_2_val:0.5951
Epoch: 0200 Model_1_loss: 0.3690 Model_2_loss: 0.3998 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6070 Model_2_val:0.6038
Epoch: 0220 Model_1_loss: 0.6731 Model_2_loss: 0.6790 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6509 Model_2_val:0.6515
Epoch: 0240 Model_1_loss: 0.6750 Model_2_loss: 0.6795 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6518 Model_2_val:0.6486
Epoch: 0260 Model_1_loss: 0.6087 Model_2_loss: 0.6177 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6534 Model_2_val:0.6583
Epoch: 0280 Model_1_loss: 0.5758 Model_2_loss: 0.5772 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6560 Model_2_val:0.6605
Epoch: 0300 Model_1_loss: 0.5638 Model_2_loss: 0.5465 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6647 Model_2_val:0.6534
Epoch: 0320 Model_1_loss: 0.5240 Model_2_loss: 0.5290 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6518 Model_2_val:0.6647
Epoch: 0340 Model_1_loss: 0.5097 Model_2_loss: 0.5059 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6464 Model_2_val:0.6544
Epoch: 0360 Model_1_loss: 0.4729 Model_2_loss: 0.5176 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6602 Model_2_val:0.6486
Epoch: 0380 Model_1_loss: 0.4379 Model_2_loss: 0.4722 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6560 Model_2_val:0.6596
Epoch: 0400 Model_1_loss: 0.4508 Model_2_loss: 0.4459 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6580 Model_2_val:0.6567
Model_one_test:0.6770 Model_two_test:0.6805
added by two output: 0.6802
15
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
178669085
Epoch: 0020 Model_1_loss: 1.7131 Model_2_loss: 1.7347 Model_1_trainacc: 0.3417 Model_2_trainacc: 0.3500 Model_1_val:0.2353 Model_2_val:0.2326
Epoch: 0040 Model_1_loss: 1.5305 Model_2_loss: 1.5778 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.7000 Model_1_val:0.4153 Model_2_val:0.3611
Epoch: 0060 Model_1_loss: 1.2508 Model_2_loss: 1.3377 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8250 Model_1_val:0.5082 Model_2_val:0.4306
Epoch: 0080 Model_1_loss: 0.9616 Model_2_loss: 1.0901 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8417 Model_1_val:0.5438 Model_2_val:0.4812
Epoch: 0100 Model_1_loss: 0.7766 Model_2_loss: 0.8514 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.8750 Model_1_val:0.5564 Model_2_val:0.5185
Epoch: 0120 Model_1_loss: 0.6408 Model_2_loss: 0.7119 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9083 Model_1_val:0.5674 Model_2_val:0.5684
Epoch: 0140 Model_1_loss: 0.5919 Model_2_loss: 0.6383 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9083 Model_1_val:0.5790 Model_2_val:0.5531
Epoch: 0160 Model_1_loss: 0.5318 Model_2_loss: 0.5161 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9333 Model_1_val:0.5903 Model_2_val:0.5784
Epoch: 0180 Model_1_loss: 0.4404 Model_2_loss: 0.5936 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9250 Model_1_val:0.5937 Model_2_val:0.5651
Epoch: 0200 Model_1_loss: 0.4275 Model_2_loss: 0.4882 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9500 Model_1_val:0.6090 Model_2_val:0.5854
Epoch: 0220 Model_1_loss: 0.7775 Model_2_loss: 0.8203 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6672 Model_2_val:0.6449
Epoch: 0240 Model_1_loss: 0.7443 Model_2_loss: 0.7857 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6672 Model_2_val:0.6556
Epoch: 0260 Model_1_loss: 0.6869 Model_2_loss: 0.8038 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9083 Model_1_val:0.6762 Model_2_val:0.6559
Epoch: 0280 Model_1_loss: 0.6484 Model_2_loss: 0.6688 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6715 Model_2_val:0.6539
Epoch: 0300 Model_1_loss: 0.6348 Model_2_loss: 0.6325 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6659 Model_2_val:0.6649
Epoch: 0320 Model_1_loss: 0.6363 Model_2_loss: 0.6821 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6676 Model_2_val:0.6656
Epoch: 0340 Model_1_loss: 0.6001 Model_2_loss: 0.6657 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6709 Model_2_val:0.6656
Epoch: 0360 Model_1_loss: 0.5129 Model_2_loss: 0.6161 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6705 Model_2_val:0.6616
Epoch: 0380 Model_1_loss: 0.5293 Model_2_loss: 0.5683 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6785 Model_2_val:0.6755
Epoch: 0400 Model_1_loss: 0.5263 Model_2_loss: 0.5721 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6759 Model_2_val:0.6602
Model_one_test:0.6962 Model_two_test:0.6852
added by two output: 0.6935
16
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
694246996
Epoch: 0020 Model_1_loss: 1.7569 Model_2_loss: 1.7234 Model_1_trainacc: 0.3750 Model_2_trainacc: 0.4167 Model_1_val:0.3060 Model_2_val:0.2883
Epoch: 0040 Model_1_loss: 1.6141 Model_2_loss: 1.5338 Model_1_trainacc: 0.6500 Model_2_trainacc: 0.8000 Model_1_val:0.3886 Model_2_val:0.4080
Epoch: 0060 Model_1_loss: 1.3301 Model_2_loss: 1.2790 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8500 Model_1_val:0.4688 Model_2_val:0.4888
Epoch: 0080 Model_1_loss: 1.0767 Model_2_loss: 0.9767 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9000 Model_1_val:0.5466 Model_2_val:0.5189
Epoch: 0100 Model_1_loss: 0.8538 Model_2_loss: 0.8476 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9167 Model_1_val:0.5680 Model_2_val:0.5630
Epoch: 0120 Model_1_loss: 0.7174 Model_2_loss: 0.6804 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9083 Model_1_val:0.5991 Model_2_val:0.5797
Epoch: 0140 Model_1_loss: 0.6062 Model_2_loss: 0.5944 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.6027 Model_2_val:0.5914
Epoch: 0160 Model_1_loss: 0.5484 Model_2_loss: 0.5336 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.5920 Model_2_val:0.5971
Epoch: 0180 Model_1_loss: 0.4484 Model_2_loss: 0.5031 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.6124 Model_2_val:0.5984
Epoch: 0200 Model_1_loss: 0.4395 Model_2_loss: 0.4525 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6017 Model_2_val:0.6104
Epoch: 0220 Model_1_loss: 0.7344 Model_2_loss: 0.7367 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6535 Model_2_val:0.6639
Epoch: 0240 Model_1_loss: 0.7783 Model_2_loss: 0.6922 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6652 Model_2_val:0.6696
Epoch: 0260 Model_1_loss: 0.7033 Model_2_loss: 0.6560 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6719 Model_2_val:0.6659
Epoch: 0280 Model_1_loss: 0.6293 Model_2_loss: 0.5958 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6722 Model_2_val:0.6782
Epoch: 0300 Model_1_loss: 0.6007 Model_2_loss: 0.5938 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6739 Model_2_val:0.6692
Epoch: 0320 Model_1_loss: 0.6002 Model_2_loss: 0.5262 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6602 Model_2_val:0.6772
Epoch: 0340 Model_1_loss: 0.6332 Model_2_loss: 0.5325 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6706 Model_2_val:0.6796
Epoch: 0360 Model_1_loss: 0.5171 Model_2_loss: 0.5509 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6762 Model_2_val:0.6806
Epoch: 0380 Model_1_loss: 0.5616 Model_2_loss: 0.4833 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.6742 Model_2_val:0.6823
Epoch: 0400 Model_1_loss: 0.5088 Model_2_loss: 0.4639 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6732 Model_2_val:0.6756
Model_one_test:0.6983 Model_two_test:0.6996
added by two output: 0.7010
17
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
600629780
Epoch: 0020 Model_1_loss: 1.7159 Model_2_loss: 1.7498 Model_1_trainacc: 0.3750 Model_2_trainacc: 0.2750 Model_1_val:0.2353 Model_2_val:0.2283
Epoch: 0040 Model_1_loss: 1.6115 Model_2_loss: 1.6045 Model_1_trainacc: 0.5750 Model_2_trainacc: 0.6083 Model_1_val:0.3416 Model_2_val:0.3646
Epoch: 0060 Model_1_loss: 1.3905 Model_2_loss: 1.3523 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.8250 Model_1_val:0.4225 Model_2_val:0.4793
Epoch: 0080 Model_1_loss: 1.1212 Model_2_loss: 0.9796 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9250 Model_1_val:0.5040 Model_2_val:0.5384
Epoch: 0100 Model_1_loss: 0.9266 Model_2_loss: 0.7725 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.5107 Model_2_val:0.5471
Epoch: 0120 Model_1_loss: 0.7861 Model_2_loss: 0.6254 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9750 Model_1_val:0.5391 Model_2_val:0.5715
Epoch: 0140 Model_1_loss: 0.6038 Model_2_loss: 0.5393 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5551 Model_2_val:0.5709
Epoch: 0160 Model_1_loss: 0.5628 Model_2_loss: 0.4458 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9917 Model_1_val:0.5702 Model_2_val:0.5922
Epoch: 0180 Model_1_loss: 0.5501 Model_2_loss: 0.3918 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5829 Model_2_val:0.5946
Epoch: 0200 Model_1_loss: 0.5036 Model_2_loss: 0.3425 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9833 Model_1_val:0.5779 Model_2_val:0.6053
Epoch: 0220 Model_1_loss: 0.7473 Model_2_loss: 0.6551 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6464 Model_2_val:0.6534
Epoch: 0240 Model_1_loss: 0.7177 Model_2_loss: 0.6298 Model_1_trainacc: 0.9500 Model_2_trainacc: 1.0000 Model_1_val:0.6651 Model_2_val:0.6661
Epoch: 0260 Model_1_loss: 0.6954 Model_2_loss: 0.5988 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6504 Model_2_val:0.6698
Epoch: 0280 Model_1_loss: 0.6694 Model_2_loss: 0.5612 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6588 Model_2_val:0.6718
Epoch: 0300 Model_1_loss: 0.5795 Model_2_loss: 0.5066 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6568 Model_2_val:0.6731
Epoch: 0320 Model_1_loss: 0.5516 Model_2_loss: 0.5139 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6547 Model_2_val:0.6608
Epoch: 0340 Model_1_loss: 0.5255 Model_2_loss: 0.5158 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6517 Model_2_val:0.6705
Epoch: 0360 Model_1_loss: 0.5158 Model_2_loss: 0.4511 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6517 Model_2_val:0.6705
Epoch: 0380 Model_1_loss: 0.5347 Model_2_loss: 0.4871 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6618 Model_2_val:0.6681
Epoch: 0400 Model_1_loss: 0.5091 Model_2_loss: 0.4343 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6474 Model_2_val:0.6574
Model_one_test:0.6875 Model_two_test:0.6872
added by two output: 0.6882
18
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
662236532
Epoch: 0020 Model_1_loss: 1.7563 Model_2_loss: 1.6816 Model_1_trainacc: 0.3083 Model_2_trainacc: 0.5167 Model_1_val:0.2371 Model_2_val:0.2891
Epoch: 0040 Model_1_loss: 1.6252 Model_2_loss: 1.4581 Model_1_trainacc: 0.7083 Model_2_trainacc: 0.7417 Model_1_val:0.3999 Model_2_val:0.4509
Epoch: 0060 Model_1_loss: 1.3313 Model_2_loss: 1.1392 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.9083 Model_1_val:0.4855 Model_2_val:0.4942
Epoch: 0080 Model_1_loss: 0.9716 Model_2_loss: 0.8519 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9000 Model_1_val:0.5103 Model_2_val:0.5375
Epoch: 0100 Model_1_loss: 0.6962 Model_2_loss: 0.6714 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.5426 Model_2_val:0.5430
Epoch: 0120 Model_1_loss: 0.5761 Model_2_loss: 0.5431 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.5711 Model_2_val:0.5753
Epoch: 0140 Model_1_loss: 0.4597 Model_2_loss: 0.5008 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.5946 Model_2_val:0.5801
Epoch: 0160 Model_1_loss: 0.4338 Model_2_loss: 0.4629 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.5872 Model_2_val:0.5685
Epoch: 0180 Model_1_loss: 0.3730 Model_2_loss: 0.4072 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.5759 Model_2_val:0.5811
Epoch: 0200 Model_1_loss: 0.3846 Model_2_loss: 0.4139 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.5885 Model_2_val:0.5917
Epoch: 0220 Model_1_loss: 0.7071 Model_2_loss: 0.7203 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6573 Model_2_val:0.6340
Epoch: 0240 Model_1_loss: 0.6477 Model_2_loss: 0.6336 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6660 Model_2_val:0.6592
Epoch: 0260 Model_1_loss: 0.6033 Model_2_loss: 0.6118 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6557 Model_2_val:0.6557
Epoch: 0280 Model_1_loss: 0.5919 Model_2_loss: 0.5968 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.6557 Model_2_val:0.6618
Epoch: 0300 Model_1_loss: 0.5704 Model_2_loss: 0.5426 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6747 Model_2_val:0.6544
Epoch: 0320 Model_1_loss: 0.5214 Model_2_loss: 0.5077 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6667 Model_2_val:0.6596
Epoch: 0340 Model_1_loss: 0.4532 Model_2_loss: 0.4769 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6609 Model_2_val:0.6689
Epoch: 0360 Model_1_loss: 0.4524 Model_2_loss: 0.4554 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6615 Model_2_val:0.6628
Epoch: 0380 Model_1_loss: 0.4641 Model_2_loss: 0.4541 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6673 Model_2_val:0.6583
Epoch: 0400 Model_1_loss: 0.4409 Model_2_loss: 0.4897 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6725 Model_2_val:0.6638
Model_one_test:0.7035 Model_two_test:0.6951
added by two output: 0.6993
19
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1206813393
Epoch: 0020 Model_1_loss: 1.7030 Model_2_loss: 1.7155 Model_1_trainacc: 0.4750 Model_2_trainacc: 0.5000 Model_1_val:0.2689 Model_2_val:0.2280
Epoch: 0040 Model_1_loss: 1.5394 Model_2_loss: 1.5176 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.7250 Model_1_val:0.3927 Model_2_val:0.4074
Epoch: 0060 Model_1_loss: 1.1982 Model_2_loss: 1.1802 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8750 Model_1_val:0.4979 Model_2_val:0.5021
Epoch: 0080 Model_1_loss: 0.9531 Model_2_loss: 0.9177 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9250 Model_1_val:0.5309 Model_2_val:0.5219
Epoch: 0100 Model_1_loss: 0.7593 Model_2_loss: 0.7011 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.5462 Model_2_val:0.5580
Epoch: 0120 Model_1_loss: 0.6026 Model_2_loss: 0.6145 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5625 Model_2_val:0.5744
Epoch: 0140 Model_1_loss: 0.5837 Model_2_loss: 0.5341 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.5817 Model_2_val:0.5919
Epoch: 0160 Model_1_loss: 0.4761 Model_2_loss: 0.4708 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5980 Model_2_val:0.5878
Epoch: 0180 Model_1_loss: 0.4160 Model_2_loss: 0.4282 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.5980 Model_2_val:0.6105
Epoch: 0200 Model_1_loss: 0.3769 Model_2_loss: 0.4564 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.5958 Model_2_val:0.6102
Epoch: 0220 Model_1_loss: 0.7710 Model_2_loss: 0.7318 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6524 Model_2_val:0.6524
Epoch: 0240 Model_1_loss: 0.6798 Model_2_loss: 0.6730 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6636 Model_2_val:0.6597
Epoch: 0260 Model_1_loss: 0.6248 Model_2_loss: 0.6266 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6668 Model_2_val:0.6706
Epoch: 0280 Model_1_loss: 0.5936 Model_2_loss: 0.6026 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6687 Model_2_val:0.6578
Epoch: 0300 Model_1_loss: 0.5981 Model_2_loss: 0.5508 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6687 Model_2_val:0.6569
Epoch: 0320 Model_1_loss: 0.5588 Model_2_loss: 0.5492 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6645 Model_2_val:0.6674
Epoch: 0340 Model_1_loss: 0.4917 Model_2_loss: 0.5239 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6652 Model_2_val:0.6655
Epoch: 0360 Model_1_loss: 0.4637 Model_2_loss: 0.5155 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6668 Model_2_val:0.6665
Epoch: 0380 Model_1_loss: 0.4772 Model_2_loss: 0.4640 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.6697 Model_2_val:0.6607
Epoch: 0400 Model_1_loss: 0.4946 Model_2_loss: 0.4272 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6572 Model_2_val:0.6559
Model_one_test:0.6856 Model_two_test:0.6799
added by two output: 0.6844
20
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
615222322
Epoch: 0020 Model_1_loss: 1.7138 Model_2_loss: 1.7168 Model_1_trainacc: 0.4000 Model_2_trainacc: 0.5250 Model_1_val:0.2541 Model_2_val:0.3055
Epoch: 0040 Model_1_loss: 1.5191 Model_2_loss: 1.4974 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8667 Model_1_val:0.4491 Model_2_val:0.4520
Epoch: 0060 Model_1_loss: 1.2402 Model_2_loss: 1.1841 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9000 Model_1_val:0.5059 Model_2_val:0.4950
Epoch: 0080 Model_1_loss: 0.8913 Model_2_loss: 0.9028 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.8917 Model_1_val:0.5246 Model_2_val:0.5368
Epoch: 0100 Model_1_loss: 0.7770 Model_2_loss: 0.6999 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9167 Model_1_val:0.5602 Model_2_val:0.5740
Epoch: 0120 Model_1_loss: 0.5848 Model_2_loss: 0.5952 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.5866 Model_2_val:0.5686
Epoch: 0140 Model_1_loss: 0.5109 Model_2_loss: 0.5289 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.5782 Model_2_val:0.5936
Epoch: 0160 Model_1_loss: 0.4733 Model_2_loss: 0.4597 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5891 Model_2_val:0.6075
Epoch: 0180 Model_1_loss: 0.4223 Model_2_loss: 0.4211 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6078 Model_2_val:0.6013
Epoch: 0200 Model_1_loss: 0.3670 Model_2_loss: 0.3812 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.5924 Model_2_val:0.6020
Epoch: 0220 Model_1_loss: 0.7181 Model_2_loss: 0.7080 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6608 Model_2_val:0.6595
Epoch: 0240 Model_1_loss: 0.6506 Model_2_loss: 0.6374 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6486 Model_2_val:0.6524
Epoch: 0260 Model_1_loss: 0.6166 Model_2_loss: 0.6315 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6505 Model_2_val:0.6691
Epoch: 0280 Model_1_loss: 0.5718 Model_2_loss: 0.5974 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6457 Model_2_val:0.6576
Epoch: 0300 Model_1_loss: 0.5805 Model_2_loss: 0.5879 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6425 Model_2_val:0.6582
Epoch: 0320 Model_1_loss: 0.5338 Model_2_loss: 0.4856 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6588 Model_2_val:0.6778
Epoch: 0340 Model_1_loss: 0.4942 Model_2_loss: 0.4863 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6572 Model_2_val:0.6617
Epoch: 0360 Model_1_loss: 0.4584 Model_2_loss: 0.4415 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6550 Model_2_val:0.6711
Epoch: 0380 Model_1_loss: 0.4731 Model_2_loss: 0.4741 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6621 Model_2_val:0.6566
Epoch: 0400 Model_1_loss: 0.4261 Model_2_loss: 0.4240 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6524 Model_2_val:0.6630
Model_one_test:0.6807 Model_two_test:0.6878
added by two output: 0.6868
21
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
632085152
Epoch: 0020 Model_1_loss: 1.6631 Model_2_loss: 1.7694 Model_1_trainacc: 0.5000 Model_2_trainacc: 0.2833 Model_1_val:0.2934 Model_2_val:0.2339
Epoch: 0040 Model_1_loss: 1.4329 Model_2_loss: 1.6159 Model_1_trainacc: 0.7417 Model_2_trainacc: 0.6167 Model_1_val:0.4207 Model_2_val:0.3606
Epoch: 0060 Model_1_loss: 1.1842 Model_2_loss: 1.3336 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.7500 Model_1_val:0.4985 Model_2_val:0.4737
Epoch: 0080 Model_1_loss: 0.9023 Model_2_loss: 1.0271 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8667 Model_1_val:0.5363 Model_2_val:0.5567
Epoch: 0100 Model_1_loss: 0.7473 Model_2_loss: 0.7712 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9000 Model_1_val:0.5622 Model_2_val:0.5761
Epoch: 0120 Model_1_loss: 0.6451 Model_2_loss: 0.7017 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9083 Model_1_val:0.5774 Model_2_val:0.5848
Epoch: 0140 Model_1_loss: 0.5632 Model_2_loss: 0.5897 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9250 Model_1_val:0.5813 Model_2_val:0.5819
Epoch: 0160 Model_1_loss: 0.4598 Model_2_loss: 0.4873 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.5719 Model_2_val:0.5903
Epoch: 0180 Model_1_loss: 0.4568 Model_2_loss: 0.4480 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5816 Model_2_val:0.6090
Epoch: 0200 Model_1_loss: 0.4347 Model_2_loss: 0.4042 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6039 Model_2_val:0.6019
Epoch: 0220 Model_1_loss: 0.7608 Model_2_loss: 0.7531 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6511 Model_2_val:0.6575
Epoch: 0240 Model_1_loss: 0.7388 Model_2_loss: 0.7410 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6585 Model_2_val:0.6607
Epoch: 0260 Model_1_loss: 0.6549 Model_2_loss: 0.6666 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6662 Model_2_val:0.6630
Epoch: 0280 Model_1_loss: 0.6352 Model_2_loss: 0.6466 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6724 Model_2_val:0.6695
Epoch: 0300 Model_1_loss: 0.6098 Model_2_loss: 0.6307 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6691 Model_2_val:0.6698
Epoch: 0320 Model_1_loss: 0.5447 Model_2_loss: 0.5581 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6666 Model_2_val:0.6659
Epoch: 0340 Model_1_loss: 0.5705 Model_2_loss: 0.5889 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6682 Model_2_val:0.6701
Epoch: 0360 Model_1_loss: 0.5516 Model_2_loss: 0.5579 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6688 Model_2_val:0.6724
Epoch: 0380 Model_1_loss: 0.5078 Model_2_loss: 0.4907 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6666 Model_2_val:0.6646
Epoch: 0400 Model_1_loss: 0.5284 Model_2_loss: 0.5714 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6685 Model_2_val:0.6730
Model_one_test:0.6995 Model_two_test:0.6985
added by two output: 0.6995
22
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
27059278
Epoch: 0020 Model_1_loss: 1.7264 Model_2_loss: 1.7296 Model_1_trainacc: 0.3750 Model_2_trainacc: 0.3417 Model_1_val:0.2510 Model_2_val:0.1933
Epoch: 0040 Model_1_loss: 1.5468 Model_2_loss: 1.5659 Model_1_trainacc: 0.7583 Model_2_trainacc: 0.7000 Model_1_val:0.4371 Model_2_val:0.4236
Epoch: 0060 Model_1_loss: 1.1783 Model_2_loss: 1.3194 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.7833 Model_1_val:0.5000 Model_2_val:0.4888
Epoch: 0080 Model_1_loss: 0.8948 Model_2_loss: 1.0285 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8667 Model_1_val:0.5412 Model_2_val:0.5431
Epoch: 0100 Model_1_loss: 0.6737 Model_2_loss: 0.8497 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9000 Model_1_val:0.5478 Model_2_val:0.5527
Epoch: 0120 Model_1_loss: 0.6305 Model_2_loss: 0.6564 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9083 Model_1_val:0.5814 Model_2_val:0.5725
Epoch: 0140 Model_1_loss: 0.4992 Model_2_loss: 0.5747 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.5935 Model_2_val:0.5787
Epoch: 0160 Model_1_loss: 0.4607 Model_2_loss: 0.4908 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.5988 Model_2_val:0.5952
Epoch: 0180 Model_1_loss: 0.4034 Model_2_loss: 0.4684 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9417 Model_1_val:0.5929 Model_2_val:0.5978
Epoch: 0200 Model_1_loss: 0.4212 Model_2_loss: 0.4270 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6265 Model_2_val:0.5777
Epoch: 0220 Model_1_loss: 0.7070 Model_2_loss: 0.7987 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6545 Model_2_val:0.6535
Epoch: 0240 Model_1_loss: 0.6902 Model_2_loss: 0.6926 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6657 Model_2_val:0.6443
Epoch: 0260 Model_1_loss: 0.6963 Model_2_loss: 0.7232 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.6548 Model_2_val:0.6650
Epoch: 0280 Model_1_loss: 0.5818 Model_2_loss: 0.6078 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6673 Model_2_val:0.6789
Epoch: 0300 Model_1_loss: 0.5777 Model_2_loss: 0.6574 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6686 Model_2_val:0.6733
Epoch: 0320 Model_1_loss: 0.5565 Model_2_loss: 0.5747 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9917 Model_1_val:0.6663 Model_2_val:0.6647
Epoch: 0340 Model_1_loss: 0.5464 Model_2_loss: 0.5746 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6815 Model_2_val:0.6601
Epoch: 0360 Model_1_loss: 0.5298 Model_2_loss: 0.5551 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6756 Model_2_val:0.6614
Epoch: 0380 Model_1_loss: 0.5133 Model_2_loss: 0.5155 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6736 Model_2_val:0.6617
Epoch: 0400 Model_1_loss: 0.5084 Model_2_loss: 0.4935 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6723 Model_2_val:0.6673
Model_one_test:0.6864 Model_two_test:0.6871
added by two output: 0.6871
23
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1362586864
Epoch: 0020 Model_1_loss: 1.7116 Model_2_loss: 1.6804 Model_1_trainacc: 0.5833 Model_2_trainacc: 0.5750 Model_1_val:0.3121 Model_2_val:0.3168
Epoch: 0040 Model_1_loss: 1.4774 Model_2_loss: 1.4302 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.7500 Model_1_val:0.4546 Model_2_val:0.4321
Epoch: 0060 Model_1_loss: 1.0787 Model_2_loss: 1.0621 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5258 Model_2_val:0.5073
Epoch: 0080 Model_1_loss: 0.8128 Model_2_loss: 0.8055 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.5394 Model_2_val:0.5374
Epoch: 0100 Model_1_loss: 0.6068 Model_2_loss: 0.6123 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5838 Model_2_val:0.5494
Epoch: 0120 Model_1_loss: 0.5168 Model_2_loss: 0.5475 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.5742 Model_2_val:0.5795
Epoch: 0140 Model_1_loss: 0.4901 Model_2_loss: 0.4402 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.5901 Model_2_val:0.5709
Epoch: 0160 Model_1_loss: 0.4029 Model_2_loss: 0.4135 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.5852 Model_2_val:0.5746
Epoch: 0180 Model_1_loss: 0.3957 Model_2_loss: 0.3704 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.5898 Model_2_val:0.6011
Epoch: 0200 Model_1_loss: 0.3108 Model_2_loss: 0.3215 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.5895 Model_2_val:0.5928
Epoch: 0220 Model_1_loss: 0.6536 Model_2_loss: 0.6642 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6534 Model_2_val:0.6521
Epoch: 0240 Model_1_loss: 0.6406 Model_2_loss: 0.5784 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6577 Model_2_val:0.6574
Epoch: 0260 Model_1_loss: 0.5915 Model_2_loss: 0.5555 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6624 Model_2_val:0.6557
Epoch: 0280 Model_1_loss: 0.5555 Model_2_loss: 0.5065 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6683 Model_2_val:0.6730
Epoch: 0300 Model_1_loss: 0.4920 Model_2_loss: 0.5359 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6561 Model_2_val:0.6643
Epoch: 0320 Model_1_loss: 0.4884 Model_2_loss: 0.4414 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6690 Model_2_val:0.6657
Epoch: 0340 Model_1_loss: 0.4939 Model_2_loss: 0.4824 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6634 Model_2_val:0.6750
Epoch: 0360 Model_1_loss: 0.4682 Model_2_loss: 0.4441 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6670 Model_2_val:0.6743
Epoch: 0380 Model_1_loss: 0.4477 Model_2_loss: 0.4142 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6753 Model_2_val:0.6637
Epoch: 0400 Model_1_loss: 0.4491 Model_2_loss: 0.4310 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6740 Model_2_val:0.6680
Model_one_test:0.6975 Model_two_test:0.6952
added by two output: 0.6958
24
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
597160737
Epoch: 0020 Model_1_loss: 1.7183 Model_2_loss: 1.6956 Model_1_trainacc: 0.5000 Model_2_trainacc: 0.4583 Model_1_val:0.2678 Model_2_val:0.2256
Epoch: 0040 Model_1_loss: 1.5355 Model_2_loss: 1.4707 Model_1_trainacc: 0.6917 Model_2_trainacc: 0.8417 Model_1_val:0.4283 Model_2_val:0.4546
Epoch: 0060 Model_1_loss: 1.1713 Model_2_loss: 1.1629 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8667 Model_1_val:0.5180 Model_2_val:0.5086
Epoch: 0080 Model_1_loss: 0.9319 Model_2_loss: 0.8854 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8750 Model_1_val:0.5487 Model_2_val:0.5319
Epoch: 0100 Model_1_loss: 0.6720 Model_2_loss: 0.6946 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5616 Model_2_val:0.5663
Epoch: 0120 Model_1_loss: 0.5833 Model_2_loss: 0.5991 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.5605 Model_2_val:0.5845
Epoch: 0140 Model_1_loss: 0.5055 Model_2_loss: 0.5499 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.5798 Model_2_val:0.5865
Epoch: 0160 Model_1_loss: 0.4336 Model_2_loss: 0.4456 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6007 Model_2_val:0.5909
Epoch: 0180 Model_1_loss: 0.3967 Model_2_loss: 0.4220 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6064 Model_2_val:0.6037
Epoch: 0200 Model_1_loss: 0.3872 Model_2_loss: 0.4092 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6118 Model_2_val:0.5949
Epoch: 0220 Model_1_loss: 0.6895 Model_2_loss: 0.7446 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6546 Model_2_val:0.6678
Epoch: 0240 Model_1_loss: 0.6436 Model_2_loss: 0.6663 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6658 Model_2_val:0.6624
Epoch: 0260 Model_1_loss: 0.6185 Model_2_loss: 0.6464 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6604 Model_2_val:0.6553
Epoch: 0280 Model_1_loss: 0.5737 Model_2_loss: 0.5745 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6543 Model_2_val:0.6637
Epoch: 0300 Model_1_loss: 0.5809 Model_2_loss: 0.5576 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6614 Model_2_val:0.6651
Epoch: 0320 Model_1_loss: 0.5165 Model_2_loss: 0.5357 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6637 Model_2_val:0.6661
Epoch: 0340 Model_1_loss: 0.4959 Model_2_loss: 0.4976 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6668 Model_2_val:0.6550
Epoch: 0360 Model_1_loss: 0.4921 Model_2_loss: 0.4616 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6573 Model_2_val:0.6681
Epoch: 0380 Model_1_loss: 0.4507 Model_2_loss: 0.4682 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6641 Model_2_val:0.6678
Epoch: 0400 Model_1_loss: 0.4820 Model_2_loss: 0.4544 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6540 Model_2_val:0.6691
Model_one_test:0.6847 Model_two_test:0.6830
added by two output: 0.6857
25
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
234020536
Epoch: 0020 Model_1_loss: 1.7313 Model_2_loss: 1.7349 Model_1_trainacc: 0.3667 Model_2_trainacc: 0.4250 Model_1_val:0.2366 Model_2_val:0.2137
Epoch: 0040 Model_1_loss: 1.5770 Model_2_loss: 1.5580 Model_1_trainacc: 0.6083 Model_2_trainacc: 0.7083 Model_1_val:0.3667 Model_2_val:0.3873
Epoch: 0060 Model_1_loss: 1.3106 Model_2_loss: 1.2525 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8167 Model_1_val:0.4490 Model_2_val:0.4868
Epoch: 0080 Model_1_loss: 1.0207 Model_2_loss: 0.9968 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8417 Model_1_val:0.5113 Model_2_val:0.5023
Epoch: 0100 Model_1_loss: 0.8062 Model_2_loss: 0.7353 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9500 Model_1_val:0.5258 Model_2_val:0.5420
Epoch: 0120 Model_1_loss: 0.6711 Model_2_loss: 0.6120 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9167 Model_1_val:0.5284 Model_2_val:0.5445
Epoch: 0140 Model_1_loss: 0.5953 Model_2_loss: 0.5290 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9667 Model_1_val:0.5575 Model_2_val:0.5245
Epoch: 0160 Model_1_loss: 0.5326 Model_2_loss: 0.4984 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5345 Model_2_val:0.5423
Epoch: 0180 Model_1_loss: 0.4812 Model_2_loss: 0.4499 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5636 Model_2_val:0.5491
Epoch: 0200 Model_1_loss: 0.4554 Model_2_loss: 0.4337 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.5668 Model_2_val:0.5684
Epoch: 0220 Model_1_loss: 0.8063 Model_2_loss: 0.7985 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9333 Model_1_val:0.6478 Model_2_val:0.6327
Epoch: 0240 Model_1_loss: 0.7223 Model_2_loss: 0.7583 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6365 Model_2_val:0.6543
Epoch: 0260 Model_1_loss: 0.7065 Model_2_loss: 0.7071 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6443 Model_2_val:0.6520
Epoch: 0280 Model_1_loss: 0.6347 Model_2_loss: 0.6757 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6704 Model_2_val:0.6478
Epoch: 0300 Model_1_loss: 0.6384 Model_2_loss: 0.6190 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6672 Model_2_val:0.6701
Epoch: 0320 Model_1_loss: 0.6207 Model_2_loss: 0.5962 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6530 Model_2_val:0.6575
Epoch: 0340 Model_1_loss: 0.5690 Model_2_loss: 0.5490 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6762 Model_2_val:0.6627
Epoch: 0360 Model_1_loss: 0.5470 Model_2_loss: 0.6177 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6698 Model_2_val:0.6546
Epoch: 0380 Model_1_loss: 0.5270 Model_2_loss: 0.5766 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6582 Model_2_val:0.6566
Epoch: 0400 Model_1_loss: 0.5805 Model_2_loss: 0.5495 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6595 Model_2_val:0.6611
Model_one_test:0.6872 Model_two_test:0.6866
added by two output: 0.6853
26
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
77195170
Epoch: 0020 Model_1_loss: 1.7312 Model_2_loss: 1.7186 Model_1_trainacc: 0.4500 Model_2_trainacc: 0.4250 Model_1_val:0.3153 Model_2_val:0.2684
Epoch: 0040 Model_1_loss: 1.5133 Model_2_loss: 1.5259 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.7167 Model_1_val:0.4662 Model_2_val:0.3934
Epoch: 0060 Model_1_loss: 1.1869 Model_2_loss: 1.2641 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8000 Model_1_val:0.5225 Model_2_val:0.4655
Epoch: 0080 Model_1_loss: 0.8938 Model_2_loss: 1.0156 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.8750 Model_1_val:0.5493 Model_2_val:0.5178
Epoch: 0100 Model_1_loss: 0.7237 Model_2_loss: 0.8495 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9000 Model_1_val:0.5734 Model_2_val:0.5318
Epoch: 0120 Model_1_loss: 0.5950 Model_2_loss: 0.7294 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9167 Model_1_val:0.5928 Model_2_val:0.5523
Epoch: 0140 Model_1_loss: 0.5653 Model_2_loss: 0.6557 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.8750 Model_1_val:0.6009 Model_2_val:0.5412
Epoch: 0160 Model_1_loss: 0.5189 Model_2_loss: 0.5473 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9083 Model_1_val:0.6002 Model_2_val:0.5761
Epoch: 0180 Model_1_loss: 0.4411 Model_2_loss: 0.5249 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.6119 Model_2_val:0.5831
Epoch: 0200 Model_1_loss: 0.3805 Model_2_loss: 0.4252 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.6039 Model_2_val:0.5942
Epoch: 0220 Model_1_loss: 0.7022 Model_2_loss: 0.7803 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6602 Model_2_val:0.6505
Epoch: 0240 Model_1_loss: 0.7121 Model_2_loss: 0.7320 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6612 Model_2_val:0.6578
Epoch: 0260 Model_1_loss: 0.6141 Model_2_loss: 0.6819 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6605 Model_2_val:0.6582
Epoch: 0280 Model_1_loss: 0.6382 Model_2_loss: 0.5893 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9833 Model_1_val:0.6679 Model_2_val:0.6726
Epoch: 0300 Model_1_loss: 0.5609 Model_2_loss: 0.6385 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6629 Model_2_val:0.6672
Epoch: 0320 Model_1_loss: 0.5976 Model_2_loss: 0.5344 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6779 Model_2_val:0.6756
Epoch: 0340 Model_1_loss: 0.5079 Model_2_loss: 0.5215 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6736 Model_2_val:0.6649
Epoch: 0360 Model_1_loss: 0.4976 Model_2_loss: 0.5741 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6652 Model_2_val:0.6588
Epoch: 0380 Model_1_loss: 0.4903 Model_2_loss: 0.5172 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6726 Model_2_val:0.6756
Epoch: 0400 Model_1_loss: 0.4446 Model_2_loss: 0.4855 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6629 Model_2_val:0.6615
Model_one_test:0.6847 Model_two_test:0.6947
added by two output: 0.6893
27
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
842963724
Epoch: 0020 Model_1_loss: 1.6899 Model_2_loss: 1.7514 Model_1_trainacc: 0.5083 Model_2_trainacc: 0.3417 Model_1_val:0.2668 Model_2_val:0.2139
Epoch: 0040 Model_1_loss: 1.4887 Model_2_loss: 1.6081 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.5833 Model_1_val:0.4139 Model_2_val:0.3328
Epoch: 0060 Model_1_loss: 1.2432 Model_2_loss: 1.3663 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.7167 Model_1_val:0.5127 Model_2_val:0.4569
Epoch: 0080 Model_1_loss: 0.9659 Model_2_loss: 1.0595 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8500 Model_1_val:0.5213 Model_2_val:0.4966
Epoch: 0100 Model_1_loss: 0.7300 Model_2_loss: 0.8338 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9000 Model_1_val:0.5515 Model_2_val:0.5268
Epoch: 0120 Model_1_loss: 0.6562 Model_2_loss: 0.7239 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8750 Model_1_val:0.5579 Model_2_val:0.5383
Epoch: 0140 Model_1_loss: 0.5505 Model_2_loss: 0.5934 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5845 Model_2_val:0.5518
Epoch: 0160 Model_1_loss: 0.4647 Model_2_loss: 0.5314 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5768 Model_2_val:0.5752
Epoch: 0180 Model_1_loss: 0.4391 Model_2_loss: 0.5068 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5848 Model_2_val:0.5624
Epoch: 0200 Model_1_loss: 0.4120 Model_2_loss: 0.4769 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.5983 Model_2_val:0.5864
Epoch: 0220 Model_1_loss: 0.7262 Model_2_loss: 0.7561 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6396 Model_2_val:0.6464
Epoch: 0240 Model_1_loss: 0.6920 Model_2_loss: 0.6878 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6659 Model_2_val:0.6618
Epoch: 0260 Model_1_loss: 0.6236 Model_2_loss: 0.6408 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6560 Model_2_val:0.6608
Epoch: 0280 Model_1_loss: 0.6474 Model_2_loss: 0.6381 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6387 Model_2_val:0.6605
Epoch: 0300 Model_1_loss: 0.5954 Model_2_loss: 0.5373 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6505 Model_2_val:0.6634
Epoch: 0320 Model_1_loss: 0.5270 Model_2_loss: 0.5530 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.6579 Model_2_val:0.6589
Epoch: 0340 Model_1_loss: 0.5762 Model_2_loss: 0.5505 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6531 Model_2_val:0.6563
Epoch: 0360 Model_1_loss: 0.5094 Model_2_loss: 0.4652 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6688 Model_2_val:0.6698
Epoch: 0380 Model_1_loss: 0.5154 Model_2_loss: 0.4823 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6521 Model_2_val:0.6643
Epoch: 0400 Model_1_loss: 0.4654 Model_2_loss: 0.4531 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6518 Model_2_val:0.6694
Model_one_test:0.6826 Model_two_test:0.6816
added by two output: 0.6800
28
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1465578734
Epoch: 0020 Model_1_loss: 1.7404 Model_2_loss: 1.7323 Model_1_trainacc: 0.4333 Model_2_trainacc: 0.4250 Model_1_val:0.2681 Model_2_val:0.2616
Epoch: 0040 Model_1_loss: 1.6026 Model_2_loss: 1.5592 Model_1_trainacc: 0.6750 Model_2_trainacc: 0.6167 Model_1_val:0.4004 Model_2_val:0.3666
Epoch: 0060 Model_1_loss: 1.2639 Model_2_loss: 1.2880 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.7833 Model_1_val:0.4660 Model_2_val:0.4618
Epoch: 0080 Model_1_loss: 0.9980 Model_2_loss: 0.9755 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8583 Model_1_val:0.5300 Model_2_val:0.5327
Epoch: 0100 Model_1_loss: 0.7148 Model_2_loss: 0.7893 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9250 Model_1_val:0.5543 Model_2_val:0.5520
Epoch: 0120 Model_1_loss: 0.6292 Model_2_loss: 0.6936 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9250 Model_1_val:0.5671 Model_2_val:0.5740
Epoch: 0140 Model_1_loss: 0.5042 Model_2_loss: 0.6316 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9083 Model_1_val:0.5796 Model_2_val:0.5478
Epoch: 0160 Model_1_loss: 0.5292 Model_2_loss: 0.4912 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5645 Model_2_val:0.5651
Epoch: 0180 Model_1_loss: 0.4449 Model_2_loss: 0.4928 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9250 Model_1_val:0.5635 Model_2_val:0.5569
Epoch: 0200 Model_1_loss: 0.4430 Model_2_loss: 0.4391 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5802 Model_2_val:0.5816
Epoch: 0220 Model_1_loss: 0.7989 Model_2_loss: 0.7669 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.6364 Model_2_val:0.6351
Epoch: 0240 Model_1_loss: 0.7398 Model_2_loss: 0.7676 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6580 Model_2_val:0.6442
Epoch: 0260 Model_1_loss: 0.7203 Model_2_loss: 0.7042 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.6544 Model_2_val:0.6469
Epoch: 0280 Model_1_loss: 0.6394 Model_2_loss: 0.7059 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.6547 Model_2_val:0.6600
Epoch: 0300 Model_1_loss: 0.6042 Model_2_loss: 0.6447 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6570 Model_2_val:0.6636
Epoch: 0320 Model_1_loss: 0.5890 Model_2_loss: 0.6140 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6505 Model_2_val:0.6495
Epoch: 0340 Model_1_loss: 0.5671 Model_2_loss: 0.5736 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6603 Model_2_val:0.6538
Epoch: 0360 Model_1_loss: 0.6051 Model_2_loss: 0.5515 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6659 Model_2_val:0.6580
Epoch: 0380 Model_1_loss: 0.4897 Model_2_loss: 0.5200 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6587 Model_2_val:0.6472
Epoch: 0400 Model_1_loss: 0.5246 Model_2_loss: 0.5319 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6584 Model_2_val:0.6538
Model_one_test:0.6817 Model_two_test:0.6843
added by two output: 0.6797
29
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
722917099
Epoch: 0020 Model_1_loss: 1.6808 Model_2_loss: 1.7368 Model_1_trainacc: 0.4417 Model_2_trainacc: 0.3667 Model_1_val:0.2607 Model_2_val:0.2059
Epoch: 0040 Model_1_loss: 1.4603 Model_2_loss: 1.5761 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.6833 Model_1_val:0.4236 Model_2_val:0.3860
Epoch: 0060 Model_1_loss: 1.1153 Model_2_loss: 1.2650 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8333 Model_1_val:0.5180 Model_2_val:0.4736
Epoch: 0080 Model_1_loss: 0.8326 Model_2_loss: 0.9697 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9000 Model_1_val:0.5559 Model_2_val:0.5240
Epoch: 0100 Model_1_loss: 0.6532 Model_2_loss: 0.8348 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.8917 Model_1_val:0.5747 Model_2_val:0.5354
Epoch: 0120 Model_1_loss: 0.5234 Model_2_loss: 0.6148 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.5586 Model_2_val:0.5398
Epoch: 0140 Model_1_loss: 0.4705 Model_2_loss: 0.5696 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5915 Model_2_val:0.5673
Epoch: 0160 Model_1_loss: 0.4195 Model_2_loss: 0.5450 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9417 Model_1_val:0.5979 Model_2_val:0.5579
Epoch: 0180 Model_1_loss: 0.3512 Model_2_loss: 0.4471 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.5778 Model_2_val:0.5707
Epoch: 0200 Model_1_loss: 0.3472 Model_2_loss: 0.4412 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9417 Model_1_val:0.5915 Model_2_val:0.5791
Epoch: 0220 Model_1_loss: 0.7052 Model_2_loss: 0.8419 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.6470 Model_2_val:0.6342
Epoch: 0240 Model_1_loss: 0.6815 Model_2_loss: 0.7329 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6530 Model_2_val:0.6302
Epoch: 0260 Model_1_loss: 0.6265 Model_2_loss: 0.6797 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6668 Model_2_val:0.6476
Epoch: 0280 Model_1_loss: 0.6167 Model_2_loss: 0.6546 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6631 Model_2_val:0.6460
Epoch: 0300 Model_1_loss: 0.5631 Model_2_loss: 0.6505 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6695 Model_2_val:0.6530
Epoch: 0320 Model_1_loss: 0.4873 Model_2_loss: 0.6101 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6564 Model_2_val:0.6557
Epoch: 0340 Model_1_loss: 0.5206 Model_2_loss: 0.6130 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6611 Model_2_val:0.6570
Epoch: 0360 Model_1_loss: 0.4854 Model_2_loss: 0.5603 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6510 Model_2_val:0.6500
Epoch: 0380 Model_1_loss: 0.4521 Model_2_loss: 0.4948 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6681 Model_2_val:0.6540
Epoch: 0400 Model_1_loss: 0.4667 Model_2_loss: 0.5090 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6651 Model_2_val:0.6544
Model_one_test:0.6876 Model_two_test:0.6923
added by two output: 0.6889
30
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1296622658
Epoch: 0020 Model_1_loss: 1.7307 Model_2_loss: 1.7152 Model_1_trainacc: 0.3250 Model_2_trainacc: 0.5667 Model_1_val:0.2616 Model_2_val:0.2839
Epoch: 0040 Model_1_loss: 1.5536 Model_2_loss: 1.5405 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.7250 Model_1_val:0.3930 Model_2_val:0.4123
Epoch: 0060 Model_1_loss: 1.2638 Model_2_loss: 1.2487 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8417 Model_1_val:0.4832 Model_2_val:0.4765
Epoch: 0080 Model_1_loss: 0.9330 Model_2_loss: 0.9689 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9417 Model_1_val:0.5168 Model_2_val:0.5128
Epoch: 0100 Model_1_loss: 0.7707 Model_2_loss: 0.7658 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9417 Model_1_val:0.5401 Model_2_val:0.5454
Epoch: 0120 Model_1_loss: 0.6295 Model_2_loss: 0.7021 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9167 Model_1_val:0.5424 Model_2_val:0.5551
Epoch: 0140 Model_1_loss: 0.5939 Model_2_loss: 0.5568 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.5597 Model_2_val:0.5671
Epoch: 0160 Model_1_loss: 0.5345 Model_2_loss: 0.4449 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5764 Model_2_val:0.5611
Epoch: 0180 Model_1_loss: 0.4677 Model_2_loss: 0.3989 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.5697 Model_2_val:0.5694
Epoch: 0200 Model_1_loss: 0.4088 Model_2_loss: 0.3698 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.5764 Model_2_val:0.5847
Epoch: 0220 Model_1_loss: 0.7612 Model_2_loss: 0.7450 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6409 Model_2_val:0.6396
Epoch: 0240 Model_1_loss: 0.7099 Model_2_loss: 0.6662 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6429 Model_2_val:0.6476
Epoch: 0260 Model_1_loss: 0.6606 Model_2_loss: 0.6364 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6589 Model_2_val:0.6519
Epoch: 0280 Model_1_loss: 0.6162 Model_2_loss: 0.6101 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6556 Model_2_val:0.6672
Epoch: 0300 Model_1_loss: 0.5217 Model_2_loss: 0.5310 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6686 Model_2_val:0.6556
Epoch: 0320 Model_1_loss: 0.5313 Model_2_loss: 0.5352 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6626 Model_2_val:0.6632
Epoch: 0340 Model_1_loss: 0.5282 Model_2_loss: 0.5306 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6642 Model_2_val:0.6672
Epoch: 0360 Model_1_loss: 0.4917 Model_2_loss: 0.5121 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6632 Model_2_val:0.6646
Epoch: 0380 Model_1_loss: 0.4813 Model_2_loss: 0.5134 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6656 Model_2_val:0.6502
Epoch: 0400 Model_1_loss: 0.4842 Model_2_loss: 0.5172 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6606 Model_2_val:0.6562
Model_one_test:0.6928 Model_two_test:0.6899
added by two output: 0.6912
Model1 Acc: 0.690613 Model2 Acc: 0.689813
Maxacc Mean: 0.692209
[0.6924372651610259, 0.6927043179398544, 0.6923088360447857, 0.6922086163222224]
Maxacc of all experiments: 0.6927043179398544
1
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
757221973
Epoch: 0020 Model_1_loss: 1.7197 Model_2_loss: 1.6905 Model_1_trainacc: 0.4000 Model_2_trainacc: 0.5333 Model_1_val:0.2976 Model_2_val:0.3396
Epoch: 0040 Model_1_loss: 1.5439 Model_2_loss: 1.4611 Model_1_trainacc: 0.7583 Model_2_trainacc: 0.8083 Model_1_val:0.4140 Model_2_val:0.4583
Epoch: 0060 Model_1_loss: 1.2556 Model_2_loss: 1.1575 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.9000 Model_1_val:0.4641 Model_2_val:0.5314
Epoch: 0080 Model_1_loss: 1.0061 Model_2_loss: 0.8855 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9083 Model_1_val:0.5071 Model_2_val:0.5398
Epoch: 0100 Model_1_loss: 0.8003 Model_2_loss: 0.7002 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9333 Model_1_val:0.5343 Model_2_val:0.5712
Epoch: 0120 Model_1_loss: 0.7072 Model_2_loss: 0.5700 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.5388 Model_2_val:0.5981
Epoch: 0140 Model_1_loss: 0.5830 Model_2_loss: 0.5251 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9250 Model_1_val:0.5484 Model_2_val:0.5898
Epoch: 0160 Model_1_loss: 0.5727 Model_2_loss: 0.4495 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.5369 Model_2_val:0.5943
Epoch: 0180 Model_1_loss: 0.4584 Model_2_loss: 0.4148 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.5638 Model_2_val:0.6001
Epoch: 0200 Model_1_loss: 0.4593 Model_2_loss: 0.3975 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5709 Model_2_val:0.5914
Epoch: 0220 Model_1_loss: 0.8283 Model_2_loss: 0.7170 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6421 Model_2_val:0.6648
Epoch: 0240 Model_1_loss: 0.8008 Model_2_loss: 0.7018 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9917 Model_1_val:0.6555 Model_2_val:0.6700
Epoch: 0260 Model_1_loss: 0.7011 Model_2_loss: 0.6297 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6671 Model_2_val:0.6822
Epoch: 0280 Model_1_loss: 0.6511 Model_2_loss: 0.6190 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6748 Model_2_val:0.6902
Epoch: 0300 Model_1_loss: 0.6102 Model_2_loss: 0.5854 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6863 Model_2_val:0.6838
Epoch: 0320 Model_1_loss: 0.6025 Model_2_loss: 0.5612 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6780 Model_2_val:0.6847
Epoch: 0340 Model_1_loss: 0.5581 Model_2_loss: 0.5341 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6780 Model_2_val:0.6851
Epoch: 0360 Model_1_loss: 0.4904 Model_2_loss: 0.5070 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6835 Model_2_val:0.6860
Epoch: 0380 Model_1_loss: 0.5527 Model_2_loss: 0.5256 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6687 Model_2_val:0.6851
Epoch: 0400 Model_1_loss: 0.5126 Model_2_loss: 0.4847 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6735 Model_2_val:0.6886
Model_one_test:0.7107 Model_two_test:0.7081
added by two output: 0.7097
2
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
125738649
Epoch: 0020 Model_1_loss: 1.7443 Model_2_loss: 1.7346 Model_1_trainacc: 0.4500 Model_2_trainacc: 0.4333 Model_1_val:0.2882 Model_2_val:0.2661
Epoch: 0040 Model_1_loss: 1.5929 Model_2_loss: 1.6054 Model_1_trainacc: 0.6250 Model_2_trainacc: 0.6667 Model_1_val:0.3981 Model_2_val:0.3747
Epoch: 0060 Model_1_loss: 1.2915 Model_2_loss: 1.4057 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.7583 Model_1_val:0.4859 Model_2_val:0.4635
Epoch: 0080 Model_1_loss: 0.9866 Model_2_loss: 1.1201 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8583 Model_1_val:0.5313 Model_2_val:0.5076
Epoch: 0100 Model_1_loss: 0.8029 Model_2_loss: 0.9782 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8833 Model_1_val:0.5527 Model_2_val:0.4998
Epoch: 0120 Model_1_loss: 0.6222 Model_2_loss: 0.7657 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5614 Model_2_val:0.5446
Epoch: 0140 Model_1_loss: 0.5394 Model_2_loss: 0.6019 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5653 Model_2_val:0.5420
Epoch: 0160 Model_1_loss: 0.4582 Model_2_loss: 0.5365 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.5712 Model_2_val:0.5712
Epoch: 0180 Model_1_loss: 0.4293 Model_2_loss: 0.4507 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5828 Model_2_val:0.5569
Epoch: 0200 Model_1_loss: 0.4269 Model_2_loss: 0.3853 Model_1_trainacc: 0.9583 Model_2_trainacc: 1.0000 Model_1_val:0.5870 Model_2_val:0.5747
Epoch: 0220 Model_1_loss: 0.7316 Model_2_loss: 0.7425 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6412 Model_2_val:0.6360
Epoch: 0240 Model_1_loss: 0.6697 Model_2_loss: 0.6771 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6421 Model_2_val:0.6635
Epoch: 0260 Model_1_loss: 0.6305 Model_2_loss: 0.6411 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6467 Model_2_val:0.6438
Epoch: 0280 Model_1_loss: 0.6080 Model_2_loss: 0.5460 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6580 Model_2_val:0.6545
Epoch: 0300 Model_1_loss: 0.5377 Model_2_loss: 0.4949 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6532 Model_2_val:0.6622
Epoch: 0320 Model_1_loss: 0.5983 Model_2_loss: 0.5098 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6590 Model_2_val:0.6626
Epoch: 0340 Model_1_loss: 0.5289 Model_2_loss: 0.5104 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6571 Model_2_val:0.6571
Epoch: 0360 Model_1_loss: 0.4734 Model_2_loss: 0.4448 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6593 Model_2_val:0.6603
Epoch: 0380 Model_1_loss: 0.4682 Model_2_loss: 0.4606 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6476 Model_2_val:0.6564
Epoch: 0400 Model_1_loss: 0.4504 Model_2_loss: 0.4204 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6645 Model_2_val:0.6658
Model_one_test:0.6810 Model_two_test:0.6817
added by two output: 0.6801
3
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1120025585
Epoch: 0020 Model_1_loss: 1.7204 Model_2_loss: 1.7237 Model_1_trainacc: 0.4583 Model_2_trainacc: 0.4917 Model_1_val:0.2555 Model_2_val:0.2733
Epoch: 0040 Model_1_loss: 1.5571 Model_2_loss: 1.5630 Model_1_trainacc: 0.6583 Model_2_trainacc: 0.7250 Model_1_val:0.3940 Model_2_val:0.4037
Epoch: 0060 Model_1_loss: 1.2608 Model_2_loss: 1.2467 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8500 Model_1_val:0.4627 Model_2_val:0.4909
Epoch: 0080 Model_1_loss: 1.0416 Model_2_loss: 1.0085 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8583 Model_1_val:0.4958 Model_2_val:0.5285
Epoch: 0100 Model_1_loss: 0.9066 Model_2_loss: 0.7640 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9333 Model_1_val:0.5292 Model_2_val:0.5613
Epoch: 0120 Model_1_loss: 0.7252 Model_2_loss: 0.6665 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5447 Model_2_val:0.5632
Epoch: 0140 Model_1_loss: 0.6414 Model_2_loss: 0.5666 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5477 Model_2_val:0.5704
Epoch: 0160 Model_1_loss: 0.5503 Model_2_loss: 0.4508 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5743 Model_2_val:0.5927
Epoch: 0180 Model_1_loss: 0.5359 Model_2_loss: 0.4776 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.5791 Model_2_val:0.5982
Epoch: 0200 Model_1_loss: 0.4425 Model_2_loss: 0.4125 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.5950 Model_2_val:0.6057
Epoch: 0220 Model_1_loss: 0.8740 Model_2_loss: 0.8182 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6440 Model_2_val:0.6433
Epoch: 0240 Model_1_loss: 0.7890 Model_2_loss: 0.6929 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6423 Model_2_val:0.6667
Epoch: 0260 Model_1_loss: 0.7300 Model_2_loss: 0.6858 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.6582 Model_2_val:0.6686
Epoch: 0280 Model_1_loss: 0.6903 Model_2_loss: 0.6468 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6621 Model_2_val:0.6634
Epoch: 0300 Model_1_loss: 0.6004 Model_2_loss: 0.6119 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6699 Model_2_val:0.6796
Epoch: 0320 Model_1_loss: 0.6090 Model_2_loss: 0.5799 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6676 Model_2_val:0.6754
Epoch: 0340 Model_1_loss: 0.5563 Model_2_loss: 0.5107 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6696 Model_2_val:0.6783
Epoch: 0360 Model_1_loss: 0.5370 Model_2_loss: 0.4669 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6680 Model_2_val:0.6851
Epoch: 0380 Model_1_loss: 0.5160 Model_2_loss: 0.4627 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6783 Model_2_val:0.6861
Epoch: 0400 Model_1_loss: 0.5213 Model_2_loss: 0.5013 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6680 Model_2_val:0.6790
Model_one_test:0.7104 Model_two_test:0.7101
added by two output: 0.7095
4
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1389131711
Epoch: 0020 Model_1_loss: 1.7344 Model_2_loss: 1.7300 Model_1_trainacc: 0.3167 Model_2_trainacc: 0.2750 Model_1_val:0.2332 Model_2_val:0.2063
Epoch: 0040 Model_1_loss: 1.5630 Model_2_loss: 1.5601 Model_1_trainacc: 0.7000 Model_2_trainacc: 0.6333 Model_1_val:0.3889 Model_2_val:0.3769
Epoch: 0060 Model_1_loss: 1.3323 Model_2_loss: 1.2687 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8000 Model_1_val:0.4679 Model_2_val:0.4919
Epoch: 0080 Model_1_loss: 1.1434 Model_2_loss: 0.9793 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.9000 Model_1_val:0.5062 Model_2_val:0.5434
Epoch: 0100 Model_1_loss: 0.8899 Model_2_loss: 0.7671 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9417 Model_1_val:0.5136 Model_2_val:0.5531
Epoch: 0120 Model_1_loss: 0.7133 Model_2_loss: 0.6059 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9583 Model_1_val:0.5230 Model_2_val:0.5683
Epoch: 0140 Model_1_loss: 0.6430 Model_2_loss: 0.5725 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5515 Model_2_val:0.5903
Epoch: 0160 Model_1_loss: 0.6060 Model_2_loss: 0.5108 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.5725 Model_2_val:0.5829
Epoch: 0180 Model_1_loss: 0.5030 Model_2_loss: 0.4324 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9667 Model_1_val:0.5651 Model_2_val:0.5881
Epoch: 0200 Model_1_loss: 0.4767 Model_2_loss: 0.4005 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9917 Model_1_val:0.5570 Model_2_val:0.5819
Epoch: 0220 Model_1_loss: 0.8864 Model_2_loss: 0.7940 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6344 Model_2_val:0.6354
Epoch: 0240 Model_1_loss: 0.7600 Model_2_loss: 0.7188 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6389 Model_2_val:0.6503
Epoch: 0260 Model_1_loss: 0.7254 Model_2_loss: 0.6291 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6512 Model_2_val:0.6690
Epoch: 0280 Model_1_loss: 0.6441 Model_2_loss: 0.6116 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.6674 Model_2_val:0.6619
Epoch: 0300 Model_1_loss: 0.6716 Model_2_loss: 0.6222 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6580 Model_2_val:0.6739
Epoch: 0320 Model_1_loss: 0.6398 Model_2_loss: 0.6044 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6626 Model_2_val:0.6554
Epoch: 0340 Model_1_loss: 0.6127 Model_2_loss: 0.5666 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6444 Model_2_val:0.6561
Epoch: 0360 Model_1_loss: 0.5619 Model_2_loss: 0.5403 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6499 Model_2_val:0.6684
Epoch: 0380 Model_1_loss: 0.5734 Model_2_loss: 0.4980 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6606 Model_2_val:0.6749
Epoch: 0400 Model_1_loss: 0.5725 Model_2_loss: 0.4753 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6551 Model_2_val:0.6626
Model_one_test:0.6885 Model_two_test:0.6856
added by two output: 0.6878
5
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
773616695
Epoch: 0020 Model_1_loss: 1.6923 Model_2_loss: 1.6983 Model_1_trainacc: 0.5250 Model_2_trainacc: 0.4667 Model_1_val:0.3078 Model_2_val:0.2487
Epoch: 0040 Model_1_loss: 1.4072 Model_2_loss: 1.4953 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.7333 Model_1_val:0.4425 Model_2_val:0.3915
Epoch: 0060 Model_1_loss: 1.1131 Model_2_loss: 1.1836 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8750 Model_1_val:0.5255 Model_2_val:0.5353
Epoch: 0080 Model_1_loss: 0.8335 Model_2_loss: 0.8643 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9000 Model_1_val:0.5322 Model_2_val:0.5741
Epoch: 0100 Model_1_loss: 0.6410 Model_2_loss: 0.6941 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5714 Model_2_val:0.5899
Epoch: 0120 Model_1_loss: 0.5692 Model_2_loss: 0.5387 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5923 Model_2_val:0.6001
Epoch: 0140 Model_1_loss: 0.5145 Model_2_loss: 0.4973 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.5906 Model_2_val:0.6058
Epoch: 0160 Model_1_loss: 0.4393 Model_2_loss: 0.4841 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.6061 Model_2_val:0.6271
Epoch: 0180 Model_1_loss: 0.4136 Model_2_loss: 0.3678 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6129 Model_2_val:0.6250
Epoch: 0200 Model_1_loss: 0.4154 Model_2_loss: 0.3487 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.6136 Model_2_val:0.6186
Epoch: 0220 Model_1_loss: 0.6840 Model_2_loss: 0.6698 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6763 Model_2_val:0.6936
Epoch: 0240 Model_1_loss: 0.6211 Model_2_loss: 0.6159 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6936 Model_2_val:0.7057
Epoch: 0260 Model_1_loss: 0.5904 Model_2_loss: 0.5830 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6902 Model_2_val:0.6946
Epoch: 0280 Model_1_loss: 0.5562 Model_2_loss: 0.5718 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6841 Model_2_val:0.6942
Epoch: 0300 Model_1_loss: 0.5176 Model_2_loss: 0.5408 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6865 Model_2_val:0.6851
Epoch: 0320 Model_1_loss: 0.5241 Model_2_loss: 0.5073 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6814 Model_2_val:0.6912
Epoch: 0340 Model_1_loss: 0.5024 Model_2_loss: 0.4389 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6871 Model_2_val:0.6878
Epoch: 0360 Model_1_loss: 0.4491 Model_2_loss: 0.4640 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6939 Model_2_val:0.6996
Epoch: 0380 Model_1_loss: 0.4691 Model_2_loss: 0.4772 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6882 Model_2_val:0.6922
Epoch: 0400 Model_1_loss: 0.4085 Model_2_loss: 0.4748 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6932 Model_2_val:0.6871
Model_one_test:0.7185 Model_two_test:0.7128
added by two output: 0.7138
6
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
646887753
Epoch: 0020 Model_1_loss: 1.7084 Model_2_loss: 1.7263 Model_1_trainacc: 0.4000 Model_2_trainacc: 0.4083 Model_1_val:0.2916 Model_2_val:0.1852
Epoch: 0040 Model_1_loss: 1.5108 Model_2_loss: 1.5623 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.7167 Model_1_val:0.4009 Model_2_val:0.3811
Epoch: 0060 Model_1_loss: 1.2270 Model_2_loss: 1.2931 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.7917 Model_1_val:0.5005 Model_2_val:0.4862
Epoch: 0080 Model_1_loss: 0.9032 Model_2_loss: 0.9725 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8917 Model_1_val:0.5300 Model_2_val:0.5092
Epoch: 0100 Model_1_loss: 0.7348 Model_2_loss: 0.7846 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9000 Model_1_val:0.5440 Model_2_val:0.5462
Epoch: 0120 Model_1_loss: 0.5984 Model_2_loss: 0.6175 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.5634 Model_2_val:0.5634
Epoch: 0140 Model_1_loss: 0.5032 Model_2_loss: 0.5265 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5848 Model_2_val:0.5712
Epoch: 0160 Model_1_loss: 0.4762 Model_2_loss: 0.5151 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5777 Model_2_val:0.5650
Epoch: 0180 Model_1_loss: 0.4305 Model_2_loss: 0.4822 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6040 Model_2_val:0.5913
Epoch: 0200 Model_1_loss: 0.3898 Model_2_loss: 0.4272 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.5923 Model_2_val:0.5848
Epoch: 0220 Model_1_loss: 0.7248 Model_2_loss: 0.7233 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6653 Model_2_val:0.6552
Epoch: 0240 Model_1_loss: 0.6794 Model_2_loss: 0.7065 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6662 Model_2_val:0.6662
Epoch: 0260 Model_1_loss: 0.6161 Model_2_loss: 0.7055 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6747 Model_2_val:0.6653
Epoch: 0280 Model_1_loss: 0.6511 Model_2_loss: 0.5944 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6776 Model_2_val:0.6643
Epoch: 0300 Model_1_loss: 0.5761 Model_2_loss: 0.5349 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6769 Model_2_val:0.6695
Epoch: 0320 Model_1_loss: 0.5469 Model_2_loss: 0.5450 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6724 Model_2_val:0.6698
Epoch: 0340 Model_1_loss: 0.5120 Model_2_loss: 0.5330 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6717 Model_2_val:0.6646
Epoch: 0360 Model_1_loss: 0.5064 Model_2_loss: 0.5427 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6656 Model_2_val:0.6630
Epoch: 0380 Model_1_loss: 0.4902 Model_2_loss: 0.5113 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6763 Model_2_val:0.6727
Epoch: 0400 Model_1_loss: 0.5193 Model_2_loss: 0.5418 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6769 Model_2_val:0.6760
Model_one_test:0.7019 Model_two_test:0.7006
added by two output: 0.7013
7
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1532560723
Epoch: 0020 Model_1_loss: 1.7175 Model_2_loss: 1.7119 Model_1_trainacc: 0.3583 Model_2_trainacc: 0.4917 Model_1_val:0.2860 Model_2_val:0.2544
Epoch: 0040 Model_1_loss: 1.5251 Model_2_loss: 1.5403 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.7917 Model_1_val:0.4260 Model_2_val:0.4148
Epoch: 0060 Model_1_loss: 1.2094 Model_2_loss: 1.2090 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8667 Model_1_val:0.5255 Model_2_val:0.5104
Epoch: 0080 Model_1_loss: 0.9400 Model_2_loss: 0.9444 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8667 Model_1_val:0.5387 Model_2_val:0.5410
Epoch: 0100 Model_1_loss: 0.7445 Model_2_loss: 0.7138 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.5479 Model_2_val:0.5766
Epoch: 0120 Model_1_loss: 0.6180 Model_2_loss: 0.6187 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5661 Model_2_val:0.5753
Epoch: 0140 Model_1_loss: 0.5728 Model_2_loss: 0.5077 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9500 Model_1_val:0.5654 Model_2_val:0.5700
Epoch: 0160 Model_1_loss: 0.4829 Model_2_loss: 0.4504 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5796 Model_2_val:0.5878
Epoch: 0180 Model_1_loss: 0.4640 Model_2_loss: 0.4198 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5651 Model_2_val:0.5842
Epoch: 0200 Model_1_loss: 0.4405 Model_2_loss: 0.3975 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5832 Model_2_val:0.5934
Epoch: 0220 Model_1_loss: 0.7831 Model_2_loss: 0.7561 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6382 Model_2_val:0.6458
Epoch: 0240 Model_1_loss: 0.6791 Model_2_loss: 0.6446 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6415 Model_2_val:0.6511
Epoch: 0260 Model_1_loss: 0.6158 Model_2_loss: 0.6221 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6484 Model_2_val:0.6586
Epoch: 0280 Model_1_loss: 0.5865 Model_2_loss: 0.6072 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6610 Model_2_val:0.6527
Epoch: 0300 Model_1_loss: 0.5764 Model_2_loss: 0.6053 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6498 Model_2_val:0.6603
Epoch: 0320 Model_1_loss: 0.5016 Model_2_loss: 0.4851 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6596 Model_2_val:0.6603
Epoch: 0340 Model_1_loss: 0.5145 Model_2_loss: 0.4988 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6600 Model_2_val:0.6629
Epoch: 0360 Model_1_loss: 0.5147 Model_2_loss: 0.4996 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6567 Model_2_val:0.6596
Epoch: 0380 Model_1_loss: 0.4366 Model_2_loss: 0.5143 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6586 Model_2_val:0.6540
Epoch: 0400 Model_1_loss: 0.4303 Model_2_loss: 0.4976 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6708 Model_2_val:0.6603
Model_one_test:0.6797 Model_two_test:0.6830
added by two output: 0.6811
8
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
387520932
Epoch: 0020 Model_1_loss: 1.7244 Model_2_loss: 1.7035 Model_1_trainacc: 0.3833 Model_2_trainacc: 0.4917 Model_1_val:0.2685 Model_2_val:0.2628
Epoch: 0040 Model_1_loss: 1.5523 Model_2_loss: 1.5385 Model_1_trainacc: 0.6917 Model_2_trainacc: 0.7583 Model_1_val:0.3793 Model_2_val:0.4231
Epoch: 0060 Model_1_loss: 1.2701 Model_2_loss: 1.1878 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.9000 Model_1_val:0.4748 Model_2_val:0.5093
Epoch: 0080 Model_1_loss: 0.9681 Model_2_loss: 0.8944 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9083 Model_1_val:0.5125 Model_2_val:0.5469
Epoch: 0100 Model_1_loss: 0.8015 Model_2_loss: 0.7525 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9083 Model_1_val:0.5351 Model_2_val:0.5680
Epoch: 0120 Model_1_loss: 0.6810 Model_2_loss: 0.5833 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.5434 Model_2_val:0.5760
Epoch: 0140 Model_1_loss: 0.5963 Model_2_loss: 0.4752 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5543 Model_2_val:0.5856
Epoch: 0160 Model_1_loss: 0.5200 Model_2_loss: 0.4754 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9917 Model_1_val:0.5808 Model_2_val:0.5904
Epoch: 0180 Model_1_loss: 0.4382 Model_2_loss: 0.4458 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5616 Model_2_val:0.5862
Epoch: 0200 Model_1_loss: 0.4604 Model_2_loss: 0.4228 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5750 Model_2_val:0.5913
Epoch: 0220 Model_1_loss: 0.7955 Model_2_loss: 0.7058 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6593 Model_2_val:0.6625
Epoch: 0240 Model_1_loss: 0.7130 Model_2_loss: 0.6911 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6683 Model_2_val:0.6782
Epoch: 0260 Model_1_loss: 0.6829 Model_2_loss: 0.6291 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6689 Model_2_val:0.6836
Epoch: 0280 Model_1_loss: 0.6619 Model_2_loss: 0.5990 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6574 Model_2_val:0.6798
Epoch: 0300 Model_1_loss: 0.6208 Model_2_loss: 0.5807 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6667 Model_2_val:0.6791
Epoch: 0320 Model_1_loss: 0.6692 Model_2_loss: 0.5579 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6785 Model_2_val:0.6852
Epoch: 0340 Model_1_loss: 0.5944 Model_2_loss: 0.5592 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6830 Model_2_val:0.6759
Epoch: 0360 Model_1_loss: 0.5365 Model_2_loss: 0.4952 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6772 Model_2_val:0.6826
Epoch: 0380 Model_1_loss: 0.5464 Model_2_loss: 0.5490 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6772 Model_2_val:0.6845
Epoch: 0400 Model_1_loss: 0.5593 Model_2_loss: 0.5638 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6724 Model_2_val:0.6801
Model_one_test:0.7091 Model_two_test:0.7098
added by two output: 0.7117
9
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1250011111
Epoch: 0020 Model_1_loss: 1.6865 Model_2_loss: 1.7557 Model_1_trainacc: 0.4417 Model_2_trainacc: 0.2917 Model_1_val:0.2743 Model_2_val:0.2400
Epoch: 0040 Model_1_loss: 1.4529 Model_2_loss: 1.6548 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.6667 Model_1_val:0.4453 Model_2_val:0.3914
Epoch: 0060 Model_1_loss: 1.1365 Model_2_loss: 1.3388 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8333 Model_1_val:0.5194 Model_2_val:0.4950
Epoch: 0080 Model_1_loss: 0.8494 Model_2_loss: 1.0158 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8667 Model_1_val:0.5627 Model_2_val:0.5630
Epoch: 0100 Model_1_loss: 0.6882 Model_2_loss: 0.8281 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.8833 Model_1_val:0.5813 Model_2_val:0.5807
Epoch: 0120 Model_1_loss: 0.5561 Model_2_loss: 0.6438 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9000 Model_1_val:0.6028 Model_2_val:0.5958
Epoch: 0140 Model_1_loss: 0.5082 Model_2_loss: 0.5062 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5999 Model_2_val:0.5897
Epoch: 0160 Model_1_loss: 0.4588 Model_2_loss: 0.4649 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5977 Model_2_val:0.5999
Epoch: 0180 Model_1_loss: 0.4010 Model_2_loss: 0.4218 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6128 Model_2_val:0.5967
Epoch: 0200 Model_1_loss: 0.3881 Model_2_loss: 0.3768 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.5990 Model_2_val:0.6022
Epoch: 0220 Model_1_loss: 0.6944 Model_2_loss: 0.7231 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6615 Model_2_val:0.6545
Epoch: 0240 Model_1_loss: 0.6402 Model_2_loss: 0.7056 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6728 Model_2_val:0.6673
Epoch: 0260 Model_1_loss: 0.6396 Model_2_loss: 0.6707 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6551 Model_2_val:0.6615
Epoch: 0280 Model_1_loss: 0.5869 Model_2_loss: 0.6212 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6676 Model_2_val:0.6631
Epoch: 0300 Model_1_loss: 0.5595 Model_2_loss: 0.6006 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6670 Model_2_val:0.6667
Epoch: 0320 Model_1_loss: 0.5995 Model_2_loss: 0.5762 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6766 Model_2_val:0.6625
Epoch: 0340 Model_1_loss: 0.5234 Model_2_loss: 0.5249 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6596 Model_2_val:0.6609
Epoch: 0360 Model_1_loss: 0.5037 Model_2_loss: 0.5170 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6740 Model_2_val:0.6660
Epoch: 0380 Model_1_loss: 0.4886 Model_2_loss: 0.4839 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6654 Model_2_val:0.6651
Epoch: 0400 Model_1_loss: 0.5041 Model_2_loss: 0.4820 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6583 Model_2_val:0.6628
Model_one_test:0.6907 Model_two_test:0.6853
added by two output: 0.6891
10
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1540345131
Epoch: 0020 Model_1_loss: 1.7488 Model_2_loss: 1.7270 Model_1_trainacc: 0.3250 Model_2_trainacc: 0.4833 Model_1_val:0.2437 Model_2_val:0.3450
Epoch: 0040 Model_1_loss: 1.6137 Model_2_loss: 1.5568 Model_1_trainacc: 0.6417 Model_2_trainacc: 0.7417 Model_1_val:0.3506 Model_2_val:0.4684
Epoch: 0060 Model_1_loss: 1.4312 Model_2_loss: 1.2398 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.8083 Model_1_val:0.4093 Model_2_val:0.4979
Epoch: 0080 Model_1_loss: 1.1871 Model_2_loss: 0.9940 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8667 Model_1_val:0.4920 Model_2_val:0.5264
Epoch: 0100 Model_1_loss: 0.8884 Model_2_loss: 0.7696 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9167 Model_1_val:0.5356 Model_2_val:0.5644
Epoch: 0120 Model_1_loss: 0.7373 Model_2_loss: 0.6584 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.5595 Model_2_val:0.5487
Epoch: 0140 Model_1_loss: 0.5968 Model_2_loss: 0.5391 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.5749 Model_2_val:0.5835
Epoch: 0160 Model_1_loss: 0.5862 Model_2_loss: 0.4751 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.5818 Model_2_val:0.5848
Epoch: 0180 Model_1_loss: 0.5009 Model_2_loss: 0.4767 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.5995 Model_2_val:0.5966
Epoch: 0200 Model_1_loss: 0.4465 Model_2_loss: 0.4276 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5897 Model_2_val:0.5900
Epoch: 0220 Model_1_loss: 0.8242 Model_2_loss: 0.7097 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.6428 Model_2_val:0.6448
Epoch: 0240 Model_1_loss: 0.7179 Model_2_loss: 0.6831 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6451 Model_2_val:0.6602
Epoch: 0260 Model_1_loss: 0.6668 Model_2_loss: 0.6172 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6605 Model_2_val:0.6651
Epoch: 0280 Model_1_loss: 0.6319 Model_2_loss: 0.5696 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6579 Model_2_val:0.6727
Epoch: 0300 Model_1_loss: 0.6419 Model_2_loss: 0.5709 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6605 Model_2_val:0.6615
Epoch: 0320 Model_1_loss: 0.5445 Model_2_loss: 0.5551 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6573 Model_2_val:0.6717
Epoch: 0340 Model_1_loss: 0.5648 Model_2_loss: 0.5223 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6664 Model_2_val:0.6769
Epoch: 0360 Model_1_loss: 0.5601 Model_2_loss: 0.5124 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.6576 Model_2_val:0.6697
Epoch: 0380 Model_1_loss: 0.4901 Model_2_loss: 0.4665 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6625 Model_2_val:0.6694
Epoch: 0400 Model_1_loss: 0.5483 Model_2_loss: 0.4463 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.6760 Model_2_val:0.6730
Model_one_test:0.6963 Model_two_test:0.6969
added by two output: 0.6976
11
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
438818927
Epoch: 0020 Model_1_loss: 1.7251 Model_2_loss: 1.6681 Model_1_trainacc: 0.3833 Model_2_trainacc: 0.5667 Model_1_val:0.2481 Model_2_val:0.2970
Epoch: 0040 Model_1_loss: 1.5333 Model_2_loss: 1.3575 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.9000 Model_1_val:0.4486 Model_2_val:0.4781
Epoch: 0060 Model_1_loss: 1.2231 Model_2_loss: 0.9950 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9167 Model_1_val:0.4940 Model_2_val:0.5549
Epoch: 0080 Model_1_loss: 0.9332 Model_2_loss: 0.7852 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9250 Model_1_val:0.5276 Model_2_val:0.5568
Epoch: 0100 Model_1_loss: 0.7329 Model_2_loss: 0.6466 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9250 Model_1_val:0.5622 Model_2_val:0.5660
Epoch: 0120 Model_1_loss: 0.6095 Model_2_loss: 0.5086 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.5654 Model_2_val:0.6037
Epoch: 0140 Model_1_loss: 0.5780 Model_2_loss: 0.4856 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5606 Model_2_val:0.6177
Epoch: 0160 Model_1_loss: 0.4781 Model_2_loss: 0.4241 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.5844 Model_2_val:0.5863
Epoch: 0180 Model_1_loss: 0.4527 Model_2_loss: 0.3623 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.5714 Model_2_val:0.5930
Epoch: 0200 Model_1_loss: 0.4119 Model_2_loss: 0.3884 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.5876 Model_2_val:0.6168
Epoch: 0220 Model_1_loss: 0.7420 Model_2_loss: 0.6953 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6399 Model_2_val:0.6529
Epoch: 0240 Model_1_loss: 0.6424 Model_2_loss: 0.6445 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6532 Model_2_val:0.6574
Epoch: 0260 Model_1_loss: 0.6102 Model_2_loss: 0.5958 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6456 Model_2_val:0.6520
Epoch: 0280 Model_1_loss: 0.5712 Model_2_loss: 0.5440 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6516 Model_2_val:0.6526
Epoch: 0300 Model_1_loss: 0.5729 Model_2_loss: 0.5324 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6520 Model_2_val:0.6542
Epoch: 0320 Model_1_loss: 0.5390 Model_2_loss: 0.5372 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6501 Model_2_val:0.6548
Epoch: 0340 Model_1_loss: 0.4902 Model_2_loss: 0.4836 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6577 Model_2_val:0.6551
Epoch: 0360 Model_1_loss: 0.5009 Model_2_loss: 0.4628 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6561 Model_2_val:0.6551
Epoch: 0380 Model_1_loss: 0.5173 Model_2_loss: 0.4609 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6516 Model_2_val:0.6548
Epoch: 0400 Model_1_loss: 0.4657 Model_2_loss: 0.4663 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6516 Model_2_val:0.6570
Model_one_test:0.6729 Model_two_test:0.6726
added by two output: 0.6720
12
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
904693707
Epoch: 0020 Model_1_loss: 1.7227 Model_2_loss: 1.7482 Model_1_trainacc: 0.4167 Model_2_trainacc: 0.3167 Model_1_val:0.2678 Model_2_val:0.2437
Epoch: 0040 Model_1_loss: 1.5734 Model_2_loss: 1.6296 Model_1_trainacc: 0.7583 Model_2_trainacc: 0.6333 Model_1_val:0.4326 Model_2_val:0.3945
Epoch: 0060 Model_1_loss: 1.3067 Model_2_loss: 1.3902 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8000 Model_1_val:0.4590 Model_2_val:0.4764
Epoch: 0080 Model_1_loss: 1.0839 Model_2_loss: 1.1261 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8250 Model_1_val:0.4962 Model_2_val:0.4908
Epoch: 0100 Model_1_loss: 0.8548 Model_2_loss: 0.9367 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8750 Model_1_val:0.5172 Model_2_val:0.5249
Epoch: 0120 Model_1_loss: 0.7662 Model_2_loss: 0.8050 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8500 Model_1_val:0.5293 Model_2_val:0.5520
Epoch: 0140 Model_1_loss: 0.6923 Model_2_loss: 0.6905 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9250 Model_1_val:0.5493 Model_2_val:0.5476
Epoch: 0160 Model_1_loss: 0.5597 Model_2_loss: 0.5742 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5527 Model_2_val:0.5664
Epoch: 0180 Model_1_loss: 0.5709 Model_2_loss: 0.5787 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9083 Model_1_val:0.5614 Model_2_val:0.5720
Epoch: 0200 Model_1_loss: 0.4879 Model_2_loss: 0.5188 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9333 Model_1_val:0.5600 Model_2_val:0.5680
Epoch: 0220 Model_1_loss: 0.8462 Model_2_loss: 0.8348 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6302 Model_2_val:0.6336
Epoch: 0240 Model_1_loss: 0.7567 Model_2_loss: 0.8023 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6489 Model_2_val:0.6419
Epoch: 0260 Model_1_loss: 0.6824 Model_2_loss: 0.6960 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6483 Model_2_val:0.6426
Epoch: 0280 Model_1_loss: 0.6750 Model_2_loss: 0.6903 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6550 Model_2_val:0.6426
Epoch: 0300 Model_1_loss: 0.5949 Model_2_loss: 0.6211 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6583 Model_2_val:0.6643
Epoch: 0320 Model_1_loss: 0.6151 Model_2_loss: 0.6105 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6596 Model_2_val:0.6643
Epoch: 0340 Model_1_loss: 0.5468 Model_2_loss: 0.5853 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6580 Model_2_val:0.6596
Epoch: 0360 Model_1_loss: 0.5092 Model_2_loss: 0.5389 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6600 Model_2_val:0.6620
Epoch: 0380 Model_1_loss: 0.5719 Model_2_loss: 0.5550 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6603 Model_2_val:0.6566
Epoch: 0400 Model_1_loss: 0.5145 Model_2_loss: 0.5077 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6476 Model_2_val:0.6496
Model_one_test:0.6760 Model_two_test:0.6794
added by two output: 0.6780
13
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
435220438
Epoch: 0020 Model_1_loss: 1.7603 Model_2_loss: 1.7385 Model_1_trainacc: 0.2917 Model_2_trainacc: 0.3500 Model_1_val:0.1483 Model_2_val:0.2159
Epoch: 0040 Model_1_loss: 1.6304 Model_2_loss: 1.5958 Model_1_trainacc: 0.6833 Model_2_trainacc: 0.7000 Model_1_val:0.3597 Model_2_val:0.3996
Epoch: 0060 Model_1_loss: 1.4058 Model_2_loss: 1.3738 Model_1_trainacc: 0.7250 Model_2_trainacc: 0.7917 Model_1_val:0.4579 Model_2_val:0.4373
Epoch: 0080 Model_1_loss: 1.0504 Model_2_loss: 1.0841 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8750 Model_1_val:0.5167 Model_2_val:0.4929
Epoch: 0100 Model_1_loss: 0.8343 Model_2_loss: 0.8939 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8417 Model_1_val:0.5183 Model_2_val:0.5064
Epoch: 0120 Model_1_loss: 0.7576 Model_2_loss: 0.7769 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8750 Model_1_val:0.5402 Model_2_val:0.5251
Epoch: 0140 Model_1_loss: 0.6071 Model_2_loss: 0.5988 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5489 Model_2_val:0.5306
Epoch: 0160 Model_1_loss: 0.6155 Model_2_loss: 0.5611 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9167 Model_1_val:0.5335 Model_2_val:0.5528
Epoch: 0180 Model_1_loss: 0.5109 Model_2_loss: 0.4778 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9333 Model_1_val:0.5370 Model_2_val:0.5660
Epoch: 0200 Model_1_loss: 0.4601 Model_2_loss: 0.4303 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9583 Model_1_val:0.5508 Model_2_val:0.5499
Epoch: 0220 Model_1_loss: 0.8016 Model_2_loss: 0.8230 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9333 Model_1_val:0.6239 Model_2_val:0.6287
Epoch: 0240 Model_1_loss: 0.8627 Model_2_loss: 0.7810 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.6454 Model_2_val:0.6509
Epoch: 0260 Model_1_loss: 0.7137 Model_2_loss: 0.7010 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6264 Model_2_val:0.6458
Epoch: 0280 Model_1_loss: 0.6701 Model_2_loss: 0.6634 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6390 Model_2_val:0.6609
Epoch: 0300 Model_1_loss: 0.6852 Model_2_loss: 0.6417 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6441 Model_2_val:0.6609
Epoch: 0320 Model_1_loss: 0.6330 Model_2_loss: 0.6458 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6441 Model_2_val:0.6503
Epoch: 0340 Model_1_loss: 0.5871 Model_2_loss: 0.5584 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6441 Model_2_val:0.6567
Epoch: 0360 Model_1_loss: 0.5870 Model_2_loss: 0.5777 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6364 Model_2_val:0.6538
Epoch: 0380 Model_1_loss: 0.6208 Model_2_loss: 0.5716 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6461 Model_2_val:0.6509
Epoch: 0400 Model_1_loss: 0.5652 Model_2_loss: 0.5060 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6458 Model_2_val:0.6612
Model_one_test:0.6815 Model_two_test:0.6770
added by two output: 0.6792
14
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
938980944
Epoch: 0020 Model_1_loss: 1.7413 Model_2_loss: 1.7174 Model_1_trainacc: 0.3083 Model_2_trainacc: 0.3917 Model_1_val:0.2216 Model_2_val:0.1425
Epoch: 0040 Model_1_loss: 1.5907 Model_2_loss: 1.5382 Model_1_trainacc: 0.6500 Model_2_trainacc: 0.7833 Model_1_val:0.3514 Model_2_val:0.4394
Epoch: 0060 Model_1_loss: 1.2775 Model_2_loss: 1.2431 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8500 Model_1_val:0.4792 Model_2_val:0.4796
Epoch: 0080 Model_1_loss: 0.9944 Model_2_loss: 0.9235 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8667 Model_1_val:0.5201 Model_2_val:0.5345
Epoch: 0100 Model_1_loss: 0.7909 Model_2_loss: 0.7590 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9333 Model_1_val:0.5378 Model_2_val:0.5433
Epoch: 0120 Model_1_loss: 0.6796 Model_2_loss: 0.5605 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9417 Model_1_val:0.5564 Model_2_val:0.5688
Epoch: 0140 Model_1_loss: 0.6097 Model_2_loss: 0.5426 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9167 Model_1_val:0.5548 Model_2_val:0.5597
Epoch: 0160 Model_1_loss: 0.5199 Model_2_loss: 0.4418 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9917 Model_1_val:0.5659 Model_2_val:0.5819
Epoch: 0180 Model_1_loss: 0.4967 Model_2_loss: 0.3984 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5819 Model_2_val:0.6071
Epoch: 0200 Model_1_loss: 0.5120 Model_2_loss: 0.4024 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.5665 Model_2_val:0.5783
Epoch: 0220 Model_1_loss: 0.8042 Model_2_loss: 0.6793 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6293 Model_2_val:0.6584
Epoch: 0240 Model_1_loss: 0.7367 Model_2_loss: 0.7092 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6414 Model_2_val:0.6483
Epoch: 0260 Model_1_loss: 0.6986 Model_2_loss: 0.6600 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6401 Model_2_val:0.6522
Epoch: 0280 Model_1_loss: 0.7255 Model_2_loss: 0.5594 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.6453 Model_2_val:0.6620
Epoch: 0300 Model_1_loss: 0.6243 Model_2_loss: 0.5621 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6525 Model_2_val:0.6558
Epoch: 0320 Model_1_loss: 0.6671 Model_2_loss: 0.5685 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6525 Model_2_val:0.6561
Epoch: 0340 Model_1_loss: 0.5768 Model_2_loss: 0.5289 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6554 Model_2_val:0.6587
Epoch: 0360 Model_1_loss: 0.6047 Model_2_loss: 0.5130 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6512 Model_2_val:0.6564
Epoch: 0380 Model_1_loss: 0.5598 Model_2_loss: 0.5251 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6528 Model_2_val:0.6590
Epoch: 0400 Model_1_loss: 0.6010 Model_2_loss: 0.4994 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6518 Model_2_val:0.6600
Model_one_test:0.6737 Model_two_test:0.6780
added by two output: 0.6751
15
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1484486112
Epoch: 0020 Model_1_loss: 1.7343 Model_2_loss: 1.7205 Model_1_trainacc: 0.4500 Model_2_trainacc: 0.3250 Model_1_val:0.2708 Model_2_val:0.2147
Epoch: 0040 Model_1_loss: 1.5816 Model_2_loss: 1.5022 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.8083 Model_1_val:0.4259 Model_2_val:0.4439
Epoch: 0060 Model_1_loss: 1.2855 Model_2_loss: 1.1445 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8833 Model_1_val:0.4533 Model_2_val:0.5139
Epoch: 0080 Model_1_loss: 1.0257 Model_2_loss: 0.8879 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9333 Model_1_val:0.5193 Model_2_val:0.5422
Epoch: 0100 Model_1_loss: 0.7898 Model_2_loss: 0.6816 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5471 Model_2_val:0.5722
Epoch: 0120 Model_1_loss: 0.7422 Model_2_loss: 0.5531 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9667 Model_1_val:0.5638 Model_2_val:0.5677
Epoch: 0140 Model_1_loss: 0.5923 Model_2_loss: 0.5311 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.5619 Model_2_val:0.5635
Epoch: 0160 Model_1_loss: 0.5171 Model_2_loss: 0.4552 Model_1_trainacc: 0.9417 Model_2_trainacc: 1.0000 Model_1_val:0.5787 Model_2_val:0.5967
Epoch: 0180 Model_1_loss: 0.4820 Model_2_loss: 0.4068 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5748 Model_2_val:0.5977
Epoch: 0200 Model_1_loss: 0.4270 Model_2_loss: 0.3622 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.5928 Model_2_val:0.5974
Epoch: 0220 Model_1_loss: 0.7773 Model_2_loss: 0.7566 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6680 Model_2_val:0.6770
Epoch: 0240 Model_1_loss: 0.7234 Model_2_loss: 0.7228 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6660 Model_2_val:0.6718
Epoch: 0260 Model_1_loss: 0.6514 Model_2_loss: 0.6098 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6789 Model_2_val:0.6786
Epoch: 0280 Model_1_loss: 0.5812 Model_2_loss: 0.5789 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6770 Model_2_val:0.6757
Epoch: 0300 Model_1_loss: 0.6059 Model_2_loss: 0.5586 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6757 Model_2_val:0.6802
Epoch: 0320 Model_1_loss: 0.5151 Model_2_loss: 0.5241 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6912 Model_2_val:0.6889
Epoch: 0340 Model_1_loss: 0.4676 Model_2_loss: 0.5363 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6792 Model_2_val:0.6760
Epoch: 0360 Model_1_loss: 0.5110 Model_2_loss: 0.4887 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6818 Model_2_val:0.6847
Epoch: 0380 Model_1_loss: 0.4940 Model_2_loss: 0.4908 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6783 Model_2_val:0.6854
Epoch: 0400 Model_1_loss: 0.4512 Model_2_loss: 0.4463 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6831 Model_2_val:0.6805
Model_one_test:0.7108 Model_two_test:0.7092
added by two output: 0.7108
16
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1423678424
Epoch: 0020 Model_1_loss: 1.7110 Model_2_loss: 1.7454 Model_1_trainacc: 0.5000 Model_2_trainacc: 0.4000 Model_1_val:0.2671 Model_2_val:0.2190
Epoch: 0040 Model_1_loss: 1.5018 Model_2_loss: 1.5714 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8083 Model_1_val:0.4637 Model_2_val:0.4358
Epoch: 0060 Model_1_loss: 1.2121 Model_2_loss: 1.2327 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.9000 Model_1_val:0.5085 Model_2_val:0.5165
Epoch: 0080 Model_1_loss: 0.9415 Model_2_loss: 0.8733 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8917 Model_1_val:0.5363 Model_2_val:0.5594
Epoch: 0100 Model_1_loss: 0.6923 Model_2_loss: 0.6679 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.5591 Model_2_val:0.5757
Epoch: 0120 Model_1_loss: 0.5724 Model_2_loss: 0.5506 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.5959 Model_2_val:0.5994
Epoch: 0140 Model_1_loss: 0.4690 Model_2_loss: 0.5399 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.5892 Model_2_val:0.6023
Epoch: 0160 Model_1_loss: 0.4890 Model_2_loss: 0.4408 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.5994 Model_2_val:0.6151
Epoch: 0180 Model_1_loss: 0.4764 Model_2_loss: 0.4166 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6013 Model_2_val:0.6074
Epoch: 0200 Model_1_loss: 0.3818 Model_2_loss: 0.4052 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6036 Model_2_val:0.6110
Epoch: 0220 Model_1_loss: 0.6740 Model_2_loss: 0.6901 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6625 Model_2_val:0.6603
Epoch: 0240 Model_1_loss: 0.6634 Model_2_loss: 0.6480 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6676 Model_2_val:0.6724
Epoch: 0260 Model_1_loss: 0.6224 Model_2_loss: 0.5665 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6734 Model_2_val:0.6808
Epoch: 0280 Model_1_loss: 0.5599 Model_2_loss: 0.5638 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6808 Model_2_val:0.6766
Epoch: 0300 Model_1_loss: 0.5377 Model_2_loss: 0.5797 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6779 Model_2_val:0.6721
Epoch: 0320 Model_1_loss: 0.5227 Model_2_loss: 0.5028 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6782 Model_2_val:0.6756
Epoch: 0340 Model_1_loss: 0.4964 Model_2_loss: 0.4833 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6772 Model_2_val:0.6798
Epoch: 0360 Model_1_loss: 0.4404 Model_2_loss: 0.4596 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6788 Model_2_val:0.6744
Epoch: 0380 Model_1_loss: 0.4557 Model_2_loss: 0.4881 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6705 Model_2_val:0.6715
Epoch: 0400 Model_1_loss: 0.4485 Model_2_loss: 0.4702 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6750 Model_2_val:0.6724
Model_one_test:0.6929 Model_two_test:0.6955
added by two output: 0.6948
17
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
109159209
Epoch: 0020 Model_1_loss: 1.6835 Model_2_loss: 1.6600 Model_1_trainacc: 0.5167 Model_2_trainacc: 0.5417 Model_1_val:0.3157 Model_2_val:0.3261
Epoch: 0040 Model_1_loss: 1.4579 Model_2_loss: 1.3961 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8167 Model_1_val:0.4969 Model_2_val:0.4651
Epoch: 0060 Model_1_loss: 1.0997 Model_2_loss: 1.0594 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8833 Model_1_val:0.5258 Model_2_val:0.5151
Epoch: 0080 Model_1_loss: 0.8309 Model_2_loss: 0.8038 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9250 Model_1_val:0.5615 Model_2_val:0.5336
Epoch: 0100 Model_1_loss: 0.6083 Model_2_loss: 0.6512 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.5771 Model_2_val:0.5625
Epoch: 0120 Model_1_loss: 0.5401 Model_2_loss: 0.5155 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.5736 Model_2_val:0.5635
Epoch: 0140 Model_1_loss: 0.4736 Model_2_loss: 0.4858 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.5885 Model_2_val:0.5658
Epoch: 0160 Model_1_loss: 0.4301 Model_2_loss: 0.4653 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.5781 Model_2_val:0.5726
Epoch: 0180 Model_1_loss: 0.3728 Model_2_loss: 0.3785 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.5856 Model_2_val:0.5797
Epoch: 0200 Model_1_loss: 0.3825 Model_2_loss: 0.3367 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.5869 Model_2_val:0.5982
Epoch: 0220 Model_1_loss: 0.6451 Model_2_loss: 0.6645 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6606 Model_2_val:0.6450
Epoch: 0240 Model_1_loss: 0.6975 Model_2_loss: 0.6617 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6661 Model_2_val:0.6564
Epoch: 0260 Model_1_loss: 0.6313 Model_2_loss: 0.6268 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6661 Model_2_val:0.6645
Epoch: 0280 Model_1_loss: 0.5752 Model_2_loss: 0.5736 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6626 Model_2_val:0.6723
Epoch: 0300 Model_1_loss: 0.5354 Model_2_loss: 0.5272 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6703 Model_2_val:0.6707
Epoch: 0320 Model_1_loss: 0.5370 Model_2_loss: 0.5420 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6658 Model_2_val:0.6684
Epoch: 0340 Model_1_loss: 0.4744 Model_2_loss: 0.4893 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6668 Model_2_val:0.6700
Epoch: 0360 Model_1_loss: 0.4970 Model_2_loss: 0.4607 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6665 Model_2_val:0.6869
Epoch: 0380 Model_1_loss: 0.4918 Model_2_loss: 0.4851 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6833 Model_2_val:0.6729
Epoch: 0400 Model_1_loss: 0.4412 Model_2_loss: 0.4511 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6690 Model_2_val:0.6765
Model_one_test:0.6944 Model_two_test:0.6970
added by two output: 0.6954
18
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1091584982
Epoch: 0020 Model_1_loss: 1.6927 Model_2_loss: 1.7320 Model_1_trainacc: 0.4583 Model_2_trainacc: 0.4083 Model_1_val:0.2941 Model_2_val:0.2602
Epoch: 0040 Model_1_loss: 1.4940 Model_2_loss: 1.5988 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.6083 Model_1_val:0.4526 Model_2_val:0.4237
Epoch: 0060 Model_1_loss: 1.2473 Model_2_loss: 1.2978 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8333 Model_1_val:0.5078 Model_2_val:0.4648
Epoch: 0080 Model_1_loss: 0.9606 Model_2_loss: 1.0694 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8167 Model_1_val:0.5593 Model_2_val:0.5229
Epoch: 0100 Model_1_loss: 0.7873 Model_2_loss: 0.8341 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9167 Model_1_val:0.5662 Model_2_val:0.5515
Epoch: 0120 Model_1_loss: 0.6786 Model_2_loss: 0.6924 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9250 Model_1_val:0.5769 Model_2_val:0.5782
Epoch: 0140 Model_1_loss: 0.5550 Model_2_loss: 0.6224 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.5832 Model_2_val:0.5763
Epoch: 0160 Model_1_loss: 0.5344 Model_2_loss: 0.5077 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.5778 Model_2_val:0.5841
Epoch: 0180 Model_1_loss: 0.4653 Model_2_loss: 0.4717 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5797 Model_2_val:0.5998
Epoch: 0200 Model_1_loss: 0.4233 Model_2_loss: 0.4581 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.5951 Model_2_val:0.5942
Epoch: 0220 Model_1_loss: 0.7434 Model_2_loss: 0.7842 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6695 Model_2_val:0.6532
Epoch: 0240 Model_1_loss: 0.6573 Model_2_loss: 0.7135 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.6638 Model_2_val:0.6758
Epoch: 0260 Model_1_loss: 0.6420 Model_2_loss: 0.6101 Model_1_trainacc: 0.9500 Model_2_trainacc: 1.0000 Model_1_val:0.6795 Model_2_val:0.6573
Epoch: 0280 Model_1_loss: 0.5613 Model_2_loss: 0.6393 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6795 Model_2_val:0.6685
Epoch: 0300 Model_1_loss: 0.5975 Model_2_loss: 0.5613 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6711 Model_2_val:0.6704
Epoch: 0320 Model_1_loss: 0.5223 Model_2_loss: 0.5232 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6733 Model_2_val:0.6714
Epoch: 0340 Model_1_loss: 0.4877 Model_2_loss: 0.5095 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6855 Model_2_val:0.6604
Epoch: 0360 Model_1_loss: 0.4846 Model_2_loss: 0.4576 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6770 Model_2_val:0.6792
Epoch: 0380 Model_1_loss: 0.4876 Model_2_loss: 0.5155 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6770 Model_2_val:0.6692
Epoch: 0400 Model_1_loss: 0.4509 Model_2_loss: 0.4940 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6798 Model_2_val:0.6711
Model_one_test:0.6965 Model_two_test:0.6940
added by two output: 0.6955
19
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
738311418
Epoch: 0020 Model_1_loss: 1.7041 Model_2_loss: 1.7164 Model_1_trainacc: 0.5750 Model_2_trainacc: 0.4333 Model_1_val:0.2430 Model_2_val:0.2736
Epoch: 0040 Model_1_loss: 1.5119 Model_2_loss: 1.5340 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.7417 Model_1_val:0.3945 Model_2_val:0.4422
Epoch: 0060 Model_1_loss: 1.2168 Model_2_loss: 1.2518 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8083 Model_1_val:0.5311 Model_2_val:0.5291
Epoch: 0080 Model_1_loss: 0.9426 Model_2_loss: 0.9777 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9000 Model_1_val:0.5407 Model_2_val:0.5420
Epoch: 0100 Model_1_loss: 0.7557 Model_2_loss: 0.7458 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9167 Model_1_val:0.5571 Model_2_val:0.5505
Epoch: 0120 Model_1_loss: 0.6173 Model_2_loss: 0.5867 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5831 Model_2_val:0.5782
Epoch: 0140 Model_1_loss: 0.5402 Model_2_loss: 0.5016 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.5825 Model_2_val:0.5703
Epoch: 0160 Model_1_loss: 0.5334 Model_2_loss: 0.4565 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.5887 Model_2_val:0.5927
Epoch: 0180 Model_1_loss: 0.4367 Model_2_loss: 0.4401 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6013 Model_2_val:0.6068
Epoch: 0200 Model_1_loss: 0.4181 Model_2_loss: 0.3786 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6082 Model_2_val:0.5963
Epoch: 0220 Model_1_loss: 0.7108 Model_2_loss: 0.7045 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6622 Model_2_val:0.6750
Epoch: 0240 Model_1_loss: 0.6475 Model_2_loss: 0.6492 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6786 Model_2_val:0.6638
Epoch: 0260 Model_1_loss: 0.5903 Model_2_loss: 0.6509 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6724 Model_2_val:0.6608
Epoch: 0280 Model_1_loss: 0.5497 Model_2_loss: 0.5959 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6796 Model_2_val:0.6592
Epoch: 0300 Model_1_loss: 0.5668 Model_2_loss: 0.6034 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6674 Model_2_val:0.6648
Epoch: 0320 Model_1_loss: 0.5254 Model_2_loss: 0.5444 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6638 Model_2_val:0.6589
Epoch: 0340 Model_1_loss: 0.4989 Model_2_loss: 0.5541 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.6707 Model_2_val:0.6615
Epoch: 0360 Model_1_loss: 0.4771 Model_2_loss: 0.5017 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6622 Model_2_val:0.6589
Epoch: 0380 Model_1_loss: 0.4900 Model_2_loss: 0.4855 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6562 Model_2_val:0.6727
Epoch: 0400 Model_1_loss: 0.4702 Model_2_loss: 0.5022 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.6625 Model_2_val:0.6579
Model_one_test:0.6842 Model_two_test:0.6908
added by two output: 0.6862
20
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
732444450
Epoch: 0020 Model_1_loss: 1.7180 Model_2_loss: 1.7435 Model_1_trainacc: 0.3917 Model_2_trainacc: 0.3417 Model_1_val:0.2286 Model_2_val:0.2555
Epoch: 0040 Model_1_loss: 1.5634 Model_2_loss: 1.6231 Model_1_trainacc: 0.6333 Model_2_trainacc: 0.6250 Model_1_val:0.3727 Model_2_val:0.3547
Epoch: 0060 Model_1_loss: 1.2602 Model_2_loss: 1.3922 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.7750 Model_1_val:0.4782 Model_2_val:0.4206
Epoch: 0080 Model_1_loss: 1.0187 Model_2_loss: 1.1321 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8250 Model_1_val:0.5264 Model_2_val:0.4923
Epoch: 0100 Model_1_loss: 0.8224 Model_2_loss: 0.8324 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9333 Model_1_val:0.5378 Model_2_val:0.5283
Epoch: 0120 Model_1_loss: 0.6665 Model_2_loss: 0.6567 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9250 Model_1_val:0.5418 Model_2_val:0.5391
Epoch: 0140 Model_1_loss: 0.6226 Model_2_loss: 0.5661 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5549 Model_2_val:0.5634
Epoch: 0160 Model_1_loss: 0.5536 Model_2_loss: 0.5191 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.5830 Model_2_val:0.5477
Epoch: 0180 Model_1_loss: 0.4895 Model_2_loss: 0.4856 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5857 Model_2_val:0.5752
Epoch: 0200 Model_1_loss: 0.4314 Model_2_loss: 0.4300 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.5568 Model_2_val:0.5647
Epoch: 0220 Model_1_loss: 0.7991 Model_2_loss: 0.7289 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6266 Model_2_val:0.6246
Epoch: 0240 Model_1_loss: 0.7307 Model_2_loss: 0.7377 Model_1_trainacc: 0.9583 Model_2_trainacc: 1.0000 Model_1_val:0.6335 Model_2_val:0.6390
Epoch: 0260 Model_1_loss: 0.6912 Model_2_loss: 0.6837 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6325 Model_2_val:0.6302
Epoch: 0280 Model_1_loss: 0.6262 Model_2_loss: 0.6447 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6302 Model_2_val:0.6364
Epoch: 0300 Model_1_loss: 0.6137 Model_2_loss: 0.5542 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6259 Model_2_val:0.6341
Epoch: 0320 Model_1_loss: 0.6086 Model_2_loss: 0.5622 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6354 Model_2_val:0.6413
Epoch: 0340 Model_1_loss: 0.5296 Model_2_loss: 0.5603 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6358 Model_2_val:0.6338
Epoch: 0360 Model_1_loss: 0.5452 Model_2_loss: 0.5528 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6361 Model_2_val:0.6331
Epoch: 0380 Model_1_loss: 0.5773 Model_2_loss: 0.5328 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6354 Model_2_val:0.6384
Epoch: 0400 Model_1_loss: 0.5506 Model_2_loss: 0.5142 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6407 Model_2_val:0.6381
Model_one_test:0.6584 Model_two_test:0.6531
added by two output: 0.6544
21
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
640353624
Epoch: 0020 Model_1_loss: 1.7198 Model_2_loss: 1.7497 Model_1_trainacc: 0.4833 Model_2_trainacc: 0.2917 Model_1_val:0.2293 Model_2_val:0.2129
Epoch: 0040 Model_1_loss: 1.5527 Model_2_loss: 1.6092 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.6250 Model_1_val:0.3584 Model_2_val:0.4228
Epoch: 0060 Model_1_loss: 1.2817 Model_2_loss: 1.3559 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.7667 Model_1_val:0.4770 Model_2_val:0.4997
Epoch: 0080 Model_1_loss: 1.0564 Model_2_loss: 1.0350 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8667 Model_1_val:0.5266 Model_2_val:0.5401
Epoch: 0100 Model_1_loss: 0.8217 Model_2_loss: 0.8535 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8583 Model_1_val:0.5558 Model_2_val:0.5522
Epoch: 0120 Model_1_loss: 0.6898 Model_2_loss: 0.7263 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9000 Model_1_val:0.5545 Model_2_val:0.5752
Epoch: 0140 Model_1_loss: 0.5396 Model_2_loss: 0.5669 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5690 Model_2_val:0.5779
Epoch: 0160 Model_1_loss: 0.5200 Model_2_loss: 0.5121 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5854 Model_2_val:0.5775
Epoch: 0180 Model_1_loss: 0.4328 Model_2_loss: 0.4546 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6005 Model_2_val:0.6058
Epoch: 0200 Model_1_loss: 0.4429 Model_2_loss: 0.4482 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6153 Model_2_val:0.5821
Epoch: 0220 Model_1_loss: 0.7706 Model_2_loss: 0.7828 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6587 Model_2_val:0.6524
Epoch: 0240 Model_1_loss: 0.6600 Model_2_loss: 0.7506 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6659 Model_2_val:0.6544
Epoch: 0260 Model_1_loss: 0.6736 Model_2_loss: 0.7282 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6712 Model_2_val:0.6669
Epoch: 0280 Model_1_loss: 0.6231 Model_2_loss: 0.6903 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6702 Model_2_val:0.6528
Epoch: 0300 Model_1_loss: 0.6064 Model_2_loss: 0.6236 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6682 Model_2_val:0.6541
Epoch: 0320 Model_1_loss: 0.5924 Model_2_loss: 0.6437 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6613 Model_2_val:0.6590
Epoch: 0340 Model_1_loss: 0.5616 Model_2_loss: 0.5412 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6695 Model_2_val:0.6652
Epoch: 0360 Model_1_loss: 0.5477 Model_2_loss: 0.5522 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6659 Model_2_val:0.6551
Epoch: 0380 Model_1_loss: 0.5171 Model_2_loss: 0.5589 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6666 Model_2_val:0.6672
Epoch: 0400 Model_1_loss: 0.4955 Model_2_loss: 0.5157 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6652 Model_2_val:0.6662
Model_one_test:0.6843 Model_two_test:0.6879
added by two output: 0.6859
22
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
181908626
Epoch: 0020 Model_1_loss: 1.7486 Model_2_loss: 1.7329 Model_1_trainacc: 0.3333 Model_2_trainacc: 0.3583 Model_1_val:0.1762 Model_2_val:0.2585
Epoch: 0040 Model_1_loss: 1.6064 Model_2_loss: 1.5707 Model_1_trainacc: 0.6333 Model_2_trainacc: 0.7500 Model_1_val:0.3550 Model_2_val:0.4314
Epoch: 0060 Model_1_loss: 1.3856 Model_2_loss: 1.3363 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8583 Model_1_val:0.4688 Model_2_val:0.4818
Epoch: 0080 Model_1_loss: 1.1237 Model_2_loss: 1.0542 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8917 Model_1_val:0.5046 Model_2_val:0.5120
Epoch: 0100 Model_1_loss: 0.8866 Model_2_loss: 0.8241 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9167 Model_1_val:0.5250 Model_2_val:0.5374
Epoch: 0120 Model_1_loss: 0.7783 Model_2_loss: 0.7058 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.9167 Model_1_val:0.5374 Model_2_val:0.5611
Epoch: 0140 Model_1_loss: 0.6372 Model_2_loss: 0.6159 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9167 Model_1_val:0.5481 Model_2_val:0.5575
Epoch: 0160 Model_1_loss: 0.5399 Model_2_loss: 0.5610 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.5556 Model_2_val:0.5686
Epoch: 0180 Model_1_loss: 0.5341 Model_2_loss: 0.5290 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5676 Model_2_val:0.5660
Epoch: 0200 Model_1_loss: 0.4529 Model_2_loss: 0.4778 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.5559 Model_2_val:0.5624
Epoch: 0220 Model_1_loss: 0.7976 Model_2_loss: 0.8706 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9583 Model_1_val:0.6343 Model_2_val:0.6437
Epoch: 0240 Model_1_loss: 0.7677 Model_2_loss: 0.7797 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6525 Model_2_val:0.6437
Epoch: 0260 Model_1_loss: 0.7677 Model_2_loss: 0.7790 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6609 Model_2_val:0.6515
Epoch: 0280 Model_1_loss: 0.7064 Model_2_loss: 0.7162 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.6668 Model_2_val:0.6622
Epoch: 0300 Model_1_loss: 0.6597 Model_2_loss: 0.7013 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6525 Model_2_val:0.6590
Epoch: 0320 Model_1_loss: 0.6630 Model_2_loss: 0.6616 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6658 Model_2_val:0.6551
Epoch: 0340 Model_1_loss: 0.5922 Model_2_loss: 0.6045 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6655 Model_2_val:0.6629
Epoch: 0360 Model_1_loss: 0.5826 Model_2_loss: 0.6175 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6655 Model_2_val:0.6609
Epoch: 0380 Model_1_loss: 0.5560 Model_2_loss: 0.5855 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9417 Model_1_val:0.6788 Model_2_val:0.6577
Epoch: 0400 Model_1_loss: 0.5774 Model_2_loss: 0.5296 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6661 Model_2_val:0.6720
Model_one_test:0.6941 Model_two_test:0.6840
added by two output: 0.6873
23
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
872460355
Epoch: 0020 Model_1_loss: 1.7111 Model_2_loss: 1.7358 Model_1_trainacc: 0.5417 Model_2_trainacc: 0.4417 Model_1_val:0.2978 Model_2_val:0.2399
Epoch: 0040 Model_1_loss: 1.4971 Model_2_loss: 1.5618 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.7250 Model_1_val:0.4303 Model_2_val:0.4224
Epoch: 0060 Model_1_loss: 1.2004 Model_2_loss: 1.4058 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.6667 Model_1_val:0.4830 Model_2_val:0.4591
Epoch: 0080 Model_1_loss: 0.9090 Model_2_loss: 1.1001 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8000 Model_1_val:0.5409 Model_2_val:0.4935
Epoch: 0100 Model_1_loss: 0.7380 Model_2_loss: 0.9572 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8167 Model_1_val:0.5553 Model_2_val:0.5196
Epoch: 0120 Model_1_loss: 0.6895 Model_2_loss: 0.7718 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8917 Model_1_val:0.5726 Model_2_val:0.5442
Epoch: 0140 Model_1_loss: 0.5877 Model_2_loss: 0.7400 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.8917 Model_1_val:0.5690 Model_2_val:0.5435
Epoch: 0160 Model_1_loss: 0.4805 Model_2_loss: 0.6686 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.8917 Model_1_val:0.5838 Model_2_val:0.5455
Epoch: 0180 Model_1_loss: 0.4415 Model_2_loss: 0.6048 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9167 Model_1_val:0.5841 Model_2_val:0.5694
Epoch: 0200 Model_1_loss: 0.3963 Model_2_loss: 0.5388 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.5870 Model_2_val:0.5573
Epoch: 0220 Model_1_loss: 0.7979 Model_2_loss: 0.9348 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9167 Model_1_val:0.6535 Model_2_val:0.6394
Epoch: 0240 Model_1_loss: 0.7036 Model_2_loss: 0.8582 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6630 Model_2_val:0.6378
Epoch: 0260 Model_1_loss: 0.6805 Model_2_loss: 0.8008 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.6522 Model_2_val:0.6492
Epoch: 0280 Model_1_loss: 0.6368 Model_2_loss: 0.7605 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9167 Model_1_val:0.6708 Model_2_val:0.6535
Epoch: 0300 Model_1_loss: 0.6020 Model_2_loss: 0.7306 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.6656 Model_2_val:0.6607
Epoch: 0320 Model_1_loss: 0.5792 Model_2_loss: 0.7362 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.6688 Model_2_val:0.6427
Epoch: 0340 Model_1_loss: 0.5125 Model_2_loss: 0.6695 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6728 Model_2_val:0.6446
Epoch: 0360 Model_1_loss: 0.5610 Model_2_loss: 0.7534 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6643 Model_2_val:0.6446
Epoch: 0380 Model_1_loss: 0.5275 Model_2_loss: 0.6690 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9167 Model_1_val:0.6626 Model_2_val:0.6610
Epoch: 0400 Model_1_loss: 0.5133 Model_2_loss: 0.6677 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9250 Model_1_val:0.6688 Model_2_val:0.6643
Model_one_test:0.6882 Model_two_test:0.6898
added by two output: 0.6911
24
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1407152928
Epoch: 0020 Model_1_loss: 1.7062 Model_2_loss: 1.6847 Model_1_trainacc: 0.4667 Model_2_trainacc: 0.5500 Model_1_val:0.2656 Model_2_val:0.2773
Epoch: 0040 Model_1_loss: 1.5524 Model_2_loss: 1.4368 Model_1_trainacc: 0.7000 Model_2_trainacc: 0.8333 Model_1_val:0.4177 Model_2_val:0.4907
Epoch: 0060 Model_1_loss: 1.2565 Model_2_loss: 1.1182 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8667 Model_1_val:0.4646 Model_2_val:0.5220
Epoch: 0080 Model_1_loss: 1.0124 Model_2_loss: 0.8520 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9083 Model_1_val:0.5275 Model_2_val:0.5712
Epoch: 0100 Model_1_loss: 0.8162 Model_2_loss: 0.6793 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9250 Model_1_val:0.5393 Model_2_val:0.5963
Epoch: 0120 Model_1_loss: 0.7007 Model_2_loss: 0.5891 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.5321 Model_2_val:0.5875
Epoch: 0140 Model_1_loss: 0.5652 Model_2_loss: 0.4752 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5683 Model_2_val:0.5943
Epoch: 0160 Model_1_loss: 0.4857 Model_2_loss: 0.4338 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.5920 Model_2_val:0.5976
Epoch: 0180 Model_1_loss: 0.4339 Model_2_loss: 0.3770 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.5894 Model_2_val:0.6083
Epoch: 0200 Model_1_loss: 0.4333 Model_2_loss: 0.3875 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6103 Model_2_val:0.6256
Epoch: 0220 Model_1_loss: 0.7517 Model_2_loss: 0.6899 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6624 Model_2_val:0.6693
Epoch: 0240 Model_1_loss: 0.6917 Model_2_loss: 0.6268 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6722 Model_2_val:0.6748
Epoch: 0260 Model_1_loss: 0.6380 Model_2_loss: 0.6045 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6755 Model_2_val:0.6797
Epoch: 0280 Model_1_loss: 0.6116 Model_2_loss: 0.5374 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6634 Model_2_val:0.6676
Epoch: 0300 Model_1_loss: 0.5458 Model_2_loss: 0.5362 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6742 Model_2_val:0.6722
Epoch: 0320 Model_1_loss: 0.5553 Model_2_loss: 0.5298 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6650 Model_2_val:0.6738
Epoch: 0340 Model_1_loss: 0.5377 Model_2_loss: 0.4676 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6703 Model_2_val:0.6777
Epoch: 0360 Model_1_loss: 0.4950 Model_2_loss: 0.4728 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6725 Model_2_val:0.6885
Epoch: 0380 Model_1_loss: 0.5159 Model_2_loss: 0.4465 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6810 Model_2_val:0.6745
Epoch: 0400 Model_1_loss: 0.5069 Model_2_loss: 0.4814 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6784 Model_2_val:0.6865
Model_one_test:0.6973 Model_two_test:0.6944
added by two output: 0.6960
25
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
29717401
Epoch: 0020 Model_1_loss: 1.7076 Model_2_loss: 1.7511 Model_1_trainacc: 0.3917 Model_2_trainacc: 0.3000 Model_1_val:0.2347 Model_2_val:0.2391
Epoch: 0040 Model_1_loss: 1.5646 Model_2_loss: 1.6185 Model_1_trainacc: 0.7000 Model_2_trainacc: 0.6417 Model_1_val:0.3501 Model_2_val:0.3730
Epoch: 0060 Model_1_loss: 1.3463 Model_2_loss: 1.3842 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.8167 Model_1_val:0.4142 Model_2_val:0.4823
Epoch: 0080 Model_1_loss: 1.1718 Model_2_loss: 1.1247 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8667 Model_1_val:0.4624 Model_2_val:0.5339
Epoch: 0100 Model_1_loss: 0.9387 Model_2_loss: 0.8435 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.9083 Model_1_val:0.4823 Model_2_val:0.5595
Epoch: 0120 Model_1_loss: 0.8908 Model_2_loss: 0.7235 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9083 Model_1_val:0.4948 Model_2_val:0.5582
Epoch: 0140 Model_1_loss: 0.7203 Model_2_loss: 0.6157 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8917 Model_1_val:0.5177 Model_2_val:0.5845
Epoch: 0160 Model_1_loss: 0.6114 Model_2_loss: 0.5145 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.5484 Model_2_val:0.5788
Epoch: 0180 Model_1_loss: 0.4985 Model_2_loss: 0.4602 Model_1_trainacc: 0.9417 Model_2_trainacc: 1.0000 Model_1_val:0.5707 Model_2_val:0.6003
Epoch: 0200 Model_1_loss: 0.4642 Model_2_loss: 0.4587 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.5757 Model_2_val:0.6078
Epoch: 0220 Model_1_loss: 0.8045 Model_2_loss: 0.7808 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.6378 Model_2_val:0.6452
Epoch: 0240 Model_1_loss: 0.7614 Model_2_loss: 0.7176 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.6469 Model_2_val:0.6550
Epoch: 0260 Model_1_loss: 0.6967 Model_2_loss: 0.6690 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6607 Model_2_val:0.6604
Epoch: 0280 Model_1_loss: 0.6127 Model_2_loss: 0.6561 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6506 Model_2_val:0.6617
Epoch: 0300 Model_1_loss: 0.5826 Model_2_loss: 0.6359 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6681 Model_2_val:0.6728
Epoch: 0320 Model_1_loss: 0.5347 Model_2_loss: 0.5626 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6722 Model_2_val:0.6688
Epoch: 0340 Model_1_loss: 0.5613 Model_2_loss: 0.5667 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6705 Model_2_val:0.6705
Epoch: 0360 Model_1_loss: 0.5036 Model_2_loss: 0.5427 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6735 Model_2_val:0.6675
Epoch: 0380 Model_1_loss: 0.4668 Model_2_loss: 0.4738 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6776 Model_2_val:0.6702
Epoch: 0400 Model_1_loss: 0.4447 Model_2_loss: 0.5143 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6712 Model_2_val:0.6678
Model_one_test:0.6944 Model_two_test:0.6971
added by two output: 0.6951
26
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
731976755
Epoch: 0020 Model_1_loss: 1.7021 Model_2_loss: 1.6997 Model_1_trainacc: 0.5083 Model_2_trainacc: 0.4167 Model_1_val:0.2620 Model_2_val:0.2554
Epoch: 0040 Model_1_loss: 1.4854 Model_2_loss: 1.5182 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.7417 Model_1_val:0.4101 Model_2_val:0.4276
Epoch: 0060 Model_1_loss: 1.2114 Model_2_loss: 1.2455 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8000 Model_1_val:0.4893 Model_2_val:0.4794
Epoch: 0080 Model_1_loss: 0.9153 Model_2_loss: 0.9129 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8667 Model_1_val:0.5114 Model_2_val:0.5559
Epoch: 0100 Model_1_loss: 0.7728 Model_2_loss: 0.7152 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9083 Model_1_val:0.5510 Model_2_val:0.5625
Epoch: 0120 Model_1_loss: 0.6420 Model_2_loss: 0.6145 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.5642 Model_2_val:0.5840
Epoch: 0140 Model_1_loss: 0.5549 Model_2_loss: 0.5861 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9083 Model_1_val:0.5737 Model_2_val:0.5830
Epoch: 0160 Model_1_loss: 0.4914 Model_2_loss: 0.4684 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5770 Model_2_val:0.5721
Epoch: 0180 Model_1_loss: 0.4266 Model_2_loss: 0.4225 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.5602 Model_2_val:0.6048
Epoch: 0200 Model_1_loss: 0.3908 Model_2_loss: 0.4397 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5876 Model_2_val:0.6028
Epoch: 0220 Model_1_loss: 0.7522 Model_2_loss: 0.7252 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6401 Model_2_val:0.6486
Epoch: 0240 Model_1_loss: 0.7021 Model_2_loss: 0.6979 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6592 Model_2_val:0.6519
Epoch: 0260 Model_1_loss: 0.6416 Model_2_loss: 0.6639 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9417 Model_1_val:0.6546 Model_2_val:0.6585
Epoch: 0280 Model_1_loss: 0.6065 Model_2_loss: 0.6316 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6595 Model_2_val:0.6579
Epoch: 0300 Model_1_loss: 0.6107 Model_2_loss: 0.5827 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6493 Model_2_val:0.6602
Epoch: 0320 Model_1_loss: 0.5916 Model_2_loss: 0.5722 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6625 Model_2_val:0.6595
Epoch: 0340 Model_1_loss: 0.5162 Model_2_loss: 0.5900 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6519 Model_2_val:0.6549
Epoch: 0360 Model_1_loss: 0.5569 Model_2_loss: 0.5820 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6539 Model_2_val:0.6539
Epoch: 0380 Model_1_loss: 0.5239 Model_2_loss: 0.5508 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6691 Model_2_val:0.6503
Epoch: 0400 Model_1_loss: 0.4946 Model_2_loss: 0.5154 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6493 Model_2_val:0.6549
Model_one_test:0.6823 Model_two_test:0.6813
added by two output: 0.6810
27
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
725951676
Epoch: 0020 Model_1_loss: 1.7042 Model_2_loss: 1.7130 Model_1_trainacc: 0.5083 Model_2_trainacc: 0.3750 Model_1_val:0.3238 Model_2_val:0.2902
Epoch: 0040 Model_1_loss: 1.5256 Model_2_loss: 1.5249 Model_1_trainacc: 0.7083 Model_2_trainacc: 0.6667 Model_1_val:0.4634 Model_2_val:0.4282
Epoch: 0060 Model_1_loss: 1.2660 Model_2_loss: 1.2703 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8000 Model_1_val:0.5244 Model_2_val:0.5046
Epoch: 0080 Model_1_loss: 1.0571 Model_2_loss: 1.0163 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8500 Model_1_val:0.5425 Model_2_val:0.5346
Epoch: 0100 Model_1_loss: 0.7829 Model_2_loss: 0.8352 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9167 Model_1_val:0.5418 Model_2_val:0.5293
Epoch: 0120 Model_1_loss: 0.7300 Model_2_loss: 0.7330 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8833 Model_1_val:0.5537 Model_2_val:0.5652
Epoch: 0140 Model_1_loss: 0.6069 Model_2_loss: 0.5823 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.5451 Model_2_val:0.5524
Epoch: 0160 Model_1_loss: 0.5614 Model_2_loss: 0.5520 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5695 Model_2_val:0.5738
Epoch: 0180 Model_1_loss: 0.4949 Model_2_loss: 0.5126 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5817 Model_2_val:0.5672
Epoch: 0200 Model_1_loss: 0.4632 Model_2_loss: 0.4801 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5942 Model_2_val:0.5876
Epoch: 0220 Model_1_loss: 0.8419 Model_2_loss: 0.8661 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6278 Model_2_val:0.6426
Epoch: 0240 Model_1_loss: 0.7878 Model_2_loss: 0.7698 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6291 Model_2_val:0.6499
Epoch: 0260 Model_1_loss: 0.7369 Model_2_loss: 0.7128 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9583 Model_1_val:0.6400 Model_2_val:0.6535
Epoch: 0280 Model_1_loss: 0.7289 Model_2_loss: 0.7024 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6482 Model_2_val:0.6512
Epoch: 0300 Model_1_loss: 0.6167 Model_2_loss: 0.6331 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6512 Model_2_val:0.6551
Epoch: 0320 Model_1_loss: 0.5688 Model_2_loss: 0.6359 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6505 Model_2_val:0.6479
Epoch: 0340 Model_1_loss: 0.5764 Model_2_loss: 0.5871 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6469 Model_2_val:0.6601
Epoch: 0360 Model_1_loss: 0.5593 Model_2_loss: 0.5484 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6538 Model_2_val:0.6584
Epoch: 0380 Model_1_loss: 0.5547 Model_2_loss: 0.5350 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6532 Model_2_val:0.6505
Epoch: 0400 Model_1_loss: 0.5252 Model_2_loss: 0.5218 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6476 Model_2_val:0.6588
Model_one_test:0.6709 Model_two_test:0.6798
added by two output: 0.6792
28
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
886732274
Epoch: 0020 Model_1_loss: 1.7116 Model_2_loss: 1.7217 Model_1_trainacc: 0.3833 Model_2_trainacc: 0.5000 Model_1_val:0.2595 Model_2_val:0.2271
Epoch: 0040 Model_1_loss: 1.5224 Model_2_loss: 1.5825 Model_1_trainacc: 0.6500 Model_2_trainacc: 0.7167 Model_1_val:0.4025 Model_2_val:0.4332
Epoch: 0060 Model_1_loss: 1.1908 Model_2_loss: 1.3184 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8833 Model_1_val:0.5283 Model_2_val:0.4863
Epoch: 0080 Model_1_loss: 0.8931 Model_2_loss: 0.9875 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9083 Model_1_val:0.5620 Model_2_val:0.5451
Epoch: 0100 Model_1_loss: 0.7045 Model_2_loss: 0.7825 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9167 Model_1_val:0.5869 Model_2_val:0.5904
Epoch: 0120 Model_1_loss: 0.6359 Model_2_loss: 0.6249 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9250 Model_1_val:0.5840 Model_2_val:0.5927
Epoch: 0140 Model_1_loss: 0.5204 Model_2_loss: 0.6022 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9250 Model_1_val:0.5937 Model_2_val:0.5865
Epoch: 0160 Model_1_loss: 0.5050 Model_2_loss: 0.4599 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6089 Model_2_val:0.6011
Epoch: 0180 Model_1_loss: 0.4215 Model_2_loss: 0.4112 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6160 Model_2_val:0.6056
Epoch: 0200 Model_1_loss: 0.4036 Model_2_loss: 0.3980 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6280 Model_2_val:0.6105
Epoch: 0220 Model_1_loss: 0.7448 Model_2_loss: 0.7091 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6525 Model_2_val:0.6677
Epoch: 0240 Model_1_loss: 0.6435 Model_2_loss: 0.6101 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6548 Model_2_val:0.6703
Epoch: 0260 Model_1_loss: 0.6540 Model_2_loss: 0.6014 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6613 Model_2_val:0.6749
Epoch: 0280 Model_1_loss: 0.5428 Model_2_loss: 0.5557 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6551 Model_2_val:0.6639
Epoch: 0300 Model_1_loss: 0.5207 Model_2_loss: 0.5296 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6567 Model_2_val:0.6703
Epoch: 0320 Model_1_loss: 0.5036 Model_2_loss: 0.4621 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6723 Model_2_val:0.6677
Epoch: 0340 Model_1_loss: 0.4671 Model_2_loss: 0.4905 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6584 Model_2_val:0.6674
Epoch: 0360 Model_1_loss: 0.4893 Model_2_loss: 0.4771 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6555 Model_2_val:0.6629
Epoch: 0380 Model_1_loss: 0.4500 Model_2_loss: 0.4886 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6622 Model_2_val:0.6645
Epoch: 0400 Model_1_loss: 0.4199 Model_2_loss: 0.4287 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6584 Model_2_val:0.6577
Model_one_test:0.6855 Model_two_test:0.6865
added by two output: 0.6865
29
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
17596165
Epoch: 0020 Model_1_loss: 1.7116 Model_2_loss: 1.7204 Model_1_trainacc: 0.4500 Model_2_trainacc: 0.4583 Model_1_val:0.2643 Model_2_val:0.2650
Epoch: 0040 Model_1_loss: 1.5443 Model_2_loss: 1.5715 Model_1_trainacc: 0.7083 Model_2_trainacc: 0.7500 Model_1_val:0.4308 Model_2_val:0.3766
Epoch: 0060 Model_1_loss: 1.2853 Model_2_loss: 1.2645 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8833 Model_1_val:0.4770 Model_2_val:0.4675
Epoch: 0080 Model_1_loss: 1.0392 Model_2_loss: 1.0208 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8167 Model_1_val:0.5118 Model_2_val:0.5281
Epoch: 0100 Model_1_loss: 0.8655 Model_2_loss: 0.8190 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8750 Model_1_val:0.5316 Model_2_val:0.5580
Epoch: 0120 Model_1_loss: 0.7953 Model_2_loss: 0.6576 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9333 Model_1_val:0.5820 Model_2_val:0.5768
Epoch: 0140 Model_1_loss: 0.6278 Model_2_loss: 0.5656 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.5794 Model_2_val:0.5909
Epoch: 0160 Model_1_loss: 0.6492 Model_2_loss: 0.4479 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9750 Model_1_val:0.5651 Model_2_val:0.5941
Epoch: 0180 Model_1_loss: 0.5728 Model_2_loss: 0.4176 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9500 Model_1_val:0.5654 Model_2_val:0.5960
Epoch: 0200 Model_1_loss: 0.4358 Model_2_loss: 0.4457 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9083 Model_1_val:0.5730 Model_2_val:0.5947
Epoch: 0220 Model_1_loss: 0.8543 Model_2_loss: 0.7436 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.6288 Model_2_val:0.6588
Epoch: 0240 Model_1_loss: 0.7978 Model_2_loss: 0.6828 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.6368 Model_2_val:0.6601
Epoch: 0260 Model_1_loss: 0.7708 Model_2_loss: 0.6356 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.6314 Model_2_val:0.6614
Epoch: 0280 Model_1_loss: 0.7161 Model_2_loss: 0.6247 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6540 Model_2_val:0.6604
Epoch: 0300 Model_1_loss: 0.6450 Model_2_loss: 0.5909 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6416 Model_2_val:0.6610
Epoch: 0320 Model_1_loss: 0.6322 Model_2_loss: 0.5304 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6429 Model_2_val:0.6636
Epoch: 0340 Model_1_loss: 0.6332 Model_2_loss: 0.5131 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6508 Model_2_val:0.6531
Epoch: 0360 Model_1_loss: 0.5812 Model_2_loss: 0.4765 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6448 Model_2_val:0.6594
Epoch: 0380 Model_1_loss: 0.6171 Model_2_loss: 0.4870 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6378 Model_2_val:0.6559
Epoch: 0400 Model_1_loss: 0.6256 Model_2_loss: 0.4781 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.6460 Model_2_val:0.6617
Model_one_test:0.6773 Model_two_test:0.6783
added by two output: 0.6770
30
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
55896959
Epoch: 0020 Model_1_loss: 1.7207 Model_2_loss: 1.7533 Model_1_trainacc: 0.4167 Model_2_trainacc: 0.4333 Model_1_val:0.2945 Model_2_val:0.2480
Epoch: 0040 Model_1_loss: 1.5591 Model_2_loss: 1.5932 Model_1_trainacc: 0.6250 Model_2_trainacc: 0.7333 Model_1_val:0.3645 Model_2_val:0.4348
Epoch: 0060 Model_1_loss: 1.2274 Model_2_loss: 1.3098 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.7833 Model_1_val:0.4735 Model_2_val:0.4990
Epoch: 0080 Model_1_loss: 0.9860 Model_2_loss: 1.0353 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8750 Model_1_val:0.5068 Model_2_val:0.5442
Epoch: 0100 Model_1_loss: 0.7544 Model_2_loss: 0.7603 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9167 Model_1_val:0.5530 Model_2_val:0.5510
Epoch: 0120 Model_1_loss: 0.6376 Model_2_loss: 0.6715 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.5591 Model_2_val:0.5659
Epoch: 0140 Model_1_loss: 0.5252 Model_2_loss: 0.5527 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5744 Model_2_val:0.5747
Epoch: 0160 Model_1_loss: 0.4602 Model_2_loss: 0.5161 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9167 Model_1_val:0.5720 Model_2_val:0.5734
Epoch: 0180 Model_1_loss: 0.4172 Model_2_loss: 0.4394 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.5778 Model_2_val:0.5622
Epoch: 0200 Model_1_loss: 0.3377 Model_2_loss: 0.3994 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9583 Model_1_val:0.5921 Model_2_val:0.5931
Epoch: 0220 Model_1_loss: 0.7032 Model_2_loss: 0.7441 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6726 Model_2_val:0.6420
Epoch: 0240 Model_1_loss: 0.6444 Model_2_loss: 0.6281 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6671 Model_2_val:0.6681
Epoch: 0260 Model_1_loss: 0.5644 Model_2_loss: 0.6238 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6736 Model_2_val:0.6739
Epoch: 0280 Model_1_loss: 0.5363 Model_2_loss: 0.5914 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6753 Model_2_val:0.6613
Epoch: 0300 Model_1_loss: 0.5211 Model_2_loss: 0.5094 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6630 Model_2_val:0.6760
Epoch: 0320 Model_1_loss: 0.5039 Model_2_loss: 0.5277 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6692 Model_2_val:0.6613
Epoch: 0340 Model_1_loss: 0.5427 Model_2_loss: 0.4967 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6624 Model_2_val:0.6715
Epoch: 0360 Model_1_loss: 0.5116 Model_2_loss: 0.5117 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6743 Model_2_val:0.6630
Epoch: 0380 Model_1_loss: 0.5048 Model_2_loss: 0.5048 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6664 Model_2_val:0.6688
Epoch: 0400 Model_1_loss: 0.4700 Model_2_loss: 0.4803 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6702 Model_2_val:0.6736
Model_one_test:0.6967 Model_two_test:0.7001
added by two output: 0.6957
Model1 Acc: 0.689979 Model2 Acc: 0.689988
Maxacc Mean: 0.691537
[0.6924372651610259, 0.6927043179398544, 0.6923088360447857, 0.6922086163222224, 0.691536895183715]
Maxacc of all experiments: 0.6927043179398544
1
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
445004750
Epoch: 0020 Model_1_loss: 1.6980 Model_2_loss: 1.7044 Model_1_trainacc: 0.4833 Model_2_trainacc: 0.4250 Model_1_val:0.2864 Model_2_val:0.1962
Epoch: 0040 Model_1_loss: 1.4804 Model_2_loss: 1.5636 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.7000 Model_1_val:0.4315 Model_2_val:0.3920
Epoch: 0060 Model_1_loss: 1.1539 Model_2_loss: 1.2609 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8500 Model_1_val:0.4953 Model_2_val:0.4793
Epoch: 0080 Model_1_loss: 0.8809 Model_2_loss: 0.9478 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9000 Model_1_val:0.5394 Model_2_val:0.5338
Epoch: 0100 Model_1_loss: 0.6490 Model_2_loss: 0.7582 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5689 Model_2_val:0.5638
Epoch: 0120 Model_1_loss: 0.5856 Model_2_loss: 0.5938 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.5779 Model_2_val:0.5715
Epoch: 0140 Model_1_loss: 0.4659 Model_2_loss: 0.5512 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.5889 Model_2_val:0.5852
Epoch: 0160 Model_1_loss: 0.4287 Model_2_loss: 0.4216 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.5829 Model_2_val:0.5969
Epoch: 0180 Model_1_loss: 0.4073 Model_2_loss: 0.3974 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5889 Model_2_val:0.5956
Epoch: 0200 Model_1_loss: 0.3942 Model_2_loss: 0.3412 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.5966 Model_2_val:0.5983
Epoch: 0220 Model_1_loss: 0.7003 Model_2_loss: 0.7068 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6531 Model_2_val:0.6427
Epoch: 0240 Model_1_loss: 0.6630 Model_2_loss: 0.7094 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6611 Model_2_val:0.6437
Epoch: 0260 Model_1_loss: 0.6619 Model_2_loss: 0.6025 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6541 Model_2_val:0.6604
Epoch: 0280 Model_1_loss: 0.5842 Model_2_loss: 0.5849 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6524 Model_2_val:0.6671
Epoch: 0300 Model_1_loss: 0.5541 Model_2_loss: 0.5526 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6511 Model_2_val:0.6614
Epoch: 0320 Model_1_loss: 0.4986 Model_2_loss: 0.5756 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6688 Model_2_val:0.6638
Epoch: 0340 Model_1_loss: 0.5109 Model_2_loss: 0.5676 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6551 Model_2_val:0.6547
Epoch: 0360 Model_1_loss: 0.4860 Model_2_loss: 0.5235 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6684 Model_2_val:0.6674
Epoch: 0380 Model_1_loss: 0.4268 Model_2_loss: 0.5026 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6591 Model_2_val:0.6664
Epoch: 0400 Model_1_loss: 0.4861 Model_2_loss: 0.4888 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6715 Model_2_val:0.6611
Model_one_test:0.6915 Model_two_test:0.6895
added by two output: 0.6905
2
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1404531152
Epoch: 0020 Model_1_loss: 1.7386 Model_2_loss: 1.7072 Model_1_trainacc: 0.3750 Model_2_trainacc: 0.6000 Model_1_val:0.1985 Model_2_val:0.3103
Epoch: 0040 Model_1_loss: 1.5838 Model_2_loss: 1.5105 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.8167 Model_1_val:0.4073 Model_2_val:0.3746
Epoch: 0060 Model_1_loss: 1.2628 Model_2_loss: 1.2063 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9000 Model_1_val:0.4912 Model_2_val:0.4998
Epoch: 0080 Model_1_loss: 0.9695 Model_2_loss: 0.9784 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9000 Model_1_val:0.5306 Model_2_val:0.5395
Epoch: 0100 Model_1_loss: 0.7140 Model_2_loss: 0.7586 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5671 Model_2_val:0.5456
Epoch: 0120 Model_1_loss: 0.6493 Model_2_loss: 0.6683 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9000 Model_1_val:0.5815 Model_2_val:0.5757
Epoch: 0140 Model_1_loss: 0.5369 Model_2_loss: 0.5493 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6007 Model_2_val:0.5914
Epoch: 0160 Model_1_loss: 0.5364 Model_2_loss: 0.4831 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6193 Model_2_val:0.5921
Epoch: 0180 Model_1_loss: 0.4552 Model_2_loss: 0.4485 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6106 Model_2_val:0.6126
Epoch: 0200 Model_1_loss: 0.4256 Model_2_loss: 0.3989 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9667 Model_1_val:0.6004 Model_2_val:0.6154
Epoch: 0220 Model_1_loss: 0.6907 Model_2_loss: 0.6968 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6804 Model_2_val:0.6814
Epoch: 0240 Model_1_loss: 0.6765 Model_2_loss: 0.6861 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6660 Model_2_val:0.6779
Epoch: 0260 Model_1_loss: 0.6741 Model_2_loss: 0.6230 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6724 Model_2_val:0.6728
Epoch: 0280 Model_1_loss: 0.5570 Model_2_loss: 0.6016 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6756 Model_2_val:0.6760
Epoch: 0300 Model_1_loss: 0.5596 Model_2_loss: 0.5594 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6744 Model_2_val:0.6769
Epoch: 0320 Model_1_loss: 0.5534 Model_2_loss: 0.5390 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6705 Model_2_val:0.6779
Epoch: 0340 Model_1_loss: 0.5332 Model_2_loss: 0.5162 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6776 Model_2_val:0.6788
Epoch: 0360 Model_1_loss: 0.4933 Model_2_loss: 0.4978 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6676 Model_2_val:0.6782
Epoch: 0380 Model_1_loss: 0.5217 Model_2_loss: 0.5110 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6667 Model_2_val:0.6744
Epoch: 0400 Model_1_loss: 0.5120 Model_2_loss: 0.5066 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6686 Model_2_val:0.6779
Model_one_test:0.6955 Model_two_test:0.6977
added by two output: 0.6971
3
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
707580983
Epoch: 0020 Model_1_loss: 1.7373 Model_2_loss: 1.7263 Model_1_trainacc: 0.3667 Model_2_trainacc: 0.3750 Model_1_val:0.2748 Model_2_val:0.2807
Epoch: 0040 Model_1_loss: 1.5646 Model_2_loss: 1.5480 Model_1_trainacc: 0.6583 Model_2_trainacc: 0.6917 Model_1_val:0.3416 Model_2_val:0.4333
Epoch: 0060 Model_1_loss: 1.3401 Model_2_loss: 1.2344 Model_1_trainacc: 0.6917 Model_2_trainacc: 0.8333 Model_1_val:0.4001 Model_2_val:0.4799
Epoch: 0080 Model_1_loss: 1.0271 Model_2_loss: 0.9316 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.9000 Model_1_val:0.4819 Model_2_val:0.5322
Epoch: 0100 Model_1_loss: 0.8310 Model_2_loss: 0.7600 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9333 Model_1_val:0.5398 Model_2_val:0.5467
Epoch: 0120 Model_1_loss: 0.7484 Model_2_loss: 0.6078 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9583 Model_1_val:0.5355 Model_2_val:0.5615
Epoch: 0140 Model_1_loss: 0.6104 Model_2_loss: 0.5864 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5582 Model_2_val:0.5809
Epoch: 0160 Model_1_loss: 0.5323 Model_2_loss: 0.4580 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5592 Model_2_val:0.5684
Epoch: 0180 Model_1_loss: 0.4861 Model_2_loss: 0.4500 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5572 Model_2_val:0.5736
Epoch: 0200 Model_1_loss: 0.4624 Model_2_loss: 0.4079 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.5697 Model_2_val:0.5769
Epoch: 0220 Model_1_loss: 0.8148 Model_2_loss: 0.7397 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6450 Model_2_val:0.6512
Epoch: 0240 Model_1_loss: 0.6875 Model_2_loss: 0.6803 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6565 Model_2_val:0.6558
Epoch: 0260 Model_1_loss: 0.6929 Model_2_loss: 0.6046 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6703 Model_2_val:0.6640
Epoch: 0280 Model_1_loss: 0.6396 Model_2_loss: 0.6166 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6644 Model_2_val:0.6706
Epoch: 0300 Model_1_loss: 0.5737 Model_2_loss: 0.5838 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6634 Model_2_val:0.6631
Epoch: 0320 Model_1_loss: 0.5938 Model_2_loss: 0.5578 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6663 Model_2_val:0.6621
Epoch: 0340 Model_1_loss: 0.5615 Model_2_loss: 0.5262 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6657 Model_2_val:0.6545
Epoch: 0360 Model_1_loss: 0.5909 Model_2_loss: 0.5239 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6673 Model_2_val:0.6624
Epoch: 0380 Model_1_loss: 0.5289 Model_2_loss: 0.4772 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6677 Model_2_val:0.6584
Epoch: 0400 Model_1_loss: 0.5215 Model_2_loss: 0.4833 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6591 Model_2_val:0.6663
Model_one_test:0.6890 Model_two_test:0.6903
added by two output: 0.6890
4
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
828326740
Epoch: 0020 Model_1_loss: 1.7284 Model_2_loss: 1.7287 Model_1_trainacc: 0.4750 Model_2_trainacc: 0.4167 Model_1_val:0.2848 Model_2_val:0.2608
Epoch: 0040 Model_1_loss: 1.5071 Model_2_loss: 1.5724 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.7167 Model_1_val:0.4487 Model_2_val:0.4190
Epoch: 0060 Model_1_loss: 1.2269 Model_2_loss: 1.3504 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.7333 Model_1_val:0.5133 Model_2_val:0.4570
Epoch: 0080 Model_1_loss: 0.8876 Model_2_loss: 1.0666 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8333 Model_1_val:0.5449 Model_2_val:0.4930
Epoch: 0100 Model_1_loss: 0.7313 Model_2_loss: 0.7950 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9167 Model_1_val:0.5554 Model_2_val:0.5465
Epoch: 0120 Model_1_loss: 0.5999 Model_2_loss: 0.7020 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.5715 Model_2_val:0.5342
Epoch: 0140 Model_1_loss: 0.5330 Model_2_loss: 0.5604 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5832 Model_2_val:0.5503
Epoch: 0160 Model_1_loss: 0.4966 Model_2_loss: 0.5545 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9417 Model_1_val:0.5842 Model_2_val:0.5617
Epoch: 0180 Model_1_loss: 0.4228 Model_2_loss: 0.4687 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9250 Model_1_val:0.5636 Model_2_val:0.5788
Epoch: 0200 Model_1_loss: 0.3965 Model_2_loss: 0.4284 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5807 Model_2_val:0.5832
Epoch: 0220 Model_1_loss: 0.7540 Model_2_loss: 0.7848 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6487 Model_2_val:0.6570
Epoch: 0240 Model_1_loss: 0.7424 Model_2_loss: 0.6940 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6519 Model_2_val:0.6544
Epoch: 0260 Model_1_loss: 0.6565 Model_2_loss: 0.7003 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6589 Model_2_val:0.6472
Epoch: 0280 Model_1_loss: 0.6027 Model_2_loss: 0.6817 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6544 Model_2_val:0.6611
Epoch: 0300 Model_1_loss: 0.5852 Model_2_loss: 0.5841 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6566 Model_2_val:0.6538
Epoch: 0320 Model_1_loss: 0.5300 Model_2_loss: 0.5655 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6627 Model_2_val:0.6532
Epoch: 0340 Model_1_loss: 0.5474 Model_2_loss: 0.5464 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6658 Model_2_val:0.6623
Epoch: 0360 Model_1_loss: 0.5029 Model_2_loss: 0.5366 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6623 Model_2_val:0.6601
Epoch: 0380 Model_1_loss: 0.5167 Model_2_loss: 0.4882 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6595 Model_2_val:0.6563
Epoch: 0400 Model_1_loss: 0.4501 Model_2_loss: 0.5076 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6661 Model_2_val:0.6582
Model_one_test:0.6896 Model_two_test:0.6892
added by two output: 0.6905
5
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
64989762
Epoch: 0020 Model_1_loss: 1.7206 Model_2_loss: 1.7279 Model_1_trainacc: 0.4167 Model_2_trainacc: 0.3667 Model_1_val:0.2360 Model_2_val:0.2285
Epoch: 0040 Model_1_loss: 1.5342 Model_2_loss: 1.5772 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.6417 Model_1_val:0.4172 Model_2_val:0.4201
Epoch: 0060 Model_1_loss: 1.2191 Model_2_loss: 1.3018 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8000 Model_1_val:0.4967 Model_2_val:0.4563
Epoch: 0080 Model_1_loss: 0.9256 Model_2_loss: 0.9754 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.9000 Model_1_val:0.5625 Model_2_val:0.5286
Epoch: 0100 Model_1_loss: 0.7088 Model_2_loss: 0.8001 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9000 Model_1_val:0.5881 Model_2_val:0.5477
Epoch: 0120 Model_1_loss: 0.6155 Model_2_loss: 0.6800 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9083 Model_1_val:0.5779 Model_2_val:0.5424
Epoch: 0140 Model_1_loss: 0.5042 Model_2_loss: 0.5500 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6065 Model_2_val:0.5819
Epoch: 0160 Model_1_loss: 0.4767 Model_2_loss: 0.4596 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5917 Model_2_val:0.5986
Epoch: 0180 Model_1_loss: 0.4074 Model_2_loss: 0.4405 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.5828 Model_2_val:0.5940
Epoch: 0200 Model_1_loss: 0.3914 Model_2_loss: 0.4225 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6009 Model_2_val:0.6154
Epoch: 0220 Model_1_loss: 0.7153 Model_2_loss: 0.7410 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6680 Model_2_val:0.6746
Epoch: 0240 Model_1_loss: 0.6863 Model_2_loss: 0.6852 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6765 Model_2_val:0.6775
Epoch: 0260 Model_1_loss: 0.6181 Model_2_loss: 0.6890 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6749 Model_2_val:0.6821
Epoch: 0280 Model_1_loss: 0.5838 Model_2_loss: 0.6106 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6870 Model_2_val:0.6847
Epoch: 0300 Model_1_loss: 0.5951 Model_2_loss: 0.5489 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6834 Model_2_val:0.6861
Epoch: 0320 Model_1_loss: 0.5572 Model_2_loss: 0.5915 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6815 Model_2_val:0.6778
Epoch: 0340 Model_1_loss: 0.5226 Model_2_loss: 0.5506 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6910 Model_2_val:0.6900
Epoch: 0360 Model_1_loss: 0.5406 Model_2_loss: 0.5069 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6795 Model_2_val:0.6841
Epoch: 0380 Model_1_loss: 0.4848 Model_2_loss: 0.4722 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6755 Model_2_val:0.6828
Epoch: 0400 Model_1_loss: 0.4858 Model_2_loss: 0.5112 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6755 Model_2_val:0.6759
Model_one_test:0.7055 Model_two_test:0.7084
added by two output: 0.7068
6
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1216229859
Epoch: 0020 Model_1_loss: 1.7291 Model_2_loss: 1.7372 Model_1_trainacc: 0.4167 Model_2_trainacc: 0.4083 Model_1_val:0.2333 Model_2_val:0.2720
Epoch: 0040 Model_1_loss: 1.5262 Model_2_loss: 1.6101 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.6500 Model_1_val:0.4407 Model_2_val:0.3608
Epoch: 0060 Model_1_loss: 1.2539 Model_2_loss: 1.3607 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.7000 Model_1_val:0.4967 Model_2_val:0.4361
Epoch: 0080 Model_1_loss: 0.9721 Model_2_loss: 1.0653 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8500 Model_1_val:0.5408 Model_2_val:0.5010
Epoch: 0100 Model_1_loss: 0.8526 Model_2_loss: 0.8597 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9417 Model_1_val:0.5742 Model_2_val:0.5295
Epoch: 0120 Model_1_loss: 0.6583 Model_2_loss: 0.7578 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9000 Model_1_val:0.5689 Model_2_val:0.5454
Epoch: 0140 Model_1_loss: 0.5837 Model_2_loss: 0.6265 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.5610 Model_2_val:0.5603
Epoch: 0160 Model_1_loss: 0.5273 Model_2_loss: 0.5778 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.5613 Model_2_val:0.5577
Epoch: 0180 Model_1_loss: 0.5108 Model_2_loss: 0.5381 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.5746 Model_2_val:0.5838
Epoch: 0200 Model_1_loss: 0.4095 Model_2_loss: 0.5032 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9333 Model_1_val:0.5716 Model_2_val:0.5842
Epoch: 0220 Model_1_loss: 0.8416 Model_2_loss: 0.8944 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6375 Model_2_val:0.6421
Epoch: 0240 Model_1_loss: 0.7815 Model_2_loss: 0.7555 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6458 Model_2_val:0.6577
Epoch: 0260 Model_1_loss: 0.7553 Model_2_loss: 0.7161 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6541 Model_2_val:0.6534
Epoch: 0280 Model_1_loss: 0.6668 Model_2_loss: 0.7050 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6551 Model_2_val:0.6587
Epoch: 0300 Model_1_loss: 0.6388 Model_2_loss: 0.6353 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6478 Model_2_val:0.6673
Epoch: 0320 Model_1_loss: 0.5921 Model_2_loss: 0.5718 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6541 Model_2_val:0.6663
Epoch: 0340 Model_1_loss: 0.5490 Model_2_loss: 0.5522 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6693 Model_2_val:0.6657
Epoch: 0360 Model_1_loss: 0.5343 Model_2_loss: 0.5500 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6590 Model_2_val:0.6597
Epoch: 0380 Model_1_loss: 0.5146 Model_2_loss: 0.5337 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6617 Model_2_val:0.6710
Epoch: 0400 Model_1_loss: 0.5009 Model_2_loss: 0.4922 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6640 Model_2_val:0.6696
Model_one_test:0.6922 Model_two_test:0.6978
added by two output: 0.6942
7
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
64851545
Epoch: 0020 Model_1_loss: 1.7338 Model_2_loss: 1.7169 Model_1_trainacc: 0.4083 Model_2_trainacc: 0.5000 Model_1_val:0.2455 Model_2_val:0.2497
Epoch: 0040 Model_1_loss: 1.5742 Model_2_loss: 1.5565 Model_1_trainacc: 0.7000 Model_2_trainacc: 0.6750 Model_1_val:0.4017 Model_2_val:0.3867
Epoch: 0060 Model_1_loss: 1.3421 Model_2_loss: 1.3005 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8167 Model_1_val:0.4913 Model_2_val:0.4689
Epoch: 0080 Model_1_loss: 1.0784 Model_2_loss: 0.9955 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8583 Model_1_val:0.5339 Model_2_val:0.5035
Epoch: 0100 Model_1_loss: 0.8622 Model_2_loss: 0.8415 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8583 Model_1_val:0.5318 Model_2_val:0.5332
Epoch: 0120 Model_1_loss: 0.6866 Model_2_loss: 0.6872 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.5573 Model_2_val:0.5493
Epoch: 0140 Model_1_loss: 0.5844 Model_2_loss: 0.6187 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9167 Model_1_val:0.5661 Model_2_val:0.5559
Epoch: 0160 Model_1_loss: 0.5425 Model_2_loss: 0.5529 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9083 Model_1_val:0.5780 Model_2_val:0.5731
Epoch: 0180 Model_1_loss: 0.4182 Model_2_loss: 0.4817 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.5909 Model_2_val:0.5664
Epoch: 0200 Model_1_loss: 0.4116 Model_2_loss: 0.4420 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.5934 Model_2_val:0.5612
Epoch: 0220 Model_1_loss: 0.7576 Model_2_loss: 0.7707 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6563 Model_2_val:0.6483
Epoch: 0240 Model_1_loss: 0.7304 Model_2_loss: 0.7421 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6706 Model_2_val:0.6626
Epoch: 0260 Model_1_loss: 0.6935 Model_2_loss: 0.7256 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6657 Model_2_val:0.6647
Epoch: 0280 Model_1_loss: 0.6479 Model_2_loss: 0.6914 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6608 Model_2_val:0.6517
Epoch: 0300 Model_1_loss: 0.6019 Model_2_loss: 0.6698 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6717 Model_2_val:0.6577
Epoch: 0320 Model_1_loss: 0.6178 Model_2_loss: 0.6438 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6682 Model_2_val:0.6591
Epoch: 0340 Model_1_loss: 0.6214 Model_2_loss: 0.6354 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6650 Model_2_val:0.6570
Epoch: 0360 Model_1_loss: 0.5604 Model_2_loss: 0.5983 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6650 Model_2_val:0.6664
Epoch: 0380 Model_1_loss: 0.5628 Model_2_loss: 0.6038 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9417 Model_1_val:0.6521 Model_2_val:0.6654
Epoch: 0400 Model_1_loss: 0.4832 Model_2_loss: 0.5671 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6692 Model_2_val:0.6612
Model_one_test:0.6916 Model_two_test:0.6906
added by two output: 0.6885
8
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1187486261
Epoch: 0020 Model_1_loss: 1.7320 Model_2_loss: 1.7286 Model_1_trainacc: 0.3833 Model_2_trainacc: 0.3333 Model_1_val:0.2369 Model_2_val:0.2263
Epoch: 0040 Model_1_loss: 1.5456 Model_2_loss: 1.5753 Model_1_trainacc: 0.7417 Model_2_trainacc: 0.6750 Model_1_val:0.3804 Model_2_val:0.3847
Epoch: 0060 Model_1_loss: 1.2522 Model_2_loss: 1.2948 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8417 Model_1_val:0.4692 Model_2_val:0.4659
Epoch: 0080 Model_1_loss: 0.9471 Model_2_loss: 0.9974 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9083 Model_1_val:0.5181 Model_2_val:0.5258
Epoch: 0100 Model_1_loss: 0.7111 Model_2_loss: 0.7820 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5314 Model_2_val:0.5451
Epoch: 0120 Model_1_loss: 0.6210 Model_2_loss: 0.6470 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.5617 Model_2_val:0.5594
Epoch: 0140 Model_1_loss: 0.5478 Model_2_loss: 0.4823 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9667 Model_1_val:0.5671 Model_2_val:0.5814
Epoch: 0160 Model_1_loss: 0.4542 Model_2_loss: 0.4482 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5993 Model_2_val:0.5910
Epoch: 0180 Model_1_loss: 0.4771 Model_2_loss: 0.4027 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5887 Model_2_val:0.5907
Epoch: 0200 Model_1_loss: 0.4346 Model_2_loss: 0.3935 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5884 Model_2_val:0.6150
Epoch: 0220 Model_1_loss: 0.7181 Model_2_loss: 0.7165 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6542 Model_2_val:0.6579
Epoch: 0240 Model_1_loss: 0.6763 Model_2_loss: 0.6886 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6622 Model_2_val:0.6562
Epoch: 0260 Model_1_loss: 0.6539 Model_2_loss: 0.5871 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6656 Model_2_val:0.6712
Epoch: 0280 Model_1_loss: 0.6130 Model_2_loss: 0.6093 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6642 Model_2_val:0.6656
Epoch: 0300 Model_1_loss: 0.5920 Model_2_loss: 0.5741 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6656 Model_2_val:0.6712
Epoch: 0320 Model_1_loss: 0.5661 Model_2_loss: 0.5053 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6749 Model_2_val:0.6769
Epoch: 0340 Model_1_loss: 0.5552 Model_2_loss: 0.5005 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6709 Model_2_val:0.6752
Epoch: 0360 Model_1_loss: 0.5120 Model_2_loss: 0.4827 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6689 Model_2_val:0.6769
Epoch: 0380 Model_1_loss: 0.4882 Model_2_loss: 0.4740 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6735 Model_2_val:0.6809
Epoch: 0400 Model_1_loss: 0.4469 Model_2_loss: 0.4824 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6802 Model_2_val:0.6729
Model_one_test:0.6988 Model_two_test:0.7008
added by two output: 0.7012
9
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
316104139
Epoch: 0020 Model_1_loss: 1.7066 Model_2_loss: 1.7118 Model_1_trainacc: 0.4417 Model_2_trainacc: 0.5000 Model_1_val:0.3207 Model_2_val:0.2792
Epoch: 0040 Model_1_loss: 1.5240 Model_2_loss: 1.4801 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.7917 Model_1_val:0.4528 Model_2_val:0.4200
Epoch: 0060 Model_1_loss: 1.2410 Model_2_loss: 1.1983 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8833 Model_1_val:0.5000 Model_2_val:0.4820
Epoch: 0080 Model_1_loss: 0.9836 Model_2_loss: 0.8995 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9500 Model_1_val:0.5112 Model_2_val:0.5270
Epoch: 0100 Model_1_loss: 0.7865 Model_2_loss: 0.7767 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9083 Model_1_val:0.5296 Model_2_val:0.5688
Epoch: 0120 Model_1_loss: 0.7112 Model_2_loss: 0.6319 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9333 Model_1_val:0.5302 Model_2_val:0.5488
Epoch: 0140 Model_1_loss: 0.6012 Model_2_loss: 0.5483 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.5280 Model_2_val:0.5688
Epoch: 0160 Model_1_loss: 0.5848 Model_2_loss: 0.4778 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.5521 Model_2_val:0.5623
Epoch: 0180 Model_1_loss: 0.5673 Model_2_loss: 0.4817 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.5681 Model_2_val:0.5932
Epoch: 0200 Model_1_loss: 0.4100 Model_2_loss: 0.4069 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.5704 Model_2_val:0.6003
Epoch: 0220 Model_1_loss: 0.8114 Model_2_loss: 0.7718 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6433 Model_2_val:0.6446
Epoch: 0240 Model_1_loss: 0.7290 Model_2_loss: 0.7630 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.6578 Model_2_val:0.6530
Epoch: 0260 Model_1_loss: 0.6626 Model_2_loss: 0.6095 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6591 Model_2_val:0.6591
Epoch: 0280 Model_1_loss: 0.7023 Model_2_loss: 0.6390 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6626 Model_2_val:0.6620
Epoch: 0300 Model_1_loss: 0.6573 Model_2_loss: 0.6268 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6713 Model_2_val:0.6655
Epoch: 0320 Model_1_loss: 0.6418 Model_2_loss: 0.6002 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6742 Model_2_val:0.6603
Epoch: 0340 Model_1_loss: 0.5698 Model_2_loss: 0.5740 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6642 Model_2_val:0.6636
Epoch: 0360 Model_1_loss: 0.5406 Model_2_loss: 0.5715 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6719 Model_2_val:0.6652
Epoch: 0380 Model_1_loss: 0.5173 Model_2_loss: 0.5314 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6677 Model_2_val:0.6726
Epoch: 0400 Model_1_loss: 0.5101 Model_2_loss: 0.5052 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6616 Model_2_val:0.6642
Model_one_test:0.6906 Model_two_test:0.6957
added by two output: 0.6931
10
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
954879900
Epoch: 0020 Model_1_loss: 1.7118 Model_2_loss: 1.7231 Model_1_trainacc: 0.5333 Model_2_trainacc: 0.4167 Model_1_val:0.2340 Model_2_val:0.1900
Epoch: 0040 Model_1_loss: 1.5298 Model_2_loss: 1.5544 Model_1_trainacc: 0.6917 Model_2_trainacc: 0.7000 Model_1_val:0.3512 Model_2_val:0.3449
Epoch: 0060 Model_1_loss: 1.1944 Model_2_loss: 1.1785 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8583 Model_1_val:0.4690 Model_2_val:0.4826
Epoch: 0080 Model_1_loss: 0.9842 Model_2_loss: 0.9107 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9083 Model_1_val:0.5031 Model_2_val:0.5081
Epoch: 0100 Model_1_loss: 0.7274 Model_2_loss: 0.6969 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9333 Model_1_val:0.5204 Model_2_val:0.5455
Epoch: 0120 Model_1_loss: 0.6470 Model_2_loss: 0.5815 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.5396 Model_2_val:0.5551
Epoch: 0140 Model_1_loss: 0.5992 Model_2_loss: 0.5307 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.5617 Model_2_val:0.5641
Epoch: 0160 Model_1_loss: 0.4594 Model_2_loss: 0.4518 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5644 Model_2_val:0.5746
Epoch: 0180 Model_1_loss: 0.4308 Model_2_loss: 0.4222 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.5667 Model_2_val:0.5813
Epoch: 0200 Model_1_loss: 0.4298 Model_2_loss: 0.3846 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5783 Model_2_val:0.5780
Epoch: 0220 Model_1_loss: 0.7262 Model_2_loss: 0.7121 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6653 Model_2_val:0.6402
Epoch: 0240 Model_1_loss: 0.6165 Model_2_loss: 0.6162 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6653 Model_2_val:0.6574
Epoch: 0260 Model_1_loss: 0.6223 Model_2_loss: 0.5924 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6647 Model_2_val:0.6600
Epoch: 0280 Model_1_loss: 0.5907 Model_2_loss: 0.5911 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.6792 Model_2_val:0.6591
Epoch: 0300 Model_1_loss: 0.5319 Model_2_loss: 0.5693 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6696 Model_2_val:0.6749
Epoch: 0320 Model_1_loss: 0.5544 Model_2_loss: 0.5236 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6736 Model_2_val:0.6650
Epoch: 0340 Model_1_loss: 0.4766 Model_2_loss: 0.4813 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6657 Model_2_val:0.6587
Epoch: 0360 Model_1_loss: 0.4581 Model_2_loss: 0.4799 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6660 Model_2_val:0.6687
Epoch: 0380 Model_1_loss: 0.4766 Model_2_loss: 0.4677 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6796 Model_2_val:0.6736
Epoch: 0400 Model_1_loss: 0.4653 Model_2_loss: 0.4566 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6713 Model_2_val:0.6673
Model_one_test:0.6882 Model_two_test:0.6895
added by two output: 0.6902
11
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
337049199
Epoch: 0020 Model_1_loss: 1.7283 Model_2_loss: 1.6960 Model_1_trainacc: 0.4083 Model_2_trainacc: 0.4750 Model_1_val:0.2627 Model_2_val:0.3112
Epoch: 0040 Model_1_loss: 1.5754 Model_2_loss: 1.5299 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.7417 Model_1_val:0.3530 Model_2_val:0.4108
Epoch: 0060 Model_1_loss: 1.3256 Model_2_loss: 1.2108 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.9000 Model_1_val:0.4564 Model_2_val:0.4925
Epoch: 0080 Model_1_loss: 1.0540 Model_2_loss: 0.9523 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8833 Model_1_val:0.5174 Model_2_val:0.5592
Epoch: 0100 Model_1_loss: 0.8751 Model_2_loss: 0.6979 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9417 Model_1_val:0.5525 Model_2_val:0.5614
Epoch: 0120 Model_1_loss: 0.7066 Model_2_loss: 0.5707 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9417 Model_1_val:0.5598 Model_2_val:0.5634
Epoch: 0140 Model_1_loss: 0.6192 Model_2_loss: 0.5239 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9667 Model_1_val:0.5551 Model_2_val:0.5886
Epoch: 0160 Model_1_loss: 0.5245 Model_2_loss: 0.4526 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5745 Model_2_val:0.5774
Epoch: 0180 Model_1_loss: 0.4537 Model_2_loss: 0.4012 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.5883 Model_2_val:0.6029
Epoch: 0200 Model_1_loss: 0.4300 Model_2_loss: 0.3894 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.5985 Model_2_val:0.6205
Epoch: 0220 Model_1_loss: 0.8114 Model_2_loss: 0.6960 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6457 Model_2_val:0.6668
Epoch: 0240 Model_1_loss: 0.7249 Model_2_loss: 0.6651 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6693 Model_2_val:0.6732
Epoch: 0260 Model_1_loss: 0.6825 Model_2_loss: 0.5736 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6687 Model_2_val:0.6738
Epoch: 0280 Model_1_loss: 0.6321 Model_2_loss: 0.5728 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6636 Model_2_val:0.6655
Epoch: 0300 Model_1_loss: 0.5791 Model_2_loss: 0.5455 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6642 Model_2_val:0.6645
Epoch: 0320 Model_1_loss: 0.5672 Model_2_loss: 0.5667 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6652 Model_2_val:0.6629
Epoch: 0340 Model_1_loss: 0.5808 Model_2_loss: 0.5610 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6636 Model_2_val:0.6642
Epoch: 0360 Model_1_loss: 0.4652 Model_2_loss: 0.4981 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6601 Model_2_val:0.6540
Epoch: 0380 Model_1_loss: 0.5024 Model_2_loss: 0.4713 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6559 Model_2_val:0.6658
Epoch: 0400 Model_1_loss: 0.5067 Model_2_loss: 0.5139 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6652 Model_2_val:0.6499
Model_one_test:0.6952 Model_two_test:0.6891
added by two output: 0.6917
12
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
518727940
Epoch: 0020 Model_1_loss: 1.7368 Model_2_loss: 1.7059 Model_1_trainacc: 0.3500 Model_2_trainacc: 0.4250 Model_1_val:0.2055 Model_2_val:0.3079
Epoch: 0040 Model_1_loss: 1.5189 Model_2_loss: 1.5169 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.7917 Model_1_val:0.4266 Model_2_val:0.4630
Epoch: 0060 Model_1_loss: 1.1736 Model_2_loss: 1.2408 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8417 Model_1_val:0.5297 Model_2_val:0.5112
Epoch: 0080 Model_1_loss: 0.9029 Model_2_loss: 0.9152 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.5568 Model_2_val:0.5740
Epoch: 0100 Model_1_loss: 0.7492 Model_2_loss: 0.7343 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.5619 Model_2_val:0.5913
Epoch: 0120 Model_1_loss: 0.5865 Model_2_loss: 0.6512 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9250 Model_1_val:0.5683 Model_2_val:0.5951
Epoch: 0140 Model_1_loss: 0.5592 Model_2_loss: 0.5901 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.5801 Model_2_val:0.5801
Epoch: 0160 Model_1_loss: 0.4320 Model_2_loss: 0.5195 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9500 Model_1_val:0.5862 Model_2_val:0.5782
Epoch: 0180 Model_1_loss: 0.4169 Model_2_loss: 0.4292 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.5877 Model_2_val:0.6101
Epoch: 0200 Model_1_loss: 0.4527 Model_2_loss: 0.3991 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.5839 Model_2_val:0.6059
Epoch: 0220 Model_1_loss: 0.7818 Model_2_loss: 0.7382 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6477 Model_2_val:0.6551
Epoch: 0240 Model_1_loss: 0.7036 Model_2_loss: 0.7027 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6541 Model_2_val:0.6573
Epoch: 0260 Model_1_loss: 0.7001 Model_2_loss: 0.7152 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6554 Model_2_val:0.6723
Epoch: 0280 Model_1_loss: 0.5973 Model_2_loss: 0.6144 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6586 Model_2_val:0.6662
Epoch: 0300 Model_1_loss: 0.6404 Model_2_loss: 0.5838 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6653 Model_2_val:0.6493
Epoch: 0320 Model_1_loss: 0.5767 Model_2_loss: 0.5952 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6650 Model_2_val:0.6713
Epoch: 0340 Model_1_loss: 0.5655 Model_2_loss: 0.5584 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6694 Model_2_val:0.6599
Epoch: 0360 Model_1_loss: 0.4968 Model_2_loss: 0.5192 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6694 Model_2_val:0.6698
Epoch: 0380 Model_1_loss: 0.5303 Model_2_loss: 0.5071 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6548 Model_2_val:0.6579
Epoch: 0400 Model_1_loss: 0.5090 Model_2_loss: 0.5074 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6694 Model_2_val:0.6698
Model_one_test:0.6921 Model_two_test:0.6908
added by two output: 0.6921
13
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1163835154
Epoch: 0020 Model_1_loss: 1.6936 Model_2_loss: 1.7122 Model_1_trainacc: 0.5750 Model_2_trainacc: 0.4667 Model_1_val:0.2769 Model_2_val:0.3016
Epoch: 0040 Model_1_loss: 1.4936 Model_2_loss: 1.4750 Model_1_trainacc: 0.7250 Model_2_trainacc: 0.7250 Model_1_val:0.4264 Model_2_val:0.4599
Epoch: 0060 Model_1_loss: 1.1564 Model_2_loss: 1.2026 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8333 Model_1_val:0.5076 Model_2_val:0.4809
Epoch: 0080 Model_1_loss: 0.8476 Model_2_loss: 0.9175 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8583 Model_1_val:0.5375 Model_2_val:0.5210
Epoch: 0100 Model_1_loss: 0.6775 Model_2_loss: 0.7854 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.5664 Model_2_val:0.5545
Epoch: 0120 Model_1_loss: 0.5602 Model_2_loss: 0.6162 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9250 Model_1_val:0.5811 Model_2_val:0.5808
Epoch: 0140 Model_1_loss: 0.5180 Model_2_loss: 0.5468 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9667 Model_1_val:0.5841 Model_2_val:0.5591
Epoch: 0160 Model_1_loss: 0.4640 Model_2_loss: 0.5702 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.5884 Model_2_val:0.5887
Epoch: 0180 Model_1_loss: 0.4658 Model_2_loss: 0.5061 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.5930 Model_2_val:0.5884
Epoch: 0200 Model_1_loss: 0.3868 Model_2_loss: 0.4577 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.5854 Model_2_val:0.6038
Epoch: 0220 Model_1_loss: 0.6877 Model_2_loss: 0.7304 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6705 Model_2_val:0.6518
Epoch: 0240 Model_1_loss: 0.6187 Model_2_loss: 0.7291 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9250 Model_1_val:0.6790 Model_2_val:0.6692
Epoch: 0260 Model_1_loss: 0.5523 Model_2_loss: 0.6023 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6843 Model_2_val:0.6807
Epoch: 0280 Model_1_loss: 0.5859 Model_2_loss: 0.6436 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6748 Model_2_val:0.6781
Epoch: 0300 Model_1_loss: 0.5293 Model_2_loss: 0.5702 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6830 Model_2_val:0.6751
Epoch: 0320 Model_1_loss: 0.5166 Model_2_loss: 0.5648 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6843 Model_2_val:0.6744
Epoch: 0340 Model_1_loss: 0.4971 Model_2_loss: 0.5029 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6767 Model_2_val:0.6721
Epoch: 0360 Model_1_loss: 0.5005 Model_2_loss: 0.5517 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6794 Model_2_val:0.6718
Epoch: 0380 Model_1_loss: 0.4912 Model_2_loss: 0.4746 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6797 Model_2_val:0.6751
Epoch: 0400 Model_1_loss: 0.4378 Model_2_loss: 0.4980 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6833 Model_2_val:0.6652
Model_one_test:0.7004 Model_two_test:0.7014
added by two output: 0.6988
14
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1058009035
Epoch: 0020 Model_1_loss: 1.6888 Model_2_loss: 1.7219 Model_1_trainacc: 0.5333 Model_2_trainacc: 0.4500 Model_1_val:0.3134 Model_2_val:0.2698
Epoch: 0040 Model_1_loss: 1.4656 Model_2_loss: 1.4974 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8000 Model_1_val:0.4436 Model_2_val:0.4239
Epoch: 0060 Model_1_loss: 1.1934 Model_2_loss: 1.1777 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8500 Model_1_val:0.4977 Model_2_val:0.5007
Epoch: 0080 Model_1_loss: 0.9680 Model_2_loss: 0.8911 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8667 Model_1_val:0.5187 Model_2_val:0.5603
Epoch: 0100 Model_1_loss: 0.8001 Model_2_loss: 0.6869 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9250 Model_1_val:0.5262 Model_2_val:0.5689
Epoch: 0120 Model_1_loss: 0.6216 Model_2_loss: 0.6192 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5584 Model_2_val:0.5780
Epoch: 0140 Model_1_loss: 0.5985 Model_2_loss: 0.4954 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5531 Model_2_val:0.5715
Epoch: 0160 Model_1_loss: 0.4947 Model_2_loss: 0.5017 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5708 Model_2_val:0.5810
Epoch: 0180 Model_1_loss: 0.5018 Model_2_loss: 0.4313 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.5813 Model_2_val:0.5934
Epoch: 0200 Model_1_loss: 0.4193 Model_2_loss: 0.4069 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.5695 Model_2_val:0.5990
Epoch: 0220 Model_1_loss: 0.7400 Model_2_loss: 0.7069 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6403 Model_2_val:0.6587
Epoch: 0240 Model_1_loss: 0.6662 Model_2_loss: 0.6509 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6600 Model_2_val:0.6659
Epoch: 0260 Model_1_loss: 0.6655 Model_2_loss: 0.6115 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6534 Model_2_val:0.6613
Epoch: 0280 Model_1_loss: 0.6344 Model_2_loss: 0.6188 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6620 Model_2_val:0.6787
Epoch: 0300 Model_1_loss: 0.5723 Model_2_loss: 0.5622 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6643 Model_2_val:0.6659
Epoch: 0320 Model_1_loss: 0.5523 Model_2_loss: 0.5102 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6613 Model_2_val:0.6679
Epoch: 0340 Model_1_loss: 0.4816 Model_2_loss: 0.4925 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6633 Model_2_val:0.6679
Epoch: 0360 Model_1_loss: 0.4592 Model_2_loss: 0.4838 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6715 Model_2_val:0.6675
Epoch: 0380 Model_1_loss: 0.4393 Model_2_loss: 0.4210 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6711 Model_2_val:0.6643
Epoch: 0400 Model_1_loss: 0.4158 Model_2_loss: 0.4439 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6725 Model_2_val:0.6613
Model_one_test:0.6889 Model_two_test:0.6931
added by two output: 0.6908
15
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
935240518
Epoch: 0020 Model_1_loss: 1.7462 Model_2_loss: 1.7362 Model_1_trainacc: 0.4167 Model_2_trainacc: 0.4250 Model_1_val:0.3149 Model_2_val:0.2639
Epoch: 0040 Model_1_loss: 1.6069 Model_2_loss: 1.6053 Model_1_trainacc: 0.6583 Model_2_trainacc: 0.6417 Model_1_val:0.4084 Model_2_val:0.3833
Epoch: 0060 Model_1_loss: 1.3665 Model_2_loss: 1.3802 Model_1_trainacc: 0.7417 Model_2_trainacc: 0.7750 Model_1_val:0.4781 Model_2_val:0.4225
Epoch: 0080 Model_1_loss: 1.0910 Model_2_loss: 1.1400 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8583 Model_1_val:0.5026 Model_2_val:0.4758
Epoch: 0100 Model_1_loss: 0.8704 Model_2_loss: 0.9150 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8833 Model_1_val:0.5298 Model_2_val:0.5075
Epoch: 0120 Model_1_loss: 0.7368 Model_2_loss: 0.8272 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8750 Model_1_val:0.5621 Model_2_val:0.5196
Epoch: 0140 Model_1_loss: 0.6147 Model_2_loss: 0.6141 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9417 Model_1_val:0.5543 Model_2_val:0.5271
Epoch: 0160 Model_1_loss: 0.5989 Model_2_loss: 0.6238 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9250 Model_1_val:0.5693 Model_2_val:0.5409
Epoch: 0180 Model_1_loss: 0.4986 Model_2_loss: 0.4965 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5827 Model_2_val:0.5458
Epoch: 0200 Model_1_loss: 0.4990 Model_2_loss: 0.4583 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9833 Model_1_val:0.5929 Model_2_val:0.5710
Epoch: 0220 Model_1_loss: 0.8365 Model_2_loss: 0.8454 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6400 Model_2_val:0.6272
Epoch: 0240 Model_1_loss: 0.8069 Model_2_loss: 0.8007 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.6494 Model_2_val:0.6380
Epoch: 0260 Model_1_loss: 0.7525 Model_2_loss: 0.7579 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6445 Model_2_val:0.6501
Epoch: 0280 Model_1_loss: 0.7064 Model_2_loss: 0.7308 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9833 Model_1_val:0.6586 Model_2_val:0.6416
Epoch: 0300 Model_1_loss: 0.6158 Model_2_loss: 0.6663 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9500 Model_1_val:0.6596 Model_2_val:0.6540
Epoch: 0320 Model_1_loss: 0.6113 Model_2_loss: 0.6387 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6599 Model_2_val:0.6606
Epoch: 0340 Model_1_loss: 0.6134 Model_2_loss: 0.6567 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6727 Model_2_val:0.6432
Epoch: 0360 Model_1_loss: 0.5884 Model_2_loss: 0.5727 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6602 Model_2_val:0.6612
Epoch: 0380 Model_1_loss: 0.5633 Model_2_loss: 0.6103 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6730 Model_2_val:0.6566
Epoch: 0400 Model_1_loss: 0.5213 Model_2_loss: 0.5741 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6730 Model_2_val:0.6573
Model_one_test:0.6913 Model_two_test:0.6867
added by two output: 0.6893
16
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
247942129
Epoch: 0020 Model_1_loss: 1.7445 Model_2_loss: 1.7241 Model_1_trainacc: 0.4000 Model_2_trainacc: 0.4500 Model_1_val:0.2509 Model_2_val:0.3082
Epoch: 0040 Model_1_loss: 1.6062 Model_2_loss: 1.5296 Model_1_trainacc: 0.6750 Model_2_trainacc: 0.7333 Model_1_val:0.3674 Model_2_val:0.3942
Epoch: 0060 Model_1_loss: 1.3582 Model_2_loss: 1.2432 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.7917 Model_1_val:0.4436 Model_2_val:0.4919
Epoch: 0080 Model_1_loss: 1.0677 Model_2_loss: 0.9738 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8750 Model_1_val:0.5071 Model_2_val:0.5372
Epoch: 0100 Model_1_loss: 0.8056 Model_2_loss: 0.7513 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9083 Model_1_val:0.5266 Model_2_val:0.5680
Epoch: 0120 Model_1_loss: 0.6784 Model_2_loss: 0.6648 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9250 Model_1_val:0.5793 Model_2_val:0.5750
Epoch: 0140 Model_1_loss: 0.5547 Model_2_loss: 0.5585 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5674 Model_2_val:0.5799
Epoch: 0160 Model_1_loss: 0.5329 Model_2_loss: 0.4795 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.5799 Model_2_val:0.5915
Epoch: 0180 Model_1_loss: 0.5246 Model_2_loss: 0.4698 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5793 Model_2_val:0.5915
Epoch: 0200 Model_1_loss: 0.4351 Model_2_loss: 0.4329 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5909 Model_2_val:0.5826
Epoch: 0220 Model_1_loss: 0.7947 Model_2_loss: 0.7304 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6365 Model_2_val:0.6465
Epoch: 0240 Model_1_loss: 0.7188 Model_2_loss: 0.6545 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6581 Model_2_val:0.6518
Epoch: 0260 Model_1_loss: 0.6866 Model_2_loss: 0.6508 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6604 Model_2_val:0.6637
Epoch: 0280 Model_1_loss: 0.6877 Model_2_loss: 0.6388 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6667 Model_2_val:0.6564
Epoch: 0300 Model_1_loss: 0.6543 Model_2_loss: 0.6294 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.6720 Model_2_val:0.6567
Epoch: 0320 Model_1_loss: 0.6048 Model_2_loss: 0.5888 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6647 Model_2_val:0.6650
Epoch: 0340 Model_1_loss: 0.5784 Model_2_loss: 0.5576 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6643 Model_2_val:0.6584
Epoch: 0360 Model_1_loss: 0.5308 Model_2_loss: 0.5219 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6610 Model_2_val:0.6600
Epoch: 0380 Model_1_loss: 0.5329 Model_2_loss: 0.5048 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6663 Model_2_val:0.6650
Epoch: 0400 Model_1_loss: 0.5207 Model_2_loss: 0.5093 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9417 Model_1_val:0.6597 Model_2_val:0.6617
Model_one_test:0.6872 Model_two_test:0.6812
added by two output: 0.6852
17
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
357287658
Epoch: 0020 Model_1_loss: 1.7137 Model_2_loss: 1.7491 Model_1_trainacc: 0.4000 Model_2_trainacc: 0.3833 Model_1_val:0.2527 Model_2_val:0.2773
Epoch: 0040 Model_1_loss: 1.5067 Model_2_loss: 1.6027 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.6833 Model_1_val:0.4325 Model_2_val:0.3989
Epoch: 0060 Model_1_loss: 1.2007 Model_2_loss: 1.3174 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8833 Model_1_val:0.5215 Model_2_val:0.4989
Epoch: 0080 Model_1_loss: 0.9178 Model_2_loss: 1.0307 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8750 Model_1_val:0.5610 Model_2_val:0.5057
Epoch: 0100 Model_1_loss: 0.7073 Model_2_loss: 0.8069 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.5713 Model_2_val:0.5412
Epoch: 0120 Model_1_loss: 0.5898 Model_2_loss: 0.6271 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5742 Model_2_val:0.5477
Epoch: 0140 Model_1_loss: 0.5488 Model_2_loss: 0.5625 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5655 Model_2_val:0.5600
Epoch: 0160 Model_1_loss: 0.4659 Model_2_loss: 0.4977 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.5927 Model_2_val:0.5681
Epoch: 0180 Model_1_loss: 0.4091 Model_2_loss: 0.4803 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9167 Model_1_val:0.5778 Model_2_val:0.5561
Epoch: 0200 Model_1_loss: 0.4498 Model_2_loss: 0.4433 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5717 Model_2_val:0.5840
Epoch: 0220 Model_1_loss: 0.7463 Model_2_loss: 0.7555 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6451 Model_2_val:0.6280
Epoch: 0240 Model_1_loss: 0.6581 Model_2_loss: 0.7296 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6448 Model_2_val:0.6377
Epoch: 0260 Model_1_loss: 0.6452 Model_2_loss: 0.6303 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6464 Model_2_val:0.6370
Epoch: 0280 Model_1_loss: 0.6488 Model_2_loss: 0.5993 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6457 Model_2_val:0.6312
Epoch: 0300 Model_1_loss: 0.5926 Model_2_loss: 0.5883 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6315 Model_2_val:0.6354
Epoch: 0320 Model_1_loss: 0.5821 Model_2_loss: 0.6283 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6441 Model_2_val:0.6322
Epoch: 0340 Model_1_loss: 0.5190 Model_2_loss: 0.5566 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6500 Model_2_val:0.6464
Epoch: 0360 Model_1_loss: 0.5362 Model_2_loss: 0.5466 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6338 Model_2_val:0.6364
Epoch: 0380 Model_1_loss: 0.5505 Model_2_loss: 0.5358 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6512 Model_2_val:0.6286
Epoch: 0400 Model_1_loss: 0.4978 Model_2_loss: 0.5194 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6490 Model_2_val:0.6428
Model_one_test:0.6587 Model_two_test:0.6639
added by two output: 0.6635
18
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
99010857
Epoch: 0020 Model_1_loss: 1.7396 Model_2_loss: 1.7257 Model_1_trainacc: 0.4083 Model_2_trainacc: 0.3500 Model_1_val:0.2784 Model_2_val:0.2680
Epoch: 0040 Model_1_loss: 1.6308 Model_2_loss: 1.5602 Model_1_trainacc: 0.5667 Model_2_trainacc: 0.7250 Model_1_val:0.3792 Model_2_val:0.4357
Epoch: 0060 Model_1_loss: 1.3788 Model_2_loss: 1.2948 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.8250 Model_1_val:0.4612 Model_2_val:0.5010
Epoch: 0080 Model_1_loss: 1.0772 Model_2_loss: 0.9963 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8917 Model_1_val:0.5362 Model_2_val:0.5235
Epoch: 0100 Model_1_loss: 0.8105 Model_2_loss: 0.8171 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9500 Model_1_val:0.5607 Model_2_val:0.5627
Epoch: 0120 Model_1_loss: 0.6732 Model_2_loss: 0.6796 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5757 Model_2_val:0.5787
Epoch: 0140 Model_1_loss: 0.5801 Model_2_loss: 0.5897 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.6090 Model_2_val:0.5956
Epoch: 0160 Model_1_loss: 0.4856 Model_2_loss: 0.5266 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6061 Model_2_val:0.5989
Epoch: 0180 Model_1_loss: 0.5072 Model_2_loss: 0.4843 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6201 Model_2_val:0.6077
Epoch: 0200 Model_1_loss: 0.4081 Model_2_loss: 0.4288 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6237 Model_2_val:0.6142
Epoch: 0220 Model_1_loss: 0.7253 Model_2_loss: 0.7391 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6782 Model_2_val:0.6599
Epoch: 0240 Model_1_loss: 0.6592 Model_2_loss: 0.6701 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6782 Model_2_val:0.6759
Epoch: 0260 Model_1_loss: 0.6165 Model_2_loss: 0.6539 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6831 Model_2_val:0.6975
Epoch: 0280 Model_1_loss: 0.5672 Model_2_loss: 0.5671 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6906 Model_2_val:0.6808
Epoch: 0300 Model_1_loss: 0.6207 Model_2_loss: 0.5519 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6926 Model_2_val:0.6870
Epoch: 0320 Model_1_loss: 0.5309 Model_2_loss: 0.5328 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6909 Model_2_val:0.6903
Epoch: 0340 Model_1_loss: 0.5074 Model_2_loss: 0.4973 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6841 Model_2_val:0.6890
Epoch: 0360 Model_1_loss: 0.4780 Model_2_loss: 0.4469 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6883 Model_2_val:0.6841
Epoch: 0380 Model_1_loss: 0.4910 Model_2_loss: 0.4637 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6785 Model_2_val:0.6899
Epoch: 0400 Model_1_loss: 0.4407 Model_2_loss: 0.4672 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6841 Model_2_val:0.6818
Model_one_test:0.7148 Model_two_test:0.7089
added by two output: 0.7105
19
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
659255403
Epoch: 0020 Model_1_loss: 1.7268 Model_2_loss: 1.6631 Model_1_trainacc: 0.5083 Model_2_trainacc: 0.6000 Model_1_val:0.3188 Model_2_val:0.2878
Epoch: 0040 Model_1_loss: 1.5080 Model_2_loss: 1.4279 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8417 Model_1_val:0.4421 Model_2_val:0.4885
Epoch: 0060 Model_1_loss: 1.1969 Model_2_loss: 1.1152 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8417 Model_1_val:0.5032 Model_2_val:0.5006
Epoch: 0080 Model_1_loss: 0.8872 Model_2_loss: 0.8584 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9250 Model_1_val:0.5246 Model_2_val:0.5611
Epoch: 0100 Model_1_loss: 0.7409 Model_2_loss: 0.6779 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.5471 Model_2_val:0.5723
Epoch: 0120 Model_1_loss: 0.5964 Model_2_loss: 0.6374 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5627 Model_2_val:0.5746
Epoch: 0140 Model_1_loss: 0.5266 Model_2_loss: 0.5473 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.5781 Model_2_val:0.5931
Epoch: 0160 Model_1_loss: 0.4477 Model_2_loss: 0.4573 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.5970 Model_2_val:0.5842
Epoch: 0180 Model_1_loss: 0.4145 Model_2_loss: 0.4686 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5880 Model_2_val:0.6066
Epoch: 0200 Model_1_loss: 0.4110 Model_2_loss: 0.4199 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.5861 Model_2_val:0.5919
Epoch: 0220 Model_1_loss: 0.7380 Model_2_loss: 0.7723 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6466 Model_2_val:0.6482
Epoch: 0240 Model_1_loss: 0.6789 Model_2_loss: 0.6548 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6610 Model_2_val:0.6780
Epoch: 0260 Model_1_loss: 0.6402 Model_2_loss: 0.6645 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6610 Model_2_val:0.6738
Epoch: 0280 Model_1_loss: 0.6631 Model_2_loss: 0.5842 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6543 Model_2_val:0.6639
Epoch: 0300 Model_1_loss: 0.6021 Model_2_loss: 0.6175 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6655 Model_2_val:0.6745
Epoch: 0320 Model_1_loss: 0.5759 Model_2_loss: 0.5700 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6767 Model_2_val:0.6681
Epoch: 0340 Model_1_loss: 0.5705 Model_2_loss: 0.5103 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6642 Model_2_val:0.6665
Epoch: 0360 Model_1_loss: 0.5424 Model_2_loss: 0.5242 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6617 Model_2_val:0.6732
Epoch: 0380 Model_1_loss: 0.5220 Model_2_loss: 0.5879 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9500 Model_1_val:0.6639 Model_2_val:0.6636
Epoch: 0400 Model_1_loss: 0.4821 Model_2_loss: 0.4827 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6629 Model_2_val:0.6681
Model_one_test:0.6905 Model_two_test:0.6953
added by two output: 0.6914
20
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
41811702
Epoch: 0020 Model_1_loss: 1.6994 Model_2_loss: 1.7011 Model_1_trainacc: 0.4333 Model_2_trainacc: 0.4917 Model_1_val:0.2508 Model_2_val:0.2479
Epoch: 0040 Model_1_loss: 1.4619 Model_2_loss: 1.4884 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.7083 Model_1_val:0.4525 Model_2_val:0.4290
Epoch: 0060 Model_1_loss: 1.1698 Model_2_loss: 1.1811 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8083 Model_1_val:0.5040 Model_2_val:0.4947
Epoch: 0080 Model_1_loss: 0.9073 Model_2_loss: 0.9445 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9250 Model_1_val:0.5419 Model_2_val:0.5535
Epoch: 0100 Model_1_loss: 0.7300 Model_2_loss: 0.7670 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8667 Model_1_val:0.5766 Model_2_val:0.5785
Epoch: 0120 Model_1_loss: 0.6060 Model_2_loss: 0.5886 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.5828 Model_2_val:0.5822
Epoch: 0140 Model_1_loss: 0.5165 Model_2_loss: 0.5399 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.6000 Model_2_val:0.5822
Epoch: 0160 Model_1_loss: 0.4758 Model_2_loss: 0.4753 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.5924 Model_2_val:0.5914
Epoch: 0180 Model_1_loss: 0.4596 Model_2_loss: 0.4571 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6046 Model_2_val:0.6030
Epoch: 0200 Model_1_loss: 0.3764 Model_2_loss: 0.4333 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6083 Model_2_val:0.5964
Epoch: 0220 Model_1_loss: 0.6840 Model_2_loss: 0.7352 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6653 Model_2_val:0.6617
Epoch: 0240 Model_1_loss: 0.6970 Model_2_loss: 0.6715 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6630 Model_2_val:0.6749
Epoch: 0260 Model_1_loss: 0.5971 Model_2_loss: 0.5593 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6723 Model_2_val:0.6752
Epoch: 0280 Model_1_loss: 0.6279 Model_2_loss: 0.6076 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6759 Model_2_val:0.6789
Epoch: 0300 Model_1_loss: 0.5665 Model_2_loss: 0.5707 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6729 Model_2_val:0.6762
Epoch: 0320 Model_1_loss: 0.5488 Model_2_loss: 0.5403 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6776 Model_2_val:0.6809
Epoch: 0340 Model_1_loss: 0.5248 Model_2_loss: 0.5394 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6782 Model_2_val:0.6746
Epoch: 0360 Model_1_loss: 0.5143 Model_2_loss: 0.4940 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6710 Model_2_val:0.6861
Epoch: 0380 Model_1_loss: 0.5289 Model_2_loss: 0.5319 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6795 Model_2_val:0.6696
Epoch: 0400 Model_1_loss: 0.5212 Model_2_loss: 0.4872 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6723 Model_2_val:0.6703
Model_one_test:0.6970 Model_two_test:0.7010
added by two output: 0.6990
21
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1097996038
Epoch: 0020 Model_1_loss: 1.7277 Model_2_loss: 1.7240 Model_1_trainacc: 0.4750 Model_2_trainacc: 0.3583 Model_1_val:0.3146 Model_2_val:0.2068
Epoch: 0040 Model_1_loss: 1.5383 Model_2_loss: 1.5550 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.7250 Model_1_val:0.4489 Model_2_val:0.4288
Epoch: 0060 Model_1_loss: 1.2986 Model_2_loss: 1.2361 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8667 Model_1_val:0.5000 Model_2_val:0.5082
Epoch: 0080 Model_1_loss: 0.9745 Model_2_loss: 0.9384 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9000 Model_1_val:0.5462 Model_2_val:0.5383
Epoch: 0100 Model_1_loss: 0.7217 Model_2_loss: 0.7594 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9083 Model_1_val:0.5788 Model_2_val:0.5752
Epoch: 0120 Model_1_loss: 0.7008 Model_2_loss: 0.6132 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9500 Model_1_val:0.5927 Model_2_val:0.5772
Epoch: 0140 Model_1_loss: 0.6366 Model_2_loss: 0.5376 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.5877 Model_2_val:0.6118
Epoch: 0160 Model_1_loss: 0.5609 Model_2_loss: 0.4754 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9667 Model_1_val:0.5927 Model_2_val:0.6131
Epoch: 0180 Model_1_loss: 0.4606 Model_2_loss: 0.4391 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6029 Model_2_val:0.6158
Epoch: 0200 Model_1_loss: 0.3751 Model_2_loss: 0.4012 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6029 Model_2_val:0.6092
Epoch: 0220 Model_1_loss: 0.7641 Model_2_loss: 0.7106 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6507 Model_2_val:0.6699
Epoch: 0240 Model_1_loss: 0.6600 Model_2_loss: 0.6762 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6788 Model_2_val:0.6755
Epoch: 0260 Model_1_loss: 0.6811 Model_2_loss: 0.5871 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6755 Model_2_val:0.6794
Epoch: 0280 Model_1_loss: 0.6153 Model_2_loss: 0.5630 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6715 Model_2_val:0.6662
Epoch: 0300 Model_1_loss: 0.5982 Model_2_loss: 0.5425 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6774 Model_2_val:0.6738
Epoch: 0320 Model_1_loss: 0.5929 Model_2_loss: 0.5289 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6705 Model_2_val:0.6751
Epoch: 0340 Model_1_loss: 0.5322 Model_2_loss: 0.5288 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6685 Model_2_val:0.6811
Epoch: 0360 Model_1_loss: 0.5566 Model_2_loss: 0.5010 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6827 Model_2_val:0.6781
Epoch: 0380 Model_1_loss: 0.5011 Model_2_loss: 0.4736 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6659 Model_2_val:0.6666
Epoch: 0400 Model_1_loss: 0.5465 Model_2_loss: 0.4714 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6695 Model_2_val:0.6883
Model_one_test:0.6969 Model_two_test:0.6959
added by two output: 0.6956
22
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
748616626
Epoch: 0020 Model_1_loss: 1.7267 Model_2_loss: 1.7002 Model_1_trainacc: 0.3750 Model_2_trainacc: 0.3833 Model_1_val:0.1509 Model_2_val:0.2147
Epoch: 0040 Model_1_loss: 1.5517 Model_2_loss: 1.5092 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.7917 Model_1_val:0.3905 Model_2_val:0.3769
Epoch: 0060 Model_1_loss: 1.2755 Model_2_loss: 1.2038 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8667 Model_1_val:0.4865 Model_2_val:0.4972
Epoch: 0080 Model_1_loss: 0.9651 Model_2_loss: 0.9065 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8917 Model_1_val:0.5324 Model_2_val:0.5414
Epoch: 0100 Model_1_loss: 0.7384 Model_2_loss: 0.6673 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5371 Model_2_val:0.5650
Epoch: 0120 Model_1_loss: 0.6284 Model_2_loss: 0.5940 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5610 Model_2_val:0.5803
Epoch: 0140 Model_1_loss: 0.5227 Model_2_loss: 0.5117 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5842 Model_2_val:0.5710
Epoch: 0160 Model_1_loss: 0.5094 Model_2_loss: 0.4745 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9583 Model_1_val:0.5793 Model_2_val:0.5896
Epoch: 0180 Model_1_loss: 0.4365 Model_2_loss: 0.3857 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.5806 Model_2_val:0.5859
Epoch: 0200 Model_1_loss: 0.3883 Model_2_loss: 0.3886 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5729 Model_2_val:0.5926
Epoch: 0220 Model_1_loss: 0.7398 Model_2_loss: 0.6971 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6331 Model_2_val:0.6427
Epoch: 0240 Model_1_loss: 0.6743 Model_2_loss: 0.6312 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6623 Model_2_val:0.6484
Epoch: 0260 Model_1_loss: 0.6405 Model_2_loss: 0.5845 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6534 Model_2_val:0.6584
Epoch: 0280 Model_1_loss: 0.5759 Model_2_loss: 0.5678 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6441 Model_2_val:0.6637
Epoch: 0300 Model_1_loss: 0.5585 Model_2_loss: 0.5006 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6544 Model_2_val:0.6574
Epoch: 0320 Model_1_loss: 0.5642 Model_2_loss: 0.4978 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6514 Model_2_val:0.6637
Epoch: 0340 Model_1_loss: 0.5115 Model_2_loss: 0.4744 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6381 Model_2_val:0.6510
Epoch: 0360 Model_1_loss: 0.4859 Model_2_loss: 0.5011 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6471 Model_2_val:0.6617
Epoch: 0380 Model_1_loss: 0.4562 Model_2_loss: 0.4473 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6567 Model_2_val:0.6567
Epoch: 0400 Model_1_loss: 0.4294 Model_2_loss: 0.4478 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6570 Model_2_val:0.6590
Model_one_test:0.6707 Model_two_test:0.6697
added by two output: 0.6697
23
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1357640666
Epoch: 0020 Model_1_loss: 1.7282 Model_2_loss: 1.7199 Model_1_trainacc: 0.2667 Model_2_trainacc: 0.5000 Model_1_val:0.2068 Model_2_val:0.2624
Epoch: 0040 Model_1_loss: 1.5650 Model_2_loss: 1.5311 Model_1_trainacc: 0.6833 Model_2_trainacc: 0.7417 Model_1_val:0.4164 Model_2_val:0.4859
Epoch: 0060 Model_1_loss: 1.2324 Model_2_loss: 1.2258 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8833 Model_1_val:0.4981 Model_2_val:0.5350
Epoch: 0080 Model_1_loss: 0.8895 Model_2_loss: 1.0018 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8917 Model_1_val:0.5508 Model_2_val:0.5550
Epoch: 0100 Model_1_loss: 0.6668 Model_2_loss: 0.7576 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5817 Model_2_val:0.5624
Epoch: 0120 Model_1_loss: 0.5726 Model_2_loss: 0.6078 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5990 Model_2_val:0.5839
Epoch: 0140 Model_1_loss: 0.4874 Model_2_loss: 0.5197 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.6077 Model_2_val:0.5746
Epoch: 0160 Model_1_loss: 0.4105 Model_2_loss: 0.4655 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6196 Model_2_val:0.5987
Epoch: 0180 Model_1_loss: 0.4051 Model_2_loss: 0.3688 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6019 Model_2_val:0.6058
Epoch: 0200 Model_1_loss: 0.3940 Model_2_loss: 0.3185 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6048 Model_2_val:0.6338
Epoch: 0220 Model_1_loss: 0.6870 Model_2_loss: 0.6392 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6598 Model_2_val:0.6743
Epoch: 0240 Model_1_loss: 0.6558 Model_2_loss: 0.6452 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6659 Model_2_val:0.6640
Epoch: 0260 Model_1_loss: 0.6189 Model_2_loss: 0.5993 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6749 Model_2_val:0.6707
Epoch: 0280 Model_1_loss: 0.5685 Model_2_loss: 0.6012 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6723 Model_2_val:0.6605
Epoch: 0300 Model_1_loss: 0.5391 Model_2_loss: 0.5207 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6685 Model_2_val:0.6621
Epoch: 0320 Model_1_loss: 0.5380 Model_2_loss: 0.5267 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6701 Model_2_val:0.6756
Epoch: 0340 Model_1_loss: 0.5473 Model_2_loss: 0.5165 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6830 Model_2_val:0.6746
Epoch: 0360 Model_1_loss: 0.4947 Model_2_loss: 0.4746 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6682 Model_2_val:0.6727
Epoch: 0380 Model_1_loss: 0.5057 Model_2_loss: 0.4264 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6749 Model_2_val:0.6646
Epoch: 0400 Model_1_loss: 0.4808 Model_2_loss: 0.4457 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6730 Model_2_val:0.6669
Model_one_test:0.6952 Model_two_test:0.6949
added by two output: 0.6945
24
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1166917475
Epoch: 0020 Model_1_loss: 1.7068 Model_2_loss: 1.7113 Model_1_trainacc: 0.5333 Model_2_trainacc: 0.4833 Model_1_val:0.3264 Model_2_val:0.2371
Epoch: 0040 Model_1_loss: 1.4833 Model_2_loss: 1.5162 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8083 Model_1_val:0.4580 Model_2_val:0.4388
Epoch: 0060 Model_1_loss: 1.1424 Model_2_loss: 1.2228 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8667 Model_1_val:0.5142 Model_2_val:0.5155
Epoch: 0080 Model_1_loss: 0.8880 Model_2_loss: 0.8859 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9167 Model_1_val:0.5248 Model_2_val:0.5552
Epoch: 0100 Model_1_loss: 0.6870 Model_2_loss: 0.6953 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5638 Model_2_val:0.5559
Epoch: 0120 Model_1_loss: 0.5668 Model_2_loss: 0.5791 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.5747 Model_2_val:0.5896
Epoch: 0140 Model_1_loss: 0.5562 Model_2_loss: 0.5025 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.5675 Model_2_val:0.5886
Epoch: 0160 Model_1_loss: 0.4335 Model_2_loss: 0.4880 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9333 Model_1_val:0.5754 Model_2_val:0.6035
Epoch: 0180 Model_1_loss: 0.4044 Model_2_loss: 0.4645 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.5870 Model_2_val:0.6134
Epoch: 0200 Model_1_loss: 0.3876 Model_2_loss: 0.4473 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.5800 Model_2_val:0.5982
Epoch: 0220 Model_1_loss: 0.7119 Model_2_loss: 0.6804 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6630 Model_2_val:0.6693
Epoch: 0240 Model_1_loss: 0.6788 Model_2_loss: 0.6557 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6782 Model_2_val:0.6736
Epoch: 0260 Model_1_loss: 0.6049 Model_2_loss: 0.6343 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6769 Model_2_val:0.6766
Epoch: 0280 Model_1_loss: 0.6018 Model_2_loss: 0.5576 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6825 Model_2_val:0.6729
Epoch: 0300 Model_1_loss: 0.5426 Model_2_loss: 0.5367 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6878 Model_2_val:0.6776
Epoch: 0320 Model_1_loss: 0.5523 Model_2_loss: 0.5360 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6815 Model_2_val:0.6799
Epoch: 0340 Model_1_loss: 0.5018 Model_2_loss: 0.4796 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6746 Model_2_val:0.6951
Epoch: 0360 Model_1_loss: 0.4691 Model_2_loss: 0.4868 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6855 Model_2_val:0.6878
Epoch: 0380 Model_1_loss: 0.4962 Model_2_loss: 0.5025 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6802 Model_2_val:0.6878
Epoch: 0400 Model_1_loss: 0.4760 Model_2_loss: 0.4863 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6845 Model_2_val:0.6905
Model_one_test:0.7054 Model_two_test:0.7040
added by two output: 0.7050
25
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1132575540
Epoch: 0020 Model_1_loss: 1.6902 Model_2_loss: 1.7212 Model_1_trainacc: 0.4083 Model_2_trainacc: 0.4417 Model_1_val:0.2241 Model_2_val:0.2160
Epoch: 0040 Model_1_loss: 1.4520 Model_2_loss: 1.5404 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.7667 Model_1_val:0.4398 Model_2_val:0.3559
Epoch: 0060 Model_1_loss: 1.0777 Model_2_loss: 1.2684 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8083 Model_1_val:0.4977 Model_2_val:0.4317
Epoch: 0080 Model_1_loss: 0.8903 Model_2_loss: 1.0192 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8667 Model_1_val:0.5221 Model_2_val:0.4723
Epoch: 0100 Model_1_loss: 0.7210 Model_2_loss: 0.8347 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.5345 Model_2_val:0.4919
Epoch: 0120 Model_1_loss: 0.6485 Model_2_loss: 0.7388 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9000 Model_1_val:0.5706 Model_2_val:0.4984
Epoch: 0140 Model_1_loss: 0.5648 Model_2_loss: 0.6721 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9167 Model_1_val:0.5725 Model_2_val:0.5348
Epoch: 0160 Model_1_loss: 0.5260 Model_2_loss: 0.5259 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.5777 Model_2_val:0.5332
Epoch: 0180 Model_1_loss: 0.4117 Model_2_loss: 0.5146 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.5852 Model_2_val:0.5527
Epoch: 0200 Model_1_loss: 0.4285 Model_2_loss: 0.4522 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.5836 Model_2_val:0.5690
Epoch: 0220 Model_1_loss: 0.7178 Model_2_loss: 0.7693 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6425 Model_2_val:0.6454
Epoch: 0240 Model_1_loss: 0.6629 Model_2_loss: 0.7175 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6545 Model_2_val:0.6405
Epoch: 0260 Model_1_loss: 0.6919 Model_2_loss: 0.6952 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6542 Model_2_val:0.6584
Epoch: 0280 Model_1_loss: 0.6043 Model_2_loss: 0.6915 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6526 Model_2_val:0.6483
Epoch: 0300 Model_1_loss: 0.6053 Model_2_loss: 0.6190 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6584 Model_2_val:0.6483
Epoch: 0320 Model_1_loss: 0.6096 Model_2_loss: 0.5692 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6552 Model_2_val:0.6461
Epoch: 0340 Model_1_loss: 0.5824 Model_2_loss: 0.5386 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6558 Model_2_val:0.6487
Epoch: 0360 Model_1_loss: 0.5505 Model_2_loss: 0.5377 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6601 Model_2_val:0.6588
Epoch: 0380 Model_1_loss: 0.5602 Model_2_loss: 0.4937 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6614 Model_2_val:0.6594
Epoch: 0400 Model_1_loss: 0.4733 Model_2_loss: 0.5013 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6630 Model_2_val:0.6555
Model_one_test:0.6815 Model_two_test:0.6783
added by two output: 0.6802
26
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
827378238
Epoch: 0020 Model_1_loss: 1.7281 Model_2_loss: 1.7036 Model_1_trainacc: 0.4333 Model_2_trainacc: 0.4500 Model_1_val:0.2763 Model_2_val:0.2843
Epoch: 0040 Model_1_loss: 1.5311 Model_2_loss: 1.4931 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.7500 Model_1_val:0.4727 Model_2_val:0.4388
Epoch: 0060 Model_1_loss: 1.1886 Model_2_loss: 1.1803 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.8917 Model_1_val:0.5428 Model_2_val:0.4960
Epoch: 0080 Model_1_loss: 0.8847 Model_2_loss: 0.8985 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8833 Model_1_val:0.5641 Model_2_val:0.5380
Epoch: 0100 Model_1_loss: 0.7416 Model_2_loss: 0.7028 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.5864 Model_2_val:0.5538
Epoch: 0120 Model_1_loss: 0.5944 Model_2_loss: 0.5764 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6000 Model_2_val:0.5674
Epoch: 0140 Model_1_loss: 0.5031 Model_2_loss: 0.5502 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6026 Model_2_val:0.5900
Epoch: 0160 Model_1_loss: 0.4060 Model_2_loss: 0.4664 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6178 Model_2_val:0.5787
Epoch: 0180 Model_1_loss: 0.3820 Model_2_loss: 0.4658 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.6058 Model_2_val:0.5893
Epoch: 0200 Model_1_loss: 0.3651 Model_2_loss: 0.3873 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6178 Model_2_val:0.5897
Epoch: 0220 Model_1_loss: 0.6833 Model_2_loss: 0.7156 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9417 Model_1_val:0.6711 Model_2_val:0.6769
Epoch: 0240 Model_1_loss: 0.6423 Model_2_loss: 0.6768 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6808 Model_2_val:0.6817
Epoch: 0260 Model_1_loss: 0.5896 Model_2_loss: 0.6123 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6821 Model_2_val:0.6772
Epoch: 0280 Model_1_loss: 0.5646 Model_2_loss: 0.6461 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6885 Model_2_val:0.6759
Epoch: 0300 Model_1_loss: 0.5415 Model_2_loss: 0.5336 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6885 Model_2_val:0.6817
Epoch: 0320 Model_1_loss: 0.4946 Model_2_loss: 0.5149 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6905 Model_2_val:0.6905
Epoch: 0340 Model_1_loss: 0.4840 Model_2_loss: 0.4915 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6908 Model_2_val:0.6837
Epoch: 0360 Model_1_loss: 0.4658 Model_2_loss: 0.4912 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6788 Model_2_val:0.6889
Epoch: 0380 Model_1_loss: 0.4800 Model_2_loss: 0.4883 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6911 Model_2_val:0.6785
Epoch: 0400 Model_1_loss: 0.4619 Model_2_loss: 0.4453 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6866 Model_2_val:0.6788
Model_one_test:0.7147 Model_two_test:0.7105
added by two output: 0.7124
27
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
524296666
Epoch: 0020 Model_1_loss: 1.7227 Model_2_loss: 1.7198 Model_1_trainacc: 0.5417 Model_2_trainacc: 0.3583 Model_1_val:0.2848 Model_2_val:0.2697
Epoch: 0040 Model_1_loss: 1.5353 Model_2_loss: 1.5531 Model_1_trainacc: 0.7083 Model_2_trainacc: 0.7250 Model_1_val:0.4149 Model_2_val:0.4636
Epoch: 0060 Model_1_loss: 1.2659 Model_2_loss: 1.3168 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.7833 Model_1_val:0.4604 Model_2_val:0.4823
Epoch: 0080 Model_1_loss: 1.0341 Model_2_loss: 1.0892 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.7750 Model_1_val:0.5168 Model_2_val:0.5174
Epoch: 0100 Model_1_loss: 0.8167 Model_2_loss: 0.8718 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8667 Model_1_val:0.5316 Model_2_val:0.5641
Epoch: 0120 Model_1_loss: 0.6484 Model_2_loss: 0.7485 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8833 Model_1_val:0.5709 Model_2_val:0.5351
Epoch: 0140 Model_1_loss: 0.5899 Model_2_loss: 0.5903 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9250 Model_1_val:0.5915 Model_2_val:0.5744
Epoch: 0160 Model_1_loss: 0.5334 Model_2_loss: 0.5783 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.6166 Model_2_val:0.5712
Epoch: 0180 Model_1_loss: 0.4367 Model_2_loss: 0.5521 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6128 Model_2_val:0.5780
Epoch: 0200 Model_1_loss: 0.4327 Model_2_loss: 0.4694 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.6137 Model_2_val:0.5812
Epoch: 0220 Model_1_loss: 0.7529 Model_2_loss: 0.8335 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6662 Model_2_val:0.6485
Epoch: 0240 Model_1_loss: 0.7240 Model_2_loss: 0.8156 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6707 Model_2_val:0.6553
Epoch: 0260 Model_1_loss: 0.6852 Model_2_loss: 0.7795 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9167 Model_1_val:0.6794 Model_2_val:0.6675
Epoch: 0280 Model_1_loss: 0.6453 Model_2_loss: 0.6674 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6691 Model_2_val:0.6666
Epoch: 0300 Model_1_loss: 0.6158 Model_2_loss: 0.6740 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9417 Model_1_val:0.6746 Model_2_val:0.6695
Epoch: 0320 Model_1_loss: 0.5348 Model_2_loss: 0.6413 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.6836 Model_2_val:0.6685
Epoch: 0340 Model_1_loss: 0.5743 Model_2_loss: 0.6108 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6772 Model_2_val:0.6720
Epoch: 0360 Model_1_loss: 0.5764 Model_2_loss: 0.6246 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6724 Model_2_val:0.6711
Epoch: 0380 Model_1_loss: 0.5573 Model_2_loss: 0.6014 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6678 Model_2_val:0.6724
Epoch: 0400 Model_1_loss: 0.5158 Model_2_loss: 0.5554 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6782 Model_2_val:0.6717
Model_one_test:0.7033 Model_two_test:0.7065
added by two output: 0.7033
28
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
16560926
Epoch: 0020 Model_1_loss: 1.7123 Model_2_loss: 1.7094 Model_1_trainacc: 0.4000 Model_2_trainacc: 0.5250 Model_1_val:0.2527 Model_2_val:0.3234
Epoch: 0040 Model_1_loss: 1.5320 Model_2_loss: 1.4910 Model_1_trainacc: 0.6750 Model_2_trainacc: 0.7917 Model_1_val:0.3865 Model_2_val:0.4561
Epoch: 0060 Model_1_loss: 1.1904 Model_2_loss: 1.1417 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8917 Model_1_val:0.4969 Model_2_val:0.5242
Epoch: 0080 Model_1_loss: 0.9503 Model_2_loss: 0.8611 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.9250 Model_1_val:0.5472 Model_2_val:0.5475
Epoch: 0100 Model_1_loss: 0.6957 Model_2_loss: 0.6443 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5619 Model_2_val:0.5922
Epoch: 0120 Model_1_loss: 0.6150 Model_2_loss: 0.5846 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5938 Model_2_val:0.5846
Epoch: 0140 Model_1_loss: 0.5067 Model_2_loss: 0.4894 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.5958 Model_2_val:0.6060
Epoch: 0160 Model_1_loss: 0.4438 Model_2_loss: 0.4544 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5925 Model_2_val:0.6103
Epoch: 0180 Model_1_loss: 0.4278 Model_2_loss: 0.3777 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6178 Model_2_val:0.6139
Epoch: 0200 Model_1_loss: 0.3417 Model_2_loss: 0.3867 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.6155 Model_2_val:0.6073
Epoch: 0220 Model_1_loss: 0.6995 Model_2_loss: 0.7428 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6523 Model_2_val:0.6494
Epoch: 0240 Model_1_loss: 0.6711 Model_2_loss: 0.6240 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6497 Model_2_val:0.6592
Epoch: 0260 Model_1_loss: 0.5810 Model_2_loss: 0.6172 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6582 Model_2_val:0.6615
Epoch: 0280 Model_1_loss: 0.5410 Model_2_loss: 0.5650 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6595 Model_2_val:0.6599
Epoch: 0300 Model_1_loss: 0.5437 Model_2_loss: 0.5437 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6572 Model_2_val:0.6687
Epoch: 0320 Model_1_loss: 0.5221 Model_2_loss: 0.5494 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6661 Model_2_val:0.6648
Epoch: 0340 Model_1_loss: 0.4891 Model_2_loss: 0.5321 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6779 Model_2_val:0.6559
Epoch: 0360 Model_1_loss: 0.4909 Model_2_loss: 0.5013 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6720 Model_2_val:0.6756
Epoch: 0380 Model_1_loss: 0.4783 Model_2_loss: 0.4838 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6641 Model_2_val:0.6714
Epoch: 0400 Model_1_loss: 0.4456 Model_2_loss: 0.4796 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6687 Model_2_val:0.6549
Model_one_test:0.6927 Model_two_test:0.6901
added by two output: 0.6901
29
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1536753220
Epoch: 0020 Model_1_loss: 1.7465 Model_2_loss: 1.7488 Model_1_trainacc: 0.3167 Model_2_trainacc: 0.2667 Model_1_val:0.2682 Model_2_val:0.1997
Epoch: 0040 Model_1_loss: 1.5828 Model_2_loss: 1.5972 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.6750 Model_1_val:0.4200 Model_2_val:0.3197
Epoch: 0060 Model_1_loss: 1.3248 Model_2_loss: 1.3237 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8500 Model_1_val:0.4574 Model_2_val:0.4702
Epoch: 0080 Model_1_loss: 1.0588 Model_2_loss: 0.9717 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8917 Model_1_val:0.4970 Model_2_val:0.5095
Epoch: 0100 Model_1_loss: 0.8449 Model_2_loss: 0.8090 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9083 Model_1_val:0.5498 Model_2_val:0.5498
Epoch: 0120 Model_1_loss: 0.6905 Model_2_loss: 0.7111 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9000 Model_1_val:0.5744 Model_2_val:0.5620
Epoch: 0140 Model_1_loss: 0.6522 Model_2_loss: 0.5425 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9417 Model_1_val:0.5741 Model_2_val:0.5885
Epoch: 0160 Model_1_loss: 0.5273 Model_2_loss: 0.5213 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.5816 Model_2_val:0.5754
Epoch: 0180 Model_1_loss: 0.5167 Model_2_loss: 0.4908 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.5777 Model_2_val:0.5790
Epoch: 0200 Model_1_loss: 0.4960 Model_2_loss: 0.4436 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5856 Model_2_val:0.5728
Epoch: 0220 Model_1_loss: 0.8121 Model_2_loss: 0.8043 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6348 Model_2_val:0.6515
Epoch: 0240 Model_1_loss: 0.7527 Model_2_loss: 0.8203 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9333 Model_1_val:0.6623 Model_2_val:0.6479
Epoch: 0260 Model_1_loss: 0.7473 Model_2_loss: 0.7440 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6731 Model_2_val:0.6695
Epoch: 0280 Model_1_loss: 0.6511 Model_2_loss: 0.7261 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9333 Model_1_val:0.6770 Model_2_val:0.6577
Epoch: 0300 Model_1_loss: 0.5654 Model_2_loss: 0.6105 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6669 Model_2_val:0.6721
Epoch: 0320 Model_1_loss: 0.5851 Model_2_loss: 0.6201 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6770 Model_2_val:0.6685
Epoch: 0340 Model_1_loss: 0.5563 Model_2_loss: 0.6270 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6656 Model_2_val:0.6725
Epoch: 0360 Model_1_loss: 0.5219 Model_2_loss: 0.5484 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6731 Model_2_val:0.6607
Epoch: 0380 Model_1_loss: 0.5402 Model_2_loss: 0.5661 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6675 Model_2_val:0.6698
Epoch: 0400 Model_1_loss: 0.5074 Model_2_loss: 0.5862 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6741 Model_2_val:0.6643
Model_one_test:0.6921 Model_two_test:0.6908
added by two output: 0.6928
30
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
67418370
Epoch: 0020 Model_1_loss: 1.7727 Model_2_loss: 1.7184 Model_1_trainacc: 0.2417 Model_2_trainacc: 0.4917 Model_1_val:0.2146 Model_2_val:0.2296
Epoch: 0040 Model_1_loss: 1.6623 Model_2_loss: 1.4927 Model_1_trainacc: 0.5833 Model_2_trainacc: 0.8417 Model_1_val:0.3418 Model_2_val:0.4719
Epoch: 0060 Model_1_loss: 1.4165 Model_2_loss: 1.2081 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.8500 Model_1_val:0.4982 Model_2_val:0.5275
Epoch: 0080 Model_1_loss: 1.0642 Model_2_loss: 0.8608 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9250 Model_1_val:0.5371 Model_2_val:0.5730
Epoch: 0100 Model_1_loss: 0.7655 Model_2_loss: 0.7380 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9250 Model_1_val:0.5747 Model_2_val:0.5797
Epoch: 0120 Model_1_loss: 0.6794 Model_2_loss: 0.5845 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9250 Model_1_val:0.5973 Model_2_val:0.6017
Epoch: 0140 Model_1_loss: 0.5214 Model_2_loss: 0.4949 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.5907 Model_2_val:0.5804
Epoch: 0160 Model_1_loss: 0.4772 Model_2_loss: 0.4877 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6166 Model_2_val:0.6063
Epoch: 0180 Model_1_loss: 0.3826 Model_2_loss: 0.4339 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6150 Model_2_val:0.6027
Epoch: 0200 Model_1_loss: 0.3995 Model_2_loss: 0.3423 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6057 Model_2_val:0.6070
Epoch: 0220 Model_1_loss: 0.6658 Model_2_loss: 0.6447 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6715 Model_2_val:0.6669
Epoch: 0240 Model_1_loss: 0.6839 Model_2_loss: 0.6578 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6646 Model_2_val:0.6636
Epoch: 0260 Model_1_loss: 0.6008 Model_2_loss: 0.5757 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6749 Model_2_val:0.6639
Epoch: 0280 Model_1_loss: 0.5774 Model_2_loss: 0.5405 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6669 Model_2_val:0.6646
Epoch: 0300 Model_1_loss: 0.5312 Model_2_loss: 0.5292 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6552 Model_2_val:0.6679
Epoch: 0320 Model_1_loss: 0.4749 Model_2_loss: 0.5022 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6626 Model_2_val:0.6592
Epoch: 0340 Model_1_loss: 0.4506 Model_2_loss: 0.4785 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6759 Model_2_val:0.6649
Epoch: 0360 Model_1_loss: 0.4751 Model_2_loss: 0.4484 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6652 Model_2_val:0.6722
Epoch: 0380 Model_1_loss: 0.4355 Model_2_loss: 0.4119 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6599 Model_2_val:0.6636
Epoch: 0400 Model_1_loss: 0.4253 Model_2_loss: 0.3927 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6646 Model_2_val:0.6672
Model_one_test:0.6849 Model_two_test:0.6865
added by two output: 0.6859
Model1 Acc: 0.692855 Model2 Acc: 0.692939
Maxacc Mean: 0.694344
[0.6924372651610259, 0.6927043179398544, 0.6923088360447857, 0.6922086163222224, 0.691536895183715, 0.6943443442678022]
Maxacc of all experiments: 0.6943443442678022
1
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1144020919
Epoch: 0020 Model_1_loss: 1.7101 Model_2_loss: 1.6948 Model_1_trainacc: 0.4333 Model_2_trainacc: 0.5417 Model_1_val:0.2832 Model_2_val:0.3132
Epoch: 0040 Model_1_loss: 1.5596 Model_2_loss: 1.4907 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.8000 Model_1_val:0.4168 Model_2_val:0.4072
Epoch: 0060 Model_1_loss: 1.2616 Model_2_loss: 1.2243 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8500 Model_1_val:0.4737 Model_2_val:0.4717
Epoch: 0080 Model_1_loss: 0.9229 Model_2_loss: 0.9908 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.5266 Model_2_val:0.5138
Epoch: 0100 Model_1_loss: 0.7306 Model_2_loss: 0.8292 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9250 Model_1_val:0.5586 Model_2_val:0.5237
Epoch: 0120 Model_1_loss: 0.6151 Model_2_loss: 0.6620 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9250 Model_1_val:0.5776 Model_2_val:0.5510
Epoch: 0140 Model_1_loss: 0.5851 Model_2_loss: 0.5265 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5569 Model_2_val:0.5477
Epoch: 0160 Model_1_loss: 0.4593 Model_2_loss: 0.4497 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5812 Model_2_val:0.5668
Epoch: 0180 Model_1_loss: 0.4095 Model_2_loss: 0.4477 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5707 Model_2_val:0.5707
Epoch: 0200 Model_1_loss: 0.4045 Model_2_loss: 0.4023 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5776 Model_2_val:0.5786
Epoch: 0220 Model_1_loss: 0.7024 Model_2_loss: 0.7099 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6474 Model_2_val:0.6513
Epoch: 0240 Model_1_loss: 0.6641 Model_2_loss: 0.7010 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6474 Model_2_val:0.6516
Epoch: 0260 Model_1_loss: 0.6140 Model_2_loss: 0.6009 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6684 Model_2_val:0.6586
Epoch: 0280 Model_1_loss: 0.6015 Model_2_loss: 0.5990 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6628 Model_2_val:0.6687
Epoch: 0300 Model_1_loss: 0.5061 Model_2_loss: 0.5891 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6707 Model_2_val:0.6658
Epoch: 0320 Model_1_loss: 0.5406 Model_2_loss: 0.5494 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6701 Model_2_val:0.6724
Epoch: 0340 Model_1_loss: 0.4691 Model_2_loss: 0.5301 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6684 Model_2_val:0.6635
Epoch: 0360 Model_1_loss: 0.4694 Model_2_loss: 0.4651 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6687 Model_2_val:0.6701
Epoch: 0380 Model_1_loss: 0.4924 Model_2_loss: 0.4918 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6671 Model_2_val:0.6720
Epoch: 0400 Model_1_loss: 0.4470 Model_2_loss: 0.4671 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6691 Model_2_val:0.6664
Model_one_test:0.6882 Model_two_test:0.6865
added by two output: 0.6882
2
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
280274269
Epoch: 0020 Model_1_loss: 1.7194 Model_2_loss: 1.7149 Model_1_trainacc: 0.3750 Model_2_trainacc: 0.4667 Model_1_val:0.2383 Model_2_val:0.2620
Epoch: 0040 Model_1_loss: 1.5382 Model_2_loss: 1.5473 Model_1_trainacc: 0.6750 Model_2_trainacc: 0.7667 Model_1_val:0.4365 Model_2_val:0.3953
Epoch: 0060 Model_1_loss: 1.2178 Model_2_loss: 1.2641 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8583 Model_1_val:0.5191 Model_2_val:0.5030
Epoch: 0080 Model_1_loss: 0.9552 Model_2_loss: 0.9169 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9333 Model_1_val:0.5444 Model_2_val:0.5573
Epoch: 0100 Model_1_loss: 0.7181 Model_2_loss: 0.7872 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5790 Model_2_val:0.5731
Epoch: 0120 Model_1_loss: 0.6089 Model_2_loss: 0.6140 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9250 Model_1_val:0.6066 Model_2_val:0.5780
Epoch: 0140 Model_1_loss: 0.5130 Model_2_loss: 0.5231 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6060 Model_2_val:0.5941
Epoch: 0160 Model_1_loss: 0.4344 Model_2_loss: 0.4743 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.5902 Model_2_val:0.6050
Epoch: 0180 Model_1_loss: 0.4249 Model_2_loss: 0.4337 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.5987 Model_2_val:0.6096
Epoch: 0200 Model_1_loss: 0.3632 Model_2_loss: 0.3943 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6251 Model_2_val:0.6119
Epoch: 0220 Model_1_loss: 0.6559 Model_2_loss: 0.7357 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.6629 Model_2_val:0.6501
Epoch: 0240 Model_1_loss: 0.6386 Model_2_loss: 0.6544 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6731 Model_2_val:0.6698
Epoch: 0260 Model_1_loss: 0.5638 Model_2_loss: 0.5921 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6791 Model_2_val:0.6619
Epoch: 0280 Model_1_loss: 0.5468 Model_2_loss: 0.5180 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6728 Model_2_val:0.6649
Epoch: 0300 Model_1_loss: 0.5174 Model_2_loss: 0.5171 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6745 Model_2_val:0.6649
Epoch: 0320 Model_1_loss: 0.4917 Model_2_loss: 0.5332 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6623 Model_2_val:0.6708
Epoch: 0340 Model_1_loss: 0.4791 Model_2_loss: 0.4838 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6728 Model_2_val:0.6758
Epoch: 0360 Model_1_loss: 0.4644 Model_2_loss: 0.4980 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6768 Model_2_val:0.6652
Epoch: 0380 Model_1_loss: 0.4438 Model_2_loss: 0.4268 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6646 Model_2_val:0.6695
Epoch: 0400 Model_1_loss: 0.4330 Model_2_loss: 0.4255 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6577 Model_2_val:0.6679
Model_one_test:0.6883 Model_two_test:0.6889
added by two output: 0.6896
3
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
294203131
Epoch: 0020 Model_1_loss: 1.7266 Model_2_loss: 1.7334 Model_1_trainacc: 0.4083 Model_2_trainacc: 0.3333 Model_1_val:0.2987 Model_2_val:0.2315
Epoch: 0040 Model_1_loss: 1.5709 Model_2_loss: 1.5318 Model_1_trainacc: 0.6750 Model_2_trainacc: 0.7667 Model_1_val:0.4376 Model_2_val:0.4534
Epoch: 0060 Model_1_loss: 1.2858 Model_2_loss: 1.2312 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.8500 Model_1_val:0.4949 Model_2_val:0.4997
Epoch: 0080 Model_1_loss: 1.0142 Model_2_loss: 0.9433 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9000 Model_1_val:0.5193 Model_2_val:0.5386
Epoch: 0100 Model_1_loss: 0.8267 Model_2_loss: 0.6713 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9417 Model_1_val:0.5476 Model_2_val:0.5576
Epoch: 0120 Model_1_loss: 0.6942 Model_2_loss: 0.6025 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5511 Model_2_val:0.5781
Epoch: 0140 Model_1_loss: 0.6192 Model_2_loss: 0.5280 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9417 Model_1_val:0.5637 Model_2_val:0.5865
Epoch: 0160 Model_1_loss: 0.5535 Model_2_loss: 0.4984 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5775 Model_2_val:0.5977
Epoch: 0180 Model_1_loss: 0.4612 Model_2_loss: 0.4242 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.5839 Model_2_val:0.5907
Epoch: 0200 Model_1_loss: 0.4043 Model_2_loss: 0.4131 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.5913 Model_2_val:0.5894
Epoch: 0220 Model_1_loss: 0.7301 Model_2_loss: 0.6993 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6576 Model_2_val:0.6608
Epoch: 0240 Model_1_loss: 0.6459 Model_2_loss: 0.6568 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6531 Model_2_val:0.6531
Epoch: 0260 Model_1_loss: 0.5733 Model_2_loss: 0.6083 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6537 Model_2_val:0.6630
Epoch: 0280 Model_1_loss: 0.5526 Model_2_loss: 0.5473 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6678 Model_2_val:0.6598
Epoch: 0300 Model_1_loss: 0.5095 Model_2_loss: 0.5416 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6582 Model_2_val:0.6646
Epoch: 0320 Model_1_loss: 0.5321 Model_2_loss: 0.4741 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6527 Model_2_val:0.6585
Epoch: 0340 Model_1_loss: 0.4927 Model_2_loss: 0.5165 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6611 Model_2_val:0.6611
Epoch: 0360 Model_1_loss: 0.4815 Model_2_loss: 0.4892 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6666 Model_2_val:0.6585
Epoch: 0380 Model_1_loss: 0.4190 Model_2_loss: 0.4671 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6646 Model_2_val:0.6611
Epoch: 0400 Model_1_loss: 0.4668 Model_2_loss: 0.4670 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6534 Model_2_val:0.6553
Model_one_test:0.6826 Model_two_test:0.6833
added by two output: 0.6839
4
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
204882795
Epoch: 0020 Model_1_loss: 1.6884 Model_2_loss: 1.7108 Model_1_trainacc: 0.4083 Model_2_trainacc: 0.4917 Model_1_val:0.2569 Model_2_val:0.2625
Epoch: 0040 Model_1_loss: 1.4609 Model_2_loss: 1.5035 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.8000 Model_1_val:0.4352 Model_2_val:0.3911
Epoch: 0060 Model_1_loss: 1.1921 Model_2_loss: 1.2066 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8000 Model_1_val:0.4959 Model_2_val:0.4985
Epoch: 0080 Model_1_loss: 0.8916 Model_2_loss: 0.8470 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9083 Model_1_val:0.5608 Model_2_val:0.5608
Epoch: 0100 Model_1_loss: 0.6962 Model_2_loss: 0.6787 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.5655 Model_2_val:0.5635
Epoch: 0120 Model_1_loss: 0.5534 Model_2_loss: 0.5493 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.5834 Model_2_val:0.5873
Epoch: 0140 Model_1_loss: 0.4862 Model_2_loss: 0.5279 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9250 Model_1_val:0.5777 Model_2_val:0.5913
Epoch: 0160 Model_1_loss: 0.4482 Model_2_loss: 0.4408 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6079 Model_2_val:0.5834
Epoch: 0180 Model_1_loss: 0.3983 Model_2_loss: 0.3775 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.5946 Model_2_val:0.5966
Epoch: 0200 Model_1_loss: 0.3993 Model_2_loss: 0.3679 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.5817 Model_2_val:0.5777
Epoch: 0220 Model_1_loss: 0.6655 Model_2_loss: 0.7213 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6553 Model_2_val:0.6589
Epoch: 0240 Model_1_loss: 0.6188 Model_2_loss: 0.6769 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6652 Model_2_val:0.6490
Epoch: 0260 Model_1_loss: 0.5740 Model_2_loss: 0.5987 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6546 Model_2_val:0.6576
Epoch: 0280 Model_1_loss: 0.5351 Model_2_loss: 0.5763 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6699 Model_2_val:0.6593
Epoch: 0300 Model_1_loss: 0.5438 Model_2_loss: 0.5686 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6705 Model_2_val:0.6629
Epoch: 0320 Model_1_loss: 0.5226 Model_2_loss: 0.5429 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6748 Model_2_val:0.6609
Epoch: 0340 Model_1_loss: 0.4676 Model_2_loss: 0.5284 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6748 Model_2_val:0.6639
Epoch: 0360 Model_1_loss: 0.5080 Model_2_loss: 0.4959 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6676 Model_2_val:0.6616
Epoch: 0380 Model_1_loss: 0.4632 Model_2_loss: 0.4447 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6692 Model_2_val:0.6689
Epoch: 0400 Model_1_loss: 0.4737 Model_2_loss: 0.4506 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6679 Model_2_val:0.6652
Model_one_test:0.6911 Model_two_test:0.6861
added by two output: 0.6891
5
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
233481300
Epoch: 0020 Model_1_loss: 1.7097 Model_2_loss: 1.6909 Model_1_trainacc: 0.3667 Model_2_trainacc: 0.5667 Model_1_val:0.2697 Model_2_val:0.3143
Epoch: 0040 Model_1_loss: 1.5526 Model_2_loss: 1.4755 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7750 Model_1_val:0.3997 Model_2_val:0.4644
Epoch: 0060 Model_1_loss: 1.2764 Model_2_loss: 1.2011 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8500 Model_1_val:0.4844 Model_2_val:0.5010
Epoch: 0080 Model_1_loss: 1.0276 Model_2_loss: 0.9415 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8833 Model_1_val:0.5128 Model_2_val:0.5142
Epoch: 0100 Model_1_loss: 0.8608 Model_2_loss: 0.7842 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9083 Model_1_val:0.5221 Model_2_val:0.5460
Epoch: 0120 Model_1_loss: 0.7363 Model_2_loss: 0.6727 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5456 Model_2_val:0.5425
Epoch: 0140 Model_1_loss: 0.6066 Model_2_loss: 0.6223 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9333 Model_1_val:0.5785 Model_2_val:0.5571
Epoch: 0160 Model_1_loss: 0.5549 Model_2_loss: 0.4808 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5654 Model_2_val:0.5764
Epoch: 0180 Model_1_loss: 0.4997 Model_2_loss: 0.5145 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9250 Model_1_val:0.5854 Model_2_val:0.5778
Epoch: 0200 Model_1_loss: 0.4207 Model_2_loss: 0.4672 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.5775 Model_2_val:0.5647
Epoch: 0220 Model_1_loss: 0.7523 Model_2_loss: 0.8372 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6425 Model_2_val:0.6075
Epoch: 0240 Model_1_loss: 0.6406 Model_2_loss: 0.7437 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9417 Model_1_val:0.6532 Model_2_val:0.6165
Epoch: 0260 Model_1_loss: 0.6200 Model_2_loss: 0.6821 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.6528 Model_2_val:0.6304
Epoch: 0280 Model_1_loss: 0.5529 Model_2_loss: 0.7034 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.6542 Model_2_val:0.6297
Epoch: 0300 Model_1_loss: 0.4981 Model_2_loss: 0.7050 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.6566 Model_2_val:0.6387
Epoch: 0320 Model_1_loss: 0.5318 Model_2_loss: 0.5808 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6487 Model_2_val:0.6317
Epoch: 0340 Model_1_loss: 0.5208 Model_2_loss: 0.5908 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6539 Model_2_val:0.6483
Epoch: 0360 Model_1_loss: 0.4532 Model_2_loss: 0.5793 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6636 Model_2_val:0.6480
Epoch: 0380 Model_1_loss: 0.4382 Model_2_loss: 0.5479 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6618 Model_2_val:0.6456
Epoch: 0400 Model_1_loss: 0.4641 Model_2_loss: 0.5640 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6546 Model_2_val:0.6570
Model_one_test:0.6781 Model_two_test:0.6781
added by two output: 0.6760
6
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
521116078
Epoch: 0020 Model_1_loss: 1.6905 Model_2_loss: 1.7009 Model_1_trainacc: 0.5167 Model_2_trainacc: 0.6167 Model_1_val:0.2284 Model_2_val:0.3008
Epoch: 0040 Model_1_loss: 1.4511 Model_2_loss: 1.4992 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.7583 Model_1_val:0.4722 Model_2_val:0.4274
Epoch: 0060 Model_1_loss: 1.1243 Model_2_loss: 1.1814 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8833 Model_1_val:0.5234 Model_2_val:0.4931
Epoch: 0080 Model_1_loss: 0.8821 Model_2_loss: 0.9268 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8667 Model_1_val:0.5699 Model_2_val:0.5460
Epoch: 0100 Model_1_loss: 0.6968 Model_2_loss: 0.7038 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9417 Model_1_val:0.5935 Model_2_val:0.5652
Epoch: 0120 Model_1_loss: 0.5426 Model_2_loss: 0.6034 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9333 Model_1_val:0.5972 Model_2_val:0.5911
Epoch: 0140 Model_1_loss: 0.4749 Model_2_loss: 0.5179 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.5989 Model_2_val:0.6032
Epoch: 0160 Model_1_loss: 0.3891 Model_2_loss: 0.4750 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9417 Model_1_val:0.5901 Model_2_val:0.5783
Epoch: 0180 Model_1_loss: 0.3841 Model_2_loss: 0.4145 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.5881 Model_2_val:0.6019
Epoch: 0200 Model_1_loss: 0.3339 Model_2_loss: 0.3803 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6053 Model_2_val:0.5854
Epoch: 0220 Model_1_loss: 0.6838 Model_2_loss: 0.7600 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6558 Model_2_val:0.6477
Epoch: 0240 Model_1_loss: 0.6581 Model_2_loss: 0.6935 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.6649 Model_2_val:0.6554
Epoch: 0260 Model_1_loss: 0.6177 Model_2_loss: 0.6393 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6666 Model_2_val:0.6511
Epoch: 0280 Model_1_loss: 0.5509 Model_2_loss: 0.5816 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6672 Model_2_val:0.6662
Epoch: 0300 Model_1_loss: 0.5414 Model_2_loss: 0.5842 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6669 Model_2_val:0.6541
Epoch: 0320 Model_1_loss: 0.5089 Model_2_loss: 0.5327 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6696 Model_2_val:0.6669
Epoch: 0340 Model_1_loss: 0.4702 Model_2_loss: 0.5299 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6767 Model_2_val:0.6585
Epoch: 0360 Model_1_loss: 0.5072 Model_2_loss: 0.4662 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6655 Model_2_val:0.6581
Epoch: 0380 Model_1_loss: 0.4626 Model_2_loss: 0.5028 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6767 Model_2_val:0.6521
Epoch: 0400 Model_1_loss: 0.4485 Model_2_loss: 0.4530 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6655 Model_2_val:0.6645
Model_one_test:0.6932 Model_two_test:0.6915
added by two output: 0.6948
7
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
978691547
Epoch: 0020 Model_1_loss: 1.6879 Model_2_loss: 1.6793 Model_1_trainacc: 0.5333 Model_2_trainacc: 0.5333 Model_1_val:0.2664 Model_2_val:0.3182
Epoch: 0040 Model_1_loss: 1.4688 Model_2_loss: 1.4224 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.8250 Model_1_val:0.4381 Model_2_val:0.4980
Epoch: 0060 Model_1_loss: 1.1576 Model_2_loss: 1.0842 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.9333 Model_1_val:0.5036 Model_2_val:0.5629
Epoch: 0080 Model_1_loss: 0.8139 Model_2_loss: 0.7721 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9083 Model_1_val:0.5406 Model_2_val:0.5727
Epoch: 0100 Model_1_loss: 0.7093 Model_2_loss: 0.6205 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9417 Model_1_val:0.5570 Model_2_val:0.5865
Epoch: 0120 Model_1_loss: 0.5920 Model_2_loss: 0.5214 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.5760 Model_2_val:0.5986
Epoch: 0140 Model_1_loss: 0.5008 Model_2_loss: 0.4581 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5855 Model_2_val:0.5885
Epoch: 0160 Model_1_loss: 0.4425 Model_2_loss: 0.4836 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5862 Model_2_val:0.5911
Epoch: 0180 Model_1_loss: 0.4333 Model_2_loss: 0.3782 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.5826 Model_2_val:0.6068
Epoch: 0200 Model_1_loss: 0.4212 Model_2_loss: 0.3740 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.5924 Model_2_val:0.6085
Epoch: 0220 Model_1_loss: 0.6750 Model_2_loss: 0.6628 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6566 Model_2_val:0.6687
Epoch: 0240 Model_1_loss: 0.6655 Model_2_loss: 0.6685 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6723 Model_2_val:0.6658
Epoch: 0260 Model_1_loss: 0.6232 Model_2_loss: 0.6345 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.6671 Model_2_val:0.6697
Epoch: 0280 Model_1_loss: 0.5993 Model_2_loss: 0.5985 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6779 Model_2_val:0.6855
Epoch: 0300 Model_1_loss: 0.5747 Model_2_loss: 0.5653 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6782 Model_2_val:0.6766
Epoch: 0320 Model_1_loss: 0.5275 Model_2_loss: 0.5576 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6828 Model_2_val:0.6769
Epoch: 0340 Model_1_loss: 0.5447 Model_2_loss: 0.4888 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6799 Model_2_val:0.6822
Epoch: 0360 Model_1_loss: 0.5100 Model_2_loss: 0.4728 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6782 Model_2_val:0.6753
Epoch: 0380 Model_1_loss: 0.4597 Model_2_loss: 0.4690 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6756 Model_2_val:0.6818
Epoch: 0400 Model_1_loss: 0.4770 Model_2_loss: 0.4841 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6809 Model_2_val:0.6707
Model_one_test:0.7002 Model_two_test:0.6992
added by two output: 0.6989
8
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
875045470
Epoch: 0020 Model_1_loss: 1.7514 Model_2_loss: 1.7178 Model_1_trainacc: 0.3583 Model_2_trainacc: 0.4167 Model_1_val:0.2344 Model_2_val:0.2497
Epoch: 0040 Model_1_loss: 1.6006 Model_2_loss: 1.5403 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.7167 Model_1_val:0.3733 Model_2_val:0.4277
Epoch: 0060 Model_1_loss: 1.3555 Model_2_loss: 1.2016 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8667 Model_1_val:0.4150 Model_2_val:0.4878
Epoch: 0080 Model_1_loss: 1.1339 Model_2_loss: 0.8914 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.9000 Model_1_val:0.4691 Model_2_val:0.5469
Epoch: 0100 Model_1_loss: 0.9188 Model_2_loss: 0.6774 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9333 Model_1_val:0.5155 Model_2_val:0.5756
Epoch: 0120 Model_1_loss: 0.7822 Model_2_loss: 0.5485 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9750 Model_1_val:0.5229 Model_2_val:0.5836
Epoch: 0140 Model_1_loss: 0.6674 Model_2_loss: 0.4897 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9667 Model_1_val:0.5299 Model_2_val:0.5977
Epoch: 0160 Model_1_loss: 0.5936 Model_2_loss: 0.4737 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.5352 Model_2_val:0.6007
Epoch: 0180 Model_1_loss: 0.5355 Model_2_loss: 0.4145 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9833 Model_1_val:0.5643 Model_2_val:0.5997
Epoch: 0200 Model_1_loss: 0.4432 Model_2_loss: 0.4108 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5653 Model_2_val:0.6167
Epoch: 0220 Model_1_loss: 0.8751 Model_2_loss: 0.6880 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.6387 Model_2_val:0.6474
Epoch: 0240 Model_1_loss: 0.7640 Model_2_loss: 0.6933 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6497 Model_2_val:0.6464
Epoch: 0260 Model_1_loss: 0.6340 Model_2_loss: 0.6505 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6484 Model_2_val:0.6651
Epoch: 0280 Model_1_loss: 0.6048 Model_2_loss: 0.5753 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6668 Model_2_val:0.6678
Epoch: 0300 Model_1_loss: 0.5496 Model_2_loss: 0.5533 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6638 Model_2_val:0.6684
Epoch: 0320 Model_1_loss: 0.4946 Model_2_loss: 0.5159 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6698 Model_2_val:0.6648
Epoch: 0340 Model_1_loss: 0.4559 Model_2_loss: 0.4406 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6648 Model_2_val:0.6658
Epoch: 0360 Model_1_loss: 0.4669 Model_2_loss: 0.4519 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6688 Model_2_val:0.6738
Epoch: 0380 Model_1_loss: 0.4478 Model_2_loss: 0.4646 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6618 Model_2_val:0.6634
Epoch: 0400 Model_1_loss: 0.4517 Model_2_loss: 0.4496 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6748 Model_2_val:0.6761
Model_one_test:0.6861 Model_two_test:0.6851
added by two output: 0.6871
9
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
918199256
Epoch: 0020 Model_1_loss: 1.6543 Model_2_loss: 1.7386 Model_1_trainacc: 0.6000 Model_2_trainacc: 0.3333 Model_1_val:0.2919 Model_2_val:0.2461
Epoch: 0040 Model_1_loss: 1.3971 Model_2_loss: 1.5439 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.7417 Model_1_val:0.4454 Model_2_val:0.4166
Epoch: 0060 Model_1_loss: 1.0195 Model_2_loss: 1.2539 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8167 Model_1_val:0.5128 Model_2_val:0.4720
Epoch: 0080 Model_1_loss: 0.7705 Model_2_loss: 0.9373 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.8750 Model_1_val:0.5662 Model_2_val:0.5171
Epoch: 0100 Model_1_loss: 0.6455 Model_2_loss: 0.8431 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.8500 Model_1_val:0.5708 Model_2_val:0.5313
Epoch: 0120 Model_1_loss: 0.5532 Model_2_loss: 0.6854 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9000 Model_1_val:0.5794 Model_2_val:0.5499
Epoch: 0140 Model_1_loss: 0.4758 Model_2_loss: 0.5383 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5718 Model_2_val:0.5794
Epoch: 0160 Model_1_loss: 0.4281 Model_2_loss: 0.5277 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.6007 Model_2_val:0.5609
Epoch: 0180 Model_1_loss: 0.4053 Model_2_loss: 0.4606 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.5964 Model_2_val:0.5794
Epoch: 0200 Model_1_loss: 0.3706 Model_2_loss: 0.3912 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5954 Model_2_val:0.5881
Epoch: 0220 Model_1_loss: 0.7376 Model_2_loss: 0.7531 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6564 Model_2_val:0.6594
Epoch: 0240 Model_1_loss: 0.6358 Model_2_loss: 0.6998 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9500 Model_1_val:0.6776 Model_2_val:0.6806
Epoch: 0260 Model_1_loss: 0.6208 Model_2_loss: 0.6481 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6743 Model_2_val:0.6740
Epoch: 0280 Model_1_loss: 0.5525 Model_2_loss: 0.5793 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6760 Model_2_val:0.6793
Epoch: 0300 Model_1_loss: 0.5556 Model_2_loss: 0.5516 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6683 Model_2_val:0.6836
Epoch: 0320 Model_1_loss: 0.5033 Model_2_loss: 0.5725 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6677 Model_2_val:0.6806
Epoch: 0340 Model_1_loss: 0.4859 Model_2_loss: 0.4989 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6760 Model_2_val:0.6753
Epoch: 0360 Model_1_loss: 0.4919 Model_2_loss: 0.4766 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6779 Model_2_val:0.6789
Epoch: 0380 Model_1_loss: 0.4296 Model_2_loss: 0.4697 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6716 Model_2_val:0.6730
Epoch: 0400 Model_1_loss: 0.4420 Model_2_loss: 0.4577 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6687 Model_2_val:0.6667
Model_one_test:0.6982 Model_two_test:0.6968
added by two output: 0.7012
10
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
929634538
Epoch: 0020 Model_1_loss: 1.6875 Model_2_loss: 1.7153 Model_1_trainacc: 0.6000 Model_2_trainacc: 0.4000 Model_1_val:0.3467 Model_2_val:0.2555
Epoch: 0040 Model_1_loss: 1.4212 Model_2_loss: 1.4980 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8083 Model_1_val:0.4684 Model_2_val:0.4638
Epoch: 0060 Model_1_loss: 1.0930 Model_2_loss: 1.1659 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8250 Model_1_val:0.5310 Model_2_val:0.5133
Epoch: 0080 Model_1_loss: 0.8091 Model_2_loss: 0.8179 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8917 Model_1_val:0.5559 Model_2_val:0.5602
Epoch: 0100 Model_1_loss: 0.5993 Model_2_loss: 0.6321 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.5805 Model_2_val:0.5763
Epoch: 0120 Model_1_loss: 0.4384 Model_2_loss: 0.5427 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9500 Model_1_val:0.5779 Model_2_val:0.5854
Epoch: 0140 Model_1_loss: 0.4008 Model_2_loss: 0.4835 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9500 Model_1_val:0.5825 Model_2_val:0.5697
Epoch: 0160 Model_1_loss: 0.4054 Model_2_loss: 0.4390 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.5940 Model_2_val:0.5890
Epoch: 0180 Model_1_loss: 0.3667 Model_2_loss: 0.3777 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.5966 Model_2_val:0.6140
Epoch: 0200 Model_1_loss: 0.3461 Model_2_loss: 0.3380 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.5989 Model_2_val:0.5946
Epoch: 0220 Model_1_loss: 0.6098 Model_2_loss: 0.5989 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6730 Model_2_val:0.6599
Epoch: 0240 Model_1_loss: 0.5581 Model_2_loss: 0.5679 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6697 Model_2_val:0.6786
Epoch: 0260 Model_1_loss: 0.5027 Model_2_loss: 0.5389 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6756 Model_2_val:0.6753
Epoch: 0280 Model_1_loss: 0.4761 Model_2_loss: 0.4720 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6783 Model_2_val:0.6786
Epoch: 0300 Model_1_loss: 0.4613 Model_2_loss: 0.5109 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6740 Model_2_val:0.6727
Epoch: 0320 Model_1_loss: 0.4757 Model_2_loss: 0.4653 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6658 Model_2_val:0.6750
Epoch: 0340 Model_1_loss: 0.4232 Model_2_loss: 0.5071 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6756 Model_2_val:0.6825
Epoch: 0360 Model_1_loss: 0.4264 Model_2_loss: 0.4314 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6704 Model_2_val:0.6714
Epoch: 0380 Model_1_loss: 0.4420 Model_2_loss: 0.4285 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6815 Model_2_val:0.6763
Epoch: 0400 Model_1_loss: 0.4679 Model_2_loss: 0.4023 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6832 Model_2_val:0.6727
Model_one_test:0.6966 Model_two_test:0.6901
added by two output: 0.6973
11
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
601866463
Epoch: 0020 Model_1_loss: 1.7221 Model_2_loss: 1.7317 Model_1_trainacc: 0.3500 Model_2_trainacc: 0.3583 Model_1_val:0.2866 Model_2_val:0.2288
Epoch: 0040 Model_1_loss: 1.5812 Model_2_loss: 1.5556 Model_1_trainacc: 0.6250 Model_2_trainacc: 0.7750 Model_1_val:0.3097 Model_2_val:0.3993
Epoch: 0060 Model_1_loss: 1.3129 Model_2_loss: 1.2450 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.7750 Model_1_val:0.4562 Model_2_val:0.4953
Epoch: 0080 Model_1_loss: 1.0465 Model_2_loss: 0.9281 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9000 Model_1_val:0.5140 Model_2_val:0.5515
Epoch: 0100 Model_1_loss: 0.8109 Model_2_loss: 0.7166 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9667 Model_1_val:0.5478 Model_2_val:0.5773
Epoch: 0120 Model_1_loss: 0.7104 Model_2_loss: 0.6207 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9583 Model_1_val:0.5629 Model_2_val:0.5796
Epoch: 0140 Model_1_loss: 0.6010 Model_2_loss: 0.4904 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.5960 Model_2_val:0.6020
Epoch: 0160 Model_1_loss: 0.5723 Model_2_loss: 0.4945 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.5916 Model_2_val:0.6054
Epoch: 0180 Model_1_loss: 0.5249 Model_2_loss: 0.4390 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9917 Model_1_val:0.5910 Model_2_val:0.5936
Epoch: 0200 Model_1_loss: 0.4416 Model_2_loss: 0.4089 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6090 Model_2_val:0.5983
Epoch: 0220 Model_1_loss: 0.8079 Model_2_loss: 0.7558 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6575 Model_2_val:0.6615
Epoch: 0240 Model_1_loss: 0.7434 Model_2_loss: 0.6825 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6729 Model_2_val:0.6716
Epoch: 0260 Model_1_loss: 0.6971 Model_2_loss: 0.6474 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6652 Model_2_val:0.6686
Epoch: 0280 Model_1_loss: 0.6520 Model_2_loss: 0.6323 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6679 Model_2_val:0.6793
Epoch: 0300 Model_1_loss: 0.6180 Model_2_loss: 0.6075 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6819 Model_2_val:0.6679
Epoch: 0320 Model_1_loss: 0.5602 Model_2_loss: 0.5672 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6702 Model_2_val:0.6766
Epoch: 0340 Model_1_loss: 0.5262 Model_2_loss: 0.5761 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.6786 Model_2_val:0.6779
Epoch: 0360 Model_1_loss: 0.5300 Model_2_loss: 0.4978 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6916 Model_2_val:0.6773
Epoch: 0380 Model_1_loss: 0.5741 Model_2_loss: 0.5437 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6829 Model_2_val:0.6783
Epoch: 0400 Model_1_loss: 0.4826 Model_2_loss: 0.5368 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6813 Model_2_val:0.6712
Model_one_test:0.7000 Model_two_test:0.7030
added by two output: 0.7030
12
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1244426509
Epoch: 0020 Model_1_loss: 1.7050 Model_2_loss: 1.6823 Model_1_trainacc: 0.5500 Model_2_trainacc: 0.4833 Model_1_val:0.3138 Model_2_val:0.2379
Epoch: 0040 Model_1_loss: 1.5223 Model_2_loss: 1.4599 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.7917 Model_1_val:0.5203 Model_2_val:0.4460
Epoch: 0060 Model_1_loss: 1.2180 Model_2_loss: 1.1465 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8750 Model_1_val:0.5239 Model_2_val:0.5330
Epoch: 0080 Model_1_loss: 0.9124 Model_2_loss: 0.8488 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9417 Model_1_val:0.5759 Model_2_val:0.5805
Epoch: 0100 Model_1_loss: 0.7249 Model_2_loss: 0.7260 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.5828 Model_2_val:0.5995
Epoch: 0120 Model_1_loss: 0.6010 Model_2_loss: 0.5943 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.6077 Model_2_val:0.6119
Epoch: 0140 Model_1_loss: 0.5512 Model_2_loss: 0.5015 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5923 Model_2_val:0.6211
Epoch: 0160 Model_1_loss: 0.4883 Model_2_loss: 0.4937 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.6086 Model_2_val:0.6234
Epoch: 0180 Model_1_loss: 0.4270 Model_2_loss: 0.4433 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6253 Model_2_val:0.6083
Epoch: 0200 Model_1_loss: 0.4044 Model_2_loss: 0.4282 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6067 Model_2_val:0.6194
Epoch: 0220 Model_1_loss: 0.7091 Model_2_loss: 0.7108 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6728 Model_2_val:0.6744
Epoch: 0240 Model_1_loss: 0.6243 Model_2_loss: 0.7027 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6813 Model_2_val:0.6810
Epoch: 0260 Model_1_loss: 0.6010 Model_2_loss: 0.6571 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6600 Model_2_val:0.6692
Epoch: 0280 Model_1_loss: 0.6099 Model_2_loss: 0.6089 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6721 Model_2_val:0.6852
Epoch: 0300 Model_1_loss: 0.6010 Model_2_loss: 0.5815 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6774 Model_2_val:0.6806
Epoch: 0320 Model_1_loss: 0.5340 Model_2_loss: 0.5728 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6741 Model_2_val:0.6796
Epoch: 0340 Model_1_loss: 0.5618 Model_2_loss: 0.5220 Model_1_trainacc: 0.9583 Model_2_trainacc: 1.0000 Model_1_val:0.6695 Model_2_val:0.6810
Epoch: 0360 Model_1_loss: 0.4762 Model_2_loss: 0.5014 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6734 Model_2_val:0.6728
Epoch: 0380 Model_1_loss: 0.5024 Model_2_loss: 0.5752 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6780 Model_2_val:0.6633
Epoch: 0400 Model_1_loss: 0.5210 Model_2_loss: 0.5043 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6760 Model_2_val:0.6682
Model_one_test:0.7019 Model_two_test:0.6976
added by two output: 0.6990
13
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
489861348
Epoch: 0020 Model_1_loss: 1.7402 Model_2_loss: 1.7174 Model_1_trainacc: 0.3250 Model_2_trainacc: 0.3833 Model_1_val:0.2634 Model_2_val:0.2854
Epoch: 0040 Model_1_loss: 1.5900 Model_2_loss: 1.5121 Model_1_trainacc: 0.7083 Model_2_trainacc: 0.7333 Model_1_val:0.3806 Model_2_val:0.4230
Epoch: 0060 Model_1_loss: 1.3345 Model_2_loss: 1.1566 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.8833 Model_1_val:0.4540 Model_2_val:0.5482
Epoch: 0080 Model_1_loss: 1.0412 Model_2_loss: 0.9054 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8917 Model_1_val:0.5104 Model_2_val:0.5650
Epoch: 0100 Model_1_loss: 0.8545 Model_2_loss: 0.6855 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9167 Model_1_val:0.5362 Model_2_val:0.5877
Epoch: 0120 Model_1_loss: 0.7277 Model_2_loss: 0.5941 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9417 Model_1_val:0.5534 Model_2_val:0.6016
Epoch: 0140 Model_1_loss: 0.6203 Model_2_loss: 0.5398 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9250 Model_1_val:0.5854 Model_2_val:0.6049
Epoch: 0160 Model_1_loss: 0.5499 Model_2_loss: 0.4311 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5689 Model_2_val:0.6120
Epoch: 0180 Model_1_loss: 0.4925 Model_2_loss: 0.4042 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5793 Model_2_val:0.6172
Epoch: 0200 Model_1_loss: 0.4700 Model_2_loss: 0.4059 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5968 Model_2_val:0.6152
Epoch: 0220 Model_1_loss: 0.7522 Model_2_loss: 0.6842 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6417 Model_2_val:0.6754
Epoch: 0240 Model_1_loss: 0.7351 Model_2_loss: 0.6511 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6605 Model_2_val:0.6725
Epoch: 0260 Model_1_loss: 0.6413 Model_2_loss: 0.5679 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6634 Model_2_val:0.6618
Epoch: 0280 Model_1_loss: 0.6130 Model_2_loss: 0.5898 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.6621 Model_2_val:0.6612
Epoch: 0300 Model_1_loss: 0.5723 Model_2_loss: 0.5627 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6641 Model_2_val:0.6618
Epoch: 0320 Model_1_loss: 0.5390 Model_2_loss: 0.4893 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6686 Model_2_val:0.6570
Epoch: 0340 Model_1_loss: 0.5822 Model_2_loss: 0.4806 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6631 Model_2_val:0.6696
Epoch: 0360 Model_1_loss: 0.5328 Model_2_loss: 0.4828 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6693 Model_2_val:0.6702
Epoch: 0380 Model_1_loss: 0.5040 Model_2_loss: 0.4751 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6706 Model_2_val:0.6780
Epoch: 0400 Model_1_loss: 0.4908 Model_2_loss: 0.4610 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6608 Model_2_val:0.6660
Model_one_test:0.6935 Model_two_test:0.6968
added by two output: 0.6961
14
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
610319441
Epoch: 0020 Model_1_loss: 1.7119 Model_2_loss: 1.7031 Model_1_trainacc: 0.3667 Model_2_trainacc: 0.4333 Model_1_val:0.3016 Model_2_val:0.3045
Epoch: 0040 Model_1_loss: 1.5228 Model_2_loss: 1.4855 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.7333 Model_1_val:0.4540 Model_2_val:0.4290
Epoch: 0060 Model_1_loss: 1.2494 Model_2_loss: 1.1573 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8333 Model_1_val:0.4857 Model_2_val:0.5188
Epoch: 0080 Model_1_loss: 0.9529 Model_2_loss: 0.8887 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9167 Model_1_val:0.5289 Model_2_val:0.5282
Epoch: 0100 Model_1_loss: 0.8373 Model_2_loss: 0.7050 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.9417 Model_1_val:0.5340 Model_2_val:0.5668
Epoch: 0120 Model_1_loss: 0.7010 Model_2_loss: 0.5881 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9417 Model_1_val:0.5366 Model_2_val:0.5623
Epoch: 0140 Model_1_loss: 0.6197 Model_2_loss: 0.5213 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.5694 Model_2_val:0.5762
Epoch: 0160 Model_1_loss: 0.5134 Model_2_loss: 0.4653 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5733 Model_2_val:0.5927
Epoch: 0180 Model_1_loss: 0.4842 Model_2_loss: 0.4122 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5837 Model_2_val:0.5743
Epoch: 0200 Model_1_loss: 0.4554 Model_2_loss: 0.4053 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.5600 Model_2_val:0.5966
Epoch: 0220 Model_1_loss: 0.7574 Model_2_loss: 0.7204 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6440 Model_2_val:0.6475
Epoch: 0240 Model_1_loss: 0.7287 Model_2_loss: 0.6649 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6569 Model_2_val:0.6625
Epoch: 0260 Model_1_loss: 0.7065 Model_2_loss: 0.6328 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6482 Model_2_val:0.6456
Epoch: 0280 Model_1_loss: 0.6967 Model_2_loss: 0.5349 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.6573 Model_2_val:0.6498
Epoch: 0300 Model_1_loss: 0.6075 Model_2_loss: 0.5322 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6495 Model_2_val:0.6582
Epoch: 0320 Model_1_loss: 0.5926 Model_2_loss: 0.5215 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6381 Model_2_val:0.6427
Epoch: 0340 Model_1_loss: 0.5843 Model_2_loss: 0.5103 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6553 Model_2_val:0.6479
Epoch: 0360 Model_1_loss: 0.5610 Model_2_loss: 0.4603 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6459 Model_2_val:0.6521
Epoch: 0380 Model_1_loss: 0.5314 Model_2_loss: 0.4752 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6534 Model_2_val:0.6524
Epoch: 0400 Model_1_loss: 0.4759 Model_2_loss: 0.4511 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6498 Model_2_val:0.6547
Model_one_test:0.6787 Model_two_test:0.6764
added by two output: 0.6757
15
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
451023227
Epoch: 0020 Model_1_loss: 1.7066 Model_2_loss: 1.7019 Model_1_trainacc: 0.4000 Model_2_trainacc: 0.4417 Model_1_val:0.2067 Model_2_val:0.2614
Epoch: 0040 Model_1_loss: 1.5123 Model_2_loss: 1.5065 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8083 Model_1_val:0.4005 Model_2_val:0.3731
Epoch: 0060 Model_1_loss: 1.2087 Model_2_loss: 1.2239 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.9250 Model_1_val:0.4555 Model_2_val:0.4980
Epoch: 0080 Model_1_loss: 0.9134 Model_2_loss: 0.8705 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.8750 Model_1_val:0.5399 Model_2_val:0.5250
Epoch: 0100 Model_1_loss: 0.7366 Model_2_loss: 0.6929 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5534 Model_2_val:0.5458
Epoch: 0120 Model_1_loss: 0.6491 Model_2_loss: 0.5587 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5817 Model_2_val:0.5583
Epoch: 0140 Model_1_loss: 0.5306 Model_2_loss: 0.5119 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5656 Model_2_val:0.5695
Epoch: 0160 Model_1_loss: 0.4231 Model_2_loss: 0.4442 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.5946 Model_2_val:0.5791
Epoch: 0180 Model_1_loss: 0.4273 Model_2_loss: 0.4064 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5883 Model_2_val:0.5916
Epoch: 0200 Model_1_loss: 0.3817 Model_2_loss: 0.4011 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.5962 Model_2_val:0.5893
Epoch: 0220 Model_1_loss: 0.7343 Model_2_loss: 0.6740 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6625 Model_2_val:0.6450
Epoch: 0240 Model_1_loss: 0.6920 Model_2_loss: 0.6681 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6585 Model_2_val:0.6589
Epoch: 0260 Model_1_loss: 0.6087 Model_2_loss: 0.6340 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6519 Model_2_val:0.6483
Epoch: 0280 Model_1_loss: 0.5861 Model_2_loss: 0.5453 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6536 Model_2_val:0.6552
Epoch: 0300 Model_1_loss: 0.5546 Model_2_loss: 0.5756 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6529 Model_2_val:0.6605
Epoch: 0320 Model_1_loss: 0.5153 Model_2_loss: 0.5105 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6582 Model_2_val:0.6635
Epoch: 0340 Model_1_loss: 0.5183 Model_2_loss: 0.4667 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6552 Model_2_val:0.6612
Epoch: 0360 Model_1_loss: 0.4803 Model_2_loss: 0.5129 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6526 Model_2_val:0.6543
Epoch: 0380 Model_1_loss: 0.4711 Model_2_loss: 0.4785 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6589 Model_2_val:0.6457
Epoch: 0400 Model_1_loss: 0.4448 Model_2_loss: 0.4181 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6523 Model_2_val:0.6569
Model_one_test:0.6806 Model_two_test:0.6773
added by two output: 0.6790
16
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
514334462
Epoch: 0020 Model_1_loss: 1.7000 Model_2_loss: 1.7396 Model_1_trainacc: 0.4417 Model_2_trainacc: 0.4333 Model_1_val:0.2956 Model_2_val:0.2511
Epoch: 0040 Model_1_loss: 1.4746 Model_2_loss: 1.5855 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.6750 Model_1_val:0.4870 Model_2_val:0.3313
Epoch: 0060 Model_1_loss: 1.1199 Model_2_loss: 1.3457 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.7917 Model_1_val:0.5052 Model_2_val:0.4711
Epoch: 0080 Model_1_loss: 0.8311 Model_2_loss: 1.0717 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8583 Model_1_val:0.5519 Model_2_val:0.5065
Epoch: 0100 Model_1_loss: 0.7059 Model_2_loss: 0.8398 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5743 Model_2_val:0.5117
Epoch: 0120 Model_1_loss: 0.5955 Model_2_loss: 0.7402 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9000 Model_1_val:0.5785 Model_2_val:0.5188
Epoch: 0140 Model_1_loss: 0.4957 Model_2_loss: 0.6598 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.8833 Model_1_val:0.5775 Model_2_val:0.5432
Epoch: 0160 Model_1_loss: 0.5061 Model_2_loss: 0.4952 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5853 Model_2_val:0.5503
Epoch: 0180 Model_1_loss: 0.3846 Model_2_loss: 0.4608 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.5788 Model_2_val:0.5678
Epoch: 0200 Model_1_loss: 0.3810 Model_2_loss: 0.4110 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.5873 Model_2_val:0.5746
Epoch: 0220 Model_1_loss: 0.7452 Model_2_loss: 0.7925 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6418 Model_2_val:0.6382
Epoch: 0240 Model_1_loss: 0.6944 Model_2_loss: 0.7625 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9333 Model_1_val:0.6473 Model_2_val:0.6473
Epoch: 0260 Model_1_loss: 0.5652 Model_2_loss: 0.6441 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6548 Model_2_val:0.6645
Epoch: 0280 Model_1_loss: 0.5712 Model_2_loss: 0.5601 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6460 Model_2_val:0.6590
Epoch: 0300 Model_1_loss: 0.5272 Model_2_loss: 0.5942 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6535 Model_2_val:0.6415
Epoch: 0320 Model_1_loss: 0.5222 Model_2_loss: 0.4990 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6554 Model_2_val:0.6622
Epoch: 0340 Model_1_loss: 0.4931 Model_2_loss: 0.5116 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6525 Model_2_val:0.6622
Epoch: 0360 Model_1_loss: 0.4775 Model_2_loss: 0.4932 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6535 Model_2_val:0.6551
Epoch: 0380 Model_1_loss: 0.4847 Model_2_loss: 0.4299 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6583 Model_2_val:0.6674
Epoch: 0400 Model_1_loss: 0.4480 Model_2_loss: 0.4458 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6548 Model_2_val:0.6434
Model_one_test:0.6801 Model_two_test:0.6856
added by two output: 0.6820
17
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
384877557
Epoch: 0020 Model_1_loss: 1.6578 Model_2_loss: 1.7024 Model_1_trainacc: 0.5833 Model_2_trainacc: 0.4500 Model_1_val:0.2671 Model_2_val:0.2450
Epoch: 0040 Model_1_loss: 1.4604 Model_2_loss: 1.5013 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8000 Model_1_val:0.4444 Model_2_val:0.4427
Epoch: 0060 Model_1_loss: 1.1638 Model_2_loss: 1.1260 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8750 Model_1_val:0.5085 Model_2_val:0.5198
Epoch: 0080 Model_1_loss: 0.8786 Model_2_loss: 0.8857 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8833 Model_1_val:0.5293 Model_2_val:0.5439
Epoch: 0100 Model_1_loss: 0.7062 Model_2_loss: 0.7447 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9000 Model_1_val:0.5426 Model_2_val:0.5716
Epoch: 0120 Model_1_loss: 0.5600 Model_2_loss: 0.6399 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9167 Model_1_val:0.5849 Model_2_val:0.5560
Epoch: 0140 Model_1_loss: 0.5287 Model_2_loss: 0.5487 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5839 Model_2_val:0.5605
Epoch: 0160 Model_1_loss: 0.4624 Model_2_loss: 0.4900 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5784 Model_2_val:0.5667
Epoch: 0180 Model_1_loss: 0.4426 Model_2_loss: 0.4700 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9167 Model_1_val:0.5895 Model_2_val:0.5898
Epoch: 0200 Model_1_loss: 0.4101 Model_2_loss: 0.3952 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.5888 Model_2_val:0.6008
Epoch: 0220 Model_1_loss: 0.7481 Model_2_loss: 0.7509 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9333 Model_1_val:0.6448 Model_2_val:0.6454
Epoch: 0240 Model_1_loss: 0.6944 Model_2_loss: 0.7045 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.6516 Model_2_val:0.6588
Epoch: 0260 Model_1_loss: 0.7117 Model_2_loss: 0.6215 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6545 Model_2_val:0.6601
Epoch: 0280 Model_1_loss: 0.6216 Model_2_loss: 0.5751 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6597 Model_2_val:0.6640
Epoch: 0300 Model_1_loss: 0.6193 Model_2_loss: 0.5845 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6623 Model_2_val:0.6620
Epoch: 0320 Model_1_loss: 0.5714 Model_2_loss: 0.6616 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.6636 Model_2_val:0.6646
Epoch: 0340 Model_1_loss: 0.5733 Model_2_loss: 0.5515 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9417 Model_1_val:0.6601 Model_2_val:0.6614
Epoch: 0360 Model_1_loss: 0.5068 Model_2_loss: 0.5606 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6656 Model_2_val:0.6727
Epoch: 0380 Model_1_loss: 0.5451 Model_2_loss: 0.4974 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6649 Model_2_val:0.6649
Epoch: 0400 Model_1_loss: 0.5207 Model_2_loss: 0.4931 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6734 Model_2_val:0.6630
Model_one_test:0.6900 Model_two_test:0.6884
added by two output: 0.6910
18
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
641195580
Epoch: 0020 Model_1_loss: 1.7403 Model_2_loss: 1.7188 Model_1_trainacc: 0.4417 Model_2_trainacc: 0.3750 Model_1_val:0.2593 Model_2_val:0.2081
Epoch: 0040 Model_1_loss: 1.6004 Model_2_loss: 1.5635 Model_1_trainacc: 0.6333 Model_2_trainacc: 0.6500 Model_1_val:0.3676 Model_2_val:0.4070
Epoch: 0060 Model_1_loss: 1.3561 Model_2_loss: 1.2951 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8333 Model_1_val:0.4470 Model_2_val:0.4805
Epoch: 0080 Model_1_loss: 1.0956 Model_2_loss: 1.0438 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8333 Model_1_val:0.5071 Model_2_val:0.5235
Epoch: 0100 Model_1_loss: 0.8906 Model_2_loss: 0.8306 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9167 Model_1_val:0.5481 Model_2_val:0.5422
Epoch: 0120 Model_1_loss: 0.6933 Model_2_loss: 0.7306 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9250 Model_1_val:0.5586 Model_2_val:0.5625
Epoch: 0140 Model_1_loss: 0.6189 Model_2_loss: 0.6184 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9250 Model_1_val:0.5737 Model_2_val:0.5927
Epoch: 0160 Model_1_loss: 0.5748 Model_2_loss: 0.5036 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5730 Model_2_val:0.5763
Epoch: 0180 Model_1_loss: 0.4767 Model_2_loss: 0.4839 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.5875 Model_2_val:0.5976
Epoch: 0200 Model_1_loss: 0.4602 Model_2_loss: 0.4103 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.5862 Model_2_val:0.5901
Epoch: 0220 Model_1_loss: 0.7894 Model_2_loss: 0.8009 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.6321 Model_2_val:0.6357
Epoch: 0240 Model_1_loss: 0.7228 Model_2_loss: 0.7713 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6383 Model_2_val:0.6541
Epoch: 0260 Model_1_loss: 0.7448 Model_2_loss: 0.7005 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.6413 Model_2_val:0.6475
Epoch: 0280 Model_1_loss: 0.6819 Model_2_loss: 0.6642 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6479 Model_2_val:0.6334
Epoch: 0300 Model_1_loss: 0.6304 Model_2_loss: 0.5762 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6308 Model_2_val:0.6452
Epoch: 0320 Model_1_loss: 0.5994 Model_2_loss: 0.5968 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6357 Model_2_val:0.6433
Epoch: 0340 Model_1_loss: 0.5278 Model_2_loss: 0.6220 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.6360 Model_2_val:0.6344
Epoch: 0360 Model_1_loss: 0.5872 Model_2_loss: 0.5554 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6370 Model_2_val:0.6344
Epoch: 0380 Model_1_loss: 0.5228 Model_2_loss: 0.5614 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6357 Model_2_val:0.6400
Epoch: 0400 Model_1_loss: 0.5470 Model_2_loss: 0.5446 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6285 Model_2_val:0.6364
Model_one_test:0.6597 Model_two_test:0.6633
added by two output: 0.6626
19
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
779319969
Epoch: 0020 Model_1_loss: 1.7225 Model_2_loss: 1.7499 Model_1_trainacc: 0.3500 Model_2_trainacc: 0.3000 Model_1_val:0.1758 Model_2_val:0.2036
Epoch: 0040 Model_1_loss: 1.5318 Model_2_loss: 1.6167 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.6583 Model_1_val:0.3817 Model_2_val:0.4037
Epoch: 0060 Model_1_loss: 1.2435 Model_2_loss: 1.3634 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.7833 Model_1_val:0.4858 Model_2_val:0.4990
Epoch: 0080 Model_1_loss: 0.9435 Model_2_loss: 1.0389 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8750 Model_1_val:0.5052 Model_2_val:0.5184
Epoch: 0100 Model_1_loss: 0.7578 Model_2_loss: 0.8413 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8833 Model_1_val:0.5275 Model_2_val:0.5003
Epoch: 0120 Model_1_loss: 0.5953 Model_2_loss: 0.7192 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.8917 Model_1_val:0.5391 Model_2_val:0.5349
Epoch: 0140 Model_1_loss: 0.5394 Model_2_loss: 0.7007 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.5559 Model_2_val:0.5520
Epoch: 0160 Model_1_loss: 0.5008 Model_2_loss: 0.6167 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.5491 Model_2_val:0.5553
Epoch: 0180 Model_1_loss: 0.4633 Model_2_loss: 0.5008 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5588 Model_2_val:0.5614
Epoch: 0200 Model_1_loss: 0.4466 Model_2_loss: 0.4386 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5501 Model_2_val:0.5585
Epoch: 0220 Model_1_loss: 0.7841 Model_2_loss: 0.7650 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6306 Model_2_val:0.6312
Epoch: 0240 Model_1_loss: 0.6909 Model_2_loss: 0.6788 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6409 Model_2_val:0.6474
Epoch: 0260 Model_1_loss: 0.6685 Model_2_loss: 0.6783 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6496 Model_2_val:0.6513
Epoch: 0280 Model_1_loss: 0.6338 Model_2_loss: 0.6429 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6477 Model_2_val:0.6513
Epoch: 0300 Model_1_loss: 0.5924 Model_2_loss: 0.6044 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6464 Model_2_val:0.6429
Epoch: 0320 Model_1_loss: 0.5482 Model_2_loss: 0.5189 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6432 Model_2_val:0.6500
Epoch: 0340 Model_1_loss: 0.5691 Model_2_loss: 0.4838 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6645 Model_2_val:0.6555
Epoch: 0360 Model_1_loss: 0.5302 Model_2_loss: 0.5127 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6496 Model_2_val:0.6474
Epoch: 0380 Model_1_loss: 0.5345 Model_2_loss: 0.4912 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6529 Model_2_val:0.6467
Epoch: 0400 Model_1_loss: 0.5026 Model_2_loss: 0.5123 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6516 Model_2_val:0.6461
Model_one_test:0.6810 Model_two_test:0.6807
added by two output: 0.6820
20
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1410047580
Epoch: 0020 Model_1_loss: 1.7106 Model_2_loss: 1.7243 Model_1_trainacc: 0.6583 Model_2_trainacc: 0.4417 Model_1_val:0.3171 Model_2_val:0.2858
Epoch: 0040 Model_1_loss: 1.4911 Model_2_loss: 1.5434 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.7583 Model_1_val:0.4600 Model_2_val:0.4147
Epoch: 0060 Model_1_loss: 1.0972 Model_2_loss: 1.2598 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8333 Model_1_val:0.5306 Model_2_val:0.5026
Epoch: 0080 Model_1_loss: 0.8081 Model_2_loss: 0.9222 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9250 Model_1_val:0.5469 Model_2_val:0.5394
Epoch: 0100 Model_1_loss: 0.6304 Model_2_loss: 0.7355 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9333 Model_1_val:0.5918 Model_2_val:0.5540
Epoch: 0120 Model_1_loss: 0.5042 Model_2_loss: 0.6357 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.5905 Model_2_val:0.5762
Epoch: 0140 Model_1_loss: 0.4575 Model_2_loss: 0.4793 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.5895 Model_2_val:0.5843
Epoch: 0160 Model_1_loss: 0.3893 Model_2_loss: 0.4475 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6042 Model_2_val:0.5938
Epoch: 0180 Model_1_loss: 0.3358 Model_2_loss: 0.3987 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.6120 Model_2_val:0.5954
Epoch: 0200 Model_1_loss: 0.3212 Model_2_loss: 0.3840 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6081 Model_2_val:0.6100
Epoch: 0220 Model_1_loss: 0.6333 Model_2_loss: 0.5802 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6602 Model_2_val:0.6559
Epoch: 0240 Model_1_loss: 0.5560 Model_2_loss: 0.5768 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6621 Model_2_val:0.6650
Epoch: 0260 Model_1_loss: 0.5380 Model_2_loss: 0.5711 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6618 Model_2_val:0.6556
Epoch: 0280 Model_1_loss: 0.5127 Model_2_loss: 0.5511 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6634 Model_2_val:0.6527
Epoch: 0300 Model_1_loss: 0.4737 Model_2_loss: 0.5155 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6663 Model_2_val:0.6523
Epoch: 0320 Model_1_loss: 0.4834 Model_2_loss: 0.4519 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6527 Model_2_val:0.6549
Epoch: 0340 Model_1_loss: 0.4584 Model_2_loss: 0.4323 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6572 Model_2_val:0.6592
Epoch: 0360 Model_1_loss: 0.4400 Model_2_loss: 0.4259 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6605 Model_2_val:0.6660
Epoch: 0380 Model_1_loss: 0.4361 Model_2_loss: 0.4477 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6595 Model_2_val:0.6709
Epoch: 0400 Model_1_loss: 0.3954 Model_2_loss: 0.4079 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6628 Model_2_val:0.6729
Model_one_test:0.6800 Model_two_test:0.6826
added by two output: 0.6813
21
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
703113698
Epoch: 0020 Model_1_loss: 1.7652 Model_2_loss: 1.7318 Model_1_trainacc: 0.3500 Model_2_trainacc: 0.4583 Model_1_val:0.2779 Model_2_val:0.2652
Epoch: 0040 Model_1_loss: 1.6810 Model_2_loss: 1.4906 Model_1_trainacc: 0.5167 Model_2_trainacc: 0.7250 Model_1_val:0.2828 Model_2_val:0.4025
Epoch: 0060 Model_1_loss: 1.4493 Model_2_loss: 1.1978 Model_1_trainacc: 0.7000 Model_2_trainacc: 0.8917 Model_1_val:0.4282 Model_2_val:0.5125
Epoch: 0080 Model_1_loss: 1.1642 Model_2_loss: 0.8933 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9000 Model_1_val:0.5275 Model_2_val:0.5516
Epoch: 0100 Model_1_loss: 0.8851 Model_2_loss: 0.6944 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9500 Model_1_val:0.5630 Model_2_val:0.5731
Epoch: 0120 Model_1_loss: 0.7479 Model_2_loss: 0.5847 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9583 Model_1_val:0.5760 Model_2_val:0.5997
Epoch: 0140 Model_1_loss: 0.5823 Model_2_loss: 0.4743 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5747 Model_2_val:0.6128
Epoch: 0160 Model_1_loss: 0.5279 Model_2_loss: 0.3817 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9917 Model_1_val:0.6082 Model_2_val:0.6173
Epoch: 0180 Model_1_loss: 0.4964 Model_2_loss: 0.4179 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6056 Model_2_val:0.6102
Epoch: 0200 Model_1_loss: 0.4124 Model_2_loss: 0.3329 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.6150 Model_2_val:0.6235
Epoch: 0220 Model_1_loss: 0.7995 Model_2_loss: 0.6707 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6671 Model_2_val:0.6697
Epoch: 0240 Model_1_loss: 0.6863 Model_2_loss: 0.6598 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6762 Model_2_val:0.6808
Epoch: 0260 Model_1_loss: 0.6830 Model_2_loss: 0.6213 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6629 Model_2_val:0.6902
Epoch: 0280 Model_1_loss: 0.6638 Model_2_loss: 0.5447 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6678 Model_2_val:0.6863
Epoch: 0300 Model_1_loss: 0.6106 Model_2_loss: 0.5352 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6814 Model_2_val:0.6830
Epoch: 0320 Model_1_loss: 0.5818 Model_2_loss: 0.5263 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6759 Model_2_val:0.6938
Epoch: 0340 Model_1_loss: 0.5928 Model_2_loss: 0.4371 Model_1_trainacc: 0.9583 Model_2_trainacc: 1.0000 Model_1_val:0.6847 Model_2_val:0.6843
Epoch: 0360 Model_1_loss: 0.4883 Model_2_loss: 0.4571 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6782 Model_2_val:0.6795
Epoch: 0380 Model_1_loss: 0.5211 Model_2_loss: 0.4426 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6821 Model_2_val:0.6853
Epoch: 0400 Model_1_loss: 0.4737 Model_2_loss: 0.4269 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6775 Model_2_val:0.6795
Model_one_test:0.7107 Model_two_test:0.7094
added by two output: 0.7110
22
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
624663480
Epoch: 0020 Model_1_loss: 1.7252 Model_2_loss: 1.7107 Model_1_trainacc: 0.4583 Model_2_trainacc: 0.4250 Model_1_val:0.2633 Model_2_val:0.2510
Epoch: 0040 Model_1_loss: 1.5742 Model_2_loss: 1.5156 Model_1_trainacc: 0.7083 Model_2_trainacc: 0.7667 Model_1_val:0.4335 Model_2_val:0.4221
Epoch: 0060 Model_1_loss: 1.2861 Model_2_loss: 1.2252 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.8333 Model_1_val:0.4778 Model_2_val:0.5153
Epoch: 0080 Model_1_loss: 0.9752 Model_2_loss: 0.9183 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8833 Model_1_val:0.5411 Model_2_val:0.5480
Epoch: 0100 Model_1_loss: 0.8531 Model_2_loss: 0.7808 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8750 Model_1_val:0.5555 Model_2_val:0.5848
Epoch: 0120 Model_1_loss: 0.7341 Model_2_loss: 0.6315 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9250 Model_1_val:0.5810 Model_2_val:0.5999
Epoch: 0140 Model_1_loss: 0.5978 Model_2_loss: 0.5419 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.5914 Model_2_val:0.6090
Epoch: 0160 Model_1_loss: 0.4986 Model_2_loss: 0.4837 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9250 Model_1_val:0.5816 Model_2_val:0.6077
Epoch: 0180 Model_1_loss: 0.4953 Model_2_loss: 0.4612 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5964 Model_2_val:0.6014
Epoch: 0200 Model_1_loss: 0.4350 Model_2_loss: 0.4245 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.5958 Model_2_val:0.5980
Epoch: 0220 Model_1_loss: 0.8238 Model_2_loss: 0.7476 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.6534 Model_2_val:0.6669
Epoch: 0240 Model_1_loss: 0.7269 Model_2_loss: 0.7892 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6684 Model_2_val:0.6707
Epoch: 0260 Model_1_loss: 0.7031 Model_2_loss: 0.6632 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.6710 Model_2_val:0.6889
Epoch: 0280 Model_1_loss: 0.6390 Model_2_loss: 0.6851 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6675 Model_2_val:0.6738
Epoch: 0300 Model_1_loss: 0.6232 Model_2_loss: 0.6525 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6719 Model_2_val:0.6735
Epoch: 0320 Model_1_loss: 0.5696 Model_2_loss: 0.6639 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.6675 Model_2_val:0.6791
Epoch: 0340 Model_1_loss: 0.5832 Model_2_loss: 0.6071 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6732 Model_2_val:0.6817
Epoch: 0360 Model_1_loss: 0.5730 Model_2_loss: 0.5473 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6751 Model_2_val:0.6744
Epoch: 0380 Model_1_loss: 0.5676 Model_2_loss: 0.5431 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6766 Model_2_val:0.6700
Epoch: 0400 Model_1_loss: 0.4980 Model_2_loss: 0.5389 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6669 Model_2_val:0.6744
Model_one_test:0.7049 Model_two_test:0.7087
added by two output: 0.7040
23
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
384835543
Epoch: 0020 Model_1_loss: 1.7295 Model_2_loss: 1.7212 Model_1_trainacc: 0.4083 Model_2_trainacc: 0.4917 Model_1_val:0.2396 Model_2_val:0.2882
Epoch: 0040 Model_1_loss: 1.5732 Model_2_loss: 1.5557 Model_1_trainacc: 0.7417 Model_2_trainacc: 0.7750 Model_1_val:0.4346 Model_2_val:0.4527
Epoch: 0060 Model_1_loss: 1.2485 Model_2_loss: 1.2536 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8583 Model_1_val:0.5225 Model_2_val:0.5426
Epoch: 0080 Model_1_loss: 0.9251 Model_2_loss: 0.9829 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8500 Model_1_val:0.5327 Model_2_val:0.5463
Epoch: 0100 Model_1_loss: 0.7077 Model_2_loss: 0.7501 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5823 Model_2_val:0.5638
Epoch: 0120 Model_1_loss: 0.6537 Model_2_loss: 0.6225 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5886 Model_2_val:0.5905
Epoch: 0140 Model_1_loss: 0.5734 Model_2_loss: 0.5586 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.5820 Model_2_val:0.5869
Epoch: 0160 Model_1_loss: 0.4535 Model_2_loss: 0.5016 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6147 Model_2_val:0.6038
Epoch: 0180 Model_1_loss: 0.4508 Model_2_loss: 0.4790 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6087 Model_2_val:0.6173
Epoch: 0200 Model_1_loss: 0.4664 Model_2_loss: 0.4272 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6044 Model_2_val:0.6058
Epoch: 0220 Model_1_loss: 0.7497 Model_2_loss: 0.7217 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6345 Model_2_val:0.6596
Epoch: 0240 Model_1_loss: 0.6777 Model_2_loss: 0.6558 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6471 Model_2_val:0.6669
Epoch: 0260 Model_1_loss: 0.6600 Model_2_loss: 0.6312 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6527 Model_2_val:0.6699
Epoch: 0280 Model_1_loss: 0.6461 Model_2_loss: 0.6149 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6675 Model_2_val:0.6599
Epoch: 0300 Model_1_loss: 0.5717 Model_2_loss: 0.5916 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6646 Model_2_val:0.6652
Epoch: 0320 Model_1_loss: 0.6087 Model_2_loss: 0.5635 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6646 Model_2_val:0.6606
Epoch: 0340 Model_1_loss: 0.5962 Model_2_loss: 0.5193 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6599 Model_2_val:0.6659
Epoch: 0360 Model_1_loss: 0.5083 Model_2_loss: 0.4467 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6596 Model_2_val:0.6666
Epoch: 0380 Model_1_loss: 0.5323 Model_2_loss: 0.5171 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6656 Model_2_val:0.6633
Epoch: 0400 Model_1_loss: 0.5144 Model_2_loss: 0.4818 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6599 Model_2_val:0.6672
Model_one_test:0.6884 Model_two_test:0.6904
added by two output: 0.6897
24
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
874292437
Epoch: 0020 Model_1_loss: 1.7070 Model_2_loss: 1.6757 Model_1_trainacc: 0.5333 Model_2_trainacc: 0.5000 Model_1_val:0.3021 Model_2_val:0.3116
Epoch: 0040 Model_1_loss: 1.4897 Model_2_loss: 1.4190 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.7250 Model_1_val:0.4570 Model_2_val:0.5008
Epoch: 0060 Model_1_loss: 1.2206 Model_2_loss: 1.0939 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8833 Model_1_val:0.5326 Model_2_val:0.5424
Epoch: 0080 Model_1_loss: 0.9378 Model_2_loss: 0.8293 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9000 Model_1_val:0.5591 Model_2_val:0.5840
Epoch: 0100 Model_1_loss: 0.7567 Model_2_loss: 0.6582 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9250 Model_1_val:0.5702 Model_2_val:0.6083
Epoch: 0120 Model_1_loss: 0.6700 Model_2_loss: 0.5689 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9417 Model_1_val:0.5989 Model_2_val:0.6071
Epoch: 0140 Model_1_loss: 0.5682 Model_2_loss: 0.4934 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5998 Model_2_val:0.6156
Epoch: 0160 Model_1_loss: 0.5445 Model_2_loss: 0.4601 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.5941 Model_2_val:0.6127
Epoch: 0180 Model_1_loss: 0.4730 Model_2_loss: 0.3972 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9583 Model_1_val:0.5926 Model_2_val:0.6200
Epoch: 0200 Model_1_loss: 0.4521 Model_2_loss: 0.3470 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6121 Model_2_val:0.6351
Epoch: 0220 Model_1_loss: 0.7689 Model_2_loss: 0.6833 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6629 Model_2_val:0.6711
Epoch: 0240 Model_1_loss: 0.6508 Model_2_loss: 0.6234 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6758 Model_2_val:0.6664
Epoch: 0260 Model_1_loss: 0.6976 Model_2_loss: 0.5942 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6547 Model_2_val:0.6692
Epoch: 0280 Model_1_loss: 0.6297 Model_2_loss: 0.5663 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6664 Model_2_val:0.6635
Epoch: 0300 Model_1_loss: 0.5592 Model_2_loss: 0.5460 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6594 Model_2_val:0.6626
Epoch: 0320 Model_1_loss: 0.5476 Model_2_loss: 0.5142 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6635 Model_2_val:0.6705
Epoch: 0340 Model_1_loss: 0.5331 Model_2_loss: 0.4878 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6585 Model_2_val:0.6679
Epoch: 0360 Model_1_loss: 0.4968 Model_2_loss: 0.4799 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6588 Model_2_val:0.6626
Epoch: 0380 Model_1_loss: 0.5026 Model_2_loss: 0.4202 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6610 Model_2_val:0.6717
Epoch: 0400 Model_1_loss: 0.4559 Model_2_loss: 0.4665 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6676 Model_2_val:0.6641
Model_one_test:0.6966 Model_two_test:0.6875
added by two output: 0.6900
25
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
118654237
Epoch: 0020 Model_1_loss: 1.7237 Model_2_loss: 1.7352 Model_1_trainacc: 0.3250 Model_2_trainacc: 0.3833 Model_1_val:0.2368 Model_2_val:0.2759
Epoch: 0040 Model_1_loss: 1.5324 Model_2_loss: 1.5524 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.7000 Model_1_val:0.4042 Model_2_val:0.3930
Epoch: 0060 Model_1_loss: 1.2646 Model_2_loss: 1.2255 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8500 Model_1_val:0.4979 Model_2_val:0.4780
Epoch: 0080 Model_1_loss: 0.9746 Model_2_loss: 0.8973 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8833 Model_1_val:0.5268 Model_2_val:0.5406
Epoch: 0100 Model_1_loss: 0.7724 Model_2_loss: 0.6812 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9333 Model_1_val:0.5313 Model_2_val:0.5711
Epoch: 0120 Model_1_loss: 0.6675 Model_2_loss: 0.6038 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9583 Model_1_val:0.5467 Model_2_val:0.5698
Epoch: 0140 Model_1_loss: 0.5444 Model_2_loss: 0.4880 Model_1_trainacc: 0.9417 Model_2_trainacc: 1.0000 Model_1_val:0.5669 Model_2_val:0.5759
Epoch: 0160 Model_1_loss: 0.5199 Model_2_loss: 0.4571 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.5714 Model_2_val:0.5646
Epoch: 0180 Model_1_loss: 0.4295 Model_2_loss: 0.4261 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.5800 Model_2_val:0.5839
Epoch: 0200 Model_1_loss: 0.3743 Model_2_loss: 0.3615 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.5797 Model_2_val:0.5980
Epoch: 0220 Model_1_loss: 0.7186 Model_2_loss: 0.7188 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6362 Model_2_val:0.6609
Epoch: 0240 Model_1_loss: 0.6873 Model_2_loss: 0.6349 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6638 Model_2_val:0.6647
Epoch: 0260 Model_1_loss: 0.6164 Model_2_loss: 0.6133 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6612 Model_2_val:0.6699
Epoch: 0280 Model_1_loss: 0.6006 Model_2_loss: 0.6626 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6673 Model_2_val:0.6647
Epoch: 0300 Model_1_loss: 0.6414 Model_2_loss: 0.5898 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6763 Model_2_val:0.6683
Epoch: 0320 Model_1_loss: 0.5309 Model_2_loss: 0.5523 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6644 Model_2_val:0.6789
Epoch: 0340 Model_1_loss: 0.5393 Model_2_loss: 0.5349 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6744 Model_2_val:0.6715
Epoch: 0360 Model_1_loss: 0.4682 Model_2_loss: 0.5033 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6734 Model_2_val:0.6721
Epoch: 0380 Model_1_loss: 0.5441 Model_2_loss: 0.4730 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6702 Model_2_val:0.6753
Epoch: 0400 Model_1_loss: 0.5180 Model_2_loss: 0.4999 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6712 Model_2_val:0.6750
Model_one_test:0.6930 Model_two_test:0.6971
added by two output: 0.6952
26
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1054891800
Epoch: 0020 Model_1_loss: 1.7187 Model_2_loss: 1.6764 Model_1_trainacc: 0.4167 Model_2_trainacc: 0.5750 Model_1_val:0.2580 Model_2_val:0.3839
Epoch: 0040 Model_1_loss: 1.5558 Model_2_loss: 1.3706 Model_1_trainacc: 0.6750 Model_2_trainacc: 0.8750 Model_1_val:0.3790 Model_2_val:0.4771
Epoch: 0060 Model_1_loss: 1.2227 Model_2_loss: 1.0342 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9000 Model_1_val:0.4814 Model_2_val:0.5317
Epoch: 0080 Model_1_loss: 0.8977 Model_2_loss: 0.7683 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9417 Model_1_val:0.5468 Model_2_val:0.5736
Epoch: 0100 Model_1_loss: 0.6723 Model_2_loss: 0.5826 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.5755 Model_2_val:0.5883
Epoch: 0120 Model_1_loss: 0.5455 Model_2_loss: 0.4968 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6050 Model_2_val:0.5896
Epoch: 0140 Model_1_loss: 0.5131 Model_2_loss: 0.4858 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6200 Model_2_val:0.6017
Epoch: 0160 Model_1_loss: 0.4126 Model_2_loss: 0.4237 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6226 Model_2_val:0.5939
Epoch: 0180 Model_1_loss: 0.3692 Model_2_loss: 0.4084 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6203 Model_2_val:0.6007
Epoch: 0200 Model_1_loss: 0.3567 Model_2_loss: 0.3580 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6292 Model_2_val:0.5958
Epoch: 0220 Model_1_loss: 0.6849 Model_2_loss: 0.6428 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6815 Model_2_val:0.6795
Epoch: 0240 Model_1_loss: 0.5496 Model_2_loss: 0.5545 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6913 Model_2_val:0.6818
Epoch: 0260 Model_1_loss: 0.5456 Model_2_loss: 0.5807 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6835 Model_2_val:0.6769
Epoch: 0280 Model_1_loss: 0.5355 Model_2_loss: 0.5533 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6802 Model_2_val:0.6818
Epoch: 0300 Model_1_loss: 0.4905 Model_2_loss: 0.4755 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6759 Model_2_val:0.6884
Epoch: 0320 Model_1_loss: 0.4270 Model_2_loss: 0.4335 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6880 Model_2_val:0.6789
Epoch: 0340 Model_1_loss: 0.4575 Model_2_loss: 0.4768 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6851 Model_2_val:0.6799
Epoch: 0360 Model_1_loss: 0.4711 Model_2_loss: 0.4632 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6861 Model_2_val:0.6776
Epoch: 0380 Model_1_loss: 0.4577 Model_2_loss: 0.4170 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6818 Model_2_val:0.6782
Epoch: 0400 Model_1_loss: 0.4245 Model_2_loss: 0.3741 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6936 Model_2_val:0.6812
Model_one_test:0.7057 Model_two_test:0.7024
added by two output: 0.7031
27
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
129873093
Epoch: 0020 Model_1_loss: 1.7194 Model_2_loss: 1.7381 Model_1_trainacc: 0.5167 Model_2_trainacc: 0.3583 Model_1_val:0.3206 Model_2_val:0.2329
Epoch: 0040 Model_1_loss: 1.5294 Model_2_loss: 1.5775 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.7333 Model_1_val:0.4306 Model_2_val:0.4320
Epoch: 0060 Model_1_loss: 1.2356 Model_2_loss: 1.3049 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8667 Model_1_val:0.4840 Model_2_val:0.5048
Epoch: 0080 Model_1_loss: 0.9081 Model_2_loss: 1.0837 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8333 Model_1_val:0.5453 Model_2_val:0.5348
Epoch: 0100 Model_1_loss: 0.7388 Model_2_loss: 0.8479 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.8917 Model_1_val:0.5502 Model_2_val:0.5535
Epoch: 0120 Model_1_loss: 0.6120 Model_2_loss: 0.6750 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.5703 Model_2_val:0.5562
Epoch: 0140 Model_1_loss: 0.5722 Model_2_loss: 0.6089 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5641 Model_2_val:0.5736
Epoch: 0160 Model_1_loss: 0.4338 Model_2_loss: 0.4834 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.5954 Model_2_val:0.5690
Epoch: 0180 Model_1_loss: 0.4578 Model_2_loss: 0.4766 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9250 Model_1_val:0.5829 Model_2_val:0.5944
Epoch: 0200 Model_1_loss: 0.4253 Model_2_loss: 0.4720 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9250 Model_1_val:0.5921 Model_2_val:0.5769
Epoch: 0220 Model_1_loss: 0.7138 Model_2_loss: 0.8415 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9000 Model_1_val:0.6633 Model_2_val:0.6399
Epoch: 0240 Model_1_loss: 0.7418 Model_2_loss: 0.7264 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.6735 Model_2_val:0.6560
Epoch: 0260 Model_1_loss: 0.6318 Model_2_loss: 0.7198 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6662 Model_2_val:0.6619
Epoch: 0280 Model_1_loss: 0.6451 Model_2_loss: 0.6525 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.6755 Model_2_val:0.6725
Epoch: 0300 Model_1_loss: 0.5677 Model_2_loss: 0.5662 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6755 Model_2_val:0.6616
Epoch: 0320 Model_1_loss: 0.5516 Model_2_loss: 0.5961 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.6794 Model_2_val:0.6669
Epoch: 0340 Model_1_loss: 0.5283 Model_2_loss: 0.5900 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.6692 Model_2_val:0.6606
Epoch: 0360 Model_1_loss: 0.4944 Model_2_loss: 0.5672 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.6712 Model_2_val:0.6679
Epoch: 0380 Model_1_loss: 0.5335 Model_2_loss: 0.5759 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6718 Model_2_val:0.6728
Epoch: 0400 Model_1_loss: 0.5384 Model_2_loss: 0.5443 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6649 Model_2_val:0.6580
Model_one_test:0.6932 Model_two_test:0.6916
added by two output: 0.6923
28
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
454593323
Epoch: 0020 Model_1_loss: 1.7300 Model_2_loss: 1.6946 Model_1_trainacc: 0.4083 Model_2_trainacc: 0.5333 Model_1_val:0.2498 Model_2_val:0.2864
Epoch: 0040 Model_1_loss: 1.5766 Model_2_loss: 1.4916 Model_1_trainacc: 0.7417 Model_2_trainacc: 0.7333 Model_1_val:0.4204 Model_2_val:0.4859
Epoch: 0060 Model_1_loss: 1.3247 Model_2_loss: 1.2162 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8583 Model_1_val:0.5077 Model_2_val:0.5421
Epoch: 0080 Model_1_loss: 1.0717 Model_2_loss: 0.9307 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9083 Model_1_val:0.5395 Model_2_val:0.5861
Epoch: 0100 Model_1_loss: 0.8616 Model_2_loss: 0.7451 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5700 Model_2_val:0.5857
Epoch: 0120 Model_1_loss: 0.7080 Model_2_loss: 0.5743 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.5999 Model_2_val:0.6066
Epoch: 0140 Model_1_loss: 0.6579 Model_2_loss: 0.5163 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9583 Model_1_val:0.5947 Model_2_val:0.6179
Epoch: 0160 Model_1_loss: 0.5123 Model_2_loss: 0.4771 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5841 Model_2_val:0.6166
Epoch: 0180 Model_1_loss: 0.5114 Model_2_loss: 0.4823 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.6063 Model_2_val:0.6230
Epoch: 0200 Model_1_loss: 0.4435 Model_2_loss: 0.4017 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9667 Model_1_val:0.6227 Model_2_val:0.6143
Epoch: 0220 Model_1_loss: 0.7616 Model_2_loss: 0.7475 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.6837 Model_2_val:0.6773
Epoch: 0240 Model_1_loss: 0.7397 Model_2_loss: 0.7149 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6802 Model_2_val:0.6696
Epoch: 0260 Model_1_loss: 0.6737 Model_2_loss: 0.6157 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6965 Model_2_val:0.6750
Epoch: 0280 Model_1_loss: 0.6269 Model_2_loss: 0.5812 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6798 Model_2_val:0.6689
Epoch: 0300 Model_1_loss: 0.6321 Model_2_loss: 0.5586 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6869 Model_2_val:0.6757
Epoch: 0320 Model_1_loss: 0.5908 Model_2_loss: 0.5652 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6863 Model_2_val:0.6811
Epoch: 0340 Model_1_loss: 0.5130 Model_2_loss: 0.4933 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6814 Model_2_val:0.6808
Epoch: 0360 Model_1_loss: 0.5072 Model_2_loss: 0.4895 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6856 Model_2_val:0.6891
Epoch: 0380 Model_1_loss: 0.5002 Model_2_loss: 0.4563 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6908 Model_2_val:0.6837
Epoch: 0400 Model_1_loss: 0.5018 Model_2_loss: 0.4720 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6773 Model_2_val:0.6879
Model_one_test:0.7052 Model_two_test:0.7001
added by two output: 0.7039
29
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
337830753
Epoch: 0020 Model_1_loss: 1.7263 Model_2_loss: 1.6754 Model_1_trainacc: 0.2917 Model_2_trainacc: 0.6250 Model_1_val:0.2077 Model_2_val:0.2904
Epoch: 0040 Model_1_loss: 1.5424 Model_2_loss: 1.4305 Model_1_trainacc: 0.6750 Model_2_trainacc: 0.8083 Model_1_val:0.3797 Model_2_val:0.4357
Epoch: 0060 Model_1_loss: 1.2777 Model_2_loss: 1.0753 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.9083 Model_1_val:0.4871 Model_2_val:0.5058
Epoch: 0080 Model_1_loss: 0.9724 Model_2_loss: 0.7892 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9417 Model_1_val:0.5158 Model_2_val:0.5582
Epoch: 0100 Model_1_loss: 0.8097 Model_2_loss: 0.6703 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5280 Model_2_val:0.5495
Epoch: 0120 Model_1_loss: 0.6797 Model_2_loss: 0.5632 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5431 Model_2_val:0.5704
Epoch: 0140 Model_1_loss: 0.5597 Model_2_loss: 0.4992 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5617 Model_2_val:0.5704
Epoch: 0160 Model_1_loss: 0.4765 Model_2_loss: 0.3697 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.5553 Model_2_val:0.5830
Epoch: 0180 Model_1_loss: 0.4034 Model_2_loss: 0.4267 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.5855 Model_2_val:0.5846
Epoch: 0200 Model_1_loss: 0.4189 Model_2_loss: 0.3854 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5904 Model_2_val:0.5768
Epoch: 0220 Model_1_loss: 0.7292 Model_2_loss: 0.7192 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6453 Model_2_val:0.6389
Epoch: 0240 Model_1_loss: 0.6459 Model_2_loss: 0.6367 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6473 Model_2_val:0.6421
Epoch: 0260 Model_1_loss: 0.6133 Model_2_loss: 0.6324 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6605 Model_2_val:0.6624
Epoch: 0280 Model_1_loss: 0.5745 Model_2_loss: 0.5913 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6537 Model_2_val:0.6498
Epoch: 0300 Model_1_loss: 0.4942 Model_2_loss: 0.5473 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6534 Model_2_val:0.6576
Epoch: 0320 Model_1_loss: 0.5290 Model_2_loss: 0.5536 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6608 Model_2_val:0.6601
Epoch: 0340 Model_1_loss: 0.4626 Model_2_loss: 0.4749 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6527 Model_2_val:0.6691
Epoch: 0360 Model_1_loss: 0.4564 Model_2_loss: 0.4395 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6630 Model_2_val:0.6579
Epoch: 0380 Model_1_loss: 0.4626 Model_2_loss: 0.4637 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6524 Model_2_val:0.6601
Epoch: 0400 Model_1_loss: 0.4809 Model_2_loss: 0.4444 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6601 Model_2_val:0.6598
Model_one_test:0.6759 Model_two_test:0.6794
added by two output: 0.6810
30
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1557980089
Epoch: 0020 Model_1_loss: 1.7168 Model_2_loss: 1.7006 Model_1_trainacc: 0.4333 Model_2_trainacc: 0.5417 Model_1_val:0.3031 Model_2_val:0.2828
Epoch: 0040 Model_1_loss: 1.5033 Model_2_loss: 1.5287 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.7333 Model_1_val:0.5164 Model_2_val:0.3971
Epoch: 0060 Model_1_loss: 1.1727 Model_2_loss: 1.2078 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8583 Model_1_val:0.5337 Model_2_val:0.5088
Epoch: 0080 Model_1_loss: 0.8603 Model_2_loss: 0.9548 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8833 Model_1_val:0.5767 Model_2_val:0.5505
Epoch: 0100 Model_1_loss: 0.6938 Model_2_loss: 0.6796 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5885 Model_2_val:0.5822
Epoch: 0120 Model_1_loss: 0.5937 Model_2_loss: 0.5571 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6180 Model_2_val:0.5826
Epoch: 0140 Model_1_loss: 0.4728 Model_2_loss: 0.5297 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6035 Model_2_val:0.6042
Epoch: 0160 Model_1_loss: 0.4103 Model_2_loss: 0.4437 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6180 Model_2_val:0.5924
Epoch: 0180 Model_1_loss: 0.3954 Model_2_loss: 0.4147 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6307 Model_2_val:0.6127
Epoch: 0200 Model_1_loss: 0.3634 Model_2_loss: 0.3964 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6026 Model_2_val:0.6052
Epoch: 0220 Model_1_loss: 0.6650 Model_2_loss: 0.6700 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6848 Model_2_val:0.6773
Epoch: 0240 Model_1_loss: 0.6193 Model_2_loss: 0.6386 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6701 Model_2_val:0.6694
Epoch: 0260 Model_1_loss: 0.5815 Model_2_loss: 0.5452 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6763 Model_2_val:0.6733
Epoch: 0280 Model_1_loss: 0.5623 Model_2_loss: 0.5840 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.6927 Model_2_val:0.6750
Epoch: 0300 Model_1_loss: 0.5336 Model_2_loss: 0.5097 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6776 Model_2_val:0.6687
Epoch: 0320 Model_1_loss: 0.4938 Model_2_loss: 0.5099 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6838 Model_2_val:0.6799
Epoch: 0340 Model_1_loss: 0.4898 Model_2_loss: 0.4455 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6733 Model_2_val:0.6773
Epoch: 0360 Model_1_loss: 0.4829 Model_2_loss: 0.4695 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6887 Model_2_val:0.6792
Epoch: 0380 Model_1_loss: 0.4480 Model_2_loss: 0.4669 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6802 Model_2_val:0.6822
Epoch: 0400 Model_1_loss: 0.4892 Model_2_loss: 0.4662 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6782 Model_2_val:0.6694
Model_one_test:0.7005 Model_two_test:0.6989
added by two output: 0.6999
Model1 Acc: 0.690738 Model2 Acc: 0.690093
Maxacc Mean: 0.691829
[0.6924372651610259, 0.6927043179398544, 0.6923088360447857, 0.6922086163222224, 0.691536895183715, 0.6943443442678022, 0.6918293560174433]
Maxacc of all experiments: 0.6943443442678022
1
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
202108576
Epoch: 0020 Model_1_loss: 1.6993 Model_2_loss: 1.7015 Model_1_trainacc: 0.5750 Model_2_trainacc: 0.3917 Model_1_val:0.3256 Model_2_val:0.2655
Epoch: 0040 Model_1_loss: 1.4382 Model_2_loss: 1.4991 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.7333 Model_1_val:0.4884 Model_2_val:0.4563
Epoch: 0060 Model_1_loss: 1.0851 Model_2_loss: 1.1928 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9083 Model_1_val:0.5593 Model_2_val:0.5320
Epoch: 0080 Model_1_loss: 0.7936 Model_2_loss: 0.8914 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5809 Model_2_val:0.5609
Epoch: 0100 Model_1_loss: 0.6126 Model_2_loss: 0.7121 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5882 Model_2_val:0.5765
Epoch: 0120 Model_1_loss: 0.5215 Model_2_loss: 0.5993 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.6076 Model_2_val:0.5971
Epoch: 0140 Model_1_loss: 0.4154 Model_2_loss: 0.4966 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.5968 Model_2_val:0.5946
Epoch: 0160 Model_1_loss: 0.4250 Model_2_loss: 0.4811 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6238 Model_2_val:0.6188
Epoch: 0180 Model_1_loss: 0.3712 Model_2_loss: 0.4370 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6038 Model_2_val:0.6032
Epoch: 0200 Model_1_loss: 0.3639 Model_2_loss: 0.4035 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6076 Model_2_val:0.6070
Epoch: 0220 Model_1_loss: 0.6539 Model_2_loss: 0.6743 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6623 Model_2_val:0.6642
Epoch: 0240 Model_1_loss: 0.5994 Model_2_loss: 0.5760 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6652 Model_2_val:0.6776
Epoch: 0260 Model_1_loss: 0.5698 Model_2_loss: 0.5806 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6734 Model_2_val:0.6706
Epoch: 0280 Model_1_loss: 0.4910 Model_2_loss: 0.5543 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6760 Model_2_val:0.6827
Epoch: 0300 Model_1_loss: 0.4865 Model_2_loss: 0.4901 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6779 Model_2_val:0.6817
Epoch: 0320 Model_1_loss: 0.4857 Model_2_loss: 0.4442 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6690 Model_2_val:0.6741
Epoch: 0340 Model_1_loss: 0.4572 Model_2_loss: 0.4412 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6684 Model_2_val:0.6868
Epoch: 0360 Model_1_loss: 0.4967 Model_2_loss: 0.4896 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6700 Model_2_val:0.6792
Epoch: 0380 Model_1_loss: 0.4528 Model_2_loss: 0.4355 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6709 Model_2_val:0.6792
Epoch: 0400 Model_1_loss: 0.4251 Model_2_loss: 0.4277 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6728 Model_2_val:0.6776
Model_one_test:0.6928 Model_two_test:0.6992
added by two output: 0.6960
2
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1046092693
Epoch: 0020 Model_1_loss: 1.7315 Model_2_loss: 1.7088 Model_1_trainacc: 0.4167 Model_2_trainacc: 0.5333 Model_1_val:0.2688 Model_2_val:0.2989
Epoch: 0040 Model_1_loss: 1.5654 Model_2_loss: 1.5198 Model_1_trainacc: 0.7417 Model_2_trainacc: 0.7500 Model_1_val:0.4181 Model_2_val:0.3734
Epoch: 0060 Model_1_loss: 1.2993 Model_2_loss: 1.2843 Model_1_trainacc: 0.7583 Model_2_trainacc: 0.8333 Model_1_val:0.4313 Model_2_val:0.4786
Epoch: 0080 Model_1_loss: 0.9995 Model_2_loss: 1.0699 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8500 Model_1_val:0.4863 Model_2_val:0.4906
Epoch: 0100 Model_1_loss: 0.8527 Model_2_loss: 0.8558 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8500 Model_1_val:0.5343 Model_2_val:0.4992
Epoch: 0120 Model_1_loss: 0.7222 Model_2_loss: 0.6920 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9167 Model_1_val:0.5419 Model_2_val:0.5283
Epoch: 0140 Model_1_loss: 0.5382 Model_2_loss: 0.6434 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.5574 Model_2_val:0.5564
Epoch: 0160 Model_1_loss: 0.5370 Model_2_loss: 0.5664 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5611 Model_2_val:0.5780
Epoch: 0180 Model_1_loss: 0.5335 Model_2_loss: 0.4820 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9417 Model_1_val:0.5707 Model_2_val:0.5611
Epoch: 0200 Model_1_loss: 0.4549 Model_2_loss: 0.4780 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.5588 Model_2_val:0.5644
Epoch: 0220 Model_1_loss: 0.8280 Model_2_loss: 0.7739 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6481 Model_2_val:0.6531
Epoch: 0240 Model_1_loss: 0.7417 Model_2_loss: 0.7269 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6577 Model_2_val:0.6630
Epoch: 0260 Model_1_loss: 0.6688 Model_2_loss: 0.6731 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6706 Model_2_val:0.6660
Epoch: 0280 Model_1_loss: 0.6389 Model_2_loss: 0.6326 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6759 Model_2_val:0.6783
Epoch: 0300 Model_1_loss: 0.5896 Model_2_loss: 0.5994 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6726 Model_2_val:0.6769
Epoch: 0320 Model_1_loss: 0.5272 Model_2_loss: 0.6001 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6733 Model_2_val:0.6663
Epoch: 0340 Model_1_loss: 0.5266 Model_2_loss: 0.5718 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6763 Model_2_val:0.6733
Epoch: 0360 Model_1_loss: 0.4524 Model_2_loss: 0.5019 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6832 Model_2_val:0.6739
Epoch: 0380 Model_1_loss: 0.4727 Model_2_loss: 0.5214 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6773 Model_2_val:0.6819
Epoch: 0400 Model_1_loss: 0.4753 Model_2_loss: 0.4828 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6816 Model_2_val:0.6706
Model_one_test:0.7014 Model_two_test:0.6998
added by two output: 0.7008
3
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
212270298
Epoch: 0020 Model_1_loss: 1.7102 Model_2_loss: 1.7466 Model_1_trainacc: 0.2917 Model_2_trainacc: 0.3917 Model_1_val:0.2257 Model_2_val:0.2638
Epoch: 0040 Model_1_loss: 1.4892 Model_2_loss: 1.5497 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7333 Model_1_val:0.4234 Model_2_val:0.3977
Epoch: 0060 Model_1_loss: 1.2261 Model_2_loss: 1.2486 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.7583 Model_1_val:0.5269 Model_2_val:0.5265
Epoch: 0080 Model_1_loss: 0.9556 Model_2_loss: 0.9643 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8667 Model_1_val:0.5442 Model_2_val:0.5633
Epoch: 0100 Model_1_loss: 0.7146 Model_2_loss: 0.7236 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9250 Model_1_val:0.5710 Model_2_val:0.5763
Epoch: 0120 Model_1_loss: 0.6190 Model_2_loss: 0.6296 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9083 Model_1_val:0.5766 Model_2_val:0.5933
Epoch: 0140 Model_1_loss: 0.5247 Model_2_loss: 0.5885 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9417 Model_1_val:0.5783 Model_2_val:0.5766
Epoch: 0160 Model_1_loss: 0.5074 Model_2_loss: 0.5048 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.5930 Model_2_val:0.5987
Epoch: 0180 Model_1_loss: 0.4418 Model_2_loss: 0.5016 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.5833 Model_2_val:0.5973
Epoch: 0200 Model_1_loss: 0.4057 Model_2_loss: 0.3987 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.5943 Model_2_val:0.6057
Epoch: 0220 Model_1_loss: 0.7909 Model_2_loss: 0.7892 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6451 Model_2_val:0.6544
Epoch: 0240 Model_1_loss: 0.7343 Model_2_loss: 0.6734 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6487 Model_2_val:0.6684
Epoch: 0260 Model_1_loss: 0.6944 Model_2_loss: 0.6768 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6658 Model_2_val:0.6785
Epoch: 0280 Model_1_loss: 0.6447 Model_2_loss: 0.6284 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6715 Model_2_val:0.6741
Epoch: 0300 Model_1_loss: 0.6024 Model_2_loss: 0.5647 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6781 Model_2_val:0.6771
Epoch: 0320 Model_1_loss: 0.6012 Model_2_loss: 0.5828 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6758 Model_2_val:0.6765
Epoch: 0340 Model_1_loss: 0.5966 Model_2_loss: 0.5294 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6811 Model_2_val:0.6788
Epoch: 0360 Model_1_loss: 0.5907 Model_2_loss: 0.5538 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6725 Model_2_val:0.6798
Epoch: 0380 Model_1_loss: 0.5639 Model_2_loss: 0.4465 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6751 Model_2_val:0.6845
Epoch: 0400 Model_1_loss: 0.5022 Model_2_loss: 0.4278 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6708 Model_2_val:0.6815
Model_one_test:0.7035 Model_two_test:0.7058
added by two output: 0.7032
4
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1001860719
Epoch: 0020 Model_1_loss: 1.7222 Model_2_loss: 1.7052 Model_1_trainacc: 0.3167 Model_2_trainacc: 0.5417 Model_1_val:0.2179 Model_2_val:0.2702
Epoch: 0040 Model_1_loss: 1.5672 Model_2_loss: 1.5163 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.8000 Model_1_val:0.3697 Model_2_val:0.4405
Epoch: 0060 Model_1_loss: 1.2961 Model_2_loss: 1.1779 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8667 Model_1_val:0.4625 Model_2_val:0.4967
Epoch: 0080 Model_1_loss: 1.0376 Model_2_loss: 0.9402 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8583 Model_1_val:0.5158 Model_2_val:0.5557
Epoch: 0100 Model_1_loss: 0.8739 Model_2_loss: 0.6722 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9417 Model_1_val:0.5132 Model_2_val:0.5786
Epoch: 0120 Model_1_loss: 0.7392 Model_2_loss: 0.6023 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5429 Model_2_val:0.5888
Epoch: 0140 Model_1_loss: 0.6500 Model_2_loss: 0.4965 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9833 Model_1_val:0.5509 Model_2_val:0.6134
Epoch: 0160 Model_1_loss: 0.5506 Model_2_loss: 0.4413 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.5678 Model_2_val:0.6102
Epoch: 0180 Model_1_loss: 0.5242 Model_2_loss: 0.4129 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9750 Model_1_val:0.5649 Model_2_val:0.6159
Epoch: 0200 Model_1_loss: 0.4404 Model_2_loss: 0.3594 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5866 Model_2_val:0.6195
Epoch: 0220 Model_1_loss: 0.7914 Model_2_loss: 0.6864 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9917 Model_1_val:0.6545 Model_2_val:0.6667
Epoch: 0240 Model_1_loss: 0.7607 Model_2_loss: 0.6457 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6702 Model_2_val:0.6804
Epoch: 0260 Model_1_loss: 0.6466 Model_2_loss: 0.6260 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6715 Model_2_val:0.6727
Epoch: 0280 Model_1_loss: 0.6487 Model_2_loss: 0.6356 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6574 Model_2_val:0.6801
Epoch: 0300 Model_1_loss: 0.5655 Model_2_loss: 0.5085 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6734 Model_2_val:0.6683
Epoch: 0320 Model_1_loss: 0.5356 Model_2_loss: 0.5342 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6702 Model_2_val:0.6842
Epoch: 0340 Model_1_loss: 0.5357 Model_2_loss: 0.5201 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6695 Model_2_val:0.6737
Epoch: 0360 Model_1_loss: 0.5180 Model_2_loss: 0.5317 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6622 Model_2_val:0.6676
Epoch: 0380 Model_1_loss: 0.5077 Model_2_loss: 0.4940 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6584 Model_2_val:0.6734
Epoch: 0400 Model_1_loss: 0.5188 Model_2_loss: 0.4345 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6581 Model_2_val:0.6753
Model_one_test:0.6954 Model_two_test:0.6928
added by two output: 0.6935
5
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
192930486
Epoch: 0020 Model_1_loss: 1.7158 Model_2_loss: 1.7314 Model_1_trainacc: 0.4667 Model_2_trainacc: 0.3000 Model_1_val:0.2880 Model_2_val:0.2405
Epoch: 0040 Model_1_loss: 1.5040 Model_2_loss: 1.5631 Model_1_trainacc: 0.7000 Model_2_trainacc: 0.6750 Model_1_val:0.4643 Model_2_val:0.3518
Epoch: 0060 Model_1_loss: 1.1720 Model_2_loss: 1.2814 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.7917 Model_1_val:0.5173 Model_2_val:0.4689
Epoch: 0080 Model_1_loss: 0.9170 Model_2_loss: 1.0090 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8333 Model_1_val:0.5546 Model_2_val:0.5304
Epoch: 0100 Model_1_loss: 0.7808 Model_2_loss: 0.7650 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9250 Model_1_val:0.5514 Model_2_val:0.5520
Epoch: 0120 Model_1_loss: 0.6873 Model_2_loss: 0.7066 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9417 Model_1_val:0.5880 Model_2_val:0.5700
Epoch: 0140 Model_1_loss: 0.6295 Model_2_loss: 0.5565 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9250 Model_1_val:0.5612 Model_2_val:0.5582
Epoch: 0160 Model_1_loss: 0.5313 Model_2_loss: 0.4978 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.5848 Model_2_val:0.5857
Epoch: 0180 Model_1_loss: 0.4962 Model_2_loss: 0.4779 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.5965 Model_2_val:0.5815
Epoch: 0200 Model_1_loss: 0.4678 Model_2_loss: 0.4142 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5848 Model_2_val:0.6001
Epoch: 0220 Model_1_loss: 0.8389 Model_2_loss: 0.7106 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9833 Model_1_val:0.6273 Model_2_val:0.6469
Epoch: 0240 Model_1_loss: 0.7127 Model_2_loss: 0.6858 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6437 Model_2_val:0.6492
Epoch: 0260 Model_1_loss: 0.7111 Model_2_loss: 0.6342 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6427 Model_2_val:0.6525
Epoch: 0280 Model_1_loss: 0.6666 Model_2_loss: 0.6507 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6531 Model_2_val:0.6669
Epoch: 0300 Model_1_loss: 0.6675 Model_2_loss: 0.6085 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6437 Model_2_val:0.6558
Epoch: 0320 Model_1_loss: 0.5968 Model_2_loss: 0.5674 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6433 Model_2_val:0.6610
Epoch: 0340 Model_1_loss: 0.5701 Model_2_loss: 0.5600 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6492 Model_2_val:0.6698
Epoch: 0360 Model_1_loss: 0.5933 Model_2_loss: 0.5512 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6548 Model_2_val:0.6685
Epoch: 0380 Model_1_loss: 0.5560 Model_2_loss: 0.5403 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6636 Model_2_val:0.6669
Epoch: 0400 Model_1_loss: 0.5098 Model_2_loss: 0.5566 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6482 Model_2_val:0.6610
Model_one_test:0.6937 Model_two_test:0.6918
added by two output: 0.6957
6
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1007535002
Epoch: 0020 Model_1_loss: 1.7493 Model_2_loss: 1.7303 Model_1_trainacc: 0.4167 Model_2_trainacc: 0.3750 Model_1_val:0.3135 Model_2_val:0.2271
Epoch: 0040 Model_1_loss: 1.6255 Model_2_loss: 1.5692 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.6583 Model_1_val:0.4345 Model_2_val:0.3547
Epoch: 0060 Model_1_loss: 1.3797 Model_2_loss: 1.2843 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8500 Model_1_val:0.4917 Model_2_val:0.4367
Epoch: 0080 Model_1_loss: 1.0792 Model_2_loss: 0.9881 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9167 Model_1_val:0.5287 Model_2_val:0.5203
Epoch: 0100 Model_1_loss: 0.8895 Model_2_loss: 0.7980 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9333 Model_1_val:0.5416 Model_2_val:0.5617
Epoch: 0120 Model_1_loss: 0.6961 Model_2_loss: 0.6771 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9167 Model_1_val:0.5614 Model_2_val:0.5812
Epoch: 0140 Model_1_loss: 0.5783 Model_2_loss: 0.5436 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.5831 Model_2_val:0.5793
Epoch: 0160 Model_1_loss: 0.5242 Model_2_loss: 0.5103 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6010 Model_2_val:0.5941
Epoch: 0180 Model_1_loss: 0.5144 Model_2_loss: 0.5014 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5900 Model_2_val:0.5910
Epoch: 0200 Model_1_loss: 0.5048 Model_2_loss: 0.4319 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6048 Model_2_val:0.6098
Epoch: 0220 Model_1_loss: 0.7922 Model_2_loss: 0.8102 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6620 Model_2_val:0.6607
Epoch: 0240 Model_1_loss: 0.7635 Model_2_loss: 0.6822 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6704 Model_2_val:0.6676
Epoch: 0260 Model_1_loss: 0.6712 Model_2_loss: 0.6158 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6726 Model_2_val:0.6865
Epoch: 0280 Model_1_loss: 0.7005 Model_2_loss: 0.6600 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6865 Model_2_val:0.6827
Epoch: 0300 Model_1_loss: 0.5737 Model_2_loss: 0.5876 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6714 Model_2_val:0.6833
Epoch: 0320 Model_1_loss: 0.5973 Model_2_loss: 0.5716 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6893 Model_2_val:0.6758
Epoch: 0340 Model_1_loss: 0.5984 Model_2_loss: 0.5457 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6921 Model_2_val:0.6896
Epoch: 0360 Model_1_loss: 0.5556 Model_2_loss: 0.5355 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6814 Model_2_val:0.6777
Epoch: 0380 Model_1_loss: 0.5484 Model_2_loss: 0.5324 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6899 Model_2_val:0.6978
Epoch: 0400 Model_1_loss: 0.5740 Model_2_loss: 0.5100 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6755 Model_2_val:0.6814
Model_one_test:0.7091 Model_two_test:0.7113
added by two output: 0.7100
7
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
937118177
Epoch: 0020 Model_1_loss: 1.7057 Model_2_loss: 1.6966 Model_1_trainacc: 0.5000 Model_2_trainacc: 0.6000 Model_1_val:0.2622 Model_2_val:0.2822
Epoch: 0040 Model_1_loss: 1.4813 Model_2_loss: 1.5028 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7917 Model_1_val:0.3997 Model_2_val:0.4257
Epoch: 0060 Model_1_loss: 1.1412 Model_2_loss: 1.1668 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8417 Model_1_val:0.5028 Model_2_val:0.4982
Epoch: 0080 Model_1_loss: 0.8098 Model_2_loss: 0.8861 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9000 Model_1_val:0.5372 Model_2_val:0.5550
Epoch: 0100 Model_1_loss: 0.6781 Model_2_loss: 0.6837 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.5734 Model_2_val:0.5730
Epoch: 0120 Model_1_loss: 0.5787 Model_2_loss: 0.5867 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5786 Model_2_val:0.5724
Epoch: 0140 Model_1_loss: 0.4453 Model_2_loss: 0.5365 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.5894 Model_2_val:0.5848
Epoch: 0160 Model_1_loss: 0.4305 Model_2_loss: 0.4804 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.5875 Model_2_val:0.5944
Epoch: 0180 Model_1_loss: 0.4140 Model_2_loss: 0.3789 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6052 Model_2_val:0.5989
Epoch: 0200 Model_1_loss: 0.3536 Model_2_loss: 0.4512 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6042 Model_2_val:0.5970
Epoch: 0220 Model_1_loss: 0.6628 Model_2_loss: 0.7069 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6462 Model_2_val:0.6561
Epoch: 0240 Model_1_loss: 0.6189 Model_2_loss: 0.6289 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6538 Model_2_val:0.6465
Epoch: 0260 Model_1_loss: 0.5576 Model_2_loss: 0.6226 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6613 Model_2_val:0.6465
Epoch: 0280 Model_1_loss: 0.5450 Model_2_loss: 0.6343 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6561 Model_2_val:0.6469
Epoch: 0300 Model_1_loss: 0.5193 Model_2_loss: 0.5709 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6580 Model_2_val:0.6547
Epoch: 0320 Model_1_loss: 0.5360 Model_2_loss: 0.5426 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6682 Model_2_val:0.6472
Epoch: 0340 Model_1_loss: 0.4724 Model_2_loss: 0.5280 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6475 Model_2_val:0.6538
Epoch: 0360 Model_1_loss: 0.4241 Model_2_loss: 0.4831 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6521 Model_2_val:0.6616
Epoch: 0380 Model_1_loss: 0.4354 Model_2_loss: 0.4840 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6541 Model_2_val:0.6511
Epoch: 0400 Model_1_loss: 0.4153 Model_2_loss: 0.4841 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6505 Model_2_val:0.6511
Model_one_test:0.6754 Model_two_test:0.6764
added by two output: 0.6751
8
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
925310485
Epoch: 0020 Model_1_loss: 1.7143 Model_2_loss: 1.7149 Model_1_trainacc: 0.4667 Model_2_trainacc: 0.5000 Model_1_val:0.2886 Model_2_val:0.2760
Epoch: 0040 Model_1_loss: 1.5028 Model_2_loss: 1.5007 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.7417 Model_1_val:0.4367 Model_2_val:0.4537
Epoch: 0060 Model_1_loss: 1.2030 Model_2_loss: 1.1776 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9250 Model_1_val:0.5075 Model_2_val:0.5191
Epoch: 0080 Model_1_loss: 0.9055 Model_2_loss: 0.8924 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9167 Model_1_val:0.5314 Model_2_val:0.5463
Epoch: 0100 Model_1_loss: 0.7638 Model_2_loss: 0.7332 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5483 Model_2_val:0.5639
Epoch: 0120 Model_1_loss: 0.6563 Model_2_loss: 0.6131 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.5829 Model_2_val:0.5829
Epoch: 0140 Model_1_loss: 0.5688 Model_2_loss: 0.5308 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5868 Model_2_val:0.5839
Epoch: 0160 Model_1_loss: 0.4326 Model_2_loss: 0.4724 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5915 Model_2_val:0.5902
Epoch: 0180 Model_1_loss: 0.3911 Model_2_loss: 0.4409 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.5809 Model_2_val:0.5802
Epoch: 0200 Model_1_loss: 0.3807 Model_2_loss: 0.4075 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5842 Model_2_val:0.5832
Epoch: 0220 Model_1_loss: 0.6946 Model_2_loss: 0.7205 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6377 Model_2_val:0.6500
Epoch: 0240 Model_1_loss: 0.6405 Model_2_loss: 0.6547 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6609 Model_2_val:0.6493
Epoch: 0260 Model_1_loss: 0.5932 Model_2_loss: 0.6320 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6662 Model_2_val:0.6606
Epoch: 0280 Model_1_loss: 0.5445 Model_2_loss: 0.6204 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6725 Model_2_val:0.6689
Epoch: 0300 Model_1_loss: 0.5216 Model_2_loss: 0.5325 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6749 Model_2_val:0.6735
Epoch: 0320 Model_1_loss: 0.5769 Model_2_loss: 0.4987 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6752 Model_2_val:0.6592
Epoch: 0340 Model_1_loss: 0.4415 Model_2_loss: 0.5094 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6672 Model_2_val:0.6569
Epoch: 0360 Model_1_loss: 0.4850 Model_2_loss: 0.5128 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6666 Model_2_val:0.6699
Epoch: 0380 Model_1_loss: 0.4636 Model_2_loss: 0.4797 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6755 Model_2_val:0.6652
Epoch: 0400 Model_1_loss: 0.4315 Model_2_loss: 0.4958 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9583 Model_1_val:0.6622 Model_2_val:0.6709
Model_one_test:0.6908 Model_two_test:0.6921
added by two output: 0.6935
9
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
465884806
Epoch: 0020 Model_1_loss: 1.7199 Model_2_loss: 1.7097 Model_1_trainacc: 0.3667 Model_2_trainacc: 0.3917 Model_1_val:0.2283 Model_2_val:0.2114
Epoch: 0040 Model_1_loss: 1.5394 Model_2_loss: 1.4773 Model_1_trainacc: 0.6750 Model_2_trainacc: 0.7667 Model_1_val:0.3784 Model_2_val:0.4189
Epoch: 0060 Model_1_loss: 1.2584 Model_2_loss: 1.1438 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8667 Model_1_val:0.4550 Model_2_val:0.5105
Epoch: 0080 Model_1_loss: 0.9689 Model_2_loss: 0.9199 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8750 Model_1_val:0.5128 Model_2_val:0.5353
Epoch: 0100 Model_1_loss: 0.8089 Model_2_loss: 0.6937 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9250 Model_1_val:0.5446 Model_2_val:0.5616
Epoch: 0120 Model_1_loss: 0.6645 Model_2_loss: 0.5703 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9583 Model_1_val:0.5602 Model_2_val:0.5821
Epoch: 0140 Model_1_loss: 0.5542 Model_2_loss: 0.4879 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5732 Model_2_val:0.5825
Epoch: 0160 Model_1_loss: 0.5404 Model_2_loss: 0.4425 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5802 Model_2_val:0.5845
Epoch: 0180 Model_1_loss: 0.4531 Model_2_loss: 0.3959 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5755 Model_2_val:0.6021
Epoch: 0200 Model_1_loss: 0.4324 Model_2_loss: 0.3876 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5997 Model_2_val:0.5891
Epoch: 0220 Model_1_loss: 0.7702 Model_2_loss: 0.6482 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6382 Model_2_val:0.6562
Epoch: 0240 Model_1_loss: 0.7474 Model_2_loss: 0.6744 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6548 Model_2_val:0.6601
Epoch: 0260 Model_1_loss: 0.6698 Model_2_loss: 0.6278 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6585 Model_2_val:0.6628
Epoch: 0280 Model_1_loss: 0.6380 Model_2_loss: 0.5574 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6565 Model_2_val:0.6721
Epoch: 0300 Model_1_loss: 0.5579 Model_2_loss: 0.5332 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6618 Model_2_val:0.6654
Epoch: 0320 Model_1_loss: 0.5657 Model_2_loss: 0.5261 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6704 Model_2_val:0.6728
Epoch: 0340 Model_1_loss: 0.5505 Model_2_loss: 0.4989 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6691 Model_2_val:0.6635
Epoch: 0360 Model_1_loss: 0.5045 Model_2_loss: 0.4602 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6664 Model_2_val:0.6701
Epoch: 0380 Model_1_loss: 0.4607 Model_2_loss: 0.4635 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6708 Model_2_val:0.6734
Epoch: 0400 Model_1_loss: 0.5036 Model_2_loss: 0.4804 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6804 Model_2_val:0.6698
Model_one_test:0.6933 Model_two_test:0.6870
added by two output: 0.6890
10
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
478116185
Epoch: 0020 Model_1_loss: 1.7520 Model_2_loss: 1.7137 Model_1_trainacc: 0.3500 Model_2_trainacc: 0.4250 Model_1_val:0.2410 Model_2_val:0.2953
Epoch: 0040 Model_1_loss: 1.6299 Model_2_loss: 1.4854 Model_1_trainacc: 0.6167 Model_2_trainacc: 0.7917 Model_1_val:0.4047 Model_2_val:0.4628
Epoch: 0060 Model_1_loss: 1.3399 Model_2_loss: 1.1997 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8833 Model_1_val:0.4766 Model_2_val:0.5039
Epoch: 0080 Model_1_loss: 1.0697 Model_2_loss: 0.9694 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8417 Model_1_val:0.5183 Model_2_val:0.5424
Epoch: 0100 Model_1_loss: 0.8443 Model_2_loss: 0.7134 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9333 Model_1_val:0.5533 Model_2_val:0.5539
Epoch: 0120 Model_1_loss: 0.7126 Model_2_loss: 0.6327 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5700 Model_2_val:0.5902
Epoch: 0140 Model_1_loss: 0.6248 Model_2_loss: 0.5801 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5793 Model_2_val:0.5854
Epoch: 0160 Model_1_loss: 0.5530 Model_2_loss: 0.5079 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.5786 Model_2_val:0.5879
Epoch: 0180 Model_1_loss: 0.4854 Model_2_loss: 0.3929 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6040 Model_2_val:0.5998
Epoch: 0200 Model_1_loss: 0.4221 Model_2_loss: 0.4143 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6184 Model_2_val:0.6120
Epoch: 0220 Model_1_loss: 0.7641 Model_2_loss: 0.7941 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6646 Model_2_val:0.6483
Epoch: 0240 Model_1_loss: 0.6821 Model_2_loss: 0.7413 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6762 Model_2_val:0.6743
Epoch: 0260 Model_1_loss: 0.6271 Model_2_loss: 0.6988 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.6579 Model_2_val:0.6585
Epoch: 0280 Model_1_loss: 0.6034 Model_2_loss: 0.6229 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6675 Model_2_val:0.6672
Epoch: 0300 Model_1_loss: 0.5748 Model_2_loss: 0.6373 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6746 Model_2_val:0.6585
Epoch: 0320 Model_1_loss: 0.5502 Model_2_loss: 0.5953 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6694 Model_2_val:0.6669
Epoch: 0340 Model_1_loss: 0.5264 Model_2_loss: 0.5457 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6694 Model_2_val:0.6595
Epoch: 0360 Model_1_loss: 0.4974 Model_2_loss: 0.4956 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6755 Model_2_val:0.6743
Epoch: 0380 Model_1_loss: 0.5630 Model_2_loss: 0.5286 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6736 Model_2_val:0.6675
Epoch: 0400 Model_1_loss: 0.5078 Model_2_loss: 0.5368 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6765 Model_2_val:0.6688
Model_one_test:0.7012 Model_two_test:0.7003
added by two output: 0.7019
11
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
626182075
Epoch: 0020 Model_1_loss: 1.7638 Model_2_loss: 1.7384 Model_1_trainacc: 0.2250 Model_2_trainacc: 0.4500 Model_1_val:0.2364 Model_2_val:0.2683
Epoch: 0040 Model_1_loss: 1.5958 Model_2_loss: 1.5947 Model_1_trainacc: 0.6917 Model_2_trainacc: 0.6333 Model_1_val:0.3717 Model_2_val:0.3850
Epoch: 0060 Model_1_loss: 1.2781 Model_2_loss: 1.3692 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.7667 Model_1_val:0.4976 Model_2_val:0.5028
Epoch: 0080 Model_1_loss: 0.9073 Model_2_loss: 1.0723 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8417 Model_1_val:0.5301 Model_2_val:0.5213
Epoch: 0100 Model_1_loss: 0.6882 Model_2_loss: 0.8833 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9083 Model_1_val:0.5655 Model_2_val:0.5437
Epoch: 0120 Model_1_loss: 0.5791 Model_2_loss: 0.6772 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5740 Model_2_val:0.5600
Epoch: 0140 Model_1_loss: 0.4726 Model_2_loss: 0.5622 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9333 Model_1_val:0.5701 Model_2_val:0.5743
Epoch: 0160 Model_1_loss: 0.4323 Model_2_loss: 0.5846 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9000 Model_1_val:0.5980 Model_2_val:0.5785
Epoch: 0180 Model_1_loss: 0.3860 Model_2_loss: 0.5007 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9250 Model_1_val:0.6007 Model_2_val:0.5587
Epoch: 0200 Model_1_loss: 0.3311 Model_2_loss: 0.4483 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6111 Model_2_val:0.5678
Epoch: 0220 Model_1_loss: 0.7240 Model_2_loss: 0.8093 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6800 Model_2_val:0.6322
Epoch: 0240 Model_1_loss: 0.6859 Model_2_loss: 0.7776 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6797 Model_2_val:0.6572
Epoch: 0260 Model_1_loss: 0.6250 Model_2_loss: 0.7390 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6774 Model_2_val:0.6520
Epoch: 0280 Model_1_loss: 0.5845 Model_2_loss: 0.7193 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6943 Model_2_val:0.6459
Epoch: 0300 Model_1_loss: 0.5687 Model_2_loss: 0.6690 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9500 Model_1_val:0.6761 Model_2_val:0.6631
Epoch: 0320 Model_1_loss: 0.5643 Model_2_loss: 0.6514 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9417 Model_1_val:0.6797 Model_2_val:0.6702
Epoch: 0340 Model_1_loss: 0.5501 Model_2_loss: 0.5388 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6761 Model_2_val:0.6780
Epoch: 0360 Model_1_loss: 0.5102 Model_2_loss: 0.5425 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6797 Model_2_val:0.6745
Epoch: 0380 Model_1_loss: 0.5178 Model_2_loss: 0.5113 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6761 Model_2_val:0.6761
Epoch: 0400 Model_1_loss: 0.4753 Model_2_loss: 0.4975 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6771 Model_2_val:0.6754
Model_one_test:0.6976 Model_two_test:0.6995
added by two output: 0.6998
12
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
830488657
Epoch: 0020 Model_1_loss: 1.7109 Model_2_loss: 1.7231 Model_1_trainacc: 0.4500 Model_2_trainacc: 0.4750 Model_1_val:0.3078 Model_2_val:0.2776
Epoch: 0040 Model_1_loss: 1.5031 Model_2_loss: 1.5231 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.8000 Model_1_val:0.4753 Model_2_val:0.4467
Epoch: 0060 Model_1_loss: 1.1861 Model_2_loss: 1.1731 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8167 Model_1_val:0.5106 Model_2_val:0.5096
Epoch: 0080 Model_1_loss: 0.8622 Model_2_loss: 0.9131 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8833 Model_1_val:0.5556 Model_2_val:0.5392
Epoch: 0100 Model_1_loss: 0.6926 Model_2_loss: 0.7236 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8917 Model_1_val:0.5813 Model_2_val:0.5585
Epoch: 0120 Model_1_loss: 0.6076 Model_2_loss: 0.6073 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.5755 Model_2_val:0.5768
Epoch: 0140 Model_1_loss: 0.5202 Model_2_loss: 0.5530 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5871 Model_2_val:0.5720
Epoch: 0160 Model_1_loss: 0.5079 Model_2_loss: 0.5068 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6048 Model_2_val:0.5839
Epoch: 0180 Model_1_loss: 0.4069 Model_2_loss: 0.4651 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.5993 Model_2_val:0.5990
Epoch: 0200 Model_1_loss: 0.4019 Model_2_loss: 0.4307 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9083 Model_1_val:0.5993 Model_2_val:0.5794
Epoch: 0220 Model_1_loss: 0.7369 Model_2_loss: 0.7547 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.6658 Model_2_val:0.6565
Epoch: 0240 Model_1_loss: 0.7050 Model_2_loss: 0.6851 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6668 Model_2_val:0.6652
Epoch: 0260 Model_1_loss: 0.6111 Model_2_loss: 0.6320 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6796 Model_2_val:0.6597
Epoch: 0280 Model_1_loss: 0.5877 Model_2_loss: 0.6125 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6783 Model_2_val:0.6710
Epoch: 0300 Model_1_loss: 0.5589 Model_2_loss: 0.5589 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6790 Model_2_val:0.6697
Epoch: 0320 Model_1_loss: 0.5784 Model_2_loss: 0.5159 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6758 Model_2_val:0.6745
Epoch: 0340 Model_1_loss: 0.5374 Model_2_loss: 0.5043 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6906 Model_2_val:0.6806
Epoch: 0360 Model_1_loss: 0.5410 Model_2_loss: 0.4921 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6799 Model_2_val:0.6748
Epoch: 0380 Model_1_loss: 0.4865 Model_2_loss: 0.4828 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6832 Model_2_val:0.6886
Epoch: 0400 Model_1_loss: 0.4913 Model_2_loss: 0.5130 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6918 Model_2_val:0.6783
Model_one_test:0.7140 Model_two_test:0.7143
added by two output: 0.7153
13
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1492928124
Epoch: 0020 Model_1_loss: 1.7499 Model_2_loss: 1.7506 Model_1_trainacc: 0.3167 Model_2_trainacc: 0.3083 Model_1_val:0.2280 Model_2_val:0.2087
Epoch: 0040 Model_1_loss: 1.6579 Model_2_loss: 1.6345 Model_1_trainacc: 0.5000 Model_2_trainacc: 0.6750 Model_1_val:0.3877 Model_2_val:0.3933
Epoch: 0060 Model_1_loss: 1.3806 Model_2_loss: 1.3778 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.8250 Model_1_val:0.5118 Model_2_val:0.4962
Epoch: 0080 Model_1_loss: 1.1318 Model_2_loss: 1.0679 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8750 Model_1_val:0.5318 Model_2_val:0.5278
Epoch: 0100 Model_1_loss: 0.8488 Model_2_loss: 0.8228 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9500 Model_1_val:0.5501 Model_2_val:0.5567
Epoch: 0120 Model_1_loss: 0.6924 Model_2_loss: 0.7216 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8917 Model_1_val:0.5597 Model_2_val:0.5704
Epoch: 0140 Model_1_loss: 0.5976 Model_2_loss: 0.5900 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5804 Model_2_val:0.5740
Epoch: 0160 Model_1_loss: 0.5291 Model_2_loss: 0.5445 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9000 Model_1_val:0.5707 Model_2_val:0.5764
Epoch: 0180 Model_1_loss: 0.5152 Model_2_loss: 0.4968 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5884 Model_2_val:0.5860
Epoch: 0200 Model_1_loss: 0.4484 Model_2_loss: 0.4543 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6000 Model_2_val:0.6010
Epoch: 0220 Model_1_loss: 0.7028 Model_2_loss: 0.7619 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6835 Model_2_val:0.6592
Epoch: 0240 Model_1_loss: 0.6941 Model_2_loss: 0.7214 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6705 Model_2_val:0.6769
Epoch: 0260 Model_1_loss: 0.6886 Model_2_loss: 0.6457 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6885 Model_2_val:0.6842
Epoch: 0280 Model_1_loss: 0.6207 Model_2_loss: 0.6123 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6882 Model_2_val:0.6915
Epoch: 0300 Model_1_loss: 0.5739 Model_2_loss: 0.5961 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6839 Model_2_val:0.6875
Epoch: 0320 Model_1_loss: 0.5527 Model_2_loss: 0.5963 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6799 Model_2_val:0.6735
Epoch: 0340 Model_1_loss: 0.5825 Model_2_loss: 0.5782 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6879 Model_2_val:0.6745
Epoch: 0360 Model_1_loss: 0.5298 Model_2_loss: 0.5526 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6842 Model_2_val:0.6742
Epoch: 0380 Model_1_loss: 0.4760 Model_2_loss: 0.4848 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6875 Model_2_val:0.6889
Epoch: 0400 Model_1_loss: 0.4800 Model_2_loss: 0.4993 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6849 Model_2_val:0.6772
Model_one_test:0.7155 Model_two_test:0.7105
added by two output: 0.7131
14
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
691807773
Epoch: 0020 Model_1_loss: 1.7105 Model_2_loss: 1.7195 Model_1_trainacc: 0.4500 Model_2_trainacc: 0.4083 Model_1_val:0.2355 Model_2_val:0.2780
Epoch: 0040 Model_1_loss: 1.5341 Model_2_loss: 1.5219 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7667 Model_1_val:0.4266 Model_2_val:0.3990
Epoch: 0060 Model_1_loss: 1.1658 Model_2_loss: 1.2314 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8833 Model_1_val:0.5100 Model_2_val:0.4794
Epoch: 0080 Model_1_loss: 0.8928 Model_2_loss: 0.9344 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9083 Model_1_val:0.5273 Model_2_val:0.5138
Epoch: 0100 Model_1_loss: 0.7118 Model_2_loss: 0.6947 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5483 Model_2_val:0.5393
Epoch: 0120 Model_1_loss: 0.5836 Model_2_loss: 0.6165 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5775 Model_2_val:0.5782
Epoch: 0140 Model_1_loss: 0.5217 Model_2_loss: 0.5331 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5644 Model_2_val:0.5898
Epoch: 0160 Model_1_loss: 0.4493 Model_2_loss: 0.4367 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.5750 Model_2_val:0.5862
Epoch: 0180 Model_1_loss: 0.3936 Model_2_loss: 0.4343 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.5718 Model_2_val:0.5801
Epoch: 0200 Model_1_loss: 0.4146 Model_2_loss: 0.4399 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5759 Model_2_val:0.5952
Epoch: 0220 Model_1_loss: 0.7528 Model_2_loss: 0.7201 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6432 Model_2_val:0.6435
Epoch: 0240 Model_1_loss: 0.6493 Model_2_loss: 0.6771 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6622 Model_2_val:0.6680
Epoch: 0260 Model_1_loss: 0.6143 Model_2_loss: 0.6350 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6689 Model_2_val:0.6641
Epoch: 0280 Model_1_loss: 0.6265 Model_2_loss: 0.5806 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6757 Model_2_val:0.6708
Epoch: 0300 Model_1_loss: 0.6249 Model_2_loss: 0.6443 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6779 Model_2_val:0.6721
Epoch: 0320 Model_1_loss: 0.5191 Model_2_loss: 0.5684 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6660 Model_2_val:0.6847
Epoch: 0340 Model_1_loss: 0.5267 Model_2_loss: 0.5276 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6657 Model_2_val:0.6744
Epoch: 0360 Model_1_loss: 0.5622 Model_2_loss: 0.5555 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6708 Model_2_val:0.6773
Epoch: 0380 Model_1_loss: 0.4627 Model_2_loss: 0.5397 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6708 Model_2_val:0.6818
Epoch: 0400 Model_1_loss: 0.4806 Model_2_loss: 0.5013 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6792 Model_2_val:0.6737
Model_one_test:0.6959 Model_two_test:0.7001
added by two output: 0.6972
15
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
814722731
Epoch: 0020 Model_1_loss: 1.7421 Model_2_loss: 1.6956 Model_1_trainacc: 0.3667 Model_2_trainacc: 0.4250 Model_1_val:0.2323 Model_2_val:0.2381
Epoch: 0040 Model_1_loss: 1.6018 Model_2_loss: 1.5220 Model_1_trainacc: 0.6417 Model_2_trainacc: 0.7083 Model_1_val:0.3562 Model_2_val:0.4518
Epoch: 0060 Model_1_loss: 1.3718 Model_2_loss: 1.2281 Model_1_trainacc: 0.7083 Model_2_trainacc: 0.8333 Model_1_val:0.4426 Model_2_val:0.5119
Epoch: 0080 Model_1_loss: 1.1380 Model_2_loss: 0.9387 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8917 Model_1_val:0.4959 Model_2_val:0.5551
Epoch: 0100 Model_1_loss: 0.9380 Model_2_loss: 0.7499 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8833 Model_1_val:0.5100 Model_2_val:0.5888
Epoch: 0120 Model_1_loss: 0.8179 Model_2_loss: 0.5915 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.9583 Model_1_val:0.5316 Model_2_val:0.5940
Epoch: 0140 Model_1_loss: 0.6609 Model_2_loss: 0.5309 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9417 Model_1_val:0.5293 Model_2_val:0.5911
Epoch: 0160 Model_1_loss: 0.6331 Model_2_loss: 0.4891 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5738 Model_2_val:0.5918
Epoch: 0180 Model_1_loss: 0.4925 Model_2_loss: 0.4386 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.5767 Model_2_val:0.6022
Epoch: 0200 Model_1_loss: 0.5080 Model_2_loss: 0.4069 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9250 Model_1_val:0.5836 Model_2_val:0.5976
Epoch: 0220 Model_1_loss: 0.8082 Model_2_loss: 0.7820 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6569 Model_2_val:0.6631
Epoch: 0240 Model_1_loss: 0.7303 Model_2_loss: 0.7207 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6742 Model_2_val:0.6784
Epoch: 0260 Model_1_loss: 0.7135 Model_2_loss: 0.6792 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6788 Model_2_val:0.6804
Epoch: 0280 Model_1_loss: 0.7181 Model_2_loss: 0.6268 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6680 Model_2_val:0.6814
Epoch: 0300 Model_1_loss: 0.7159 Model_2_loss: 0.6184 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6640 Model_2_val:0.6827
Epoch: 0320 Model_1_loss: 0.5924 Model_2_loss: 0.5929 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6683 Model_2_val:0.6794
Epoch: 0340 Model_1_loss: 0.6371 Model_2_loss: 0.5798 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9917 Model_1_val:0.6745 Model_2_val:0.6752
Epoch: 0360 Model_1_loss: 0.6218 Model_2_loss: 0.5887 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6627 Model_2_val:0.6801
Epoch: 0380 Model_1_loss: 0.6022 Model_2_loss: 0.5139 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6716 Model_2_val:0.6804
Epoch: 0400 Model_1_loss: 0.5708 Model_2_loss: 0.4823 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6748 Model_2_val:0.6784
Model_one_test:0.7072 Model_two_test:0.7026
added by two output: 0.7053
16
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1319013200
Epoch: 0020 Model_1_loss: 1.7103 Model_2_loss: 1.7321 Model_1_trainacc: 0.4417 Model_2_trainacc: 0.5667 Model_1_val:0.2462 Model_2_val:0.3039
Epoch: 0040 Model_1_loss: 1.5100 Model_2_loss: 1.5754 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.7583 Model_1_val:0.4557 Model_2_val:0.4230
Epoch: 0060 Model_1_loss: 1.1800 Model_2_loss: 1.3232 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8167 Model_1_val:0.5225 Model_2_val:0.4781
Epoch: 0080 Model_1_loss: 0.8552 Model_2_loss: 1.0134 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8833 Model_1_val:0.5527 Model_2_val:0.5307
Epoch: 0100 Model_1_loss: 0.6624 Model_2_loss: 0.7641 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9083 Model_1_val:0.5761 Model_2_val:0.5553
Epoch: 0120 Model_1_loss: 0.5553 Model_2_loss: 0.6719 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9250 Model_1_val:0.5874 Model_2_val:0.5757
Epoch: 0140 Model_1_loss: 0.4837 Model_2_loss: 0.5422 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.5926 Model_2_val:0.5939
Epoch: 0160 Model_1_loss: 0.4415 Model_2_loss: 0.4912 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.5955 Model_2_val:0.6085
Epoch: 0180 Model_1_loss: 0.3825 Model_2_loss: 0.4273 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.5907 Model_2_val:0.5981
Epoch: 0200 Model_1_loss: 0.4049 Model_2_loss: 0.3723 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6036 Model_2_val:0.5942
Epoch: 0220 Model_1_loss: 0.7188 Model_2_loss: 0.7074 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6572 Model_2_val:0.6584
Epoch: 0240 Model_1_loss: 0.6292 Model_2_loss: 0.6469 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6614 Model_2_val:0.6659
Epoch: 0260 Model_1_loss: 0.6078 Model_2_loss: 0.5876 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6688 Model_2_val:0.6734
Epoch: 0280 Model_1_loss: 0.5753 Model_2_loss: 0.5565 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6688 Model_2_val:0.6711
Epoch: 0300 Model_1_loss: 0.5395 Model_2_loss: 0.6019 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9417 Model_1_val:0.6675 Model_2_val:0.6766
Epoch: 0320 Model_1_loss: 0.5273 Model_2_loss: 0.5011 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6705 Model_2_val:0.6747
Epoch: 0340 Model_1_loss: 0.5126 Model_2_loss: 0.4972 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6617 Model_2_val:0.6695
Epoch: 0360 Model_1_loss: 0.4851 Model_2_loss: 0.4755 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6679 Model_2_val:0.6753
Epoch: 0380 Model_1_loss: 0.4784 Model_2_loss: 0.5044 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6747 Model_2_val:0.6727
Epoch: 0400 Model_1_loss: 0.4543 Model_2_loss: 0.4388 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6782 Model_2_val:0.6760
Model_one_test:0.6945 Model_two_test:0.6983
added by two output: 0.6961
17
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
683720816
Epoch: 0020 Model_1_loss: 1.7128 Model_2_loss: 1.7361 Model_1_trainacc: 0.3833 Model_2_trainacc: 0.3917 Model_1_val:0.2601 Model_2_val:0.2853
Epoch: 0040 Model_1_loss: 1.5154 Model_2_loss: 1.5365 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.7667 Model_1_val:0.4638 Model_2_val:0.4294
Epoch: 0060 Model_1_loss: 1.2133 Model_2_loss: 1.2236 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8333 Model_1_val:0.5160 Model_2_val:0.5171
Epoch: 0080 Model_1_loss: 0.8611 Model_2_loss: 0.9246 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8833 Model_1_val:0.5751 Model_2_val:0.5614
Epoch: 0100 Model_1_loss: 0.7240 Model_2_loss: 0.7673 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.5887 Model_2_val:0.5713
Epoch: 0120 Model_1_loss: 0.5747 Model_2_loss: 0.6325 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.5891 Model_2_val:0.5642
Epoch: 0140 Model_1_loss: 0.5007 Model_2_loss: 0.5444 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.6119 Model_2_val:0.6010
Epoch: 0160 Model_1_loss: 0.4484 Model_2_loss: 0.5112 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.5969 Model_2_val:0.6014
Epoch: 0180 Model_1_loss: 0.4122 Model_2_loss: 0.4443 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6061 Model_2_val:0.6191
Epoch: 0200 Model_1_loss: 0.3529 Model_2_loss: 0.4193 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6031 Model_2_val:0.6024
Epoch: 0220 Model_1_loss: 0.7146 Model_2_loss: 0.7260 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6539 Model_2_val:0.6502
Epoch: 0240 Model_1_loss: 0.6419 Model_2_loss: 0.6529 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6590 Model_2_val:0.6638
Epoch: 0260 Model_1_loss: 0.5814 Model_2_loss: 0.6054 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6584 Model_2_val:0.6724
Epoch: 0280 Model_1_loss: 0.5344 Model_2_loss: 0.5788 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6577 Model_2_val:0.6720
Epoch: 0300 Model_1_loss: 0.5312 Model_2_loss: 0.5405 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6621 Model_2_val:0.6683
Epoch: 0320 Model_1_loss: 0.4908 Model_2_loss: 0.4960 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6775 Model_2_val:0.6628
Epoch: 0340 Model_1_loss: 0.5086 Model_2_loss: 0.4840 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6703 Model_2_val:0.6683
Epoch: 0360 Model_1_loss: 0.4768 Model_2_loss: 0.4843 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6662 Model_2_val:0.6635
Epoch: 0380 Model_1_loss: 0.4793 Model_2_loss: 0.4649 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6621 Model_2_val:0.6659
Epoch: 0400 Model_1_loss: 0.4638 Model_2_loss: 0.4791 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6679 Model_2_val:0.6648
Model_one_test:0.6932 Model_two_test:0.6915
added by two output: 0.6949
18
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
335697403
Epoch: 0020 Model_1_loss: 1.7430 Model_2_loss: 1.7015 Model_1_trainacc: 0.3250 Model_2_trainacc: 0.4500 Model_1_val:0.2544 Model_2_val:0.2695
Epoch: 0040 Model_1_loss: 1.5587 Model_2_loss: 1.5053 Model_1_trainacc: 0.7250 Model_2_trainacc: 0.7667 Model_1_val:0.4147 Model_2_val:0.4810
Epoch: 0060 Model_1_loss: 1.2696 Model_2_loss: 1.1882 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8583 Model_1_val:0.5167 Model_2_val:0.5236
Epoch: 0080 Model_1_loss: 0.9376 Model_2_loss: 0.9041 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8750 Model_1_val:0.5470 Model_2_val:0.5609
Epoch: 0100 Model_1_loss: 0.7652 Model_2_loss: 0.7375 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9333 Model_1_val:0.5846 Model_2_val:0.5701
Epoch: 0120 Model_1_loss: 0.6320 Model_2_loss: 0.6169 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9250 Model_1_val:0.5850 Model_2_val:0.5932
Epoch: 0140 Model_1_loss: 0.5609 Model_2_loss: 0.5523 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9167 Model_1_val:0.5919 Model_2_val:0.6117
Epoch: 0160 Model_1_loss: 0.5761 Model_2_loss: 0.4493 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.5919 Model_2_val:0.6183
Epoch: 0180 Model_1_loss: 0.4779 Model_2_loss: 0.4229 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.5955 Model_2_val:0.6143
Epoch: 0200 Model_1_loss: 0.4684 Model_2_loss: 0.3934 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.6219 Model_2_val:0.6057
Epoch: 0220 Model_1_loss: 0.7548 Model_2_loss: 0.6652 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6565 Model_2_val:0.6674
Epoch: 0240 Model_1_loss: 0.7025 Model_2_loss: 0.6344 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6641 Model_2_val:0.6681
Epoch: 0260 Model_1_loss: 0.6303 Model_2_loss: 0.6434 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6777 Model_2_val:0.6767
Epoch: 0280 Model_1_loss: 0.6036 Model_2_loss: 0.6137 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6747 Model_2_val:0.6800
Epoch: 0300 Model_1_loss: 0.6004 Model_2_loss: 0.5756 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6829 Model_2_val:0.6740
Epoch: 0320 Model_1_loss: 0.5825 Model_2_loss: 0.5677 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6803 Model_2_val:0.6793
Epoch: 0340 Model_1_loss: 0.5328 Model_2_loss: 0.5438 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6833 Model_2_val:0.6859
Epoch: 0360 Model_1_loss: 0.5265 Model_2_loss: 0.5134 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6787 Model_2_val:0.6816
Epoch: 0380 Model_1_loss: 0.5596 Model_2_loss: 0.4706 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6806 Model_2_val:0.6820
Epoch: 0400 Model_1_loss: 0.5386 Model_2_loss: 0.4922 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6833 Model_2_val:0.6790
Model_one_test:0.7044 Model_two_test:0.7031
added by two output: 0.7024
19
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
311877880
Epoch: 0020 Model_1_loss: 1.7415 Model_2_loss: 1.7425 Model_1_trainacc: 0.3917 Model_2_trainacc: 0.3333 Model_1_val:0.2582 Model_2_val:0.2254
Epoch: 0040 Model_1_loss: 1.6056 Model_2_loss: 1.5861 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.6500 Model_1_val:0.4057 Model_2_val:0.3622
Epoch: 0060 Model_1_loss: 1.3500 Model_2_loss: 1.2901 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.8417 Model_1_val:0.4890 Model_2_val:0.4610
Epoch: 0080 Model_1_loss: 1.0392 Model_2_loss: 0.9807 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8917 Model_1_val:0.5059 Model_2_val:0.5234
Epoch: 0100 Model_1_loss: 0.8559 Model_2_loss: 0.7848 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9333 Model_1_val:0.5367 Model_2_val:0.5402
Epoch: 0120 Model_1_loss: 0.7207 Model_2_loss: 0.6880 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5348 Model_2_val:0.5752
Epoch: 0140 Model_1_loss: 0.6170 Model_2_loss: 0.5771 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5320 Model_2_val:0.5701
Epoch: 0160 Model_1_loss: 0.5314 Model_2_loss: 0.5272 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5370 Model_2_val:0.5940
Epoch: 0180 Model_1_loss: 0.5502 Model_2_loss: 0.4304 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.5323 Model_2_val:0.5879
Epoch: 0200 Model_1_loss: 0.4858 Model_2_loss: 0.3799 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.5507 Model_2_val:0.5905
Epoch: 0220 Model_1_loss: 0.8821 Model_2_loss: 0.7753 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6121 Model_2_val:0.6448
Epoch: 0240 Model_1_loss: 0.7716 Model_2_loss: 0.6850 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6245 Model_2_val:0.6556
Epoch: 0260 Model_1_loss: 0.6774 Model_2_loss: 0.7169 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6277 Model_2_val:0.6563
Epoch: 0280 Model_1_loss: 0.6558 Model_2_loss: 0.6391 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6293 Model_2_val:0.6566
Epoch: 0300 Model_1_loss: 0.6023 Model_2_loss: 0.6429 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6455 Model_2_val:0.6677
Epoch: 0320 Model_1_loss: 0.6380 Model_2_loss: 0.5779 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6407 Model_2_val:0.6680
Epoch: 0340 Model_1_loss: 0.5569 Model_2_loss: 0.5448 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6442 Model_2_val:0.6607
Epoch: 0360 Model_1_loss: 0.5802 Model_2_loss: 0.5710 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6509 Model_2_val:0.6588
Epoch: 0380 Model_1_loss: 0.5739 Model_2_loss: 0.5161 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6518 Model_2_val:0.6595
Epoch: 0400 Model_1_loss: 0.5346 Model_2_loss: 0.5265 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6560 Model_2_val:0.6601
Model_one_test:0.6906 Model_two_test:0.6925
added by two output: 0.6919
20
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
207256290
Epoch: 0020 Model_1_loss: 1.7266 Model_2_loss: 1.7108 Model_1_trainacc: 0.4000 Model_2_trainacc: 0.3833 Model_1_val:0.2772 Model_2_val:0.2652
Epoch: 0040 Model_1_loss: 1.5599 Model_2_loss: 1.5015 Model_1_trainacc: 0.7000 Model_2_trainacc: 0.5667 Model_1_val:0.4586 Model_2_val:0.3311
Epoch: 0060 Model_1_loss: 1.2795 Model_2_loss: 1.2858 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.7583 Model_1_val:0.5063 Model_2_val:0.3937
Epoch: 0080 Model_1_loss: 0.9807 Model_2_loss: 1.0719 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8000 Model_1_val:0.5255 Model_2_val:0.4703
Epoch: 0100 Model_1_loss: 0.8365 Model_2_loss: 0.9049 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8667 Model_1_val:0.5537 Model_2_val:0.5122
Epoch: 0120 Model_1_loss: 0.6891 Model_2_loss: 0.7653 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9083 Model_1_val:0.5514 Model_2_val:0.5352
Epoch: 0140 Model_1_loss: 0.5739 Model_2_loss: 0.6725 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.5589 Model_2_val:0.5673
Epoch: 0160 Model_1_loss: 0.5446 Model_2_loss: 0.5913 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5826 Model_2_val:0.5751
Epoch: 0180 Model_1_loss: 0.4563 Model_2_loss: 0.4755 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5982 Model_2_val:0.5852
Epoch: 0200 Model_1_loss: 0.4324 Model_2_loss: 0.4316 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5904 Model_2_val:0.5884
Epoch: 0220 Model_1_loss: 0.7708 Model_2_loss: 0.7983 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6498 Model_2_val:0.6563
Epoch: 0240 Model_1_loss: 0.6816 Model_2_loss: 0.7368 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6647 Model_2_val:0.6657
Epoch: 0260 Model_1_loss: 0.6434 Model_2_loss: 0.7014 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6706 Model_2_val:0.6832
Epoch: 0280 Model_1_loss: 0.6092 Model_2_loss: 0.6432 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6748 Model_2_val:0.6706
Epoch: 0300 Model_1_loss: 0.5725 Model_2_loss: 0.5964 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6758 Model_2_val:0.6754
Epoch: 0320 Model_1_loss: 0.5650 Model_2_loss: 0.5862 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6709 Model_2_val:0.6670
Epoch: 0340 Model_1_loss: 0.5237 Model_2_loss: 0.5546 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6654 Model_2_val:0.6634
Epoch: 0360 Model_1_loss: 0.5505 Model_2_loss: 0.5611 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6842 Model_2_val:0.6654
Epoch: 0380 Model_1_loss: 0.5459 Model_2_loss: 0.5419 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6725 Model_2_val:0.6754
Epoch: 0400 Model_1_loss: 0.4789 Model_2_loss: 0.5207 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.6787 Model_2_val:0.6745
Model_one_test:0.6956 Model_two_test:0.6933
added by two output: 0.6952
21
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
943358059
Epoch: 0020 Model_1_loss: 1.6976 Model_2_loss: 1.7120 Model_1_trainacc: 0.4750 Model_2_trainacc: 0.3917 Model_1_val:0.2568 Model_2_val:0.2221
Epoch: 0040 Model_1_loss: 1.5172 Model_2_loss: 1.4953 Model_1_trainacc: 0.6833 Model_2_trainacc: 0.8167 Model_1_val:0.3850 Model_2_val:0.4563
Epoch: 0060 Model_1_loss: 1.2387 Model_2_loss: 1.2492 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8083 Model_1_val:0.4733 Model_2_val:0.4975
Epoch: 0080 Model_1_loss: 0.9152 Model_2_loss: 1.0081 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9000 Model_1_val:0.5191 Model_2_val:0.5394
Epoch: 0100 Model_1_loss: 0.7510 Model_2_loss: 0.8080 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9000 Model_1_val:0.5715 Model_2_val:0.5541
Epoch: 0120 Model_1_loss: 0.5848 Model_2_loss: 0.6639 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9167 Model_1_val:0.5734 Model_2_val:0.5744
Epoch: 0140 Model_1_loss: 0.5356 Model_2_loss: 0.6308 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9000 Model_1_val:0.6104 Model_2_val:0.5918
Epoch: 0160 Model_1_loss: 0.4766 Model_2_loss: 0.5222 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.6091 Model_2_val:0.6039
Epoch: 0180 Model_1_loss: 0.4108 Model_2_loss: 0.4690 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6127 Model_2_val:0.6254
Epoch: 0200 Model_1_loss: 0.3353 Model_2_loss: 0.4150 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9250 Model_1_val:0.6075 Model_2_val:0.5963
Epoch: 0220 Model_1_loss: 0.6611 Model_2_loss: 0.7619 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6860 Model_2_val:0.6716
Epoch: 0240 Model_1_loss: 0.5844 Model_2_loss: 0.6636 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6860 Model_2_val:0.6752
Epoch: 0260 Model_1_loss: 0.5605 Model_2_loss: 0.5922 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6876 Model_2_val:0.6889
Epoch: 0280 Model_1_loss: 0.4972 Model_2_loss: 0.5406 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6837 Model_2_val:0.6863
Epoch: 0300 Model_1_loss: 0.5272 Model_2_loss: 0.5204 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6856 Model_2_val:0.6775
Epoch: 0320 Model_1_loss: 0.4898 Model_2_loss: 0.5273 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6752 Model_2_val:0.6748
Epoch: 0340 Model_1_loss: 0.4951 Model_2_loss: 0.4970 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6716 Model_2_val:0.6919
Epoch: 0360 Model_1_loss: 0.4796 Model_2_loss: 0.4579 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6778 Model_2_val:0.6873
Epoch: 0380 Model_1_loss: 0.4562 Model_2_loss: 0.4707 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6843 Model_2_val:0.6883
Epoch: 0400 Model_1_loss: 0.4374 Model_2_loss: 0.4324 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6824 Model_2_val:0.6827
Model_one_test:0.7013 Model_two_test:0.6991
added by two output: 0.6991
22
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
470399154
Epoch: 0020 Model_1_loss: 1.6894 Model_2_loss: 1.7011 Model_1_trainacc: 0.4417 Model_2_trainacc: 0.4833 Model_1_val:0.2357 Model_2_val:0.3497
Epoch: 0040 Model_1_loss: 1.4720 Model_2_loss: 1.4814 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8167 Model_1_val:0.4708 Model_2_val:0.4625
Epoch: 0060 Model_1_loss: 1.0855 Model_2_loss: 1.1979 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8750 Model_1_val:0.5238 Model_2_val:0.5299
Epoch: 0080 Model_1_loss: 0.8388 Model_2_loss: 0.9570 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8917 Model_1_val:0.5503 Model_2_val:0.5407
Epoch: 0100 Model_1_loss: 0.6212 Model_2_loss: 0.7205 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9250 Model_1_val:0.5672 Model_2_val:0.5797
Epoch: 0120 Model_1_loss: 0.5004 Model_2_loss: 0.6171 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9333 Model_1_val:0.5925 Model_2_val:0.5637
Epoch: 0140 Model_1_loss: 0.4543 Model_2_loss: 0.4821 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6065 Model_2_val:0.5928
Epoch: 0160 Model_1_loss: 0.4232 Model_2_loss: 0.4504 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.5842 Model_2_val:0.5966
Epoch: 0180 Model_1_loss: 0.3834 Model_2_loss: 0.5004 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9417 Model_1_val:0.6097 Model_2_val:0.5953
Epoch: 0200 Model_1_loss: 0.3712 Model_2_loss: 0.3651 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6161 Model_2_val:0.6017
Epoch: 0220 Model_1_loss: 0.6772 Model_2_loss: 0.6923 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6630 Model_2_val:0.6618
Epoch: 0240 Model_1_loss: 0.6344 Model_2_loss: 0.6567 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6643 Model_2_val:0.6675
Epoch: 0260 Model_1_loss: 0.5410 Model_2_loss: 0.5675 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6758 Model_2_val:0.6723
Epoch: 0280 Model_1_loss: 0.5565 Model_2_loss: 0.5528 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6621 Model_2_val:0.6698
Epoch: 0300 Model_1_loss: 0.5286 Model_2_loss: 0.5095 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6726 Model_2_val:0.6768
Epoch: 0320 Model_1_loss: 0.5421 Model_2_loss: 0.4864 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6736 Model_2_val:0.6682
Epoch: 0340 Model_1_loss: 0.5187 Model_2_loss: 0.4475 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6643 Model_2_val:0.6701
Epoch: 0360 Model_1_loss: 0.4584 Model_2_loss: 0.4290 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6691 Model_2_val:0.6723
Epoch: 0380 Model_1_loss: 0.4770 Model_2_loss: 0.4492 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6742 Model_2_val:0.6809
Epoch: 0400 Model_1_loss: 0.4142 Model_2_loss: 0.4098 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6666 Model_2_val:0.6710
Model_one_test:0.7074 Model_two_test:0.7058
added by two output: 0.7068
23
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1394714167
Epoch: 0020 Model_1_loss: 1.7393 Model_2_loss: 1.7122 Model_1_trainacc: 0.3500 Model_2_trainacc: 0.4583 Model_1_val:0.2325 Model_2_val:0.2781
Epoch: 0040 Model_1_loss: 1.6402 Model_2_loss: 1.5357 Model_1_trainacc: 0.5833 Model_2_trainacc: 0.7167 Model_1_val:0.3136 Model_2_val:0.4309
Epoch: 0060 Model_1_loss: 1.4249 Model_2_loss: 1.2408 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.8250 Model_1_val:0.4735 Model_2_val:0.5157
Epoch: 0080 Model_1_loss: 1.0849 Model_2_loss: 0.9381 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9417 Model_1_val:0.5272 Model_2_val:0.5458
Epoch: 0100 Model_1_loss: 0.8358 Model_2_loss: 0.7355 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5549 Model_2_val:0.5438
Epoch: 0120 Model_1_loss: 0.6898 Model_2_loss: 0.6287 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9000 Model_1_val:0.5461 Model_2_val:0.5867
Epoch: 0140 Model_1_loss: 0.6030 Model_2_loss: 0.5657 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.5779 Model_2_val:0.5769
Epoch: 0160 Model_1_loss: 0.4957 Model_2_loss: 0.4510 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5715 Model_2_val:0.5874
Epoch: 0180 Model_1_loss: 0.5160 Model_2_loss: 0.4427 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5644 Model_2_val:0.5860
Epoch: 0200 Model_1_loss: 0.4512 Model_2_loss: 0.4337 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5742 Model_2_val:0.5870
Epoch: 0220 Model_1_loss: 0.8002 Model_2_loss: 0.7896 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6333 Model_2_val:0.6509
Epoch: 0240 Model_1_loss: 0.7442 Model_2_loss: 0.7118 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6445 Model_2_val:0.6587
Epoch: 0260 Model_1_loss: 0.6905 Model_2_loss: 0.6768 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.6610 Model_2_val:0.6570
Epoch: 0280 Model_1_loss: 0.6732 Model_2_loss: 0.6425 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6627 Model_2_val:0.6604
Epoch: 0300 Model_1_loss: 0.6436 Model_2_loss: 0.6074 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6536 Model_2_val:0.6566
Epoch: 0320 Model_1_loss: 0.6662 Model_2_loss: 0.5362 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6580 Model_2_val:0.6617
Epoch: 0340 Model_1_loss: 0.6203 Model_2_loss: 0.5496 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.6550 Model_2_val:0.6641
Epoch: 0360 Model_1_loss: 0.5068 Model_2_loss: 0.5075 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6556 Model_2_val:0.6597
Epoch: 0380 Model_1_loss: 0.5948 Model_2_loss: 0.4996 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6675 Model_2_val:0.6641
Epoch: 0400 Model_1_loss: 0.4979 Model_2_loss: 0.5156 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6580 Model_2_val:0.6610
Model_one_test:0.6887 Model_two_test:0.6840
added by two output: 0.6881
24
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
902055285
Epoch: 0020 Model_1_loss: 1.7223 Model_2_loss: 1.7132 Model_1_trainacc: 0.4417 Model_2_trainacc: 0.4417 Model_1_val:0.2931 Model_2_val:0.2041
Epoch: 0040 Model_1_loss: 1.5346 Model_2_loss: 1.5767 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.7167 Model_1_val:0.4391 Model_2_val:0.3911
Epoch: 0060 Model_1_loss: 1.2230 Model_2_loss: 1.3206 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8167 Model_1_val:0.5205 Model_2_val:0.4772
Epoch: 0080 Model_1_loss: 0.9592 Model_2_loss: 1.0258 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8750 Model_1_val:0.5382 Model_2_val:0.5195
Epoch: 0100 Model_1_loss: 0.7423 Model_2_loss: 0.8755 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8833 Model_1_val:0.5745 Model_2_val:0.5375
Epoch: 0120 Model_1_loss: 0.5864 Model_2_loss: 0.6822 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5949 Model_2_val:0.5458
Epoch: 0140 Model_1_loss: 0.5255 Model_2_loss: 0.6060 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.5779 Model_2_val:0.5852
Epoch: 0160 Model_1_loss: 0.5224 Model_2_loss: 0.5181 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.5875 Model_2_val:0.5865
Epoch: 0180 Model_1_loss: 0.4107 Model_2_loss: 0.5760 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9417 Model_1_val:0.6019 Model_2_val:0.5675
Epoch: 0200 Model_1_loss: 0.4254 Model_2_loss: 0.4275 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.6149 Model_2_val:0.5759
Epoch: 0220 Model_1_loss: 0.7221 Model_2_loss: 0.8046 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6632 Model_2_val:0.6529
Epoch: 0240 Model_1_loss: 0.6906 Model_2_loss: 0.8064 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9417 Model_1_val:0.6782 Model_2_val:0.6602
Epoch: 0260 Model_1_loss: 0.6849 Model_2_loss: 0.6992 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6662 Model_2_val:0.6619
Epoch: 0280 Model_1_loss: 0.6263 Model_2_loss: 0.6869 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6796 Model_2_val:0.6719
Epoch: 0300 Model_1_loss: 0.6172 Model_2_loss: 0.6621 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6786 Model_2_val:0.6666
Epoch: 0320 Model_1_loss: 0.6081 Model_2_loss: 0.5943 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6632 Model_2_val:0.6732
Epoch: 0340 Model_1_loss: 0.5410 Model_2_loss: 0.5910 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6666 Model_2_val:0.6839
Epoch: 0360 Model_1_loss: 0.5566 Model_2_loss: 0.5237 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6682 Model_2_val:0.6779
Epoch: 0380 Model_1_loss: 0.5303 Model_2_loss: 0.4606 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.6679 Model_2_val:0.6822
Epoch: 0400 Model_1_loss: 0.5288 Model_2_loss: 0.5143 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6736 Model_2_val:0.6732
Model_one_test:0.6956 Model_two_test:0.6962
added by two output: 0.6952
25
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
606343763
Epoch: 0020 Model_1_loss: 1.7261 Model_2_loss: 1.6885 Model_1_trainacc: 0.4667 Model_2_trainacc: 0.4833 Model_1_val:0.3054 Model_2_val:0.2355
Epoch: 0040 Model_1_loss: 1.5390 Model_2_loss: 1.4923 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.7833 Model_1_val:0.4676 Model_2_val:0.4458
Epoch: 0060 Model_1_loss: 1.2268 Model_2_loss: 1.1900 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8833 Model_1_val:0.5475 Model_2_val:0.5251
Epoch: 0080 Model_1_loss: 0.9062 Model_2_loss: 0.9402 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8750 Model_1_val:0.5776 Model_2_val:0.5505
Epoch: 0100 Model_1_loss: 0.7377 Model_2_loss: 0.7250 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9083 Model_1_val:0.5873 Model_2_val:0.5753
Epoch: 0120 Model_1_loss: 0.5626 Model_2_loss: 0.6505 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9250 Model_1_val:0.5896 Model_2_val:0.5666
Epoch: 0140 Model_1_loss: 0.4709 Model_2_loss: 0.5168 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6177 Model_2_val:0.5983
Epoch: 0160 Model_1_loss: 0.4919 Model_2_loss: 0.5275 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9333 Model_1_val:0.5973 Model_2_val:0.5796
Epoch: 0180 Model_1_loss: 0.4246 Model_2_loss: 0.4531 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5926 Model_2_val:0.6007
Epoch: 0200 Model_1_loss: 0.3676 Model_2_loss: 0.3961 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.5963 Model_2_val:0.5910
Epoch: 0220 Model_1_loss: 0.6792 Model_2_loss: 0.6974 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6545 Model_2_val:0.6421
Epoch: 0240 Model_1_loss: 0.6335 Model_2_loss: 0.6759 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6722 Model_2_val:0.6666
Epoch: 0260 Model_1_loss: 0.6536 Model_2_loss: 0.6546 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6645 Model_2_val:0.6679
Epoch: 0280 Model_1_loss: 0.5524 Model_2_loss: 0.5926 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.6706 Model_2_val:0.6696
Epoch: 0300 Model_1_loss: 0.5186 Model_2_loss: 0.5968 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6676 Model_2_val:0.6696
Epoch: 0320 Model_1_loss: 0.5213 Model_2_loss: 0.5315 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6739 Model_2_val:0.6702
Epoch: 0340 Model_1_loss: 0.5011 Model_2_loss: 0.5703 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6763 Model_2_val:0.6732
Epoch: 0360 Model_1_loss: 0.4907 Model_2_loss: 0.4804 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6746 Model_2_val:0.6689
Epoch: 0380 Model_1_loss: 0.4469 Model_2_loss: 0.4613 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6699 Model_2_val:0.6669
Epoch: 0400 Model_1_loss: 0.4456 Model_2_loss: 0.4666 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6676 Model_2_val:0.6639
Model_one_test:0.6973 Model_two_test:0.6957
added by two output: 0.6963
26
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
496596266
Epoch: 0020 Model_1_loss: 1.7336 Model_2_loss: 1.7195 Model_1_trainacc: 0.3917 Model_2_trainacc: 0.4000 Model_1_val:0.2401 Model_2_val:0.2653
Epoch: 0040 Model_1_loss: 1.5787 Model_2_loss: 1.5076 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.7167 Model_1_val:0.3667 Model_2_val:0.4256
Epoch: 0060 Model_1_loss: 1.3145 Model_2_loss: 1.2148 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8583 Model_1_val:0.4853 Model_2_val:0.5310
Epoch: 0080 Model_1_loss: 0.9649 Model_2_loss: 0.9130 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8917 Model_1_val:0.5346 Model_2_val:0.5658
Epoch: 0100 Model_1_loss: 0.8074 Model_2_loss: 0.7130 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9167 Model_1_val:0.5614 Model_2_val:0.5939
Epoch: 0120 Model_1_loss: 0.6599 Model_2_loss: 0.5997 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5545 Model_2_val:0.6148
Epoch: 0140 Model_1_loss: 0.5622 Model_2_loss: 0.4756 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5787 Model_2_val:0.5979
Epoch: 0160 Model_1_loss: 0.5288 Model_2_loss: 0.4319 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5787 Model_2_val:0.6048
Epoch: 0180 Model_1_loss: 0.5143 Model_2_loss: 0.3797 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.5833 Model_2_val:0.6019
Epoch: 0200 Model_1_loss: 0.4197 Model_2_loss: 0.3701 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5707 Model_2_val:0.6267
Epoch: 0220 Model_1_loss: 0.8210 Model_2_loss: 0.7285 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6605 Model_2_val:0.6744
Epoch: 0240 Model_1_loss: 0.7162 Model_2_loss: 0.6478 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6661 Model_2_val:0.6757
Epoch: 0260 Model_1_loss: 0.6545 Model_2_loss: 0.6156 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6658 Model_2_val:0.6820
Epoch: 0280 Model_1_loss: 0.6215 Model_2_loss: 0.5932 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6691 Model_2_val:0.6797
Epoch: 0300 Model_1_loss: 0.5732 Model_2_loss: 0.5803 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6780 Model_2_val:0.6850
Epoch: 0320 Model_1_loss: 0.6535 Model_2_loss: 0.5736 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6780 Model_2_val:0.6853
Epoch: 0340 Model_1_loss: 0.5158 Model_2_loss: 0.5185 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6701 Model_2_val:0.6814
Epoch: 0360 Model_1_loss: 0.5372 Model_2_loss: 0.5182 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6784 Model_2_val:0.6827
Epoch: 0380 Model_1_loss: 0.5007 Model_2_loss: 0.4836 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6731 Model_2_val:0.6873
Epoch: 0400 Model_1_loss: 0.4804 Model_2_loss: 0.4902 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6764 Model_2_val:0.6880
Model_one_test:0.6989 Model_two_test:0.7006
added by two output: 0.7009
27
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
946704377
Epoch: 0020 Model_1_loss: 1.7294 Model_2_loss: 1.7054 Model_1_trainacc: 0.2750 Model_2_trainacc: 0.4250 Model_1_val:0.2210 Model_2_val:0.2450
Epoch: 0040 Model_1_loss: 1.5455 Model_2_loss: 1.5284 Model_1_trainacc: 0.7417 Model_2_trainacc: 0.8083 Model_1_val:0.3964 Model_2_val:0.4559
Epoch: 0060 Model_1_loss: 1.2927 Model_2_loss: 1.2180 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8583 Model_1_val:0.4803 Model_2_val:0.5093
Epoch: 0080 Model_1_loss: 0.9704 Model_2_loss: 0.9548 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8833 Model_1_val:0.4950 Model_2_val:0.5561
Epoch: 0100 Model_1_loss: 0.8009 Model_2_loss: 0.7790 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9417 Model_1_val:0.5291 Model_2_val:0.5584
Epoch: 0120 Model_1_loss: 0.6635 Model_2_loss: 0.6926 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9083 Model_1_val:0.5555 Model_2_val:0.5734
Epoch: 0140 Model_1_loss: 0.6109 Model_2_loss: 0.5025 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9750 Model_1_val:0.5682 Model_2_val:0.5799
Epoch: 0160 Model_1_loss: 0.5099 Model_2_loss: 0.4654 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5678 Model_2_val:0.6046
Epoch: 0180 Model_1_loss: 0.4824 Model_2_loss: 0.4077 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5744 Model_2_val:0.5971
Epoch: 0200 Model_1_loss: 0.3986 Model_2_loss: 0.3447 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.5799 Model_2_val:0.5994
Epoch: 0220 Model_1_loss: 0.7214 Model_2_loss: 0.7300 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6583 Model_2_val:0.6785
Epoch: 0240 Model_1_loss: 0.7051 Model_2_loss: 0.6315 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6853 Model_2_val:0.6671
Epoch: 0260 Model_1_loss: 0.6330 Model_2_loss: 0.5991 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6765 Model_2_val:0.6863
Epoch: 0280 Model_1_loss: 0.6174 Model_2_loss: 0.5859 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6749 Model_2_val:0.6671
Epoch: 0300 Model_1_loss: 0.5996 Model_2_loss: 0.5289 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9833 Model_1_val:0.6850 Model_2_val:0.6778
Epoch: 0320 Model_1_loss: 0.5493 Model_2_loss: 0.5511 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6684 Model_2_val:0.6778
Epoch: 0340 Model_1_loss: 0.5171 Model_2_loss: 0.5527 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6681 Model_2_val:0.6749
Epoch: 0360 Model_1_loss: 0.5013 Model_2_loss: 0.5694 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6834 Model_2_val:0.6795
Epoch: 0380 Model_1_loss: 0.5246 Model_2_loss: 0.5109 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6746 Model_2_val:0.6733
Epoch: 0400 Model_1_loss: 0.4662 Model_2_loss: 0.4791 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6739 Model_2_val:0.6723
Model_one_test:0.6931 Model_two_test:0.6935
added by two output: 0.6951
28
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1213081314
Epoch: 0020 Model_1_loss: 1.7465 Model_2_loss: 1.7332 Model_1_trainacc: 0.4500 Model_2_trainacc: 0.4417 Model_1_val:0.3032 Model_2_val:0.2961
Epoch: 0040 Model_1_loss: 1.6181 Model_2_loss: 1.5563 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.6333 Model_1_val:0.4173 Model_2_val:0.3926
Epoch: 0060 Model_1_loss: 1.3687 Model_2_loss: 1.2546 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.7917 Model_1_val:0.4728 Model_2_val:0.4777
Epoch: 0080 Model_1_loss: 0.9791 Model_2_loss: 0.9601 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9083 Model_1_val:0.5217 Model_2_val:0.5497
Epoch: 0100 Model_1_loss: 0.8158 Model_2_loss: 0.7150 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9333 Model_1_val:0.5347 Model_2_val:0.5732
Epoch: 0120 Model_1_loss: 0.6157 Model_2_loss: 0.6091 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5745 Model_2_val:0.5765
Epoch: 0140 Model_1_loss: 0.4944 Model_2_loss: 0.5179 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.5950 Model_2_val:0.5908
Epoch: 0160 Model_1_loss: 0.4583 Model_2_loss: 0.4357 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.5840 Model_2_val:0.5980
Epoch: 0180 Model_1_loss: 0.4429 Model_2_loss: 0.4056 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6071 Model_2_val:0.6035
Epoch: 0200 Model_1_loss: 0.3749 Model_2_loss: 0.3933 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6140 Model_2_val:0.6078
Epoch: 0220 Model_1_loss: 0.6913 Model_2_loss: 0.7201 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6599 Model_2_val:0.6501
Epoch: 0240 Model_1_loss: 0.6415 Model_2_loss: 0.6339 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6720 Model_2_val:0.6622
Epoch: 0260 Model_1_loss: 0.6499 Model_2_loss: 0.6588 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6746 Model_2_val:0.6567
Epoch: 0280 Model_1_loss: 0.5424 Model_2_loss: 0.6004 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6704 Model_2_val:0.6642
Epoch: 0300 Model_1_loss: 0.5463 Model_2_loss: 0.5856 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6616 Model_2_val:0.6619
Epoch: 0320 Model_1_loss: 0.4923 Model_2_loss: 0.5470 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6762 Model_2_val:0.6733
Epoch: 0340 Model_1_loss: 0.4862 Model_2_loss: 0.5009 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6616 Model_2_val:0.6700
Epoch: 0360 Model_1_loss: 0.4964 Model_2_loss: 0.4738 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6687 Model_2_val:0.6678
Epoch: 0380 Model_1_loss: 0.4544 Model_2_loss: 0.4486 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6720 Model_2_val:0.6818
Epoch: 0400 Model_1_loss: 0.4341 Model_2_loss: 0.4397 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6590 Model_2_val:0.6622
Model_one_test:0.6922 Model_two_test:0.6906
added by two output: 0.6916
29
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
184132749
Epoch: 0020 Model_1_loss: 1.7443 Model_2_loss: 1.7415 Model_1_trainacc: 0.4833 Model_2_trainacc: 0.3500 Model_1_val:0.3133 Model_2_val:0.2558
Epoch: 0040 Model_1_loss: 1.6285 Model_2_loss: 1.5811 Model_1_trainacc: 0.6500 Model_2_trainacc: 0.7833 Model_1_val:0.4096 Model_2_val:0.4571
Epoch: 0060 Model_1_loss: 1.3806 Model_2_loss: 1.3545 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8167 Model_1_val:0.5126 Model_2_val:0.5010
Epoch: 0080 Model_1_loss: 1.1201 Model_2_loss: 0.9797 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9000 Model_1_val:0.5326 Model_2_val:0.5518
Epoch: 0100 Model_1_loss: 0.9331 Model_2_loss: 0.7962 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9583 Model_1_val:0.5718 Model_2_val:0.5711
Epoch: 0120 Model_1_loss: 0.7440 Model_2_loss: 0.6524 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.5631 Model_2_val:0.5801
Epoch: 0140 Model_1_loss: 0.6539 Model_2_loss: 0.5757 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9417 Model_1_val:0.5857 Model_2_val:0.5997
Epoch: 0160 Model_1_loss: 0.4951 Model_2_loss: 0.4711 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5864 Model_2_val:0.5904
Epoch: 0180 Model_1_loss: 0.4897 Model_2_loss: 0.4803 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5834 Model_2_val:0.6116
Epoch: 0200 Model_1_loss: 0.4624 Model_2_loss: 0.3895 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.6150 Model_2_val:0.6269
Epoch: 0220 Model_1_loss: 0.8060 Model_2_loss: 0.7347 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.6571 Model_2_val:0.6625
Epoch: 0240 Model_1_loss: 0.7406 Model_2_loss: 0.7135 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6611 Model_2_val:0.6595
Epoch: 0260 Model_1_loss: 0.6634 Model_2_loss: 0.6185 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6741 Model_2_val:0.6708
Epoch: 0280 Model_1_loss: 0.6734 Model_2_loss: 0.6100 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6651 Model_2_val:0.6761
Epoch: 0300 Model_1_loss: 0.6091 Model_2_loss: 0.5872 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6741 Model_2_val:0.6744
Epoch: 0320 Model_1_loss: 0.6430 Model_2_loss: 0.5792 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.6581 Model_2_val:0.6698
Epoch: 0340 Model_1_loss: 0.5355 Model_2_loss: 0.5006 Model_1_trainacc: 0.9583 Model_2_trainacc: 1.0000 Model_1_val:0.6651 Model_2_val:0.6651
Epoch: 0360 Model_1_loss: 0.5666 Model_2_loss: 0.5100 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6731 Model_2_val:0.6748
Epoch: 0380 Model_1_loss: 0.5150 Model_2_loss: 0.4910 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6625 Model_2_val:0.6718
Epoch: 0400 Model_1_loss: 0.4550 Model_2_loss: 0.5028 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6664 Model_2_val:0.6618
Model_one_test:0.6887 Model_two_test:0.6944
added by two output: 0.6914
30
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
979129457
Epoch: 0020 Model_1_loss: 1.6861 Model_2_loss: 1.7087 Model_1_trainacc: 0.6083 Model_2_trainacc: 0.4167 Model_1_val:0.2847 Model_2_val:0.2811
Epoch: 0040 Model_1_loss: 1.4562 Model_2_loss: 1.5492 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.7917 Model_1_val:0.4603 Model_2_val:0.4352
Epoch: 0060 Model_1_loss: 1.1062 Model_2_loss: 1.2927 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8500 Model_1_val:0.5199 Model_2_val:0.5020
Epoch: 0080 Model_1_loss: 0.8498 Model_2_loss: 0.9953 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9167 Model_1_val:0.5577 Model_2_val:0.5358
Epoch: 0100 Model_1_loss: 0.6723 Model_2_loss: 0.7884 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5599 Model_2_val:0.5544
Epoch: 0120 Model_1_loss: 0.5722 Model_2_loss: 0.6868 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5674 Model_2_val:0.5573
Epoch: 0140 Model_1_loss: 0.5055 Model_2_loss: 0.5670 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5883 Model_2_val:0.5687
Epoch: 0160 Model_1_loss: 0.4393 Model_2_loss: 0.5302 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.5902 Model_2_val:0.5736
Epoch: 0180 Model_1_loss: 0.3995 Model_2_loss: 0.4666 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9333 Model_1_val:0.5814 Model_2_val:0.5655
Epoch: 0200 Model_1_loss: 0.3507 Model_2_loss: 0.3938 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6121 Model_2_val:0.5834
Epoch: 0220 Model_1_loss: 0.6946 Model_2_loss: 0.7897 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6717 Model_2_val:0.6570
Epoch: 0240 Model_1_loss: 0.6129 Model_2_loss: 0.6868 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6642 Model_2_val:0.6638
Epoch: 0260 Model_1_loss: 0.5997 Model_2_loss: 0.6197 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6655 Model_2_val:0.6739
Epoch: 0280 Model_1_loss: 0.5845 Model_2_loss: 0.5918 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6635 Model_2_val:0.6606
Epoch: 0300 Model_1_loss: 0.5253 Model_2_loss: 0.5392 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6619 Model_2_val:0.6642
Epoch: 0320 Model_1_loss: 0.5164 Model_2_loss: 0.5185 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6580 Model_2_val:0.6567
Epoch: 0340 Model_1_loss: 0.5056 Model_2_loss: 0.5070 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6700 Model_2_val:0.6622
Epoch: 0360 Model_1_loss: 0.4847 Model_2_loss: 0.4815 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6671 Model_2_val:0.6664
Epoch: 0380 Model_1_loss: 0.4458 Model_2_loss: 0.4492 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6638 Model_2_val:0.6684
Epoch: 0400 Model_1_loss: 0.4468 Model_2_loss: 0.4446 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6648 Model_2_val:0.6651
Model_one_test:0.6827 Model_two_test:0.6795
added by two output: 0.6831
Model1 Acc: 0.697041 Model2 Acc: 0.696717
Maxacc Mean: 0.698166
[0.6924372651610259, 0.6927043179398544, 0.6923088360447857, 0.6922086163222224, 0.691536895183715, 0.6943443442678022, 0.6918293560174433, 0.6981663724760395]
Maxacc of all experiments: 0.6981663724760395
1
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
774133350
Epoch: 0020 Model_1_loss: 1.6977 Model_2_loss: 1.7342 Model_1_trainacc: 0.4750 Model_2_trainacc: 0.3250 Model_1_val:0.2481 Model_2_val:0.2656
Epoch: 0040 Model_1_loss: 1.4604 Model_2_loss: 1.5413 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.6667 Model_1_val:0.3954 Model_2_val:0.3437
Epoch: 0060 Model_1_loss: 1.0992 Model_2_loss: 1.2499 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8250 Model_1_val:0.4890 Model_2_val:0.4444
Epoch: 0080 Model_1_loss: 0.8342 Model_2_loss: 0.9949 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8833 Model_1_val:0.5441 Model_2_val:0.5015
Epoch: 0100 Model_1_loss: 0.6528 Model_2_loss: 0.7428 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5813 Model_2_val:0.5434
Epoch: 0120 Model_1_loss: 0.6059 Model_2_loss: 0.6285 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9250 Model_1_val:0.5860 Model_2_val:0.5482
Epoch: 0140 Model_1_loss: 0.4890 Model_2_loss: 0.5559 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.5694 Model_2_val:0.5684
Epoch: 0160 Model_1_loss: 0.4618 Model_2_loss: 0.4638 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.5813 Model_2_val:0.5647
Epoch: 0180 Model_1_loss: 0.4025 Model_2_loss: 0.4050 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6029 Model_2_val:0.5759
Epoch: 0200 Model_1_loss: 0.3325 Model_2_loss: 0.4052 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6012 Model_2_val:0.5951
Epoch: 0220 Model_1_loss: 0.6653 Model_2_loss: 0.6862 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6563 Model_2_val:0.6570
Epoch: 0240 Model_1_loss: 0.6595 Model_2_loss: 0.6456 Model_1_trainacc: 0.9583 Model_2_trainacc: 1.0000 Model_1_val:0.6597 Model_2_val:0.6641
Epoch: 0260 Model_1_loss: 0.5808 Model_2_loss: 0.5650 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6641 Model_2_val:0.6637
Epoch: 0280 Model_1_loss: 0.5396 Model_2_loss: 0.4898 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6664 Model_2_val:0.6671
Epoch: 0300 Model_1_loss: 0.4982 Model_2_loss: 0.5374 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6702 Model_2_val:0.6607
Epoch: 0320 Model_1_loss: 0.4614 Model_2_loss: 0.4701 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6708 Model_2_val:0.6664
Epoch: 0340 Model_1_loss: 0.4283 Model_2_loss: 0.4680 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6732 Model_2_val:0.6681
Epoch: 0360 Model_1_loss: 0.4270 Model_2_loss: 0.4349 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6806 Model_2_val:0.6617
Epoch: 0380 Model_1_loss: 0.4520 Model_2_loss: 0.4032 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6776 Model_2_val:0.6688
Epoch: 0400 Model_1_loss: 0.4364 Model_2_loss: 0.4122 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6810 Model_2_val:0.6695
Model_one_test:0.6904 Model_two_test:0.6891
added by two output: 0.6931
2
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1054389153
Epoch: 0020 Model_1_loss: 1.7329 Model_2_loss: 1.6582 Model_1_trainacc: 0.2667 Model_2_trainacc: 0.6417 Model_1_val:0.2276 Model_2_val:0.3202
Epoch: 0040 Model_1_loss: 1.4760 Model_2_loss: 1.4442 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.7500 Model_1_val:0.3880 Model_2_val:0.4265
Epoch: 0060 Model_1_loss: 1.1646 Model_2_loss: 1.1059 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9333 Model_1_val:0.4790 Model_2_val:0.5035
Epoch: 0080 Model_1_loss: 0.8627 Model_2_loss: 0.8483 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8833 Model_1_val:0.5411 Model_2_val:0.5477
Epoch: 0100 Model_1_loss: 0.6914 Model_2_loss: 0.6376 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5608 Model_2_val:0.5738
Epoch: 0120 Model_1_loss: 0.5470 Model_2_loss: 0.5386 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.5777 Model_2_val:0.5894
Epoch: 0140 Model_1_loss: 0.5248 Model_2_loss: 0.4924 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5917 Model_2_val:0.5933
Epoch: 0160 Model_1_loss: 0.4391 Model_2_loss: 0.4433 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6012 Model_2_val:0.6108
Epoch: 0180 Model_1_loss: 0.3947 Model_2_loss: 0.4170 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5888 Model_2_val:0.6060
Epoch: 0200 Model_1_loss: 0.3548 Model_2_loss: 0.3895 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.5983 Model_2_val:0.6232
Epoch: 0220 Model_1_loss: 0.6781 Model_2_loss: 0.6776 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6824 Model_2_val:0.6731
Epoch: 0240 Model_1_loss: 0.6180 Model_2_loss: 0.6269 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6875 Model_2_val:0.6779
Epoch: 0260 Model_1_loss: 0.5860 Model_2_loss: 0.5299 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6725 Model_2_val:0.6817
Epoch: 0280 Model_1_loss: 0.5057 Model_2_loss: 0.6109 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6776 Model_2_val:0.6824
Epoch: 0300 Model_1_loss: 0.5272 Model_2_loss: 0.5007 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6766 Model_2_val:0.6728
Epoch: 0320 Model_1_loss: 0.5030 Model_2_loss: 0.4872 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6827 Model_2_val:0.6843
Epoch: 0340 Model_1_loss: 0.4813 Model_2_loss: 0.4842 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6792 Model_2_val:0.6719
Epoch: 0360 Model_1_loss: 0.4626 Model_2_loss: 0.4272 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6811 Model_2_val:0.6636
Epoch: 0380 Model_1_loss: 0.4969 Model_2_loss: 0.4729 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6652 Model_2_val:0.6750
Epoch: 0400 Model_1_loss: 0.4476 Model_2_loss: 0.5055 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9500 Model_1_val:0.6817 Model_2_val:0.6712
Model_one_test:0.6992 Model_two_test:0.6996
added by two output: 0.7018
3
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
584816883
Epoch: 0020 Model_1_loss: 1.7316 Model_2_loss: 1.7155 Model_1_trainacc: 0.3917 Model_2_trainacc: 0.5250 Model_1_val:0.2779 Model_2_val:0.3589
Epoch: 0040 Model_1_loss: 1.5362 Model_2_loss: 1.5158 Model_1_trainacc: 0.7250 Model_2_trainacc: 0.6917 Model_1_val:0.4551 Model_2_val:0.4127
Epoch: 0060 Model_1_loss: 1.2130 Model_2_loss: 1.2325 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8500 Model_1_val:0.5177 Model_2_val:0.4976
Epoch: 0080 Model_1_loss: 0.9205 Model_2_loss: 0.9158 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.5640 Model_2_val:0.5397
Epoch: 0100 Model_1_loss: 0.7350 Model_2_loss: 0.7189 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9167 Model_1_val:0.5743 Model_2_val:0.5591
Epoch: 0120 Model_1_loss: 0.6591 Model_2_loss: 0.5902 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9833 Model_1_val:0.5844 Model_2_val:0.5679
Epoch: 0140 Model_1_loss: 0.5338 Model_2_loss: 0.5762 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5944 Model_2_val:0.6009
Epoch: 0160 Model_1_loss: 0.4816 Model_2_loss: 0.4964 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5867 Model_2_val:0.5996
Epoch: 0180 Model_1_loss: 0.4417 Model_2_loss: 0.4183 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5970 Model_2_val:0.5831
Epoch: 0200 Model_1_loss: 0.4127 Model_2_loss: 0.4461 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6041 Model_2_val:0.5973
Epoch: 0220 Model_1_loss: 0.7239 Model_2_loss: 0.7430 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6589 Model_2_val:0.6638
Epoch: 0240 Model_1_loss: 0.6790 Model_2_loss: 0.6598 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6582 Model_2_val:0.6667
Epoch: 0260 Model_1_loss: 0.6419 Model_2_loss: 0.6280 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6599 Model_2_val:0.6638
Epoch: 0280 Model_1_loss: 0.5694 Model_2_loss: 0.5564 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6628 Model_2_val:0.6634
Epoch: 0300 Model_1_loss: 0.5483 Model_2_loss: 0.5576 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6566 Model_2_val:0.6667
Epoch: 0320 Model_1_loss: 0.4549 Model_2_loss: 0.5168 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6770 Model_2_val:0.6673
Epoch: 0340 Model_1_loss: 0.4956 Model_2_loss: 0.4779 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6715 Model_2_val:0.6725
Epoch: 0360 Model_1_loss: 0.4697 Model_2_loss: 0.4770 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6715 Model_2_val:0.6670
Epoch: 0380 Model_1_loss: 0.4728 Model_2_loss: 0.4417 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6718 Model_2_val:0.6731
Epoch: 0400 Model_1_loss: 0.4349 Model_2_loss: 0.4551 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6770 Model_2_val:0.6686
Model_one_test:0.6961 Model_two_test:0.6958
added by two output: 0.6968
4
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
289746958
Epoch: 0020 Model_1_loss: 1.7212 Model_2_loss: 1.7630 Model_1_trainacc: 0.2750 Model_2_trainacc: 0.3167 Model_1_val:0.2018 Model_2_val:0.2066
Epoch: 0040 Model_1_loss: 1.5574 Model_2_loss: 1.6557 Model_1_trainacc: 0.6250 Model_2_trainacc: 0.5417 Model_1_val:0.3532 Model_2_val:0.2676
Epoch: 0060 Model_1_loss: 1.2524 Model_2_loss: 1.4539 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.7083 Model_1_val:0.4502 Model_2_val:0.3990
Epoch: 0080 Model_1_loss: 0.9922 Model_2_loss: 1.1535 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8250 Model_1_val:0.5092 Model_2_val:0.4755
Epoch: 0100 Model_1_loss: 0.7924 Model_2_loss: 0.8951 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8917 Model_1_val:0.5608 Model_2_val:0.5375
Epoch: 0120 Model_1_loss: 0.6097 Model_2_loss: 0.7362 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.8917 Model_1_val:0.5397 Model_2_val:0.5517
Epoch: 0140 Model_1_loss: 0.5705 Model_2_loss: 0.6102 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.5641 Model_2_val:0.5608
Epoch: 0160 Model_1_loss: 0.4731 Model_2_loss: 0.5749 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9167 Model_1_val:0.5851 Model_2_val:0.5686
Epoch: 0180 Model_1_loss: 0.4801 Model_2_loss: 0.5442 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.5868 Model_2_val:0.5728
Epoch: 0200 Model_1_loss: 0.4029 Model_2_loss: 0.4312 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.5689 Model_2_val:0.5838
Epoch: 0220 Model_1_loss: 0.7286 Model_2_loss: 0.7599 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6393 Model_2_val:0.6448
Epoch: 0240 Model_1_loss: 0.7533 Model_2_loss: 0.7104 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6604 Model_2_val:0.6374
Epoch: 0260 Model_1_loss: 0.6512 Model_2_loss: 0.6797 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6536 Model_2_val:0.6403
Epoch: 0280 Model_1_loss: 0.6256 Model_2_loss: 0.6203 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6607 Model_2_val:0.6546
Epoch: 0300 Model_1_loss: 0.5900 Model_2_loss: 0.5778 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6630 Model_2_val:0.6539
Epoch: 0320 Model_1_loss: 0.5650 Model_2_loss: 0.5926 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6529 Model_2_val:0.6552
Epoch: 0340 Model_1_loss: 0.5685 Model_2_loss: 0.5348 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6520 Model_2_val:0.6471
Epoch: 0360 Model_1_loss: 0.5345 Model_2_loss: 0.5579 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6477 Model_2_val:0.6422
Epoch: 0380 Model_1_loss: 0.4801 Model_2_loss: 0.5046 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6562 Model_2_val:0.6468
Epoch: 0400 Model_1_loss: 0.5132 Model_2_loss: 0.5291 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6533 Model_2_val:0.6507
Model_one_test:0.6792 Model_two_test:0.6769
added by two output: 0.6782
5
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
333952181
Epoch: 0020 Model_1_loss: 1.6943 Model_2_loss: 1.7136 Model_1_trainacc: 0.4417 Model_2_trainacc: 0.4833 Model_1_val:0.2826 Model_2_val:0.2944
Epoch: 0040 Model_1_loss: 1.4583 Model_2_loss: 1.5222 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.6917 Model_1_val:0.4224 Model_2_val:0.4233
Epoch: 0060 Model_1_loss: 1.1364 Model_2_loss: 1.1952 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8417 Model_1_val:0.4962 Model_2_val:0.5130
Epoch: 0080 Model_1_loss: 0.8305 Model_2_loss: 0.8838 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.5532 Model_2_val:0.5447
Epoch: 0100 Model_1_loss: 0.6640 Model_2_loss: 0.7245 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9417 Model_1_val:0.5668 Model_2_val:0.5651
Epoch: 0120 Model_1_loss: 0.5353 Model_2_loss: 0.6174 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9250 Model_1_val:0.5783 Model_2_val:0.5889
Epoch: 0140 Model_1_loss: 0.4867 Model_2_loss: 0.5305 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.5915 Model_2_val:0.5813
Epoch: 0160 Model_1_loss: 0.4510 Model_2_loss: 0.4680 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9250 Model_1_val:0.5833 Model_2_val:0.5833
Epoch: 0180 Model_1_loss: 0.3796 Model_2_loss: 0.4682 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9417 Model_1_val:0.5829 Model_2_val:0.6109
Epoch: 0200 Model_1_loss: 0.3734 Model_2_loss: 0.3775 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9833 Model_1_val:0.6027 Model_2_val:0.5948
Epoch: 0220 Model_1_loss: 0.7141 Model_2_loss: 0.6681 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6660 Model_2_val:0.6584
Epoch: 0240 Model_1_loss: 0.6018 Model_2_loss: 0.6483 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6713 Model_2_val:0.6706
Epoch: 0260 Model_1_loss: 0.6146 Model_2_loss: 0.5623 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6683 Model_2_val:0.6637
Epoch: 0280 Model_1_loss: 0.5503 Model_2_loss: 0.6008 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6713 Model_2_val:0.6766
Epoch: 0300 Model_1_loss: 0.5041 Model_2_loss: 0.5280 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6607 Model_2_val:0.6670
Epoch: 0320 Model_1_loss: 0.4922 Model_2_loss: 0.5104 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6667 Model_2_val:0.6775
Epoch: 0340 Model_1_loss: 0.5138 Model_2_loss: 0.4953 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6729 Model_2_val:0.6719
Epoch: 0360 Model_1_loss: 0.4971 Model_2_loss: 0.4808 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6670 Model_2_val:0.6627
Epoch: 0380 Model_1_loss: 0.4585 Model_2_loss: 0.5083 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6733 Model_2_val:0.6759
Epoch: 0400 Model_1_loss: 0.4261 Model_2_loss: 0.4614 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6604 Model_2_val:0.6733
Model_one_test:0.6904 Model_two_test:0.6937
added by two output: 0.6907
6
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1175001414
Epoch: 0020 Model_1_loss: 1.7203 Model_2_loss: 1.7295 Model_1_trainacc: 0.3583 Model_2_trainacc: 0.3250 Model_1_val:0.2711 Model_2_val:0.2020
Epoch: 0040 Model_1_loss: 1.5871 Model_2_loss: 1.5321 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.7667 Model_1_val:0.3469 Model_2_val:0.4003
Epoch: 0060 Model_1_loss: 1.3503 Model_2_loss: 1.2803 Model_1_trainacc: 0.7250 Model_2_trainacc: 0.8250 Model_1_val:0.4170 Model_2_val:0.4854
Epoch: 0080 Model_1_loss: 1.0685 Model_2_loss: 0.9296 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.8667 Model_1_val:0.4820 Model_2_val:0.5272
Epoch: 0100 Model_1_loss: 0.8344 Model_2_loss: 0.7457 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9333 Model_1_val:0.5364 Model_2_val:0.5653
Epoch: 0120 Model_1_loss: 0.7177 Model_2_loss: 0.5898 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9333 Model_1_val:0.5473 Model_2_val:0.5908
Epoch: 0140 Model_1_loss: 0.6190 Model_2_loss: 0.5805 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9250 Model_1_val:0.5765 Model_2_val:0.5721
Epoch: 0160 Model_1_loss: 0.5103 Model_2_loss: 0.5022 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5731 Model_2_val:0.6007
Epoch: 0180 Model_1_loss: 0.5381 Model_2_loss: 0.4447 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5861 Model_2_val:0.5942
Epoch: 0200 Model_1_loss: 0.4553 Model_2_loss: 0.4326 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5779 Model_2_val:0.6010
Epoch: 0220 Model_1_loss: 0.7275 Model_2_loss: 0.7294 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6435 Model_2_val:0.6500
Epoch: 0240 Model_1_loss: 0.6631 Model_2_loss: 0.7103 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6612 Model_2_val:0.6633
Epoch: 0260 Model_1_loss: 0.6914 Model_2_loss: 0.6613 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6531 Model_2_val:0.6619
Epoch: 0280 Model_1_loss: 0.6045 Model_2_loss: 0.6174 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6510 Model_2_val:0.6561
Epoch: 0300 Model_1_loss: 0.5757 Model_2_loss: 0.5652 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6541 Model_2_val:0.6622
Epoch: 0320 Model_1_loss: 0.5130 Model_2_loss: 0.5610 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6554 Model_2_val:0.6639
Epoch: 0340 Model_1_loss: 0.4903 Model_2_loss: 0.5229 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6670 Model_2_val:0.6592
Epoch: 0360 Model_1_loss: 0.4830 Model_2_loss: 0.4766 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6582 Model_2_val:0.6721
Epoch: 0380 Model_1_loss: 0.4758 Model_2_loss: 0.4983 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6616 Model_2_val:0.6575
Epoch: 0400 Model_1_loss: 0.4026 Model_2_loss: 0.4410 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6612 Model_2_val:0.6568
Model_one_test:0.6867 Model_two_test:0.6884
added by two output: 0.6861
7
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
693635873
Epoch: 0020 Model_1_loss: 1.6868 Model_2_loss: 1.6942 Model_1_trainacc: 0.5917 Model_2_trainacc: 0.5500 Model_1_val:0.3309 Model_2_val:0.3157
Epoch: 0040 Model_1_loss: 1.4344 Model_2_loss: 1.4177 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.7583 Model_1_val:0.4883 Model_2_val:0.4321
Epoch: 0060 Model_1_loss: 1.0652 Model_2_loss: 1.1006 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9167 Model_1_val:0.5230 Model_2_val:0.5038
Epoch: 0080 Model_1_loss: 0.7732 Model_2_loss: 0.8490 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.8750 Model_1_val:0.5511 Model_2_val:0.5504
Epoch: 0100 Model_1_loss: 0.6376 Model_2_loss: 0.6447 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9083 Model_1_val:0.5739 Model_2_val:0.5418
Epoch: 0120 Model_1_loss: 0.5058 Model_2_loss: 0.5590 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.5772 Model_2_val:0.5782
Epoch: 0140 Model_1_loss: 0.4513 Model_2_loss: 0.4833 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.5745 Model_2_val:0.5782
Epoch: 0160 Model_1_loss: 0.4187 Model_2_loss: 0.4536 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.5884 Model_2_val:0.5848
Epoch: 0180 Model_1_loss: 0.3693 Model_2_loss: 0.3936 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.5927 Model_2_val:0.6013
Epoch: 0200 Model_1_loss: 0.3728 Model_2_loss: 0.3567 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.5821 Model_2_val:0.5987
Epoch: 0220 Model_1_loss: 0.6549 Model_2_loss: 0.6725 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6483 Model_2_val:0.6509
Epoch: 0240 Model_1_loss: 0.6291 Model_2_loss: 0.6071 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6565 Model_2_val:0.6572
Epoch: 0260 Model_1_loss: 0.5927 Model_2_loss: 0.5555 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6704 Model_2_val:0.6579
Epoch: 0280 Model_1_loss: 0.5328 Model_2_loss: 0.5186 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6598 Model_2_val:0.6757
Epoch: 0300 Model_1_loss: 0.5270 Model_2_loss: 0.5144 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6668 Model_2_val:0.6731
Epoch: 0320 Model_1_loss: 0.5101 Model_2_loss: 0.4894 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6671 Model_2_val:0.6750
Epoch: 0340 Model_1_loss: 0.5046 Model_2_loss: 0.4490 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6664 Model_2_val:0.6698
Epoch: 0360 Model_1_loss: 0.4943 Model_2_loss: 0.4355 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6608 Model_2_val:0.6740
Epoch: 0380 Model_1_loss: 0.4642 Model_2_loss: 0.4765 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6678 Model_2_val:0.6681
Epoch: 0400 Model_1_loss: 0.4290 Model_2_loss: 0.4103 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6615 Model_2_val:0.6764
Model_one_test:0.6926 Model_two_test:0.6975
added by two output: 0.6979
8
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
456829983
Epoch: 0020 Model_1_loss: 1.7196 Model_2_loss: 1.7384 Model_1_trainacc: 0.5250 Model_2_trainacc: 0.4250 Model_1_val:0.2700 Model_2_val:0.2541
Epoch: 0040 Model_1_loss: 1.5344 Model_2_loss: 1.5688 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.6667 Model_1_val:0.4148 Model_2_val:0.4102
Epoch: 0060 Model_1_loss: 1.1759 Model_2_loss: 1.3005 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8750 Model_1_val:0.5035 Model_2_val:0.4895
Epoch: 0080 Model_1_loss: 0.8649 Model_2_loss: 0.9894 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8833 Model_1_val:0.5410 Model_2_val:0.5340
Epoch: 0100 Model_1_loss: 0.6621 Model_2_loss: 0.7860 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5822 Model_2_val:0.5457
Epoch: 0120 Model_1_loss: 0.5794 Model_2_loss: 0.6524 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9333 Model_1_val:0.5912 Model_2_val:0.5673
Epoch: 0140 Model_1_loss: 0.4930 Model_2_loss: 0.5851 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.5935 Model_2_val:0.5759
Epoch: 0160 Model_1_loss: 0.4348 Model_2_loss: 0.5249 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.5942 Model_2_val:0.5782
Epoch: 0180 Model_1_loss: 0.3733 Model_2_loss: 0.4158 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6174 Model_2_val:0.5912
Epoch: 0200 Model_1_loss: 0.3956 Model_2_loss: 0.4211 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6081 Model_2_val:0.6048
Epoch: 0220 Model_1_loss: 0.7142 Model_2_loss: 0.7660 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6639 Model_2_val:0.6583
Epoch: 0240 Model_1_loss: 0.6740 Model_2_loss: 0.6938 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6682 Model_2_val:0.6642
Epoch: 0260 Model_1_loss: 0.6348 Model_2_loss: 0.6643 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6662 Model_2_val:0.6596
Epoch: 0280 Model_1_loss: 0.5895 Model_2_loss: 0.6800 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6782 Model_2_val:0.6539
Epoch: 0300 Model_1_loss: 0.5353 Model_2_loss: 0.5496 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6685 Model_2_val:0.6573
Epoch: 0320 Model_1_loss: 0.4821 Model_2_loss: 0.5754 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6769 Model_2_val:0.6682
Epoch: 0340 Model_1_loss: 0.4773 Model_2_loss: 0.5329 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6715 Model_2_val:0.6699
Epoch: 0360 Model_1_loss: 0.4858 Model_2_loss: 0.5040 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6742 Model_2_val:0.6619
Epoch: 0380 Model_1_loss: 0.4765 Model_2_loss: 0.5268 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6732 Model_2_val:0.6715
Epoch: 0400 Model_1_loss: 0.4359 Model_2_loss: 0.4786 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6749 Model_2_val:0.6695
Model_one_test:0.6951 Model_two_test:0.6951
added by two output: 0.6978
9
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1217584148
Epoch: 0020 Model_1_loss: 1.6887 Model_2_loss: 1.6850 Model_1_trainacc: 0.5500 Model_2_trainacc: 0.5250 Model_1_val:0.3070 Model_2_val:0.3390
Epoch: 0040 Model_1_loss: 1.4673 Model_2_loss: 1.4427 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8250 Model_1_val:0.4492 Model_2_val:0.5036
Epoch: 0060 Model_1_loss: 1.1394 Model_2_loss: 1.1031 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8917 Model_1_val:0.5225 Model_2_val:0.5290
Epoch: 0080 Model_1_loss: 0.8422 Model_2_loss: 0.8544 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9333 Model_1_val:0.5554 Model_2_val:0.5561
Epoch: 0100 Model_1_loss: 0.7103 Model_2_loss: 0.6663 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9250 Model_1_val:0.5877 Model_2_val:0.6017
Epoch: 0120 Model_1_loss: 0.5865 Model_2_loss: 0.5526 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5684 Model_2_val:0.6082
Epoch: 0140 Model_1_loss: 0.5255 Model_2_loss: 0.4405 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.5900 Model_2_val:0.6030
Epoch: 0160 Model_1_loss: 0.4796 Model_2_loss: 0.4332 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6046 Model_2_val:0.6121
Epoch: 0180 Model_1_loss: 0.4176 Model_2_loss: 0.4289 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9333 Model_1_val:0.6017 Model_2_val:0.6314
Epoch: 0200 Model_1_loss: 0.3877 Model_2_loss: 0.3289 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6151 Model_2_val:0.6235
Epoch: 0220 Model_1_loss: 0.6951 Model_2_loss: 0.6895 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6662 Model_2_val:0.6809
Epoch: 0240 Model_1_loss: 0.6537 Model_2_loss: 0.6708 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6744 Model_2_val:0.6757
Epoch: 0260 Model_1_loss: 0.6537 Model_2_loss: 0.5690 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6845 Model_2_val:0.6776
Epoch: 0280 Model_1_loss: 0.5787 Model_2_loss: 0.5433 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6770 Model_2_val:0.6728
Epoch: 0300 Model_1_loss: 0.6365 Model_2_loss: 0.5651 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6796 Model_2_val:0.6780
Epoch: 0320 Model_1_loss: 0.5171 Model_2_loss: 0.5054 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6708 Model_2_val:0.6718
Epoch: 0340 Model_1_loss: 0.5266 Model_2_loss: 0.4953 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6760 Model_2_val:0.6747
Epoch: 0360 Model_1_loss: 0.4783 Model_2_loss: 0.5004 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6832 Model_2_val:0.6721
Epoch: 0380 Model_1_loss: 0.4934 Model_2_loss: 0.4682 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6897 Model_2_val:0.6799
Epoch: 0400 Model_1_loss: 0.4828 Model_2_loss: 0.4477 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6877 Model_2_val:0.6747
Model_one_test:0.7050 Model_two_test:0.6998
added by two output: 0.7037
10
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1111938069
Epoch: 0020 Model_1_loss: 1.7337 Model_2_loss: 1.7134 Model_1_trainacc: 0.5083 Model_2_trainacc: 0.5250 Model_1_val:0.2847 Model_2_val:0.2791
Epoch: 0040 Model_1_loss: 1.5603 Model_2_loss: 1.5281 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8000 Model_1_val:0.4108 Model_2_val:0.4157
Epoch: 0060 Model_1_loss: 1.2772 Model_2_loss: 1.2230 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8750 Model_1_val:0.4520 Model_2_val:0.5094
Epoch: 0080 Model_1_loss: 0.9346 Model_2_loss: 0.9071 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.4962 Model_2_val:0.5249
Epoch: 0100 Model_1_loss: 0.7810 Model_2_loss: 0.7205 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9417 Model_1_val:0.5186 Model_2_val:0.5655
Epoch: 0120 Model_1_loss: 0.6105 Model_2_loss: 0.5780 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5655 Model_2_val:0.5642
Epoch: 0140 Model_1_loss: 0.4760 Model_2_loss: 0.5539 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9250 Model_1_val:0.5612 Model_2_val:0.5922
Epoch: 0160 Model_1_loss: 0.4436 Model_2_loss: 0.5225 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.5714 Model_2_val:0.5823
Epoch: 0180 Model_1_loss: 0.4284 Model_2_loss: 0.3985 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5817 Model_2_val:0.5793
Epoch: 0200 Model_1_loss: 0.3890 Model_2_loss: 0.3695 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.5906 Model_2_val:0.5949
Epoch: 0220 Model_1_loss: 0.6833 Model_2_loss: 0.6985 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6417 Model_2_val:0.6377
Epoch: 0240 Model_1_loss: 0.6470 Model_2_loss: 0.5902 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6437 Model_2_val:0.6549
Epoch: 0260 Model_1_loss: 0.5760 Model_2_loss: 0.5782 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6602 Model_2_val:0.6589
Epoch: 0280 Model_1_loss: 0.5813 Model_2_loss: 0.5514 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6440 Model_2_val:0.6486
Epoch: 0300 Model_1_loss: 0.5359 Model_2_loss: 0.5182 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6529 Model_2_val:0.6615
Epoch: 0320 Model_1_loss: 0.5431 Model_2_loss: 0.5171 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6605 Model_2_val:0.6552
Epoch: 0340 Model_1_loss: 0.4961 Model_2_loss: 0.5243 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6536 Model_2_val:0.6592
Epoch: 0360 Model_1_loss: 0.4715 Model_2_loss: 0.4262 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6608 Model_2_val:0.6526
Epoch: 0380 Model_1_loss: 0.5236 Model_2_loss: 0.4521 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6526 Model_2_val:0.6562
Epoch: 0400 Model_1_loss: 0.4664 Model_2_loss: 0.4407 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6559 Model_2_val:0.6546
Model_one_test:0.6843 Model_two_test:0.6823
added by two output: 0.6833
11
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
188905210
Epoch: 0020 Model_1_loss: 1.7545 Model_2_loss: 1.7252 Model_1_trainacc: 0.2667 Model_2_trainacc: 0.3750 Model_1_val:0.1559 Model_2_val:0.2327
Epoch: 0040 Model_1_loss: 1.6196 Model_2_loss: 1.5577 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.7583 Model_1_val:0.3264 Model_2_val:0.3562
Epoch: 0060 Model_1_loss: 1.3178 Model_2_loss: 1.2978 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.7917 Model_1_val:0.4502 Model_2_val:0.4541
Epoch: 0080 Model_1_loss: 1.0715 Model_2_loss: 0.9560 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8750 Model_1_val:0.5073 Model_2_val:0.4904
Epoch: 0100 Model_1_loss: 0.8246 Model_2_loss: 0.7639 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9250 Model_1_val:0.5138 Model_2_val:0.5232
Epoch: 0120 Model_1_loss: 0.6546 Model_2_loss: 0.5800 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.5478 Model_2_val:0.5400
Epoch: 0140 Model_1_loss: 0.5694 Model_2_loss: 0.5250 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5767 Model_2_val:0.5669
Epoch: 0160 Model_1_loss: 0.5194 Model_2_loss: 0.4887 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.5605 Model_2_val:0.5630
Epoch: 0180 Model_1_loss: 0.4404 Model_2_loss: 0.4417 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.5828 Model_2_val:0.5763
Epoch: 0200 Model_1_loss: 0.4458 Model_2_loss: 0.3908 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5802 Model_2_val:0.5588
Epoch: 0220 Model_1_loss: 0.7654 Model_2_loss: 0.7128 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6558 Model_2_val:0.6402
Epoch: 0240 Model_1_loss: 0.7589 Model_2_loss: 0.7080 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.6558 Model_2_val:0.6470
Epoch: 0260 Model_1_loss: 0.6656 Model_2_loss: 0.6455 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6554 Model_2_val:0.6525
Epoch: 0280 Model_1_loss: 0.6832 Model_2_loss: 0.5824 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9833 Model_1_val:0.6499 Model_2_val:0.6613
Epoch: 0300 Model_1_loss: 0.6167 Model_2_loss: 0.6226 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6603 Model_2_val:0.6609
Epoch: 0320 Model_1_loss: 0.5520 Model_2_loss: 0.5559 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6668 Model_2_val:0.6580
Epoch: 0340 Model_1_loss: 0.5888 Model_2_loss: 0.5423 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6609 Model_2_val:0.6613
Epoch: 0360 Model_1_loss: 0.5414 Model_2_loss: 0.5589 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6593 Model_2_val:0.6681
Epoch: 0380 Model_1_loss: 0.5491 Model_2_loss: 0.4789 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.6668 Model_2_val:0.6658
Epoch: 0400 Model_1_loss: 0.4487 Model_2_loss: 0.4902 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6697 Model_2_val:0.6677
Model_one_test:0.6878 Model_two_test:0.6878
added by two output: 0.6865
12
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
450487632
Epoch: 0020 Model_1_loss: 1.7427 Model_2_loss: 1.7223 Model_1_trainacc: 0.3500 Model_2_trainacc: 0.3417 Model_1_val:0.2335 Model_2_val:0.2828
Epoch: 0040 Model_1_loss: 1.5624 Model_2_loss: 1.5622 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.7250 Model_1_val:0.4442 Model_2_val:0.4297
Epoch: 0060 Model_1_loss: 1.2882 Model_2_loss: 1.2632 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8167 Model_1_val:0.5094 Model_2_val:0.4863
Epoch: 0080 Model_1_loss: 0.9685 Model_2_loss: 0.9880 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8917 Model_1_val:0.5479 Model_2_val:0.5528
Epoch: 0100 Model_1_loss: 0.7481 Model_2_loss: 0.8192 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8917 Model_1_val:0.5565 Model_2_val:0.5670
Epoch: 0120 Model_1_loss: 0.6271 Model_2_loss: 0.6689 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9083 Model_1_val:0.5841 Model_2_val:0.5808
Epoch: 0140 Model_1_loss: 0.5285 Model_2_loss: 0.5720 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5841 Model_2_val:0.5891
Epoch: 0160 Model_1_loss: 0.4992 Model_2_loss: 0.5349 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.5957 Model_2_val:0.6075
Epoch: 0180 Model_1_loss: 0.4439 Model_2_loss: 0.4786 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.6013 Model_2_val:0.5996
Epoch: 0200 Model_1_loss: 0.4153 Model_2_loss: 0.4317 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6121 Model_2_val:0.6019
Epoch: 0220 Model_1_loss: 0.7674 Model_2_loss: 0.7142 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6516 Model_2_val:0.6707
Epoch: 0240 Model_1_loss: 0.6632 Model_2_loss: 0.6826 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6516 Model_2_val:0.6645
Epoch: 0260 Model_1_loss: 0.6333 Model_2_loss: 0.5710 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6641 Model_2_val:0.6780
Epoch: 0280 Model_1_loss: 0.5928 Model_2_loss: 0.5605 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6773 Model_2_val:0.6638
Epoch: 0300 Model_1_loss: 0.5373 Model_2_loss: 0.5317 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6651 Model_2_val:0.6846
Epoch: 0320 Model_1_loss: 0.5554 Model_2_loss: 0.5015 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6711 Model_2_val:0.6760
Epoch: 0340 Model_1_loss: 0.5353 Model_2_loss: 0.4920 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6671 Model_2_val:0.6694
Epoch: 0360 Model_1_loss: 0.5284 Model_2_loss: 0.4950 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6622 Model_2_val:0.6776
Epoch: 0380 Model_1_loss: 0.4979 Model_2_loss: 0.4686 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6622 Model_2_val:0.6813
Epoch: 0400 Model_1_loss: 0.4580 Model_2_loss: 0.4817 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6697 Model_2_val:0.6694
Model_one_test:0.6882 Model_two_test:0.6902
added by two output: 0.6885
13
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1103610665
Epoch: 0020 Model_1_loss: 1.7333 Model_2_loss: 1.7010 Model_1_trainacc: 0.4833 Model_2_trainacc: 0.4583 Model_1_val:0.3069 Model_2_val:0.3136
Epoch: 0040 Model_1_loss: 1.5444 Model_2_loss: 1.4778 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8000 Model_1_val:0.4445 Model_2_val:0.4605
Epoch: 0060 Model_1_loss: 1.2425 Model_2_loss: 1.1465 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8917 Model_1_val:0.5104 Model_2_val:0.4912
Epoch: 0080 Model_1_loss: 1.0102 Model_2_loss: 0.8846 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8833 Model_1_val:0.5293 Model_2_val:0.5405
Epoch: 0100 Model_1_loss: 0.8013 Model_2_loss: 0.6782 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9167 Model_1_val:0.5389 Model_2_val:0.5501
Epoch: 0120 Model_1_loss: 0.6566 Model_2_loss: 0.6234 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9583 Model_1_val:0.5478 Model_2_val:0.5725
Epoch: 0140 Model_1_loss: 0.5729 Model_2_loss: 0.5287 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9417 Model_1_val:0.5587 Model_2_val:0.5549
Epoch: 0160 Model_1_loss: 0.4632 Model_2_loss: 0.4757 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.5690 Model_2_val:0.5693
Epoch: 0180 Model_1_loss: 0.4769 Model_2_loss: 0.4635 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5606 Model_2_val:0.5750
Epoch: 0200 Model_1_loss: 0.4319 Model_2_loss: 0.3454 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5699 Model_2_val:0.5866
Epoch: 0220 Model_1_loss: 0.7918 Model_2_loss: 0.7344 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6240 Model_2_val:0.6352
Epoch: 0240 Model_1_loss: 0.6952 Model_2_loss: 0.7025 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6410 Model_2_val:0.6550
Epoch: 0260 Model_1_loss: 0.6798 Model_2_loss: 0.6545 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6355 Model_2_val:0.6467
Epoch: 0280 Model_1_loss: 0.7048 Model_2_loss: 0.6475 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.6371 Model_2_val:0.6550
Epoch: 0300 Model_1_loss: 0.6177 Model_2_loss: 0.6024 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6422 Model_2_val:0.6518
Epoch: 0320 Model_1_loss: 0.6341 Model_2_loss: 0.5525 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6547 Model_2_val:0.6560
Epoch: 0340 Model_1_loss: 0.6327 Model_2_loss: 0.5293 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6397 Model_2_val:0.6474
Epoch: 0360 Model_1_loss: 0.5596 Model_2_loss: 0.5535 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6448 Model_2_val:0.6499
Epoch: 0380 Model_1_loss: 0.5326 Model_2_loss: 0.5260 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9333 Model_1_val:0.6653 Model_2_val:0.6515
Epoch: 0400 Model_1_loss: 0.5516 Model_2_loss: 0.5224 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6589 Model_2_val:0.6458
Model_one_test:0.6499 Model_two_test:0.6752
added by two output: 0.6758
14
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
119062291
Epoch: 0020 Model_1_loss: 1.7108 Model_2_loss: 1.7350 Model_1_trainacc: 0.4000 Model_2_trainacc: 0.3333 Model_1_val:0.3133 Model_2_val:0.2039
Epoch: 0040 Model_1_loss: 1.4762 Model_2_loss: 1.5833 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.6917 Model_1_val:0.4464 Model_2_val:0.3655
Epoch: 0060 Model_1_loss: 1.1820 Model_2_loss: 1.3164 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8333 Model_1_val:0.5215 Model_2_val:0.4923
Epoch: 0080 Model_1_loss: 0.8717 Model_2_loss: 1.0697 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8333 Model_1_val:0.5703 Model_2_val:0.5333
Epoch: 0100 Model_1_loss: 0.7166 Model_2_loss: 0.8659 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8833 Model_1_val:0.5739 Model_2_val:0.5624
Epoch: 0120 Model_1_loss: 0.5696 Model_2_loss: 0.7385 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9000 Model_1_val:0.5814 Model_2_val:0.5719
Epoch: 0140 Model_1_loss: 0.4996 Model_2_loss: 0.6151 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.6067 Model_2_val:0.5765
Epoch: 0160 Model_1_loss: 0.4827 Model_2_loss: 0.5151 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6175 Model_2_val:0.5903
Epoch: 0180 Model_1_loss: 0.4323 Model_2_loss: 0.4577 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.6080 Model_2_val:0.6070
Epoch: 0200 Model_1_loss: 0.3546 Model_2_loss: 0.4788 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6168 Model_2_val:0.6070
Epoch: 0220 Model_1_loss: 0.7506 Model_2_loss: 0.7211 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6614 Model_2_val:0.6650
Epoch: 0240 Model_1_loss: 0.6005 Model_2_loss: 0.6506 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6837 Model_2_val:0.6644
Epoch: 0260 Model_1_loss: 0.5782 Model_2_loss: 0.5931 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6719 Model_2_val:0.6608
Epoch: 0280 Model_1_loss: 0.5398 Model_2_loss: 0.5301 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6647 Model_2_val:0.6670
Epoch: 0300 Model_1_loss: 0.5475 Model_2_loss: 0.5392 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6660 Model_2_val:0.6726
Epoch: 0320 Model_1_loss: 0.5527 Model_2_loss: 0.5138 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6726 Model_2_val:0.6644
Epoch: 0340 Model_1_loss: 0.4710 Model_2_loss: 0.4976 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6713 Model_2_val:0.6644
Epoch: 0360 Model_1_loss: 0.5068 Model_2_loss: 0.4642 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6719 Model_2_val:0.6735
Epoch: 0380 Model_1_loss: 0.4468 Model_2_loss: 0.4698 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6654 Model_2_val:0.6732
Epoch: 0400 Model_1_loss: 0.4483 Model_2_loss: 0.4908 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6801 Model_2_val:0.6703
Model_one_test:0.6926 Model_two_test:0.6883
added by two output: 0.6893
15
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1405447923
Epoch: 0020 Model_1_loss: 1.7251 Model_2_loss: 1.7353 Model_1_trainacc: 0.3917 Model_2_trainacc: 0.4667 Model_1_val:0.2756 Model_2_val:0.2816
Epoch: 0040 Model_1_loss: 1.5739 Model_2_loss: 1.5400 Model_1_trainacc: 0.7583 Model_2_trainacc: 0.7667 Model_1_val:0.4106 Model_2_val:0.4279
Epoch: 0060 Model_1_loss: 1.3128 Model_2_loss: 1.2320 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8417 Model_1_val:0.4939 Model_2_val:0.4849
Epoch: 0080 Model_1_loss: 1.0445 Model_2_loss: 0.9263 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8833 Model_1_val:0.5350 Model_2_val:0.5390
Epoch: 0100 Model_1_loss: 0.8020 Model_2_loss: 0.7447 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.5536 Model_2_val:0.5423
Epoch: 0120 Model_1_loss: 0.6689 Model_2_loss: 0.5776 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.5688 Model_2_val:0.5648
Epoch: 0140 Model_1_loss: 0.5788 Model_2_loss: 0.5005 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5907 Model_2_val:0.5818
Epoch: 0160 Model_1_loss: 0.5207 Model_2_loss: 0.4855 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.5831 Model_2_val:0.5884
Epoch: 0180 Model_1_loss: 0.4410 Model_2_loss: 0.4253 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.5960 Model_2_val:0.5947
Epoch: 0200 Model_1_loss: 0.4569 Model_2_loss: 0.3886 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.5940 Model_2_val:0.5927
Epoch: 0220 Model_1_loss: 0.8245 Model_2_loss: 0.7577 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6395 Model_2_val:0.6415
Epoch: 0240 Model_1_loss: 0.7487 Model_2_loss: 0.6820 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.6521 Model_2_val:0.6594
Epoch: 0260 Model_1_loss: 0.6693 Model_2_loss: 0.6176 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6474 Model_2_val:0.6498
Epoch: 0280 Model_1_loss: 0.6821 Model_2_loss: 0.6458 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6454 Model_2_val:0.6551
Epoch: 0300 Model_1_loss: 0.6249 Model_2_loss: 0.5767 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6567 Model_2_val:0.6683
Epoch: 0320 Model_1_loss: 0.5765 Model_2_loss: 0.5978 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6507 Model_2_val:0.6554
Epoch: 0340 Model_1_loss: 0.5686 Model_2_loss: 0.5457 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6474 Model_2_val:0.6657
Epoch: 0360 Model_1_loss: 0.5429 Model_2_loss: 0.5238 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6491 Model_2_val:0.6600
Epoch: 0380 Model_1_loss: 0.5198 Model_2_loss: 0.4937 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6544 Model_2_val:0.6723
Epoch: 0400 Model_1_loss: 0.5389 Model_2_loss: 0.5018 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6597 Model_2_val:0.6597
Model_one_test:0.6876 Model_two_test:0.6876
added by two output: 0.6879
16
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
156914026
Epoch: 0020 Model_1_loss: 1.7312 Model_2_loss: 1.6932 Model_1_trainacc: 0.4583 Model_2_trainacc: 0.5750 Model_1_val:0.2781 Model_2_val:0.3488
Epoch: 0040 Model_1_loss: 1.5655 Model_2_loss: 1.4815 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.7583 Model_1_val:0.4163 Model_2_val:0.4821
Epoch: 0060 Model_1_loss: 1.2777 Model_2_loss: 1.2056 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8417 Model_1_val:0.4831 Model_2_val:0.5236
Epoch: 0080 Model_1_loss: 1.0785 Model_2_loss: 0.9178 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8917 Model_1_val:0.5156 Model_2_val:0.5661
Epoch: 0100 Model_1_loss: 0.8926 Model_2_loss: 0.7347 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9250 Model_1_val:0.5312 Model_2_val:0.5827
Epoch: 0120 Model_1_loss: 0.7214 Model_2_loss: 0.6171 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9500 Model_1_val:0.5661 Model_2_val:0.5854
Epoch: 0140 Model_1_loss: 0.6169 Model_2_loss: 0.5460 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9500 Model_1_val:0.5721 Model_2_val:0.5937
Epoch: 0160 Model_1_loss: 0.5769 Model_2_loss: 0.5106 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9667 Model_1_val:0.5831 Model_2_val:0.6053
Epoch: 0180 Model_1_loss: 0.4883 Model_2_loss: 0.4894 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5870 Model_2_val:0.6193
Epoch: 0200 Model_1_loss: 0.4240 Model_2_loss: 0.4683 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.5834 Model_2_val:0.6090
Epoch: 0220 Model_1_loss: 0.7983 Model_2_loss: 0.7417 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6698 Model_2_val:0.6674
Epoch: 0240 Model_1_loss: 0.7019 Model_2_loss: 0.7359 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6701 Model_2_val:0.6841
Epoch: 0260 Model_1_loss: 0.6426 Model_2_loss: 0.6727 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6741 Model_2_val:0.6960
Epoch: 0280 Model_1_loss: 0.6314 Model_2_loss: 0.6255 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6801 Model_2_val:0.6894
Epoch: 0300 Model_1_loss: 0.6157 Model_2_loss: 0.5692 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6801 Model_2_val:0.6890
Epoch: 0320 Model_1_loss: 0.6092 Model_2_loss: 0.5774 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.6804 Model_2_val:0.6774
Epoch: 0340 Model_1_loss: 0.5927 Model_2_loss: 0.5464 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.6761 Model_2_val:0.6907
Epoch: 0360 Model_1_loss: 0.5442 Model_2_loss: 0.5265 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6731 Model_2_val:0.6777
Epoch: 0380 Model_1_loss: 0.5189 Model_2_loss: 0.5110 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6754 Model_2_val:0.6791
Epoch: 0400 Model_1_loss: 0.5224 Model_2_loss: 0.5167 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6731 Model_2_val:0.6824
Model_one_test:0.6940 Model_two_test:0.6930
added by two output: 0.6937
17
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
405124025
Epoch: 0020 Model_1_loss: 1.7450 Model_2_loss: 1.6755 Model_1_trainacc: 0.4167 Model_2_trainacc: 0.4500 Model_1_val:0.2643 Model_2_val:0.2851
Epoch: 0040 Model_1_loss: 1.6296 Model_2_loss: 1.4965 Model_1_trainacc: 0.6000 Model_2_trainacc: 0.7333 Model_1_val:0.3761 Model_2_val:0.4382
Epoch: 0060 Model_1_loss: 1.3332 Model_2_loss: 1.1882 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.8417 Model_1_val:0.4561 Model_2_val:0.5000
Epoch: 0080 Model_1_loss: 1.0913 Model_2_loss: 0.9187 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8667 Model_1_val:0.5234 Model_2_val:0.5361
Epoch: 0100 Model_1_loss: 0.8352 Model_2_loss: 0.7157 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.5387 Model_2_val:0.5585
Epoch: 0120 Model_1_loss: 0.7489 Model_2_loss: 0.5653 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9417 Model_1_val:0.5686 Model_2_val:0.5904
Epoch: 0140 Model_1_loss: 0.5947 Model_2_loss: 0.5008 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5770 Model_2_val:0.6008
Epoch: 0160 Model_1_loss: 0.5435 Model_2_loss: 0.4789 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5783 Model_2_val:0.5946
Epoch: 0180 Model_1_loss: 0.5136 Model_2_loss: 0.4689 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9417 Model_1_val:0.5852 Model_2_val:0.6105
Epoch: 0200 Model_1_loss: 0.4527 Model_2_loss: 0.3793 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6005 Model_2_val:0.6239
Epoch: 0220 Model_1_loss: 0.7230 Model_2_loss: 0.6828 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6596 Model_2_val:0.6593
Epoch: 0240 Model_1_loss: 0.6584 Model_2_loss: 0.6359 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6590 Model_2_val:0.6616
Epoch: 0260 Model_1_loss: 0.6212 Model_2_loss: 0.5793 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6593 Model_2_val:0.6534
Epoch: 0280 Model_1_loss: 0.6111 Model_2_loss: 0.6208 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6638 Model_2_val:0.6603
Epoch: 0300 Model_1_loss: 0.5621 Model_2_loss: 0.5542 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6590 Model_2_val:0.6658
Epoch: 0320 Model_1_loss: 0.5269 Model_2_loss: 0.4934 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6635 Model_2_val:0.6573
Epoch: 0340 Model_1_loss: 0.5058 Model_2_loss: 0.5190 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6570 Model_2_val:0.6645
Epoch: 0360 Model_1_loss: 0.5278 Model_2_loss: 0.4977 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6466 Model_2_val:0.6664
Epoch: 0380 Model_1_loss: 0.5185 Model_2_loss: 0.4848 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6606 Model_2_val:0.6743
Epoch: 0400 Model_1_loss: 0.4524 Model_2_loss: 0.4801 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6632 Model_2_val:0.6616
Model_one_test:0.6798 Model_two_test:0.6791
added by two output: 0.6808
18
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1071857106
Epoch: 0020 Model_1_loss: 1.7316 Model_2_loss: 1.7317 Model_1_trainacc: 0.3417 Model_2_trainacc: 0.4000 Model_1_val:0.2582 Model_2_val:0.2394
Epoch: 0040 Model_1_loss: 1.5078 Model_2_loss: 1.5761 Model_1_trainacc: 0.7417 Model_2_trainacc: 0.7167 Model_1_val:0.4252 Model_2_val:0.4147
Epoch: 0060 Model_1_loss: 1.1790 Model_2_loss: 1.3446 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8083 Model_1_val:0.4998 Model_2_val:0.4843
Epoch: 0080 Model_1_loss: 0.8776 Model_2_loss: 1.0723 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9000 Model_1_val:0.5367 Model_2_val:0.5364
Epoch: 0100 Model_1_loss: 0.7402 Model_2_loss: 0.7943 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9250 Model_1_val:0.5662 Model_2_val:0.5522
Epoch: 0120 Model_1_loss: 0.5760 Model_2_loss: 0.6624 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.5567 Model_2_val:0.5675
Epoch: 0140 Model_1_loss: 0.5533 Model_2_loss: 0.6107 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9083 Model_1_val:0.5996 Model_2_val:0.5678
Epoch: 0160 Model_1_loss: 0.4002 Model_2_loss: 0.4722 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.5945 Model_2_val:0.5865
Epoch: 0180 Model_1_loss: 0.3407 Model_2_loss: 0.4305 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9250 Model_1_val:0.6199 Model_2_val:0.6034
Epoch: 0200 Model_1_loss: 0.3535 Model_2_loss: 0.3740 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6024 Model_2_val:0.5999
Epoch: 0220 Model_1_loss: 0.7067 Model_2_loss: 0.7186 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6783 Model_2_val:0.6739
Epoch: 0240 Model_1_loss: 0.6156 Model_2_loss: 0.6658 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6780 Model_2_val:0.6780
Epoch: 0260 Model_1_loss: 0.6043 Model_2_loss: 0.6046 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6701 Model_2_val:0.6789
Epoch: 0280 Model_1_loss: 0.5231 Model_2_loss: 0.5499 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6809 Model_2_val:0.6666
Epoch: 0300 Model_1_loss: 0.5383 Model_2_loss: 0.6081 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6875 Model_2_val:0.6831
Epoch: 0320 Model_1_loss: 0.5059 Model_2_loss: 0.5458 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6872 Model_2_val:0.6710
Epoch: 0340 Model_1_loss: 0.4459 Model_2_loss: 0.5252 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.6758 Model_2_val:0.6840
Epoch: 0360 Model_1_loss: 0.4596 Model_2_loss: 0.4921 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6853 Model_2_val:0.6812
Epoch: 0380 Model_1_loss: 0.4137 Model_2_loss: 0.4879 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6837 Model_2_val:0.6723
Epoch: 0400 Model_1_loss: 0.4286 Model_2_loss: 0.4366 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6872 Model_2_val:0.6821
Model_one_test:0.7031 Model_two_test:0.7037
added by two output: 0.7040
19
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
197883770
Epoch: 0020 Model_1_loss: 1.6999 Model_2_loss: 1.7153 Model_1_trainacc: 0.4833 Model_2_trainacc: 0.4500 Model_1_val:0.2518 Model_2_val:0.1982
Epoch: 0040 Model_1_loss: 1.4679 Model_2_loss: 1.5095 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.7417 Model_1_val:0.4240 Model_2_val:0.3866
Epoch: 0060 Model_1_loss: 1.1359 Model_2_loss: 1.1720 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8917 Model_1_val:0.5084 Model_2_val:0.4711
Epoch: 0080 Model_1_loss: 0.8801 Model_2_loss: 0.9431 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8583 Model_1_val:0.5484 Model_2_val:0.5387
Epoch: 0100 Model_1_loss: 0.7071 Model_2_loss: 0.7721 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9083 Model_1_val:0.5750 Model_2_val:0.5552
Epoch: 0120 Model_1_loss: 0.5995 Model_2_loss: 0.6417 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.5780 Model_2_val:0.5669
Epoch: 0140 Model_1_loss: 0.5260 Model_2_loss: 0.5424 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.5994 Model_2_val:0.5757
Epoch: 0160 Model_1_loss: 0.4501 Model_2_loss: 0.4918 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.5952 Model_2_val:0.5783
Epoch: 0180 Model_1_loss: 0.4436 Model_2_loss: 0.4675 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.5965 Model_2_val:0.5900
Epoch: 0200 Model_1_loss: 0.4019 Model_2_loss: 0.4614 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9417 Model_1_val:0.6030 Model_2_val:0.5923
Epoch: 0220 Model_1_loss: 0.7098 Model_2_loss: 0.7102 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6417 Model_2_val:0.6670
Epoch: 0240 Model_1_loss: 0.6924 Model_2_loss: 0.6354 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6569 Model_2_val:0.6667
Epoch: 0260 Model_1_loss: 0.5792 Model_2_loss: 0.6016 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6686 Model_2_val:0.6595
Epoch: 0280 Model_1_loss: 0.5954 Model_2_loss: 0.5684 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6647 Model_2_val:0.6709
Epoch: 0300 Model_1_loss: 0.5210 Model_2_loss: 0.4946 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6660 Model_2_val:0.6637
Epoch: 0320 Model_1_loss: 0.5143 Model_2_loss: 0.5611 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6699 Model_2_val:0.6680
Epoch: 0340 Model_1_loss: 0.4868 Model_2_loss: 0.5205 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6702 Model_2_val:0.6634
Epoch: 0360 Model_1_loss: 0.4831 Model_2_loss: 0.4693 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6676 Model_2_val:0.6641
Epoch: 0380 Model_1_loss: 0.4364 Model_2_loss: 0.5218 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6608 Model_2_val:0.6654
Epoch: 0400 Model_1_loss: 0.4087 Model_2_loss: 0.4716 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6712 Model_2_val:0.6696
Model_one_test:0.6780 Model_two_test:0.6790
added by two output: 0.6787
20
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
231878912
Epoch: 0020 Model_1_loss: 1.7151 Model_2_loss: 1.6912 Model_1_trainacc: 0.4417 Model_2_trainacc: 0.5000 Model_1_val:0.3109 Model_2_val:0.3613
Epoch: 0040 Model_1_loss: 1.4863 Model_2_loss: 1.4397 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.8417 Model_1_val:0.4702 Model_2_val:0.5018
Epoch: 0060 Model_1_loss: 1.1676 Model_2_loss: 1.1394 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8500 Model_1_val:0.5047 Model_2_val:0.5233
Epoch: 0080 Model_1_loss: 0.9007 Model_2_loss: 0.8740 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8917 Model_1_val:0.5460 Model_2_val:0.5457
Epoch: 0100 Model_1_loss: 0.7140 Model_2_loss: 0.6637 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9000 Model_1_val:0.5623 Model_2_val:0.5652
Epoch: 0120 Model_1_loss: 0.5988 Model_2_loss: 0.6098 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9333 Model_1_val:0.5769 Model_2_val:0.5854
Epoch: 0140 Model_1_loss: 0.5621 Model_2_loss: 0.5068 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.5567 Model_2_val:0.5854
Epoch: 0160 Model_1_loss: 0.4556 Model_2_loss: 0.4924 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.5925 Model_2_val:0.5681
Epoch: 0180 Model_1_loss: 0.3950 Model_2_loss: 0.4358 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.5759 Model_2_val:0.5834
Epoch: 0200 Model_1_loss: 0.3765 Model_2_loss: 0.3945 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.5870 Model_2_val:0.5964
Epoch: 0220 Model_1_loss: 0.7359 Model_2_loss: 0.6806 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6524 Model_2_val:0.6501
Epoch: 0240 Model_1_loss: 0.6708 Model_2_loss: 0.6169 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6459 Model_2_val:0.6699
Epoch: 0260 Model_1_loss: 0.6485 Model_2_loss: 0.6015 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6628 Model_2_val:0.6537
Epoch: 0280 Model_1_loss: 0.5894 Model_2_loss: 0.5545 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6585 Model_2_val:0.6556
Epoch: 0300 Model_1_loss: 0.5586 Model_2_loss: 0.5694 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6673 Model_2_val:0.6680
Epoch: 0320 Model_1_loss: 0.5253 Model_2_loss: 0.5016 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6631 Model_2_val:0.6598
Epoch: 0340 Model_1_loss: 0.4931 Model_2_loss: 0.4885 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6676 Model_2_val:0.6605
Epoch: 0360 Model_1_loss: 0.5184 Model_2_loss: 0.4747 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6683 Model_2_val:0.6647
Epoch: 0380 Model_1_loss: 0.4790 Model_2_loss: 0.4284 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6550 Model_2_val:0.6608
Epoch: 0400 Model_1_loss: 0.4714 Model_2_loss: 0.4952 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6696 Model_2_val:0.6569
Model_one_test:0.6885 Model_two_test:0.6849
added by two output: 0.6865
21
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
370102476
Epoch: 0020 Model_1_loss: 1.6929 Model_2_loss: 1.7092 Model_1_trainacc: 0.4667 Model_2_trainacc: 0.4417 Model_1_val:0.2841 Model_2_val:0.2459
Epoch: 0040 Model_1_loss: 1.4656 Model_2_loss: 1.5135 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.6667 Model_1_val:0.5188 Model_2_val:0.4527
Epoch: 0060 Model_1_loss: 1.1738 Model_2_loss: 1.1144 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8667 Model_1_val:0.5252 Model_2_val:0.5293
Epoch: 0080 Model_1_loss: 0.9064 Model_2_loss: 0.8275 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9417 Model_1_val:0.5643 Model_2_val:0.5794
Epoch: 0100 Model_1_loss: 0.7482 Model_2_loss: 0.6590 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.5540 Model_2_val:0.6021
Epoch: 0120 Model_1_loss: 0.7127 Model_2_loss: 0.5660 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9583 Model_1_val:0.5739 Model_2_val:0.5941
Epoch: 0140 Model_1_loss: 0.5462 Model_2_loss: 0.4894 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.5838 Model_2_val:0.5906
Epoch: 0160 Model_1_loss: 0.5179 Model_2_loss: 0.4141 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.5906 Model_2_val:0.5928
Epoch: 0180 Model_1_loss: 0.4602 Model_2_loss: 0.4207 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6044 Model_2_val:0.5999
Epoch: 0200 Model_1_loss: 0.4288 Model_2_loss: 0.3806 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.5899 Model_2_val:0.6153
Epoch: 0220 Model_1_loss: 0.7621 Model_2_loss: 0.7437 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6432 Model_2_val:0.6537
Epoch: 0240 Model_1_loss: 0.6993 Model_2_loss: 0.6527 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6499 Model_2_val:0.6553
Epoch: 0260 Model_1_loss: 0.7089 Model_2_loss: 0.6568 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6492 Model_2_val:0.6582
Epoch: 0280 Model_1_loss: 0.6224 Model_2_loss: 0.6049 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6451 Model_2_val:0.6547
Epoch: 0300 Model_1_loss: 0.5748 Model_2_loss: 0.5912 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6499 Model_2_val:0.6627
Epoch: 0320 Model_1_loss: 0.5712 Model_2_loss: 0.5678 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6281 Model_2_val:0.6694
Epoch: 0340 Model_1_loss: 0.5784 Model_2_loss: 0.5291 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6579 Model_2_val:0.6569
Epoch: 0360 Model_1_loss: 0.5047 Model_2_loss: 0.5301 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6685 Model_2_val:0.6585
Epoch: 0380 Model_1_loss: 0.5253 Model_2_loss: 0.4783 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6589 Model_2_val:0.6694
Epoch: 0400 Model_1_loss: 0.5078 Model_2_loss: 0.4848 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6541 Model_2_val:0.6573
Model_one_test:0.6848 Model_two_test:0.6826
added by two output: 0.6852
22
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
956520950
Epoch: 0020 Model_1_loss: 1.6814 Model_2_loss: 1.7305 Model_1_trainacc: 0.5167 Model_2_trainacc: 0.4667 Model_1_val:0.3098 Model_2_val:0.2688
Epoch: 0040 Model_1_loss: 1.4146 Model_2_loss: 1.5339 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8083 Model_1_val:0.4607 Model_2_val:0.4481
Epoch: 0060 Model_1_loss: 1.1563 Model_2_loss: 1.2453 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8583 Model_1_val:0.5125 Model_2_val:0.5288
Epoch: 0080 Model_1_loss: 0.8924 Model_2_loss: 0.9178 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9083 Model_1_val:0.5553 Model_2_val:0.5607
Epoch: 0100 Model_1_loss: 0.7038 Model_2_loss: 0.7534 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9000 Model_1_val:0.5739 Model_2_val:0.5685
Epoch: 0120 Model_1_loss: 0.6039 Model_2_loss: 0.6663 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.5654 Model_2_val:0.5844
Epoch: 0140 Model_1_loss: 0.5258 Model_2_loss: 0.5225 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.5803 Model_2_val:0.5715
Epoch: 0160 Model_1_loss: 0.4202 Model_2_loss: 0.4855 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6000 Model_2_val:0.5983
Epoch: 0180 Model_1_loss: 0.4374 Model_2_loss: 0.4595 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.5837 Model_2_val:0.5976
Epoch: 0200 Model_1_loss: 0.4186 Model_2_loss: 0.4423 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.5858 Model_2_val:0.6051
Epoch: 0220 Model_1_loss: 0.7283 Model_2_loss: 0.7386 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6475 Model_2_val:0.6586
Epoch: 0240 Model_1_loss: 0.5934 Model_2_loss: 0.7167 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6729 Model_2_val:0.6492
Epoch: 0260 Model_1_loss: 0.5843 Model_2_loss: 0.6462 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6671 Model_2_val:0.6624
Epoch: 0280 Model_1_loss: 0.5804 Model_2_loss: 0.6042 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6722 Model_2_val:0.6647
Epoch: 0300 Model_1_loss: 0.5681 Model_2_loss: 0.5836 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6631 Model_2_val:0.6610
Epoch: 0320 Model_1_loss: 0.5051 Model_2_loss: 0.5150 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6725 Model_2_val:0.6692
Epoch: 0340 Model_1_loss: 0.5572 Model_2_loss: 0.4962 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6664 Model_2_val:0.6603
Epoch: 0360 Model_1_loss: 0.5159 Model_2_loss: 0.5350 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6692 Model_2_val:0.6590
Epoch: 0380 Model_1_loss: 0.4916 Model_2_loss: 0.4803 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6654 Model_2_val:0.6644
Epoch: 0400 Model_1_loss: 0.4374 Model_2_loss: 0.5024 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6658 Model_2_val:0.6566
Model_one_test:0.6895 Model_two_test:0.6868
added by two output: 0.6871
23
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1482775147
Epoch: 0020 Model_1_loss: 1.7011 Model_2_loss: 1.7391 Model_1_trainacc: 0.5083 Model_2_trainacc: 0.4750 Model_1_val:0.2497 Model_2_val:0.2753
Epoch: 0040 Model_1_loss: 1.5306 Model_2_loss: 1.6086 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.7167 Model_1_val:0.4042 Model_2_val:0.4201
Epoch: 0060 Model_1_loss: 1.3140 Model_2_loss: 1.3307 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.8083 Model_1_val:0.4769 Model_2_val:0.4736
Epoch: 0080 Model_1_loss: 1.0503 Model_2_loss: 1.0591 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8917 Model_1_val:0.5210 Model_2_val:0.5187
Epoch: 0100 Model_1_loss: 0.8218 Model_2_loss: 0.8889 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8833 Model_1_val:0.5557 Model_2_val:0.5375
Epoch: 0120 Model_1_loss: 0.6764 Model_2_loss: 0.7984 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8833 Model_1_val:0.5591 Model_2_val:0.5685
Epoch: 0140 Model_1_loss: 0.5767 Model_2_loss: 0.6994 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8833 Model_1_val:0.5742 Model_2_val:0.5527
Epoch: 0160 Model_1_loss: 0.5459 Model_2_loss: 0.5351 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.5884 Model_2_val:0.5732
Epoch: 0180 Model_1_loss: 0.4861 Model_2_loss: 0.4999 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5786 Model_2_val:0.5671
Epoch: 0200 Model_1_loss: 0.4710 Model_2_loss: 0.5227 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9250 Model_1_val:0.5853 Model_2_val:0.5719
Epoch: 0220 Model_1_loss: 0.7642 Model_2_loss: 0.8234 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6587 Model_2_val:0.6503
Epoch: 0240 Model_1_loss: 0.7525 Model_2_loss: 0.8337 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.6634 Model_2_val:0.6671
Epoch: 0260 Model_1_loss: 0.6754 Model_2_loss: 0.7832 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.6752 Model_2_val:0.6671
Epoch: 0280 Model_1_loss: 0.6478 Model_2_loss: 0.7333 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6873 Model_2_val:0.6627
Epoch: 0300 Model_1_loss: 0.6367 Model_2_loss: 0.7488 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.6738 Model_2_val:0.6678
Epoch: 0320 Model_1_loss: 0.6498 Model_2_loss: 0.6377 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6839 Model_2_val:0.6722
Epoch: 0340 Model_1_loss: 0.5971 Model_2_loss: 0.6323 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6789 Model_2_val:0.6597
Epoch: 0360 Model_1_loss: 0.5607 Model_2_loss: 0.6119 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6762 Model_2_val:0.6782
Epoch: 0380 Model_1_loss: 0.6171 Model_2_loss: 0.5576 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.6833 Model_2_val:0.6611
Epoch: 0400 Model_1_loss: 0.5373 Model_2_loss: 0.5194 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6799 Model_2_val:0.6779
Model_one_test:0.7048 Model_two_test:0.7014
added by two output: 0.7038
24
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
529097125
Epoch: 0020 Model_1_loss: 1.7160 Model_2_loss: 1.7154 Model_1_trainacc: 0.4417 Model_2_trainacc: 0.6750 Model_1_val:0.2575 Model_2_val:0.3793
Epoch: 0040 Model_1_loss: 1.5250 Model_2_loss: 1.5105 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.7250 Model_1_val:0.3813 Model_2_val:0.4267
Epoch: 0060 Model_1_loss: 1.2048 Model_2_loss: 1.2237 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8083 Model_1_val:0.4807 Model_2_val:0.4758
Epoch: 0080 Model_1_loss: 0.9177 Model_2_loss: 0.9982 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9000 Model_1_val:0.5130 Model_2_val:0.5156
Epoch: 0100 Model_1_loss: 0.7574 Model_2_loss: 0.7976 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9000 Model_1_val:0.5482 Model_2_val:0.5400
Epoch: 0120 Model_1_loss: 0.6610 Model_2_loss: 0.7265 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9000 Model_1_val:0.5736 Model_2_val:0.5631
Epoch: 0140 Model_1_loss: 0.5881 Model_2_loss: 0.6270 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9167 Model_1_val:0.5752 Model_2_val:0.5624
Epoch: 0160 Model_1_loss: 0.5435 Model_2_loss: 0.5285 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5818 Model_2_val:0.5719
Epoch: 0180 Model_1_loss: 0.4966 Model_2_loss: 0.4665 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5884 Model_2_val:0.5848
Epoch: 0200 Model_1_loss: 0.4673 Model_2_loss: 0.4544 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9250 Model_1_val:0.5749 Model_2_val:0.5841
Epoch: 0220 Model_1_loss: 0.8102 Model_2_loss: 0.7674 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6483 Model_2_val:0.6635
Epoch: 0240 Model_1_loss: 0.6926 Model_2_loss: 0.7457 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6740 Model_2_val:0.6582
Epoch: 0260 Model_1_loss: 0.6599 Model_2_loss: 0.7043 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6648 Model_2_val:0.6707
Epoch: 0280 Model_1_loss: 0.6413 Model_2_loss: 0.6969 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9500 Model_1_val:0.6727 Model_2_val:0.6641
Epoch: 0300 Model_1_loss: 0.5764 Model_2_loss: 0.6552 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6750 Model_2_val:0.6628
Epoch: 0320 Model_1_loss: 0.5778 Model_2_loss: 0.5601 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6730 Model_2_val:0.6576
Epoch: 0340 Model_1_loss: 0.5215 Model_2_loss: 0.5724 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6757 Model_2_val:0.6651
Epoch: 0360 Model_1_loss: 0.5482 Model_2_loss: 0.5764 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6750 Model_2_val:0.6664
Epoch: 0380 Model_1_loss: 0.5377 Model_2_loss: 0.5439 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6743 Model_2_val:0.6655
Epoch: 0400 Model_1_loss: 0.4640 Model_2_loss: 0.4690 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6734 Model_2_val:0.6559
Model_one_test:0.6915 Model_two_test:0.6971
added by two output: 0.6921
25
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
847779626
Epoch: 0020 Model_1_loss: 1.6979 Model_2_loss: 1.7056 Model_1_trainacc: 0.5917 Model_2_trainacc: 0.5500 Model_1_val:0.2831 Model_2_val:0.3081
Epoch: 0040 Model_1_loss: 1.4663 Model_2_loss: 1.5063 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.7833 Model_1_val:0.4287 Model_2_val:0.4414
Epoch: 0060 Model_1_loss: 1.1558 Model_2_loss: 1.2015 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8500 Model_1_val:0.4902 Model_2_val:0.5023
Epoch: 0080 Model_1_loss: 0.9692 Model_2_loss: 0.8914 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.9250 Model_1_val:0.5397 Model_2_val:0.5355
Epoch: 0100 Model_1_loss: 0.7092 Model_2_loss: 0.7033 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5466 Model_2_val:0.5772
Epoch: 0120 Model_1_loss: 0.6690 Model_2_loss: 0.6126 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9417 Model_1_val:0.5668 Model_2_val:0.5684
Epoch: 0140 Model_1_loss: 0.5310 Model_2_loss: 0.5539 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5980 Model_2_val:0.5772
Epoch: 0160 Model_1_loss: 0.4288 Model_2_loss: 0.5020 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.6062 Model_2_val:0.5941
Epoch: 0180 Model_1_loss: 0.4235 Model_2_loss: 0.4464 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5906 Model_2_val:0.6023
Epoch: 0200 Model_1_loss: 0.3845 Model_2_loss: 0.4187 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.5993 Model_2_val:0.5886
Epoch: 0220 Model_1_loss: 0.7362 Model_2_loss: 0.7870 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6358 Model_2_val:0.6388
Epoch: 0240 Model_1_loss: 0.6895 Model_2_loss: 0.6558 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6456 Model_2_val:0.6430
Epoch: 0260 Model_1_loss: 0.6463 Model_2_loss: 0.6700 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6463 Model_2_val:0.6502
Epoch: 0280 Model_1_loss: 0.6119 Model_2_loss: 0.6645 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6427 Model_2_val:0.6476
Epoch: 0300 Model_1_loss: 0.5956 Model_2_loss: 0.5978 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6479 Model_2_val:0.6596
Epoch: 0320 Model_1_loss: 0.5437 Model_2_loss: 0.5740 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6547 Model_2_val:0.6495
Epoch: 0340 Model_1_loss: 0.5450 Model_2_loss: 0.5421 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6482 Model_2_val:0.6541
Epoch: 0360 Model_1_loss: 0.4998 Model_2_loss: 0.5416 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6583 Model_2_val:0.6586
Epoch: 0380 Model_1_loss: 0.5275 Model_2_loss: 0.5036 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6466 Model_2_val:0.6505
Epoch: 0400 Model_1_loss: 0.4693 Model_2_loss: 0.5040 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6554 Model_2_val:0.6502
Model_one_test:0.6720 Model_two_test:0.6772
added by two output: 0.6746
26
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
823424363
Epoch: 0020 Model_1_loss: 1.7266 Model_2_loss: 1.7029 Model_1_trainacc: 0.3917 Model_2_trainacc: 0.4917 Model_1_val:0.2137 Model_2_val:0.2676
Epoch: 0040 Model_1_loss: 1.5768 Model_2_loss: 1.4865 Model_1_trainacc: 0.6583 Model_2_trainacc: 0.7417 Model_1_val:0.4083 Model_2_val:0.4408
Epoch: 0060 Model_1_loss: 1.2843 Model_2_loss: 1.1752 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8417 Model_1_val:0.4668 Model_2_val:0.4924
Epoch: 0080 Model_1_loss: 1.0578 Model_2_loss: 0.9346 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.9083 Model_1_val:0.5309 Model_2_val:0.5457
Epoch: 0100 Model_1_loss: 0.8422 Model_2_loss: 0.7715 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9250 Model_1_val:0.5325 Model_2_val:0.5723
Epoch: 0120 Model_1_loss: 0.7056 Model_2_loss: 0.6359 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9333 Model_1_val:0.5523 Model_2_val:0.5726
Epoch: 0140 Model_1_loss: 0.5966 Model_2_loss: 0.5281 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.5631 Model_2_val:0.5773
Epoch: 0160 Model_1_loss: 0.5716 Model_2_loss: 0.5165 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9333 Model_1_val:0.5703 Model_2_val:0.5796
Epoch: 0180 Model_1_loss: 0.5378 Model_2_loss: 0.4535 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.5838 Model_2_val:0.5809
Epoch: 0200 Model_1_loss: 0.4749 Model_2_loss: 0.4272 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5743 Model_2_val:0.5796
Epoch: 0220 Model_1_loss: 0.8368 Model_2_loss: 0.8371 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9333 Model_1_val:0.6466 Model_2_val:0.6548
Epoch: 0240 Model_1_loss: 0.7763 Model_2_loss: 0.7901 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6568 Model_2_val:0.6581
Epoch: 0260 Model_1_loss: 0.7310 Model_2_loss: 0.6819 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6502 Model_2_val:0.6617
Epoch: 0280 Model_1_loss: 0.6716 Model_2_loss: 0.6124 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6473 Model_2_val:0.6558
Epoch: 0300 Model_1_loss: 0.7271 Model_2_loss: 0.6525 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.6607 Model_2_val:0.6555
Epoch: 0320 Model_1_loss: 0.6238 Model_2_loss: 0.6110 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6657 Model_2_val:0.6647
Epoch: 0340 Model_1_loss: 0.5996 Model_2_loss: 0.6047 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6584 Model_2_val:0.6713
Epoch: 0360 Model_1_loss: 0.6328 Model_2_loss: 0.5786 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6591 Model_2_val:0.6607
Epoch: 0380 Model_1_loss: 0.5866 Model_2_loss: 0.5917 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6558 Model_2_val:0.6627
Epoch: 0400 Model_1_loss: 0.6028 Model_2_loss: 0.5241 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6525 Model_2_val:0.6686
Model_one_test:0.6811 Model_two_test:0.6884
added by two output: 0.6851
27
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
803757130
Epoch: 0020 Model_1_loss: 1.7037 Model_2_loss: 1.7336 Model_1_trainacc: 0.5750 Model_2_trainacc: 0.3917 Model_1_val:0.3270 Model_2_val:0.1882
Epoch: 0040 Model_1_loss: 1.5129 Model_2_loss: 1.5973 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.7083 Model_1_val:0.4233 Model_2_val:0.3574
Epoch: 0060 Model_1_loss: 1.2091 Model_2_loss: 1.3476 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8250 Model_1_val:0.5333 Model_2_val:0.4316
Epoch: 0080 Model_1_loss: 0.8904 Model_2_loss: 1.0421 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8750 Model_1_val:0.5420 Model_2_val:0.4835
Epoch: 0100 Model_1_loss: 0.7225 Model_2_loss: 0.8388 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.5704 Model_2_val:0.5346
Epoch: 0120 Model_1_loss: 0.5929 Model_2_loss: 0.6883 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9333 Model_1_val:0.5754 Model_2_val:0.5406
Epoch: 0140 Model_1_loss: 0.5378 Model_2_loss: 0.6097 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5864 Model_2_val:0.5570
Epoch: 0160 Model_1_loss: 0.4817 Model_2_loss: 0.5467 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9333 Model_1_val:0.5811 Model_2_val:0.5697
Epoch: 0180 Model_1_loss: 0.4626 Model_2_loss: 0.4396 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5854 Model_2_val:0.5817
Epoch: 0200 Model_1_loss: 0.4200 Model_2_loss: 0.4072 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.5971 Model_2_val:0.5747
Epoch: 0220 Model_1_loss: 0.7840 Model_2_loss: 0.7581 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6316 Model_2_val:0.6510
Epoch: 0240 Model_1_loss: 0.7674 Model_2_loss: 0.7237 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6640 Model_2_val:0.6757
Epoch: 0260 Model_1_loss: 0.6738 Model_2_loss: 0.6964 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6780 Model_2_val:0.6667
Epoch: 0280 Model_1_loss: 0.7161 Model_2_loss: 0.6554 Model_1_trainacc: 0.9583 Model_2_trainacc: 1.0000 Model_1_val:0.6790 Model_2_val:0.6777
Epoch: 0300 Model_1_loss: 0.6245 Model_2_loss: 0.5689 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6620 Model_2_val:0.6824
Epoch: 0320 Model_1_loss: 0.6673 Model_2_loss: 0.5862 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6727 Model_2_val:0.6877
Epoch: 0340 Model_1_loss: 0.5577 Model_2_loss: 0.5682 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6834 Model_2_val:0.6861
Epoch: 0360 Model_1_loss: 0.5416 Model_2_loss: 0.5282 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6784 Model_2_val:0.6857
Epoch: 0380 Model_1_loss: 0.5361 Model_2_loss: 0.5518 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6784 Model_2_val:0.6937
Epoch: 0400 Model_1_loss: 0.5433 Model_2_loss: 0.4944 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6854 Model_2_val:0.6944
Model_one_test:0.7068 Model_two_test:0.7081
added by two output: 0.7071
28
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
615062057
Epoch: 0020 Model_1_loss: 1.7492 Model_2_loss: 1.7334 Model_1_trainacc: 0.2500 Model_2_trainacc: 0.4167 Model_1_val:0.1731 Model_2_val:0.2936
Epoch: 0040 Model_1_loss: 1.5796 Model_2_loss: 1.6094 Model_1_trainacc: 0.7667 Model_2_trainacc: 0.5583 Model_1_val:0.4184 Model_2_val:0.3836
Epoch: 0060 Model_1_loss: 1.2888 Model_2_loss: 1.3797 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.7750 Model_1_val:0.4765 Model_2_val:0.4483
Epoch: 0080 Model_1_loss: 1.0060 Model_2_loss: 1.1039 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8750 Model_1_val:0.5307 Model_2_val:0.4936
Epoch: 0100 Model_1_loss: 0.8342 Model_2_loss: 0.9266 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8250 Model_1_val:0.5593 Model_2_val:0.5300
Epoch: 0120 Model_1_loss: 0.7321 Model_2_loss: 0.7999 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9000 Model_1_val:0.5718 Model_2_val:0.5606
Epoch: 0140 Model_1_loss: 0.5373 Model_2_loss: 0.6265 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5885 Model_2_val:0.5704
Epoch: 0160 Model_1_loss: 0.4887 Model_2_loss: 0.6257 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9000 Model_1_val:0.5967 Model_2_val:0.5803
Epoch: 0180 Model_1_loss: 0.4365 Model_2_loss: 0.5264 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9250 Model_1_val:0.5875 Model_2_val:0.5859
Epoch: 0200 Model_1_loss: 0.4438 Model_2_loss: 0.4510 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6085 Model_2_val:0.6020
Epoch: 0220 Model_1_loss: 0.7290 Model_2_loss: 0.8050 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6571 Model_2_val:0.6476
Epoch: 0240 Model_1_loss: 0.7126 Model_2_loss: 0.7571 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6745 Model_2_val:0.6519
Epoch: 0260 Model_1_loss: 0.6199 Model_2_loss: 0.7160 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6640 Model_2_val:0.6430
Epoch: 0280 Model_1_loss: 0.5739 Model_2_loss: 0.6896 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6634 Model_2_val:0.6496
Epoch: 0300 Model_1_loss: 0.5923 Model_2_loss: 0.6306 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6608 Model_2_val:0.6637
Epoch: 0320 Model_1_loss: 0.5592 Model_2_loss: 0.6232 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6604 Model_2_val:0.6552
Epoch: 0340 Model_1_loss: 0.5025 Model_2_loss: 0.5726 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.6604 Model_2_val:0.6489
Epoch: 0360 Model_1_loss: 0.5253 Model_2_loss: 0.5440 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6631 Model_2_val:0.6519
Epoch: 0380 Model_1_loss: 0.4479 Model_2_loss: 0.5338 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6604 Model_2_val:0.6502
Epoch: 0400 Model_1_loss: 0.4744 Model_2_loss: 0.5456 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6631 Model_2_val:0.6460
Model_one_test:0.6811 Model_two_test:0.6752
added by two output: 0.6782
29
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1086193293
Epoch: 0020 Model_1_loss: 1.7052 Model_2_loss: 1.7454 Model_1_trainacc: 0.6083 Model_2_trainacc: 0.4750 Model_1_val:0.3365 Model_2_val:0.2906
Epoch: 0040 Model_1_loss: 1.5197 Model_2_loss: 1.5747 Model_1_trainacc: 0.7750 Model_2_trainacc: 0.7083 Model_1_val:0.4759 Model_2_val:0.4125
Epoch: 0060 Model_1_loss: 1.1754 Model_2_loss: 1.3344 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.6917 Model_1_val:0.5271 Model_2_val:0.4967
Epoch: 0080 Model_1_loss: 0.8922 Model_2_loss: 1.0558 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8417 Model_1_val:0.5578 Model_2_val:0.5215
Epoch: 0100 Model_1_loss: 0.6853 Model_2_loss: 0.7690 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9333 Model_1_val:0.5908 Model_2_val:0.5370
Epoch: 0120 Model_1_loss: 0.5977 Model_2_loss: 0.7100 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9083 Model_1_val:0.5869 Model_2_val:0.5684
Epoch: 0140 Model_1_loss: 0.4811 Model_2_loss: 0.5513 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6073 Model_2_val:0.5822
Epoch: 0160 Model_1_loss: 0.4266 Model_2_loss: 0.5130 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6235 Model_2_val:0.5895
Epoch: 0180 Model_1_loss: 0.3599 Model_2_loss: 0.4488 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6106 Model_2_val:0.5809
Epoch: 0200 Model_1_loss: 0.3535 Model_2_loss: 0.4398 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.5981 Model_2_val:0.5935
Epoch: 0220 Model_1_loss: 0.6973 Model_2_loss: 0.7839 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6549 Model_2_val:0.6486
Epoch: 0240 Model_1_loss: 0.6589 Model_2_loss: 0.7031 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6681 Model_2_val:0.6522
Epoch: 0260 Model_1_loss: 0.6316 Model_2_loss: 0.6571 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6691 Model_2_val:0.6638
Epoch: 0280 Model_1_loss: 0.5564 Model_2_loss: 0.6186 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6664 Model_2_val:0.6618
Epoch: 0300 Model_1_loss: 0.5564 Model_2_loss: 0.6130 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6694 Model_2_val:0.6697
Epoch: 0320 Model_1_loss: 0.5374 Model_2_loss: 0.5513 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6688 Model_2_val:0.6651
Epoch: 0340 Model_1_loss: 0.4809 Model_2_loss: 0.5493 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6658 Model_2_val:0.6707
Epoch: 0360 Model_1_loss: 0.5248 Model_2_loss: 0.5613 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6747 Model_2_val:0.6645
Epoch: 0380 Model_1_loss: 0.4815 Model_2_loss: 0.5383 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6704 Model_2_val:0.6694
Epoch: 0400 Model_1_loss: 0.5093 Model_2_loss: 0.5084 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6714 Model_2_val:0.6737
Model_one_test:0.6939 Model_two_test:0.6912
added by two output: 0.6932
30
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
739522346
Epoch: 0020 Model_1_loss: 1.7144 Model_2_loss: 1.6731 Model_1_trainacc: 0.3500 Model_2_trainacc: 0.5083 Model_1_val:0.2628 Model_2_val:0.3449
Epoch: 0040 Model_1_loss: 1.5452 Model_2_loss: 1.4178 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.8167 Model_1_val:0.4244 Model_2_val:0.4768
Epoch: 0060 Model_1_loss: 1.2297 Model_2_loss: 1.0506 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.9083 Model_1_val:0.5065 Model_2_val:0.5111
Epoch: 0080 Model_1_loss: 0.8919 Model_2_loss: 0.7986 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9167 Model_1_val:0.5183 Model_2_val:0.5311
Epoch: 0100 Model_1_loss: 0.7632 Model_2_loss: 0.6119 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9417 Model_1_val:0.5582 Model_2_val:0.5615
Epoch: 0120 Model_1_loss: 0.6735 Model_2_loss: 0.5125 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5406 Model_2_val:0.5717
Epoch: 0140 Model_1_loss: 0.5132 Model_2_loss: 0.4913 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5661 Model_2_val:0.5756
Epoch: 0160 Model_1_loss: 0.5103 Model_2_loss: 0.4339 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.5707 Model_2_val:0.5946
Epoch: 0180 Model_1_loss: 0.4641 Model_2_loss: 0.4034 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.5602 Model_2_val:0.5942
Epoch: 0200 Model_1_loss: 0.3911 Model_2_loss: 0.3836 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.5789 Model_2_val:0.5884
Epoch: 0220 Model_1_loss: 0.7103 Model_2_loss: 0.6938 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6502 Model_2_val:0.6538
Epoch: 0240 Model_1_loss: 0.7181 Model_2_loss: 0.6547 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.6584 Model_2_val:0.6561
Epoch: 0260 Model_1_loss: 0.6460 Model_2_loss: 0.6552 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.6610 Model_2_val:0.6420
Epoch: 0280 Model_1_loss: 0.5674 Model_2_loss: 0.5387 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6564 Model_2_val:0.6600
Epoch: 0300 Model_1_loss: 0.5855 Model_2_loss: 0.5273 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6646 Model_2_val:0.6538
Epoch: 0320 Model_1_loss: 0.5614 Model_2_loss: 0.5373 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6695 Model_2_val:0.6567
Epoch: 0340 Model_1_loss: 0.4951 Model_2_loss: 0.4760 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6698 Model_2_val:0.6626
Epoch: 0360 Model_1_loss: 0.4647 Model_2_loss: 0.4789 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6594 Model_2_val:0.6528
Epoch: 0380 Model_1_loss: 0.4627 Model_2_loss: 0.4603 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6656 Model_2_val:0.6636
Epoch: 0400 Model_1_loss: 0.4744 Model_2_loss: 0.4392 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6623 Model_2_val:0.6770
Model_one_test:0.6868 Model_two_test:0.6839
added by two output: 0.6855
Model1 Acc: 0.688697 Model2 Acc: 0.689299
Maxacc Mean: 0.690647
[0.6924372651610259, 0.6927043179398544, 0.6923088360447857, 0.6922086163222224, 0.691536895183715, 0.6943443442678022, 0.6918293560174433, 0.6981663724760395, 0.6906473485346307]
Maxacc of all experiments: 0.6981663724760395
1
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
475786316
Epoch: 0020 Model_1_loss: 1.7003 Model_2_loss: 1.7236 Model_1_trainacc: 0.4333 Model_2_trainacc: 0.3583 Model_1_val:0.2508 Model_2_val:0.2703
Epoch: 0040 Model_1_loss: 1.5474 Model_2_loss: 1.5274 Model_1_trainacc: 0.6833 Model_2_trainacc: 0.7750 Model_1_val:0.4048 Model_2_val:0.4126
Epoch: 0060 Model_1_loss: 1.3205 Model_2_loss: 1.2338 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8167 Model_1_val:0.4582 Model_2_val:0.5107
Epoch: 0080 Model_1_loss: 1.0923 Model_2_loss: 1.0086 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8667 Model_1_val:0.5437 Model_2_val:0.5462
Epoch: 0100 Model_1_loss: 0.9127 Model_2_loss: 0.8068 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.9083 Model_1_val:0.5446 Model_2_val:0.5591
Epoch: 0120 Model_1_loss: 0.8554 Model_2_loss: 0.6567 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9167 Model_1_val:0.5509 Model_2_val:0.5757
Epoch: 0140 Model_1_loss: 0.7136 Model_2_loss: 0.5827 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9667 Model_1_val:0.5723 Model_2_val:0.5930
Epoch: 0160 Model_1_loss: 0.6554 Model_2_loss: 0.5218 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9667 Model_1_val:0.5651 Model_2_val:0.5952
Epoch: 0180 Model_1_loss: 0.5930 Model_2_loss: 0.4746 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9917 Model_1_val:0.5830 Model_2_val:0.6009
Epoch: 0200 Model_1_loss: 0.5290 Model_2_loss: 0.3904 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5717 Model_2_val:0.6072
Epoch: 0220 Model_1_loss: 0.9264 Model_2_loss: 0.8261 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6449 Model_2_val:0.6493
Epoch: 0240 Model_1_loss: 0.8639 Model_2_loss: 0.6939 Model_1_trainacc: 0.9500 Model_2_trainacc: 1.0000 Model_1_val:0.6521 Model_2_val:0.6540
Epoch: 0260 Model_1_loss: 0.7870 Model_2_loss: 0.7040 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6559 Model_2_val:0.6700
Epoch: 0280 Model_1_loss: 0.8375 Model_2_loss: 0.6756 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6471 Model_2_val:0.6728
Epoch: 0300 Model_1_loss: 0.7705 Model_2_loss: 0.6272 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6549 Model_2_val:0.6747
Epoch: 0320 Model_1_loss: 0.7147 Model_2_loss: 0.5674 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6521 Model_2_val:0.6766
Epoch: 0340 Model_1_loss: 0.7061 Model_2_loss: 0.5861 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.6596 Model_2_val:0.6669
Epoch: 0360 Model_1_loss: 0.6562 Model_2_loss: 0.5587 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9917 Model_1_val:0.6688 Model_2_val:0.6779
Epoch: 0380 Model_1_loss: 0.5971 Model_2_loss: 0.5451 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6549 Model_2_val:0.6675
Epoch: 0400 Model_1_loss: 0.4995 Model_2_loss: 0.5225 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6640 Model_2_val:0.6631
Model_one_test:0.6926 Model_two_test:0.6933
added by two output: 0.6923
2
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
14155212
Epoch: 0020 Model_1_loss: 1.7344 Model_2_loss: 1.7573 Model_1_trainacc: 0.4250 Model_2_trainacc: 0.2500 Model_1_val:0.3033 Model_2_val:0.2231
Epoch: 0040 Model_1_loss: 1.5745 Model_2_loss: 1.6545 Model_1_trainacc: 0.7167 Model_2_trainacc: 0.5833 Model_1_val:0.4088 Model_2_val:0.3684
Epoch: 0060 Model_1_loss: 1.2700 Model_2_loss: 1.4075 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.7667 Model_1_val:0.5040 Model_2_val:0.4830
Epoch: 0080 Model_1_loss: 0.9223 Model_2_loss: 1.0375 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9000 Model_1_val:0.5351 Model_2_val:0.5264
Epoch: 0100 Model_1_loss: 0.7877 Model_2_loss: 0.7992 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8917 Model_1_val:0.5611 Model_2_val:0.5474
Epoch: 0120 Model_1_loss: 0.6324 Model_2_loss: 0.6753 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.5842 Model_2_val:0.5635
Epoch: 0140 Model_1_loss: 0.5730 Model_2_loss: 0.5479 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.5945 Model_2_val:0.5908
Epoch: 0160 Model_1_loss: 0.5345 Model_2_loss: 0.5032 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9500 Model_1_val:0.5959 Model_2_val:0.5898
Epoch: 0180 Model_1_loss: 0.4533 Model_2_loss: 0.5071 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9250 Model_1_val:0.5949 Model_2_val:0.5858
Epoch: 0200 Model_1_loss: 0.4235 Model_2_loss: 0.4740 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.6152 Model_2_val:0.5935
Epoch: 0220 Model_1_loss: 0.7788 Model_2_loss: 0.7716 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9917 Model_1_val:0.6593 Model_2_val:0.6597
Epoch: 0240 Model_1_loss: 0.6802 Model_2_loss: 0.6994 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6733 Model_2_val:0.6540
Epoch: 0260 Model_1_loss: 0.6312 Model_2_loss: 0.6592 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6764 Model_2_val:0.6583
Epoch: 0280 Model_1_loss: 0.5742 Model_2_loss: 0.6524 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6693 Model_2_val:0.6617
Epoch: 0300 Model_1_loss: 0.5878 Model_2_loss: 0.6339 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.6794 Model_2_val:0.6680
Epoch: 0320 Model_1_loss: 0.4934 Model_2_loss: 0.6289 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6804 Model_2_val:0.6727
Epoch: 0340 Model_1_loss: 0.4952 Model_2_loss: 0.5741 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6740 Model_2_val:0.6637
Epoch: 0360 Model_1_loss: 0.5133 Model_2_loss: 0.5591 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6620 Model_2_val:0.6513
Epoch: 0380 Model_1_loss: 0.4769 Model_2_loss: 0.5735 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6774 Model_2_val:0.6597
Epoch: 0400 Model_1_loss: 0.4281 Model_2_loss: 0.5025 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9583 Model_1_val:0.6703 Model_2_val:0.6743
Model_one_test:0.6917 Model_two_test:0.6884
added by two output: 0.6914
3
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1138348902
Epoch: 0020 Model_1_loss: 1.7623 Model_2_loss: 1.7099 Model_1_trainacc: 0.3250 Model_2_trainacc: 0.4250 Model_1_val:0.2052 Model_2_val:0.2817
Epoch: 0040 Model_1_loss: 1.6816 Model_2_loss: 1.5403 Model_1_trainacc: 0.5833 Model_2_trainacc: 0.7667 Model_1_val:0.3481 Model_2_val:0.4608
Epoch: 0060 Model_1_loss: 1.4525 Model_2_loss: 1.2053 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.9083 Model_1_val:0.4550 Model_2_val:0.4888
Epoch: 0080 Model_1_loss: 1.1030 Model_2_loss: 0.9440 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8667 Model_1_val:0.5297 Model_2_val:0.5396
Epoch: 0100 Model_1_loss: 0.8095 Model_2_loss: 0.6664 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.5632 Model_2_val:0.5740
Epoch: 0120 Model_1_loss: 0.6547 Model_2_loss: 0.5829 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.5753 Model_2_val:0.5664
Epoch: 0140 Model_1_loss: 0.5403 Model_2_loss: 0.5286 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.5750 Model_2_val:0.5865
Epoch: 0160 Model_1_loss: 0.4514 Model_2_loss: 0.4543 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6075 Model_2_val:0.5785
Epoch: 0180 Model_1_loss: 0.4160 Model_2_loss: 0.4320 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.5973 Model_2_val:0.5702
Epoch: 0200 Model_1_loss: 0.3966 Model_2_loss: 0.3872 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6002 Model_2_val:0.5759
Epoch: 0220 Model_1_loss: 0.6786 Model_2_loss: 0.7469 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.6583 Model_2_val:0.6560
Epoch: 0240 Model_1_loss: 0.6204 Model_2_loss: 0.6734 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6599 Model_2_val:0.6439
Epoch: 0260 Model_1_loss: 0.5731 Model_2_loss: 0.6137 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6599 Model_2_val:0.6477
Epoch: 0280 Model_1_loss: 0.5421 Model_2_loss: 0.6014 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6611 Model_2_val:0.6567
Epoch: 0300 Model_1_loss: 0.5598 Model_2_loss: 0.5319 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6777 Model_2_val:0.6611
Epoch: 0320 Model_1_loss: 0.5142 Model_2_loss: 0.4916 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9917 Model_1_val:0.6650 Model_2_val:0.6653
Epoch: 0340 Model_1_loss: 0.4646 Model_2_loss: 0.4693 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6646 Model_2_val:0.6688
Epoch: 0360 Model_1_loss: 0.4791 Model_2_loss: 0.4476 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6780 Model_2_val:0.6576
Epoch: 0380 Model_1_loss: 0.5022 Model_2_loss: 0.4994 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6666 Model_2_val:0.6774
Epoch: 0400 Model_1_loss: 0.4705 Model_2_loss: 0.4750 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6707 Model_2_val:0.6573
Model_one_test:0.6969 Model_two_test:0.6934
added by two output: 0.6927
4
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
943660709
Epoch: 0020 Model_1_loss: 1.7219 Model_2_loss: 1.7602 Model_1_trainacc: 0.4667 Model_2_trainacc: 0.2167 Model_1_val:0.2489 Model_2_val:0.2204
Epoch: 0040 Model_1_loss: 1.5385 Model_2_loss: 1.6453 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.6417 Model_1_val:0.4339 Model_2_val:0.3665
Epoch: 0060 Model_1_loss: 1.2957 Model_2_loss: 1.4077 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.7583 Model_1_val:0.5105 Model_2_val:0.4716
Epoch: 0080 Model_1_loss: 1.0217 Model_2_loss: 1.0458 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8500 Model_1_val:0.5054 Model_2_val:0.5042
Epoch: 0100 Model_1_loss: 0.8503 Model_2_loss: 0.8390 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9083 Model_1_val:0.5211 Model_2_val:0.5230
Epoch: 0120 Model_1_loss: 0.6812 Model_2_loss: 0.6561 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5649 Model_2_val:0.5527
Epoch: 0140 Model_1_loss: 0.6066 Model_2_loss: 0.5523 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.5604 Model_2_val:0.5677
Epoch: 0160 Model_1_loss: 0.5392 Model_2_loss: 0.5238 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5658 Model_2_val:0.5681
Epoch: 0180 Model_1_loss: 0.4412 Model_2_loss: 0.4622 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9750 Model_1_val:0.5818 Model_2_val:0.5588
Epoch: 0200 Model_1_loss: 0.4130 Model_2_loss: 0.4747 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5965 Model_2_val:0.5764
Epoch: 0220 Model_1_loss: 0.7973 Model_2_loss: 0.7761 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6339 Model_2_val:0.6450
Epoch: 0240 Model_1_loss: 0.6907 Model_2_loss: 0.6861 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6581 Model_2_val:0.6623
Epoch: 0260 Model_1_loss: 0.6552 Model_2_loss: 0.7061 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6581 Model_2_val:0.6652
Epoch: 0280 Model_1_loss: 0.6242 Model_2_loss: 0.6512 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6524 Model_2_val:0.6677
Epoch: 0300 Model_1_loss: 0.6152 Model_2_loss: 0.6301 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6642 Model_2_val:0.6585
Epoch: 0320 Model_1_loss: 0.6037 Model_2_loss: 0.5654 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6540 Model_2_val:0.6588
Epoch: 0340 Model_1_loss: 0.5452 Model_2_loss: 0.6041 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6572 Model_2_val:0.6639
Epoch: 0360 Model_1_loss: 0.4971 Model_2_loss: 0.5355 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6645 Model_2_val:0.6629
Epoch: 0380 Model_1_loss: 0.5164 Model_2_loss: 0.5425 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6473 Model_2_val:0.6591
Epoch: 0400 Model_1_loss: 0.5340 Model_2_loss: 0.5105 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6613 Model_2_val:0.6607
Model_one_test:0.6850 Model_two_test:0.6847
added by two output: 0.6875
5
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
115640931
Epoch: 0020 Model_1_loss: 1.7165 Model_2_loss: 1.7459 Model_1_trainacc: 0.4417 Model_2_trainacc: 0.3167 Model_1_val:0.2524 Model_2_val:0.2359
Epoch: 0040 Model_1_loss: 1.5298 Model_2_loss: 1.5962 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.6417 Model_1_val:0.3885 Model_2_val:0.3684
Epoch: 0060 Model_1_loss: 1.2692 Model_2_loss: 1.3662 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8333 Model_1_val:0.4807 Model_2_val:0.4790
Epoch: 0080 Model_1_loss: 0.9585 Model_2_loss: 1.0282 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8917 Model_1_val:0.5395 Model_2_val:0.5355
Epoch: 0100 Model_1_loss: 0.8395 Model_2_loss: 0.8010 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9000 Model_1_val:0.5358 Model_2_val:0.5464
Epoch: 0120 Model_1_loss: 0.6886 Model_2_loss: 0.6668 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9333 Model_1_val:0.5748 Model_2_val:0.5692
Epoch: 0140 Model_1_loss: 0.6085 Model_2_loss: 0.5644 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5864 Model_2_val:0.5844
Epoch: 0160 Model_1_loss: 0.5727 Model_2_loss: 0.5189 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9583 Model_1_val:0.5814 Model_2_val:0.5824
Epoch: 0180 Model_1_loss: 0.4455 Model_2_loss: 0.4835 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.5728 Model_2_val:0.5900
Epoch: 0200 Model_1_loss: 0.4637 Model_2_loss: 0.3943 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5705 Model_2_val:0.6098
Epoch: 0220 Model_1_loss: 0.8124 Model_2_loss: 0.8059 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6472 Model_2_val:0.6673
Epoch: 0240 Model_1_loss: 0.7650 Model_2_loss: 0.7836 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6515 Model_2_val:0.6667
Epoch: 0260 Model_1_loss: 0.7200 Model_2_loss: 0.7512 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.6663 Model_2_val:0.6749
Epoch: 0280 Model_1_loss: 0.6680 Model_2_loss: 0.6830 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6700 Model_2_val:0.6660
Epoch: 0300 Model_1_loss: 0.6620 Model_2_loss: 0.7116 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9250 Model_1_val:0.6686 Model_2_val:0.6624
Epoch: 0320 Model_1_loss: 0.5732 Model_2_loss: 0.6593 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6713 Model_2_val:0.6716
Epoch: 0340 Model_1_loss: 0.5446 Model_2_loss: 0.6238 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6710 Model_2_val:0.6720
Epoch: 0360 Model_1_loss: 0.5511 Model_2_loss: 0.5700 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6614 Model_2_val:0.6743
Epoch: 0380 Model_1_loss: 0.5403 Model_2_loss: 0.5406 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6729 Model_2_val:0.6617
Epoch: 0400 Model_1_loss: 0.5394 Model_2_loss: 0.5342 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6703 Model_2_val:0.6743
Model_one_test:0.6941 Model_two_test:0.6994
added by two output: 0.6964
6
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
686224223
Epoch: 0020 Model_1_loss: 1.7426 Model_2_loss: 1.7477 Model_1_trainacc: 0.3583 Model_2_trainacc: 0.2833 Model_1_val:0.2456 Model_2_val:0.2268
Epoch: 0040 Model_1_loss: 1.5894 Model_2_loss: 1.6231 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.6917 Model_1_val:0.3992 Model_2_val:0.3915
Epoch: 0060 Model_1_loss: 1.2749 Model_2_loss: 1.4186 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.7750 Model_1_val:0.4911 Model_2_val:0.4646
Epoch: 0080 Model_1_loss: 0.9557 Model_2_loss: 1.1725 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8750 Model_1_val:0.5334 Model_2_val:0.4710
Epoch: 0100 Model_1_loss: 0.7155 Model_2_loss: 0.9577 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.8833 Model_1_val:0.5391 Model_2_val:0.5025
Epoch: 0120 Model_1_loss: 0.6150 Model_2_loss: 0.7964 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9167 Model_1_val:0.5498 Model_2_val:0.5159
Epoch: 0140 Model_1_loss: 0.5228 Model_2_loss: 0.7287 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9250 Model_1_val:0.5599 Model_2_val:0.5307
Epoch: 0160 Model_1_loss: 0.4821 Model_2_loss: 0.6685 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.8917 Model_1_val:0.5592 Model_2_val:0.5153
Epoch: 0180 Model_1_loss: 0.5015 Model_2_loss: 0.5910 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9167 Model_1_val:0.5528 Model_2_val:0.5253
Epoch: 0200 Model_1_loss: 0.4333 Model_2_loss: 0.5204 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9167 Model_1_val:0.5663 Model_2_val:0.5642
Epoch: 0220 Model_1_loss: 0.7703 Model_2_loss: 0.7640 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6209 Model_2_val:0.6095
Epoch: 0240 Model_1_loss: 0.7150 Model_2_loss: 0.7769 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6448 Model_2_val:0.6203
Epoch: 0260 Model_1_loss: 0.6686 Model_2_loss: 0.6880 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6323 Model_2_val:0.6307
Epoch: 0280 Model_1_loss: 0.6256 Model_2_loss: 0.6759 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6360 Model_2_val:0.6367
Epoch: 0300 Model_1_loss: 0.6449 Model_2_loss: 0.5955 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6307 Model_2_val:0.6333
Epoch: 0320 Model_1_loss: 0.6052 Model_2_loss: 0.5709 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6283 Model_2_val:0.6337
Epoch: 0340 Model_1_loss: 0.5369 Model_2_loss: 0.5388 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6364 Model_2_val:0.6357
Epoch: 0360 Model_1_loss: 0.5490 Model_2_loss: 0.5289 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6360 Model_2_val:0.6360
Epoch: 0380 Model_1_loss: 0.5586 Model_2_loss: 0.5237 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6327 Model_2_val:0.6340
Epoch: 0400 Model_1_loss: 0.5042 Model_2_loss: 0.5252 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.6411 Model_2_val:0.6286
Model_one_test:0.6659 Model_two_test:0.6635
added by two output: 0.6642
7
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
736506249
Epoch: 0020 Model_1_loss: 1.7169 Model_2_loss: 1.7200 Model_1_trainacc: 0.3833 Model_2_trainacc: 0.4083 Model_1_val:0.2291 Model_2_val:0.2361
Epoch: 0040 Model_1_loss: 1.5333 Model_2_loss: 1.5775 Model_1_trainacc: 0.7417 Model_2_trainacc: 0.6750 Model_1_val:0.4587 Model_2_val:0.3603
Epoch: 0060 Model_1_loss: 1.1981 Model_2_loss: 1.3380 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8417 Model_1_val:0.5011 Model_2_val:0.4728
Epoch: 0080 Model_1_loss: 0.9589 Model_2_loss: 1.0533 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9083 Model_1_val:0.5470 Model_2_val:0.5062
Epoch: 0100 Model_1_loss: 0.7528 Model_2_loss: 0.8645 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.8833 Model_1_val:0.5460 Model_2_val:0.5355
Epoch: 0120 Model_1_loss: 0.6407 Model_2_loss: 0.7894 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9250 Model_1_val:0.5699 Model_2_val:0.5282
Epoch: 0140 Model_1_loss: 0.5796 Model_2_loss: 0.6228 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5868 Model_2_val:0.5569
Epoch: 0160 Model_1_loss: 0.5365 Model_2_loss: 0.5842 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9333 Model_1_val:0.5785 Model_2_val:0.5594
Epoch: 0180 Model_1_loss: 0.4778 Model_2_loss: 0.5124 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9167 Model_1_val:0.5948 Model_2_val:0.5702
Epoch: 0200 Model_1_loss: 0.4131 Model_2_loss: 0.4538 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.5996 Model_2_val:0.5945
Epoch: 0220 Model_1_loss: 0.7045 Model_2_loss: 0.8167 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6470 Model_2_val:0.6375
Epoch: 0240 Model_1_loss: 0.6898 Model_2_loss: 0.6822 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6610 Model_2_val:0.6464
Epoch: 0260 Model_1_loss: 0.6112 Model_2_loss: 0.6588 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6524 Model_2_val:0.6426
Epoch: 0280 Model_1_loss: 0.6650 Model_2_loss: 0.6615 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6547 Model_2_val:0.6489
Epoch: 0300 Model_1_loss: 0.5688 Model_2_loss: 0.5981 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6575 Model_2_val:0.6499
Epoch: 0320 Model_1_loss: 0.5933 Model_2_loss: 0.5193 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6432 Model_2_val:0.6582
Epoch: 0340 Model_1_loss: 0.5479 Model_2_loss: 0.5637 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6477 Model_2_val:0.6598
Epoch: 0360 Model_1_loss: 0.5118 Model_2_loss: 0.4850 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6502 Model_2_val:0.6594
Epoch: 0380 Model_1_loss: 0.5387 Model_2_loss: 0.5143 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6457 Model_2_val:0.6486
Epoch: 0400 Model_1_loss: 0.4935 Model_2_loss: 0.4476 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6515 Model_2_val:0.6588
Model_one_test:0.6754 Model_two_test:0.6802
added by two output: 0.6757
8
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
466856288
Epoch: 0020 Model_1_loss: 1.7457 Model_2_loss: 1.7206 Model_1_trainacc: 0.3250 Model_2_trainacc: 0.3917 Model_1_val:0.2152 Model_2_val:0.2494
Epoch: 0040 Model_1_loss: 1.5936 Model_2_loss: 1.5373 Model_1_trainacc: 0.7417 Model_2_trainacc: 0.7250 Model_1_val:0.4531 Model_2_val:0.4273
Epoch: 0060 Model_1_loss: 1.3733 Model_2_loss: 1.2236 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8667 Model_1_val:0.5175 Model_2_val:0.5163
Epoch: 0080 Model_1_loss: 1.1082 Model_2_loss: 0.9647 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8583 Model_1_val:0.5561 Model_2_val:0.5558
Epoch: 0100 Model_1_loss: 0.8712 Model_2_loss: 0.7303 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9250 Model_1_val:0.5682 Model_2_val:0.5791
Epoch: 0120 Model_1_loss: 0.6996 Model_2_loss: 0.6209 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9500 Model_1_val:0.5867 Model_2_val:0.5772
Epoch: 0140 Model_1_loss: 0.6145 Model_2_loss: 0.5159 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6078 Model_2_val:0.6158
Epoch: 0160 Model_1_loss: 0.5388 Model_2_loss: 0.4610 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9667 Model_1_val:0.5989 Model_2_val:0.6107
Epoch: 0180 Model_1_loss: 0.5019 Model_2_loss: 0.4079 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.6087 Model_2_val:0.6091
Epoch: 0200 Model_1_loss: 0.4255 Model_2_loss: 0.3701 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.6065 Model_2_val:0.6145
Epoch: 0220 Model_1_loss: 0.7141 Model_2_loss: 0.6675 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6843 Model_2_val:0.6706
Epoch: 0240 Model_1_loss: 0.6408 Model_2_loss: 0.6342 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6891 Model_2_val:0.6716
Epoch: 0260 Model_1_loss: 0.6250 Model_2_loss: 0.5761 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6843 Model_2_val:0.6865
Epoch: 0280 Model_1_loss: 0.5763 Model_2_loss: 0.5723 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6760 Model_2_val:0.6830
Epoch: 0300 Model_1_loss: 0.5949 Model_2_loss: 0.5483 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6818 Model_2_val:0.6856
Epoch: 0320 Model_1_loss: 0.5204 Model_2_loss: 0.4934 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6869 Model_2_val:0.6805
Epoch: 0340 Model_1_loss: 0.4862 Model_2_loss: 0.5104 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6834 Model_2_val:0.6744
Epoch: 0360 Model_1_loss: 0.5094 Model_2_loss: 0.4488 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6824 Model_2_val:0.6757
Epoch: 0380 Model_1_loss: 0.5130 Model_2_loss: 0.4625 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6849 Model_2_val:0.6814
Epoch: 0400 Model_1_loss: 0.4786 Model_2_loss: 0.4033 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6808 Model_2_val:0.6834
Model_one_test:0.6983 Model_two_test:0.7034
added by two output: 0.7006
9
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
19445022
Epoch: 0020 Model_1_loss: 1.7018 Model_2_loss: 1.7292 Model_1_trainacc: 0.4500 Model_2_trainacc: 0.3333 Model_1_val:0.2871 Model_2_val:0.1949
Epoch: 0040 Model_1_loss: 1.4640 Model_2_loss: 1.5269 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.7833 Model_1_val:0.4226 Model_2_val:0.4114
Epoch: 0060 Model_1_loss: 1.1030 Model_2_loss: 1.2177 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8667 Model_1_val:0.5276 Model_2_val:0.5062
Epoch: 0080 Model_1_loss: 0.8796 Model_2_loss: 0.9586 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8917 Model_1_val:0.5669 Model_2_val:0.5548
Epoch: 0100 Model_1_loss: 0.6820 Model_2_loss: 0.7443 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9250 Model_1_val:0.5846 Model_2_val:0.5584
Epoch: 0120 Model_1_loss: 0.5465 Model_2_loss: 0.6518 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9250 Model_1_val:0.5997 Model_2_val:0.5863
Epoch: 0140 Model_1_loss: 0.4653 Model_2_loss: 0.5556 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6165 Model_2_val:0.6037
Epoch: 0160 Model_1_loss: 0.4270 Model_2_loss: 0.5063 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6004 Model_2_val:0.5994
Epoch: 0180 Model_1_loss: 0.4254 Model_2_loss: 0.4384 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6056 Model_2_val:0.6070
Epoch: 0200 Model_1_loss: 0.3742 Model_2_loss: 0.3969 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6050 Model_2_val:0.6211
Epoch: 0220 Model_1_loss: 0.7240 Model_2_loss: 0.7463 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6732 Model_2_val:0.6631
Epoch: 0240 Model_1_loss: 0.6419 Model_2_loss: 0.6459 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6690 Model_2_val:0.6699
Epoch: 0260 Model_1_loss: 0.5857 Model_2_loss: 0.6334 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6841 Model_2_val:0.6850
Epoch: 0280 Model_1_loss: 0.5512 Model_2_loss: 0.5879 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6732 Model_2_val:0.6673
Epoch: 0300 Model_1_loss: 0.5197 Model_2_loss: 0.5446 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6831 Model_2_val:0.6722
Epoch: 0320 Model_1_loss: 0.5355 Model_2_loss: 0.5324 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6759 Model_2_val:0.6844
Epoch: 0340 Model_1_loss: 0.4779 Model_2_loss: 0.5311 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6709 Model_2_val:0.6726
Epoch: 0360 Model_1_loss: 0.4862 Model_2_loss: 0.4776 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6788 Model_2_val:0.6716
Epoch: 0380 Model_1_loss: 0.5000 Model_2_loss: 0.4855 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6804 Model_2_val:0.6604
Epoch: 0400 Model_1_loss: 0.4917 Model_2_loss: 0.5390 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6755 Model_2_val:0.6634
Model_one_test:0.6952 Model_two_test:0.6965
added by two output: 0.6946
10
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1443598946
Epoch: 0020 Model_1_loss: 1.6839 Model_2_loss: 1.7095 Model_1_trainacc: 0.6417 Model_2_trainacc: 0.4750 Model_1_val:0.3422 Model_2_val:0.3079
Epoch: 0040 Model_1_loss: 1.4307 Model_2_loss: 1.5053 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.7333 Model_1_val:0.4722 Model_2_val:0.4069
Epoch: 0060 Model_1_loss: 1.1219 Model_2_loss: 1.2165 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8417 Model_1_val:0.4958 Model_2_val:0.4806
Epoch: 0080 Model_1_loss: 0.8466 Model_2_loss: 0.9478 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.8750 Model_1_val:0.5294 Model_2_val:0.5220
Epoch: 0100 Model_1_loss: 0.6986 Model_2_loss: 0.7270 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.5540 Model_2_val:0.5398
Epoch: 0120 Model_1_loss: 0.5569 Model_2_loss: 0.5708 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.5627 Model_2_val:0.5792
Epoch: 0140 Model_1_loss: 0.5410 Model_2_loss: 0.5489 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9250 Model_1_val:0.5831 Model_2_val:0.5886
Epoch: 0160 Model_1_loss: 0.4285 Model_2_loss: 0.4283 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5702 Model_2_val:0.5737
Epoch: 0180 Model_1_loss: 0.4623 Model_2_loss: 0.4047 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.5831 Model_2_val:0.5821
Epoch: 0200 Model_1_loss: 0.3978 Model_2_loss: 0.3731 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.5666 Model_2_val:0.6028
Epoch: 0220 Model_1_loss: 0.6910 Model_2_loss: 0.8172 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6452 Model_2_val:0.6588
Epoch: 0240 Model_1_loss: 0.6646 Model_2_loss: 0.6450 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6417 Model_2_val:0.6552
Epoch: 0260 Model_1_loss: 0.6638 Model_2_loss: 0.6552 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6404 Model_2_val:0.6575
Epoch: 0280 Model_1_loss: 0.6428 Model_2_loss: 0.6104 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6510 Model_2_val:0.6620
Epoch: 0300 Model_1_loss: 0.5894 Model_2_loss: 0.5685 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6539 Model_2_val:0.6394
Epoch: 0320 Model_1_loss: 0.5863 Model_2_loss: 0.6076 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6368 Model_2_val:0.6510
Epoch: 0340 Model_1_loss: 0.5461 Model_2_loss: 0.5777 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6488 Model_2_val:0.6488
Epoch: 0360 Model_1_loss: 0.4866 Model_2_loss: 0.5450 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6546 Model_2_val:0.6433
Epoch: 0380 Model_1_loss: 0.4580 Model_2_loss: 0.5209 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6478 Model_2_val:0.6362
Epoch: 0400 Model_1_loss: 0.4713 Model_2_loss: 0.5022 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6520 Model_2_val:0.6459
Model_one_test:0.6691 Model_two_test:0.6708
added by two output: 0.6679
11
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
715573062
Epoch: 0020 Model_1_loss: 1.7298 Model_2_loss: 1.6882 Model_1_trainacc: 0.3583 Model_2_trainacc: 0.5500 Model_1_val:0.2588 Model_2_val:0.2837
Epoch: 0040 Model_1_loss: 1.5713 Model_2_loss: 1.4523 Model_1_trainacc: 0.6667 Model_2_trainacc: 0.8583 Model_1_val:0.3837 Model_2_val:0.4568
Epoch: 0060 Model_1_loss: 1.3306 Model_2_loss: 1.1265 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.8583 Model_1_val:0.4672 Model_2_val:0.5125
Epoch: 0080 Model_1_loss: 1.0239 Model_2_loss: 0.7994 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9250 Model_1_val:0.5070 Model_2_val:0.5519
Epoch: 0100 Model_1_loss: 0.7968 Model_2_loss: 0.6272 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5209 Model_2_val:0.5720
Epoch: 0120 Model_1_loss: 0.6669 Model_2_loss: 0.5282 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.5665 Model_2_val:0.5823
Epoch: 0140 Model_1_loss: 0.6180 Model_2_loss: 0.4476 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.5662 Model_2_val:0.5859
Epoch: 0160 Model_1_loss: 0.4810 Model_2_loss: 0.3975 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.5710 Model_2_val:0.5823
Epoch: 0180 Model_1_loss: 0.5133 Model_2_loss: 0.3487 Model_1_trainacc: 0.9167 Model_2_trainacc: 1.0000 Model_1_val:0.5678 Model_2_val:0.5930
Epoch: 0200 Model_1_loss: 0.4051 Model_2_loss: 0.3251 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.5882 Model_2_val:0.5985
Epoch: 0220 Model_1_loss: 0.7271 Model_2_loss: 0.6932 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6435 Model_2_val:0.6432
Epoch: 0240 Model_1_loss: 0.6573 Model_2_loss: 0.6442 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6347 Model_2_val:0.6467
Epoch: 0260 Model_1_loss: 0.6187 Model_2_loss: 0.6058 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6503 Model_2_val:0.6574
Epoch: 0280 Model_1_loss: 0.5974 Model_2_loss: 0.5654 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6470 Model_2_val:0.6590
Epoch: 0300 Model_1_loss: 0.5774 Model_2_loss: 0.5569 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6383 Model_2_val:0.6632
Epoch: 0320 Model_1_loss: 0.5314 Model_2_loss: 0.5485 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6480 Model_2_val:0.6600
Epoch: 0340 Model_1_loss: 0.5376 Model_2_loss: 0.4619 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6558 Model_2_val:0.6561
Epoch: 0360 Model_1_loss: 0.5814 Model_2_loss: 0.4847 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6467 Model_2_val:0.6542
Epoch: 0380 Model_1_loss: 0.5306 Model_2_loss: 0.4763 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6613 Model_2_val:0.6671
Epoch: 0400 Model_1_loss: 0.5295 Model_2_loss: 0.4372 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6639 Model_2_val:0.6642
Model_one_test:0.6813 Model_two_test:0.6775
added by two output: 0.6807
12
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
729070142
Epoch: 0020 Model_1_loss: 1.7239 Model_2_loss: 1.6785 Model_1_trainacc: 0.4583 Model_2_trainacc: 0.4250 Model_1_val:0.2853 Model_2_val:0.2460
Epoch: 0040 Model_1_loss: 1.5073 Model_2_loss: 1.4441 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8333 Model_1_val:0.4158 Model_2_val:0.3977
Epoch: 0060 Model_1_loss: 1.1592 Model_2_loss: 1.0751 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9250 Model_1_val:0.5162 Model_2_val:0.4916
Epoch: 0080 Model_1_loss: 0.8323 Model_2_loss: 0.7731 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.5401 Model_2_val:0.5210
Epoch: 0100 Model_1_loss: 0.6256 Model_2_loss: 0.6249 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9750 Model_1_val:0.5630 Model_2_val:0.5743
Epoch: 0120 Model_1_loss: 0.5247 Model_2_loss: 0.5259 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5764 Model_2_val:0.5692
Epoch: 0140 Model_1_loss: 0.4524 Model_2_loss: 0.4750 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.5962 Model_2_val:0.5668
Epoch: 0160 Model_1_loss: 0.4185 Model_2_loss: 0.4570 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.5914 Model_2_val:0.5815
Epoch: 0180 Model_1_loss: 0.3448 Model_2_loss: 0.3857 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.5948 Model_2_val:0.5767
Epoch: 0200 Model_1_loss: 0.3269 Model_2_loss: 0.3443 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.5986 Model_2_val:0.5842
Epoch: 0220 Model_1_loss: 0.6149 Model_2_loss: 0.6930 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6549 Model_2_val:0.6607
Epoch: 0240 Model_1_loss: 0.5576 Model_2_loss: 0.5660 Model_1_trainacc: 0.9917 Model_2_trainacc: 1.0000 Model_1_val:0.6666 Model_2_val:0.6594
Epoch: 0260 Model_1_loss: 0.5277 Model_2_loss: 0.5152 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6666 Model_2_val:0.6672
Epoch: 0280 Model_1_loss: 0.4960 Model_2_loss: 0.4953 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6775 Model_2_val:0.6638
Epoch: 0300 Model_1_loss: 0.4777 Model_2_loss: 0.4827 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6700 Model_2_val:0.6601
Epoch: 0320 Model_1_loss: 0.4994 Model_2_loss: 0.4836 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6720 Model_2_val:0.6628
Epoch: 0340 Model_1_loss: 0.4584 Model_2_loss: 0.4630 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6669 Model_2_val:0.6655
Epoch: 0360 Model_1_loss: 0.4437 Model_2_loss: 0.4280 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6607 Model_2_val:0.6597
Epoch: 0380 Model_1_loss: 0.4402 Model_2_loss: 0.4085 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6611 Model_2_val:0.6724
Epoch: 0400 Model_1_loss: 0.4020 Model_2_loss: 0.4134 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6744 Model_2_val:0.6607
Model_one_test:0.6874 Model_two_test:0.6894
added by two output: 0.6881
13
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
813150962
Epoch: 0020 Model_1_loss: 1.7147 Model_2_loss: 1.7179 Model_1_trainacc: 0.4083 Model_2_trainacc: 0.3500 Model_1_val:0.2959 Model_2_val:0.1904
Epoch: 0040 Model_1_loss: 1.5037 Model_2_loss: 1.5872 Model_1_trainacc: 0.7583 Model_2_trainacc: 0.6750 Model_1_val:0.4111 Model_2_val:0.3366
Epoch: 0060 Model_1_loss: 1.2283 Model_2_loss: 1.3259 Model_1_trainacc: 0.8083 Model_2_trainacc: 0.7583 Model_1_val:0.4877 Model_2_val:0.4101
Epoch: 0080 Model_1_loss: 0.9485 Model_2_loss: 1.1389 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.7917 Model_1_val:0.5320 Model_2_val:0.4794
Epoch: 0100 Model_1_loss: 0.7807 Model_2_loss: 0.9594 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8750 Model_1_val:0.5639 Model_2_val:0.5526
Epoch: 0120 Model_1_loss: 0.6291 Model_2_loss: 0.7327 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9250 Model_1_val:0.5872 Model_2_val:0.5536
Epoch: 0140 Model_1_loss: 0.5493 Model_2_loss: 0.6674 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.8750 Model_1_val:0.5699 Model_2_val:0.5619
Epoch: 0160 Model_1_loss: 0.4400 Model_2_loss: 0.5149 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.5882 Model_2_val:0.5599
Epoch: 0180 Model_1_loss: 0.4048 Model_2_loss: 0.4870 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6065 Model_2_val:0.5789
Epoch: 0200 Model_1_loss: 0.3616 Model_2_loss: 0.5211 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9250 Model_1_val:0.6052 Model_2_val:0.5702
Epoch: 0220 Model_1_loss: 0.7484 Model_2_loss: 0.8714 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9417 Model_1_val:0.6525 Model_2_val:0.6428
Epoch: 0240 Model_1_loss: 0.6791 Model_2_loss: 0.8176 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9333 Model_1_val:0.6625 Model_2_val:0.6578
Epoch: 0260 Model_1_loss: 0.7101 Model_2_loss: 0.7395 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6628 Model_2_val:0.6435
Epoch: 0280 Model_1_loss: 0.6199 Model_2_loss: 0.7292 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9500 Model_1_val:0.6578 Model_2_val:0.6468
Epoch: 0300 Model_1_loss: 0.6026 Model_2_loss: 0.6703 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6651 Model_2_val:0.6551
Epoch: 0320 Model_1_loss: 0.5494 Model_2_loss: 0.6254 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6718 Model_2_val:0.6714
Epoch: 0340 Model_1_loss: 0.5703 Model_2_loss: 0.5456 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6575 Model_2_val:0.6585
Epoch: 0360 Model_1_loss: 0.5070 Model_2_loss: 0.5490 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6651 Model_2_val:0.6575
Epoch: 0380 Model_1_loss: 0.4985 Model_2_loss: 0.5616 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6644 Model_2_val:0.6478
Epoch: 0400 Model_1_loss: 0.5321 Model_2_loss: 0.5062 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6664 Model_2_val:0.6548
Model_one_test:0.6871 Model_two_test:0.6851
added by two output: 0.6858
14
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
497392073
Epoch: 0020 Model_1_loss: 1.7371 Model_2_loss: 1.7462 Model_1_trainacc: 0.5333 Model_2_trainacc: 0.3417 Model_1_val:0.3494 Model_2_val:0.2445
Epoch: 0040 Model_1_loss: 1.5733 Model_2_loss: 1.5750 Model_1_trainacc: 0.7250 Model_2_trainacc: 0.7333 Model_1_val:0.4396 Model_2_val:0.3587
Epoch: 0060 Model_1_loss: 1.2752 Model_2_loss: 1.2675 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8917 Model_1_val:0.4973 Model_2_val:0.4794
Epoch: 0080 Model_1_loss: 0.9791 Model_2_loss: 0.9047 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9417 Model_1_val:0.5229 Model_2_val:0.5441
Epoch: 0100 Model_1_loss: 0.7734 Model_2_loss: 0.6647 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9417 Model_1_val:0.5594 Model_2_val:0.5564
Epoch: 0120 Model_1_loss: 0.6490 Model_2_loss: 0.5348 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.5484 Model_2_val:0.5664
Epoch: 0140 Model_1_loss: 0.5694 Model_2_loss: 0.5340 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.5786 Model_2_val:0.5713
Epoch: 0160 Model_1_loss: 0.5328 Model_2_loss: 0.4526 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5796 Model_2_val:0.5853
Epoch: 0180 Model_1_loss: 0.4653 Model_2_loss: 0.4271 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.5763 Model_2_val:0.5873
Epoch: 0200 Model_1_loss: 0.4439 Model_2_loss: 0.3339 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5936 Model_2_val:0.6012
Epoch: 0220 Model_1_loss: 0.7451 Model_2_loss: 0.6629 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6400 Model_2_val:0.6589
Epoch: 0240 Model_1_loss: 0.6862 Model_2_loss: 0.6240 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6563 Model_2_val:0.6692
Epoch: 0260 Model_1_loss: 0.6370 Model_2_loss: 0.5791 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6526 Model_2_val:0.6632
Epoch: 0280 Model_1_loss: 0.6054 Model_2_loss: 0.5263 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6599 Model_2_val:0.6626
Epoch: 0300 Model_1_loss: 0.5667 Model_2_loss: 0.5484 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6599 Model_2_val:0.6709
Epoch: 0320 Model_1_loss: 0.5819 Model_2_loss: 0.4721 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6616 Model_2_val:0.6612
Epoch: 0340 Model_1_loss: 0.5225 Model_2_loss: 0.4404 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6636 Model_2_val:0.6775
Epoch: 0360 Model_1_loss: 0.4979 Model_2_loss: 0.4471 Model_1_trainacc: 1.0000 Model_2_trainacc: 1.0000 Model_1_val:0.6612 Model_2_val:0.6765
Epoch: 0380 Model_1_loss: 0.4727 Model_2_loss: 0.4660 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6679 Model_2_val:0.6612
Epoch: 0400 Model_1_loss: 0.4694 Model_2_loss: 0.4327 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6622 Model_2_val:0.6692
Model_one_test:0.6924 Model_two_test:0.6921
added by two output: 0.6934
15
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1543318784
Epoch: 0020 Model_1_loss: 1.7272 Model_2_loss: 1.7105 Model_1_trainacc: 0.5000 Model_2_trainacc: 0.4333 Model_1_val:0.2870 Model_2_val:0.3098
Epoch: 0040 Model_1_loss: 1.5744 Model_2_loss: 1.4982 Model_1_trainacc: 0.7083 Model_2_trainacc: 0.6917 Model_1_val:0.4412 Model_2_val:0.4476
Epoch: 0060 Model_1_loss: 1.2751 Model_2_loss: 1.1757 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.8667 Model_1_val:0.4866 Model_2_val:0.5370
Epoch: 0080 Model_1_loss: 0.9893 Model_2_loss: 0.8901 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8917 Model_1_val:0.5302 Model_2_val:0.5551
Epoch: 0100 Model_1_loss: 0.7973 Model_2_loss: 0.6868 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9250 Model_1_val:0.5548 Model_2_val:0.5820
Epoch: 0120 Model_1_loss: 0.6576 Model_2_loss: 0.5506 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.5571 Model_2_val:0.5847
Epoch: 0140 Model_1_loss: 0.5639 Model_2_loss: 0.4668 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9833 Model_1_val:0.5776 Model_2_val:0.5934
Epoch: 0160 Model_1_loss: 0.5117 Model_2_loss: 0.3901 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.5682 Model_2_val:0.6035
Epoch: 0180 Model_1_loss: 0.4006 Model_2_loss: 0.3719 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.5830 Model_2_val:0.6099
Epoch: 0200 Model_1_loss: 0.3724 Model_2_loss: 0.3136 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.5927 Model_2_val:0.5857
Epoch: 0220 Model_1_loss: 0.7539 Model_2_loss: 0.6694 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6606 Model_2_val:0.6731
Epoch: 0240 Model_1_loss: 0.7045 Model_2_loss: 0.6398 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6754 Model_2_val:0.6771
Epoch: 0260 Model_1_loss: 0.6377 Model_2_loss: 0.5767 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6603 Model_2_val:0.6660
Epoch: 0280 Model_1_loss: 0.6040 Model_2_loss: 0.5248 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6650 Model_2_val:0.6710
Epoch: 0300 Model_1_loss: 0.5640 Model_2_loss: 0.5181 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6724 Model_2_val:0.6680
Epoch: 0320 Model_1_loss: 0.5227 Model_2_loss: 0.5180 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6794 Model_2_val:0.6754
Epoch: 0340 Model_1_loss: 0.5005 Model_2_loss: 0.5071 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6704 Model_2_val:0.6673
Epoch: 0360 Model_1_loss: 0.5484 Model_2_loss: 0.4784 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6744 Model_2_val:0.6724
Epoch: 0380 Model_1_loss: 0.5236 Model_2_loss: 0.5124 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6731 Model_2_val:0.6673
Epoch: 0400 Model_1_loss: 0.4883 Model_2_loss: 0.4412 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6647 Model_2_val:0.6700
Model_one_test:0.6946 Model_two_test:0.6969
added by two output: 0.6969
16
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
128431656
Epoch: 0020 Model_1_loss: 1.7383 Model_2_loss: 1.7451 Model_1_trainacc: 0.3250 Model_2_trainacc: 0.4083 Model_1_val:0.2592 Model_2_val:0.2843
Epoch: 0040 Model_1_loss: 1.5912 Model_2_loss: 1.6279 Model_1_trainacc: 0.6417 Model_2_trainacc: 0.6417 Model_1_val:0.4120 Model_2_val:0.3825
Epoch: 0060 Model_1_loss: 1.3212 Model_2_loss: 1.4104 Model_1_trainacc: 0.7250 Model_2_trainacc: 0.7667 Model_1_val:0.4450 Model_2_val:0.4671
Epoch: 0080 Model_1_loss: 1.0607 Model_2_loss: 1.1841 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.8417 Model_1_val:0.5367 Model_2_val:0.4857
Epoch: 0100 Model_1_loss: 0.8642 Model_2_loss: 1.0290 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8417 Model_1_val:0.5435 Model_2_val:0.5245
Epoch: 0120 Model_1_loss: 0.7352 Model_2_loss: 0.7903 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8750 Model_1_val:0.5571 Model_2_val:0.5537
Epoch: 0140 Model_1_loss: 0.6861 Model_2_loss: 0.7291 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8833 Model_1_val:0.5740 Model_2_val:0.5679
Epoch: 0160 Model_1_loss: 0.6062 Model_2_loss: 0.6911 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8750 Model_1_val:0.5829 Model_2_val:0.5822
Epoch: 0180 Model_1_loss: 0.5342 Model_2_loss: 0.5851 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9000 Model_1_val:0.5781 Model_2_val:0.5880
Epoch: 0200 Model_1_loss: 0.4866 Model_2_loss: 0.4800 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9250 Model_1_val:0.6029 Model_2_val:0.6080
Epoch: 0220 Model_1_loss: 0.8536 Model_2_loss: 0.8487 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9250 Model_1_val:0.6359 Model_2_val:0.6471
Epoch: 0240 Model_1_loss: 0.8320 Model_2_loss: 0.8016 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.6698 Model_2_val:0.6654
Epoch: 0260 Model_1_loss: 0.7410 Model_2_loss: 0.7338 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9333 Model_1_val:0.6613 Model_2_val:0.6695
Epoch: 0280 Model_1_loss: 0.6811 Model_2_loss: 0.6738 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6732 Model_2_val:0.6797
Epoch: 0300 Model_1_loss: 0.6868 Model_2_loss: 0.6769 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6702 Model_2_val:0.6800
Epoch: 0320 Model_1_loss: 0.6464 Model_2_loss: 0.5965 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9500 Model_1_val:0.6844 Model_2_val:0.6814
Epoch: 0340 Model_1_loss: 0.5981 Model_2_loss: 0.6119 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6834 Model_2_val:0.6831
Epoch: 0360 Model_1_loss: 0.5875 Model_2_loss: 0.5703 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6776 Model_2_val:0.6804
Epoch: 0380 Model_1_loss: 0.5861 Model_2_loss: 0.5319 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6736 Model_2_val:0.6827
Epoch: 0400 Model_1_loss: 0.5136 Model_2_loss: 0.5089 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6865 Model_2_val:0.6882
Model_one_test:0.7062 Model_two_test:0.7011
added by two output: 0.7041
17
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1499602403
Epoch: 0020 Model_1_loss: 1.6972 Model_2_loss: 1.6997 Model_1_trainacc: 0.4750 Model_2_trainacc: 0.4917 Model_1_val:0.2626 Model_2_val:0.2723
Epoch: 0040 Model_1_loss: 1.4841 Model_2_loss: 1.4778 Model_1_trainacc: 0.7000 Model_2_trainacc: 0.8417 Model_1_val:0.4126 Model_2_val:0.4690
Epoch: 0060 Model_1_loss: 1.1576 Model_2_loss: 1.2082 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.9000 Model_1_val:0.5238 Model_2_val:0.4853
Epoch: 0080 Model_1_loss: 0.8606 Model_2_loss: 0.9252 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8833 Model_1_val:0.5634 Model_2_val:0.5209
Epoch: 0100 Model_1_loss: 0.6548 Model_2_loss: 0.7656 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9250 Model_1_val:0.6000 Model_2_val:0.5569
Epoch: 0120 Model_1_loss: 0.5878 Model_2_loss: 0.6436 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9417 Model_1_val:0.5877 Model_2_val:0.5786
Epoch: 0140 Model_1_loss: 0.5251 Model_2_loss: 0.5093 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5971 Model_2_val:0.5948
Epoch: 0160 Model_1_loss: 0.4813 Model_2_loss: 0.4667 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6078 Model_2_val:0.5990
Epoch: 0180 Model_1_loss: 0.4289 Model_2_loss: 0.4624 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9500 Model_1_val:0.6104 Model_2_val:0.5912
Epoch: 0200 Model_1_loss: 0.3979 Model_2_loss: 0.3804 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6256 Model_2_val:0.6019
Epoch: 0220 Model_1_loss: 0.6852 Model_2_loss: 0.7530 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.6765 Model_2_val:0.6687
Epoch: 0240 Model_1_loss: 0.6732 Model_2_loss: 0.6815 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6833 Model_2_val:0.6778
Epoch: 0260 Model_1_loss: 0.5960 Model_2_loss: 0.6579 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6917 Model_2_val:0.6771
Epoch: 0280 Model_1_loss: 0.5731 Model_2_loss: 0.5943 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6878 Model_2_val:0.6791
Epoch: 0300 Model_1_loss: 0.5391 Model_2_loss: 0.5716 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6934 Model_2_val:0.6917
Epoch: 0320 Model_1_loss: 0.5047 Model_2_loss: 0.5764 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6888 Model_2_val:0.6768
Epoch: 0340 Model_1_loss: 0.4681 Model_2_loss: 0.4922 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6888 Model_2_val:0.6820
Epoch: 0360 Model_1_loss: 0.4582 Model_2_loss: 0.4630 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6914 Model_2_val:0.6853
Epoch: 0380 Model_1_loss: 0.4698 Model_2_loss: 0.4951 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6930 Model_2_val:0.6833
Epoch: 0400 Model_1_loss: 0.4454 Model_2_loss: 0.5013 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6901 Model_2_val:0.6878
Model_one_test:0.7079 Model_two_test:0.7066
added by two output: 0.7089
18
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
693655206
Epoch: 0020 Model_1_loss: 1.7016 Model_2_loss: 1.7056 Model_1_trainacc: 0.5250 Model_2_trainacc: 0.5250 Model_1_val:0.2965 Model_2_val:0.2912
Epoch: 0040 Model_1_loss: 1.4770 Model_2_loss: 1.5176 Model_1_trainacc: 0.7833 Model_2_trainacc: 0.7750 Model_1_val:0.4614 Model_2_val:0.4254
Epoch: 0060 Model_1_loss: 1.1942 Model_2_loss: 1.2449 Model_1_trainacc: 0.7917 Model_2_trainacc: 0.7917 Model_1_val:0.5121 Model_2_val:0.4797
Epoch: 0080 Model_1_loss: 0.9140 Model_2_loss: 0.9243 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8417 Model_1_val:0.5481 Model_2_val:0.5154
Epoch: 0100 Model_1_loss: 0.6734 Model_2_loss: 0.7744 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9000 Model_1_val:0.5707 Model_2_val:0.5609
Epoch: 0120 Model_1_loss: 0.5775 Model_2_loss: 0.6696 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9167 Model_1_val:0.5877 Model_2_val:0.5658
Epoch: 0140 Model_1_loss: 0.5340 Model_2_loss: 0.5504 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.5818 Model_2_val:0.5933
Epoch: 0160 Model_1_loss: 0.4745 Model_2_loss: 0.4863 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6047 Model_2_val:0.5867
Epoch: 0180 Model_1_loss: 0.4695 Model_2_loss: 0.4788 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9417 Model_1_val:0.5906 Model_2_val:0.5713
Epoch: 0200 Model_1_loss: 0.4246 Model_2_loss: 0.4560 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.5798 Model_2_val:0.5798
Epoch: 0220 Model_1_loss: 0.7223 Model_2_loss: 0.7899 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.6600 Model_2_val:0.6525
Epoch: 0240 Model_1_loss: 0.6473 Model_2_loss: 0.7337 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6636 Model_2_val:0.6528
Epoch: 0260 Model_1_loss: 0.6032 Model_2_loss: 0.7530 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6692 Model_2_val:0.6541
Epoch: 0280 Model_1_loss: 0.6272 Model_2_loss: 0.6841 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6590 Model_2_val:0.6541
Epoch: 0300 Model_1_loss: 0.5414 Model_2_loss: 0.5856 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6587 Model_2_val:0.6558
Epoch: 0320 Model_1_loss: 0.5434 Model_2_loss: 0.5883 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6715 Model_2_val:0.6531
Epoch: 0340 Model_1_loss: 0.4897 Model_2_loss: 0.5733 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6473 Model_2_val:0.6626
Epoch: 0360 Model_1_loss: 0.4886 Model_2_loss: 0.5497 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9750 Model_1_val:0.6646 Model_2_val:0.6453
Epoch: 0380 Model_1_loss: 0.5165 Model_2_loss: 0.5077 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6639 Model_2_val:0.6528
Epoch: 0400 Model_1_loss: 0.4432 Model_2_loss: 0.5345 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6515 Model_2_val:0.6551
Model_one_test:0.6855 Model_two_test:0.6904
added by two output: 0.6862
19
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1350044968
Epoch: 0020 Model_1_loss: 1.7281 Model_2_loss: 1.7195 Model_1_trainacc: 0.4250 Model_2_trainacc: 0.4750 Model_1_val:0.2296 Model_2_val:0.2980
Epoch: 0040 Model_1_loss: 1.5797 Model_2_loss: 1.5260 Model_1_trainacc: 0.6500 Model_2_trainacc: 0.7083 Model_1_val:0.4093 Model_2_val:0.4378
Epoch: 0060 Model_1_loss: 1.3272 Model_2_loss: 1.2557 Model_1_trainacc: 0.8167 Model_2_trainacc: 0.8417 Model_1_val:0.4874 Model_2_val:0.4973
Epoch: 0080 Model_1_loss: 1.0221 Model_2_loss: 0.9690 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8833 Model_1_val:0.5002 Model_2_val:0.5302
Epoch: 0100 Model_1_loss: 0.8703 Model_2_loss: 0.7914 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9167 Model_1_val:0.5334 Model_2_val:0.5440
Epoch: 0120 Model_1_loss: 0.6880 Model_2_loss: 0.6614 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.5414 Model_2_val:0.5539
Epoch: 0140 Model_1_loss: 0.5274 Model_2_loss: 0.5823 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9250 Model_1_val:0.5654 Model_2_val:0.5510
Epoch: 0160 Model_1_loss: 0.4581 Model_2_loss: 0.5007 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.5833 Model_2_val:0.5657
Epoch: 0180 Model_1_loss: 0.3909 Model_2_loss: 0.4350 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9417 Model_1_val:0.5967 Model_2_val:0.5760
Epoch: 0200 Model_1_loss: 0.4082 Model_2_loss: 0.3819 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.5785 Model_2_val:0.5734
Epoch: 0220 Model_1_loss: 0.6864 Model_2_loss: 0.6976 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6546 Model_2_val:0.6473
Epoch: 0240 Model_1_loss: 0.6511 Model_2_loss: 0.6596 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6677 Model_2_val:0.6553
Epoch: 0260 Model_1_loss: 0.5739 Model_2_loss: 0.6622 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6652 Model_2_val:0.6681
Epoch: 0280 Model_1_loss: 0.5925 Model_2_loss: 0.5648 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6658 Model_2_val:0.6553
Epoch: 0300 Model_1_loss: 0.5161 Model_2_loss: 0.5458 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6690 Model_2_val:0.6633
Epoch: 0320 Model_1_loss: 0.5511 Model_2_loss: 0.5999 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6728 Model_2_val:0.6703
Epoch: 0340 Model_1_loss: 0.4874 Model_2_loss: 0.5239 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.6735 Model_2_val:0.6594
Epoch: 0360 Model_1_loss: 0.4813 Model_2_loss: 0.5084 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6885 Model_2_val:0.6556
Epoch: 0380 Model_1_loss: 0.4065 Model_2_loss: 0.4464 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9917 Model_1_val:0.6773 Model_2_val:0.6703
Epoch: 0400 Model_1_loss: 0.4540 Model_2_loss: 0.4882 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6796 Model_2_val:0.6693
Model_one_test:0.7000 Model_two_test:0.6968
added by two output: 0.6975
20
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
173186350
Epoch: 0020 Model_1_loss: 1.6813 Model_2_loss: 1.6998 Model_1_trainacc: 0.4250 Model_2_trainacc: 0.4167 Model_1_val:0.2580 Model_2_val:0.2664
Epoch: 0040 Model_1_loss: 1.4560 Model_2_loss: 1.4490 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8333 Model_1_val:0.4340 Model_2_val:0.4652
Epoch: 0060 Model_1_loss: 1.1874 Model_2_loss: 1.1338 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8917 Model_1_val:0.5143 Model_2_val:0.5511
Epoch: 0080 Model_1_loss: 0.9011 Model_2_loss: 0.8509 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9000 Model_1_val:0.5527 Model_2_val:0.5751
Epoch: 0100 Model_1_loss: 0.7221 Model_2_loss: 0.6793 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9417 Model_1_val:0.5823 Model_2_val:0.6067
Epoch: 0120 Model_1_loss: 0.6037 Model_2_loss: 0.6027 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9500 Model_1_val:0.5904 Model_2_val:0.6103
Epoch: 0140 Model_1_loss: 0.5535 Model_2_loss: 0.5130 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.5774 Model_2_val:0.6087
Epoch: 0160 Model_1_loss: 0.4674 Model_2_loss: 0.4345 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.5856 Model_2_val:0.6236
Epoch: 0180 Model_1_loss: 0.4625 Model_2_loss: 0.4181 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6096 Model_2_val:0.6210
Epoch: 0200 Model_1_loss: 0.4344 Model_2_loss: 0.3885 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9667 Model_1_val:0.5820 Model_2_val:0.6132
Epoch: 0220 Model_1_loss: 0.7538 Model_2_loss: 0.6667 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6415 Model_2_val:0.6633
Epoch: 0240 Model_1_loss: 0.7274 Model_2_loss: 0.6389 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.6640 Model_2_val:0.6669
Epoch: 0260 Model_1_loss: 0.6723 Model_2_loss: 0.5962 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6558 Model_2_val:0.6805
Epoch: 0280 Model_1_loss: 0.6329 Model_2_loss: 0.5839 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9750 Model_1_val:0.6448 Model_2_val:0.6737
Epoch: 0300 Model_1_loss: 0.6575 Model_2_loss: 0.5610 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9583 Model_1_val:0.6789 Model_2_val:0.6747
Epoch: 0320 Model_1_loss: 0.6031 Model_2_loss: 0.5312 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6692 Model_2_val:0.6753
Epoch: 0340 Model_1_loss: 0.5635 Model_2_loss: 0.5324 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6568 Model_2_val:0.6630
Epoch: 0360 Model_1_loss: 0.5193 Model_2_loss: 0.4559 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6705 Model_2_val:0.6695
Epoch: 0380 Model_1_loss: 0.5638 Model_2_loss: 0.4954 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6675 Model_2_val:0.6701
Epoch: 0400 Model_1_loss: 0.4594 Model_2_loss: 0.4559 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6669 Model_2_val:0.6757
Model_one_test:0.6942 Model_two_test:0.6975
added by two output: 0.6962
21
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
788884115
Epoch: 0020 Model_1_loss: 1.7210 Model_2_loss: 1.7122 Model_1_trainacc: 0.4000 Model_2_trainacc: 0.5250 Model_1_val:0.2535 Model_2_val:0.3070
Epoch: 0040 Model_1_loss: 1.5092 Model_2_loss: 1.5251 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.6833 Model_1_val:0.4445 Model_2_val:0.4254
Epoch: 0060 Model_1_loss: 1.2348 Model_2_loss: 1.2767 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8000 Model_1_val:0.5081 Model_2_val:0.4859
Epoch: 0080 Model_1_loss: 0.9544 Model_2_loss: 1.0368 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.8583 Model_1_val:0.5198 Model_2_val:0.5155
Epoch: 0100 Model_1_loss: 0.8195 Model_2_loss: 0.8342 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.9167 Model_1_val:0.5296 Model_2_val:0.5340
Epoch: 0120 Model_1_loss: 0.7242 Model_2_loss: 0.7387 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.8750 Model_1_val:0.5669 Model_2_val:0.5464
Epoch: 0140 Model_1_loss: 0.6537 Model_2_loss: 0.6196 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9500 Model_1_val:0.5703 Model_2_val:0.5612
Epoch: 0160 Model_1_loss: 0.5365 Model_2_loss: 0.5931 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.8917 Model_1_val:0.5696 Model_2_val:0.5592
Epoch: 0180 Model_1_loss: 0.5690 Model_2_loss: 0.4818 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9583 Model_1_val:0.5716 Model_2_val:0.5706
Epoch: 0200 Model_1_loss: 0.4457 Model_2_loss: 0.4876 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.5713 Model_2_val:0.5777
Epoch: 0220 Model_1_loss: 0.8333 Model_2_loss: 0.7821 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9750 Model_1_val:0.6449 Model_2_val:0.6281
Epoch: 0240 Model_1_loss: 0.6716 Model_2_loss: 0.7524 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.6711 Model_2_val:0.6463
Epoch: 0260 Model_1_loss: 0.6883 Model_2_loss: 0.6632 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6661 Model_2_val:0.6570
Epoch: 0280 Model_1_loss: 0.6080 Model_2_loss: 0.6340 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6859 Model_2_val:0.6604
Epoch: 0300 Model_1_loss: 0.5785 Model_2_loss: 0.6058 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6715 Model_2_val:0.6580
Epoch: 0320 Model_1_loss: 0.6038 Model_2_loss: 0.6259 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9833 Model_1_val:0.6722 Model_2_val:0.6634
Epoch: 0340 Model_1_loss: 0.5543 Model_2_loss: 0.5911 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6792 Model_2_val:0.6685
Epoch: 0360 Model_1_loss: 0.5107 Model_2_loss: 0.5598 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6685 Model_2_val:0.6627
Epoch: 0380 Model_1_loss: 0.5084 Model_2_loss: 0.5529 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6738 Model_2_val:0.6705
Epoch: 0400 Model_1_loss: 0.5033 Model_2_loss: 0.5042 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6738 Model_2_val:0.6611
Model_one_test:0.6944 Model_two_test:0.7001
added by two output: 0.6964
22
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1095438444
Epoch: 0020 Model_1_loss: 1.7623 Model_2_loss: 1.6946 Model_1_trainacc: 0.2417 Model_2_trainacc: 0.4833 Model_1_val:0.2272 Model_2_val:0.2654
Epoch: 0040 Model_1_loss: 1.6222 Model_2_loss: 1.4652 Model_1_trainacc: 0.7083 Model_2_trainacc: 0.8000 Model_1_val:0.4397 Model_2_val:0.4447
Epoch: 0060 Model_1_loss: 1.3464 Model_2_loss: 1.1191 Model_1_trainacc: 0.8333 Model_2_trainacc: 0.9417 Model_1_val:0.4968 Model_2_val:0.5354
Epoch: 0080 Model_1_loss: 1.0220 Model_2_loss: 0.8664 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9583 Model_1_val:0.5344 Model_2_val:0.5835
Epoch: 0100 Model_1_loss: 0.7466 Model_2_loss: 0.6265 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.5649 Model_2_val:0.5991
Epoch: 0120 Model_1_loss: 0.6376 Model_2_loss: 0.5350 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9917 Model_1_val:0.5882 Model_2_val:0.5958
Epoch: 0140 Model_1_loss: 0.5270 Model_2_loss: 0.4404 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.5878 Model_2_val:0.6071
Epoch: 0160 Model_1_loss: 0.4592 Model_2_loss: 0.4062 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6008 Model_2_val:0.6224
Epoch: 0180 Model_1_loss: 0.4033 Model_2_loss: 0.3437 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6001 Model_2_val:0.6174
Epoch: 0200 Model_1_loss: 0.3701 Model_2_loss: 0.3313 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6217 Model_2_val:0.6141
Epoch: 0220 Model_1_loss: 0.6886 Model_2_loss: 0.6608 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6682 Model_2_val:0.6486
Epoch: 0240 Model_1_loss: 0.5984 Model_2_loss: 0.6148 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6659 Model_2_val:0.6699
Epoch: 0260 Model_1_loss: 0.5417 Model_2_loss: 0.5700 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6662 Model_2_val:0.6632
Epoch: 0280 Model_1_loss: 0.5361 Model_2_loss: 0.5309 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6709 Model_2_val:0.6632
Epoch: 0300 Model_1_loss: 0.5280 Model_2_loss: 0.4975 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6702 Model_2_val:0.6646
Epoch: 0320 Model_1_loss: 0.4934 Model_2_loss: 0.5169 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6778 Model_2_val:0.6672
Epoch: 0340 Model_1_loss: 0.4572 Model_2_loss: 0.4976 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6719 Model_2_val:0.6632
Epoch: 0360 Model_1_loss: 0.4105 Model_2_loss: 0.4393 Model_1_trainacc: 0.9833 Model_2_trainacc: 1.0000 Model_1_val:0.6679 Model_2_val:0.6636
Epoch: 0380 Model_1_loss: 0.4313 Model_2_loss: 0.4405 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6735 Model_2_val:0.6669
Epoch: 0400 Model_1_loss: 0.4157 Model_2_loss: 0.4633 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6742 Model_2_val:0.6652
Model_one_test:0.6951 Model_two_test:0.6908
added by two output: 0.6935
23
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
615732809
Epoch: 0020 Model_1_loss: 1.7425 Model_2_loss: 1.7220 Model_1_trainacc: 0.3250 Model_2_trainacc: 0.4167 Model_1_val:0.2411 Model_2_val:0.2632
Epoch: 0040 Model_1_loss: 1.5740 Model_2_loss: 1.5554 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.6917 Model_1_val:0.3518 Model_2_val:0.3876
Epoch: 0060 Model_1_loss: 1.3248 Model_2_loss: 1.2545 Model_1_trainacc: 0.8000 Model_2_trainacc: 0.8833 Model_1_val:0.4445 Model_2_val:0.4987
Epoch: 0080 Model_1_loss: 1.0494 Model_2_loss: 0.9731 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8583 Model_1_val:0.5010 Model_2_val:0.5194
Epoch: 0100 Model_1_loss: 0.8358 Model_2_loss: 0.7850 Model_1_trainacc: 0.9000 Model_2_trainacc: 0.9333 Model_1_val:0.5244 Model_2_val:0.5304
Epoch: 0120 Model_1_loss: 0.7023 Model_2_loss: 0.6172 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5348 Model_2_val:0.5502
Epoch: 0140 Model_1_loss: 0.6267 Model_2_loss: 0.5679 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9250 Model_1_val:0.5458 Model_2_val:0.5502
Epoch: 0160 Model_1_loss: 0.5763 Model_2_loss: 0.4946 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9667 Model_1_val:0.5699 Model_2_val:0.5819
Epoch: 0180 Model_1_loss: 0.5432 Model_2_loss: 0.4497 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9667 Model_1_val:0.5639 Model_2_val:0.5799
Epoch: 0200 Model_1_loss: 0.4929 Model_2_loss: 0.4189 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9583 Model_1_val:0.5696 Model_2_val:0.5766
Epoch: 0220 Model_1_loss: 0.8133 Model_2_loss: 0.7770 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6515 Model_2_val:0.6532
Epoch: 0240 Model_1_loss: 0.7632 Model_2_loss: 0.6954 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.6629 Model_2_val:0.6625
Epoch: 0260 Model_1_loss: 0.7074 Model_2_loss: 0.6548 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6652 Model_2_val:0.6739
Epoch: 0280 Model_1_loss: 0.7359 Model_2_loss: 0.6120 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9750 Model_1_val:0.6729 Model_2_val:0.6853
Epoch: 0300 Model_1_loss: 0.6704 Model_2_loss: 0.6059 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6662 Model_2_val:0.6806
Epoch: 0320 Model_1_loss: 0.6397 Model_2_loss: 0.5691 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9667 Model_1_val:0.6732 Model_2_val:0.6793
Epoch: 0340 Model_1_loss: 0.5844 Model_2_loss: 0.5133 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6756 Model_2_val:0.6809
Epoch: 0360 Model_1_loss: 0.6412 Model_2_loss: 0.5865 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6729 Model_2_val:0.6763
Epoch: 0380 Model_1_loss: 0.5190 Model_2_loss: 0.5205 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6759 Model_2_val:0.6729
Epoch: 0400 Model_1_loss: 0.5432 Model_2_loss: 0.5301 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6726 Model_2_val:0.6676
Model_one_test:0.7047 Model_two_test:0.7030
added by two output: 0.7020
24
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
368628834
Epoch: 0020 Model_1_loss: 1.7273 Model_2_loss: 1.7434 Model_1_trainacc: 0.4333 Model_2_trainacc: 0.3000 Model_1_val:0.2292 Model_2_val:0.2233
Epoch: 0040 Model_1_loss: 1.5722 Model_2_loss: 1.5932 Model_1_trainacc: 0.6917 Model_2_trainacc: 0.6167 Model_1_val:0.4188 Model_2_val:0.3494
Epoch: 0060 Model_1_loss: 1.3314 Model_2_loss: 1.3115 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.8667 Model_1_val:0.4561 Model_2_val:0.4492
Epoch: 0080 Model_1_loss: 1.0452 Model_2_loss: 1.0502 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.8667 Model_1_val:0.5088 Model_2_val:0.5124
Epoch: 0100 Model_1_loss: 0.8766 Model_2_loss: 0.9258 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8583 Model_1_val:0.5288 Model_2_val:0.5498
Epoch: 0120 Model_1_loss: 0.6837 Model_2_loss: 0.7286 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9167 Model_1_val:0.5665 Model_2_val:0.5432
Epoch: 0140 Model_1_loss: 0.6490 Model_2_loss: 0.6112 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9500 Model_1_val:0.5550 Model_2_val:0.5547
Epoch: 0160 Model_1_loss: 0.5890 Model_2_loss: 0.6026 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9000 Model_1_val:0.5760 Model_2_val:0.5537
Epoch: 0180 Model_1_loss: 0.4922 Model_2_loss: 0.4922 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.5658 Model_2_val:0.5655
Epoch: 0200 Model_1_loss: 0.4101 Model_2_loss: 0.4877 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.5799 Model_2_val:0.5737
Epoch: 0220 Model_1_loss: 0.7973 Model_2_loss: 0.8210 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.6473 Model_2_val:0.6529
Epoch: 0240 Model_1_loss: 0.7119 Model_2_loss: 0.7044 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9417 Model_1_val:0.6663 Model_2_val:0.6775
Epoch: 0260 Model_1_loss: 0.6878 Model_2_loss: 0.7030 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9583 Model_1_val:0.6739 Model_2_val:0.6745
Epoch: 0280 Model_1_loss: 0.5958 Model_2_loss: 0.6596 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6680 Model_2_val:0.6686
Epoch: 0300 Model_1_loss: 0.5619 Model_2_loss: 0.5883 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6696 Model_2_val:0.6807
Epoch: 0320 Model_1_loss: 0.6265 Model_2_loss: 0.5699 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6618 Model_2_val:0.6690
Epoch: 0340 Model_1_loss: 0.5267 Model_2_loss: 0.5798 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6686 Model_2_val:0.6735
Epoch: 0360 Model_1_loss: 0.5651 Model_2_loss: 0.5603 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6732 Model_2_val:0.6863
Epoch: 0380 Model_1_loss: 0.5274 Model_2_loss: 0.5545 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6752 Model_2_val:0.6765
Epoch: 0400 Model_1_loss: 0.5299 Model_2_loss: 0.4844 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6755 Model_2_val:0.6794
Model_one_test:0.6952 Model_two_test:0.6991
added by two output: 0.6981
25
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1285526050
Epoch: 0020 Model_1_loss: 1.7140 Model_2_loss: 1.7275 Model_1_trainacc: 0.4500 Model_2_trainacc: 0.4083 Model_1_val:0.2465 Model_2_val:0.2370
Epoch: 0040 Model_1_loss: 1.5348 Model_2_loss: 1.5699 Model_1_trainacc: 0.7417 Model_2_trainacc: 0.7000 Model_1_val:0.4218 Model_2_val:0.3976
Epoch: 0060 Model_1_loss: 1.2568 Model_2_loss: 1.2535 Model_1_trainacc: 0.8250 Model_2_trainacc: 0.8750 Model_1_val:0.4701 Model_2_val:0.4987
Epoch: 0080 Model_1_loss: 0.9727 Model_2_loss: 1.0291 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8583 Model_1_val:0.4851 Model_2_val:0.5041
Epoch: 0100 Model_1_loss: 0.8427 Model_2_loss: 0.7937 Model_1_trainacc: 0.8917 Model_2_trainacc: 0.9083 Model_1_val:0.5261 Model_2_val:0.5366
Epoch: 0120 Model_1_loss: 0.6732 Model_2_loss: 0.6635 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9333 Model_1_val:0.5557 Model_2_val:0.5522
Epoch: 0140 Model_1_loss: 0.6169 Model_2_loss: 0.6172 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5398 Model_2_val:0.5525
Epoch: 0160 Model_1_loss: 0.5600 Model_2_loss: 0.4749 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9667 Model_1_val:0.5725 Model_2_val:0.5703
Epoch: 0180 Model_1_loss: 0.4943 Model_2_loss: 0.4122 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9750 Model_1_val:0.5608 Model_2_val:0.5719
Epoch: 0200 Model_1_loss: 0.4403 Model_2_loss: 0.4404 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9167 Model_1_val:0.5655 Model_2_val:0.5814
Epoch: 0220 Model_1_loss: 0.7873 Model_2_loss: 0.7175 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9667 Model_1_val:0.6434 Model_2_val:0.6225
Epoch: 0240 Model_1_loss: 0.7263 Model_2_loss: 0.7072 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6549 Model_2_val:0.6450
Epoch: 0260 Model_1_loss: 0.7106 Model_2_loss: 0.6248 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9917 Model_1_val:0.6501 Model_2_val:0.6498
Epoch: 0280 Model_1_loss: 0.6542 Model_2_loss: 0.6209 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9917 Model_1_val:0.6565 Model_2_val:0.6565
Epoch: 0300 Model_1_loss: 0.6385 Model_2_loss: 0.6222 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6533 Model_2_val:0.6409
Epoch: 0320 Model_1_loss: 0.5719 Model_2_loss: 0.5670 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6530 Model_2_val:0.6587
Epoch: 0340 Model_1_loss: 0.5452 Model_2_loss: 0.5345 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6450 Model_2_val:0.6565
Epoch: 0360 Model_1_loss: 0.5688 Model_2_loss: 0.5205 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9833 Model_1_val:0.6399 Model_2_val:0.6584
Epoch: 0380 Model_1_loss: 0.5308 Model_2_loss: 0.4900 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6479 Model_2_val:0.6489
Epoch: 0400 Model_1_loss: 0.4814 Model_2_loss: 0.5022 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6476 Model_2_val:0.6511
Model_one_test:0.6826 Model_two_test:0.6743
added by two output: 0.6803
26
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
854390892
Epoch: 0020 Model_1_loss: 1.7107 Model_2_loss: 1.6975 Model_1_trainacc: 0.3917 Model_2_trainacc: 0.5250 Model_1_val:0.2559 Model_2_val:0.2855
Epoch: 0040 Model_1_loss: 1.5075 Model_2_loss: 1.5221 Model_1_trainacc: 0.7250 Model_2_trainacc: 0.7500 Model_1_val:0.3930 Model_2_val:0.4474
Epoch: 0060 Model_1_loss: 1.1882 Model_2_loss: 1.2286 Model_1_trainacc: 0.8500 Model_2_trainacc: 0.8833 Model_1_val:0.4975 Model_2_val:0.5058
Epoch: 0080 Model_1_loss: 0.9070 Model_2_loss: 0.9275 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.9000 Model_1_val:0.5387 Model_2_val:0.5460
Epoch: 0100 Model_1_loss: 0.7083 Model_2_loss: 0.7249 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9333 Model_1_val:0.5645 Model_2_val:0.5783
Epoch: 0120 Model_1_loss: 0.5701 Model_2_loss: 0.5856 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9500 Model_1_val:0.5783 Model_2_val:0.5833
Epoch: 0140 Model_1_loss: 0.5392 Model_2_loss: 0.5651 Model_1_trainacc: 0.9333 Model_2_trainacc: 0.9417 Model_1_val:0.5859 Model_2_val:0.6093
Epoch: 0160 Model_1_loss: 0.4347 Model_2_loss: 0.4632 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.5875 Model_2_val:0.6001
Epoch: 0180 Model_1_loss: 0.4064 Model_2_loss: 0.4371 Model_1_trainacc: 0.9583 Model_2_trainacc: 0.9500 Model_1_val:0.5925 Model_2_val:0.5882
Epoch: 0200 Model_1_loss: 0.3488 Model_2_loss: 0.3816 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6040 Model_2_val:0.6024
Epoch: 0220 Model_1_loss: 0.7103 Model_2_loss: 0.7323 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6683 Model_2_val:0.6561
Epoch: 0240 Model_1_loss: 0.6469 Model_2_loss: 0.6469 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6597 Model_2_val:0.6660
Epoch: 0260 Model_1_loss: 0.5796 Model_2_loss: 0.6660 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6693 Model_2_val:0.6660
Epoch: 0280 Model_1_loss: 0.5923 Model_2_loss: 0.6471 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6716 Model_2_val:0.6607
Epoch: 0300 Model_1_loss: 0.5514 Model_2_loss: 0.5832 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6667 Model_2_val:0.6614
Epoch: 0320 Model_1_loss: 0.5518 Model_2_loss: 0.5508 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6713 Model_2_val:0.6647
Epoch: 0340 Model_1_loss: 0.5474 Model_2_loss: 0.5902 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6650 Model_2_val:0.6683
Epoch: 0360 Model_1_loss: 0.5151 Model_2_loss: 0.5050 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6607 Model_2_val:0.6611
Epoch: 0380 Model_1_loss: 0.4792 Model_2_loss: 0.4995 Model_1_trainacc: 0.9750 Model_2_trainacc: 1.0000 Model_1_val:0.6703 Model_2_val:0.6640
Epoch: 0400 Model_1_loss: 0.4851 Model_2_loss: 0.5076 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9667 Model_1_val:0.6703 Model_2_val:0.6617
Model_one_test:0.6911 Model_two_test:0.6894
added by two output: 0.6921
27
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
683466063
Epoch: 0020 Model_1_loss: 1.7590 Model_2_loss: 1.7385 Model_1_trainacc: 0.3667 Model_2_trainacc: 0.5333 Model_1_val:0.2550 Model_2_val:0.3339
Epoch: 0040 Model_1_loss: 1.6178 Model_2_loss: 1.6214 Model_1_trainacc: 0.6917 Model_2_trainacc: 0.5917 Model_1_val:0.4493 Model_2_val:0.3854
Epoch: 0060 Model_1_loss: 1.3482 Model_2_loss: 1.3867 Model_1_trainacc: 0.7500 Model_2_trainacc: 0.7750 Model_1_val:0.4888 Model_2_val:0.4734
Epoch: 0080 Model_1_loss: 0.9992 Model_2_loss: 1.1635 Model_1_trainacc: 0.8667 Model_2_trainacc: 0.8583 Model_1_val:0.5334 Model_2_val:0.5073
Epoch: 0100 Model_1_loss: 0.7644 Model_2_loss: 0.9047 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9167 Model_1_val:0.5615 Model_2_val:0.5311
Epoch: 0120 Model_1_loss: 0.6741 Model_2_loss: 0.7640 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.8750 Model_1_val:0.5709 Model_2_val:0.5422
Epoch: 0140 Model_1_loss: 0.5608 Model_2_loss: 0.6897 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9083 Model_1_val:0.5810 Model_2_val:0.5592
Epoch: 0160 Model_1_loss: 0.5052 Model_2_loss: 0.5647 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9250 Model_1_val:0.6012 Model_2_val:0.5569
Epoch: 0180 Model_1_loss: 0.4056 Model_2_loss: 0.4771 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.5794 Model_2_val:0.5706
Epoch: 0200 Model_1_loss: 0.3808 Model_2_loss: 0.4677 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.5908 Model_2_val:0.5813
Epoch: 0220 Model_1_loss: 0.7473 Model_2_loss: 0.8288 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6498 Model_2_val:0.6436
Epoch: 0240 Model_1_loss: 0.6737 Model_2_loss: 0.7586 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6717 Model_2_val:0.6622
Epoch: 0260 Model_1_loss: 0.6338 Model_2_loss: 0.7325 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.6814 Model_2_val:0.6785
Epoch: 0280 Model_1_loss: 0.6166 Model_2_loss: 0.6409 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6687 Model_2_val:0.6710
Epoch: 0300 Model_1_loss: 0.5681 Model_2_loss: 0.6176 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6795 Model_2_val:0.6798
Epoch: 0320 Model_1_loss: 0.5313 Model_2_loss: 0.6218 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9667 Model_1_val:0.6831 Model_2_val:0.6726
Epoch: 0340 Model_1_loss: 0.5465 Model_2_loss: 0.5909 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9500 Model_1_val:0.6785 Model_2_val:0.6801
Epoch: 0360 Model_1_loss: 0.4983 Model_2_loss: 0.4715 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9917 Model_1_val:0.6814 Model_2_val:0.6991
Epoch: 0380 Model_1_loss: 0.5119 Model_2_loss: 0.5012 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6792 Model_2_val:0.6808
Epoch: 0400 Model_1_loss: 0.4722 Model_2_loss: 0.4572 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6769 Model_2_val:0.6893
Model_one_test:0.7114 Model_two_test:0.7114
added by two output: 0.7121
28
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
192853332
Epoch: 0020 Model_1_loss: 1.6885 Model_2_loss: 1.6905 Model_1_trainacc: 0.5417 Model_2_trainacc: 0.5417 Model_1_val:0.3334 Model_2_val:0.3507
Epoch: 0040 Model_1_loss: 1.4497 Model_2_loss: 1.4412 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.9000 Model_1_val:0.4617 Model_2_val:0.5103
Epoch: 0060 Model_1_loss: 1.1405 Model_2_loss: 1.0787 Model_1_trainacc: 0.8417 Model_2_trainacc: 0.9167 Model_1_val:0.5383 Model_2_val:0.5265
Epoch: 0080 Model_1_loss: 0.8908 Model_2_loss: 0.7475 Model_1_trainacc: 0.9250 Model_2_trainacc: 0.9583 Model_1_val:0.5796 Model_2_val:0.5760
Epoch: 0100 Model_1_loss: 0.6634 Model_2_loss: 0.5954 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9583 Model_1_val:0.5874 Model_2_val:0.5952
Epoch: 0120 Model_1_loss: 0.5606 Model_2_loss: 0.5296 Model_1_trainacc: 0.9417 Model_2_trainacc: 0.9417 Model_1_val:0.6027 Model_2_val:0.6125
Epoch: 0140 Model_1_loss: 0.4543 Model_2_loss: 0.4112 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9917 Model_1_val:0.6053 Model_2_val:0.6070
Epoch: 0160 Model_1_loss: 0.3730 Model_2_loss: 0.3884 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.6197 Model_2_val:0.6106
Epoch: 0180 Model_1_loss: 0.3926 Model_2_loss: 0.3745 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6197 Model_2_val:0.6167
Epoch: 0200 Model_1_loss: 0.3484 Model_2_loss: 0.3474 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9833 Model_1_val:0.6141 Model_2_val:0.6275
Epoch: 0220 Model_1_loss: 0.6229 Model_2_loss: 0.6560 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6874 Model_2_val:0.6653
Epoch: 0240 Model_1_loss: 0.5319 Model_2_loss: 0.5989 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6858 Model_2_val:0.6871
Epoch: 0260 Model_1_loss: 0.5475 Model_2_loss: 0.5376 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6923 Model_2_val:0.6737
Epoch: 0280 Model_1_loss: 0.4821 Model_2_loss: 0.5008 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6910 Model_2_val:0.6828
Epoch: 0300 Model_1_loss: 0.4858 Model_2_loss: 0.5121 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6780 Model_2_val:0.6887
Epoch: 0320 Model_1_loss: 0.4855 Model_2_loss: 0.4716 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6780 Model_2_val:0.6900
Epoch: 0340 Model_1_loss: 0.4347 Model_2_loss: 0.5289 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9833 Model_1_val:0.6929 Model_2_val:0.6825
Epoch: 0360 Model_1_loss: 0.4428 Model_2_loss: 0.4335 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9833 Model_1_val:0.6985 Model_2_val:0.6887
Epoch: 0380 Model_1_loss: 0.4285 Model_2_loss: 0.4245 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6806 Model_2_val:0.6900
Epoch: 0400 Model_1_loss: 0.4209 Model_2_loss: 0.4372 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6946 Model_2_val:0.6864
Model_one_test:0.7118 Model_two_test:0.7105
added by two output: 0.7108
29
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
866216503
Epoch: 0020 Model_1_loss: 1.7071 Model_2_loss: 1.7191 Model_1_trainacc: 0.4333 Model_2_trainacc: 0.4333 Model_1_val:0.2743 Model_2_val:0.2619
Epoch: 0040 Model_1_loss: 1.4908 Model_2_loss: 1.5549 Model_1_trainacc: 0.7333 Model_2_trainacc: 0.7333 Model_1_val:0.4546 Model_2_val:0.4037
Epoch: 0060 Model_1_loss: 1.1167 Model_2_loss: 1.2509 Model_1_trainacc: 0.8750 Model_2_trainacc: 0.8667 Model_1_val:0.4935 Model_2_val:0.4722
Epoch: 0080 Model_1_loss: 0.8635 Model_2_loss: 0.9908 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9083 Model_1_val:0.5474 Model_2_val:0.5114
Epoch: 0100 Model_1_loss: 0.6745 Model_2_loss: 0.7737 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.9333 Model_1_val:0.5712 Model_2_val:0.5186
Epoch: 0120 Model_1_loss: 0.5545 Model_2_loss: 0.6077 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9500 Model_1_val:0.5764 Model_2_val:0.5451
Epoch: 0140 Model_1_loss: 0.4566 Model_2_loss: 0.5496 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9417 Model_1_val:0.5800 Model_2_val:0.5529
Epoch: 0160 Model_1_loss: 0.4348 Model_2_loss: 0.5181 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9333 Model_1_val:0.5980 Model_2_val:0.5523
Epoch: 0180 Model_1_loss: 0.3485 Model_2_loss: 0.4240 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9583 Model_1_val:0.5911 Model_2_val:0.5748
Epoch: 0200 Model_1_loss: 0.3836 Model_2_loss: 0.4243 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.5950 Model_2_val:0.5732
Epoch: 0220 Model_1_loss: 0.6776 Model_2_loss: 0.6535 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6577 Model_2_val:0.6447
Epoch: 0240 Model_1_loss: 0.6057 Model_2_loss: 0.6304 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6675 Model_2_val:0.6519
Epoch: 0260 Model_1_loss: 0.5477 Model_2_loss: 0.6221 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9583 Model_1_val:0.6803 Model_2_val:0.6571
Epoch: 0280 Model_1_loss: 0.5286 Model_2_loss: 0.5243 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6783 Model_2_val:0.6607
Epoch: 0300 Model_1_loss: 0.5163 Model_2_loss: 0.5453 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9750 Model_1_val:0.6656 Model_2_val:0.6476
Epoch: 0320 Model_1_loss: 0.5420 Model_2_loss: 0.5176 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9500 Model_1_val:0.6613 Model_2_val:0.6639
Epoch: 0340 Model_1_loss: 0.4477 Model_2_loss: 0.5196 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6688 Model_2_val:0.6617
Epoch: 0360 Model_1_loss: 0.4831 Model_2_loss: 0.4551 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6633 Model_2_val:0.6702
Epoch: 0380 Model_1_loss: 0.4869 Model_2_loss: 0.4582 Model_1_trainacc: 0.9667 Model_2_trainacc: 1.0000 Model_1_val:0.6718 Model_2_val:0.6610
Epoch: 0400 Model_1_loss: 0.4501 Model_2_loss: 0.4315 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9917 Model_1_val:0.6685 Model_2_val:0.6620
Model_one_test:0.6943 Model_two_test:0.6907
added by two output: 0.6914
30
labels of each class :  [20. 20. 20. 20. 20. 20.]
t= [216 216 216 216 216 216]
1338307220
Epoch: 0020 Model_1_loss: 1.6924 Model_2_loss: 1.7610 Model_1_trainacc: 0.5000 Model_2_trainacc: 0.2083 Model_1_val:0.3315 Model_2_val:0.2178
Epoch: 0040 Model_1_loss: 1.4899 Model_2_loss: 1.6239 Model_1_trainacc: 0.6833 Model_2_trainacc: 0.6667 Model_1_val:0.4540 Model_2_val:0.3924
Epoch: 0060 Model_1_loss: 1.1511 Model_2_loss: 1.3663 Model_1_trainacc: 0.8583 Model_2_trainacc: 0.7500 Model_1_val:0.4844 Model_2_val:0.4684
Epoch: 0080 Model_1_loss: 0.9499 Model_2_loss: 1.0230 Model_1_trainacc: 0.8833 Model_2_trainacc: 0.8833 Model_1_val:0.5408 Model_2_val:0.5047
Epoch: 0100 Model_1_loss: 0.7566 Model_2_loss: 0.8708 Model_1_trainacc: 0.9167 Model_2_trainacc: 0.8750 Model_1_val:0.5591 Model_2_val:0.5457
Epoch: 0120 Model_1_loss: 0.6403 Model_2_loss: 0.6730 Model_1_trainacc: 0.9083 Model_2_trainacc: 0.9583 Model_1_val:0.5640 Model_2_val:0.5391
Epoch: 0140 Model_1_loss: 0.5588 Model_2_loss: 0.6011 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9250 Model_1_val:0.5778 Model_2_val:0.5680
Epoch: 0160 Model_1_loss: 0.5207 Model_2_loss: 0.5376 Model_1_trainacc: 0.9500 Model_2_trainacc: 0.9417 Model_1_val:0.5801 Model_2_val:0.5696
Epoch: 0180 Model_1_loss: 0.4201 Model_2_loss: 0.4884 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9750 Model_1_val:0.5876 Model_2_val:0.5886
Epoch: 0200 Model_1_loss: 0.4456 Model_2_loss: 0.3932 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667 Model_1_val:0.6020 Model_2_val:0.6096
Epoch: 0220 Model_1_loss: 0.7110 Model_2_loss: 0.7615 Model_1_trainacc: 0.9917 Model_2_trainacc: 0.9500 Model_1_val:0.6512 Model_2_val:0.6528
Epoch: 0240 Model_1_loss: 0.6222 Model_2_loss: 0.6954 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6659 Model_2_val:0.6662
Epoch: 0260 Model_1_loss: 0.6654 Model_2_loss: 0.6846 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9583 Model_1_val:0.6692 Model_2_val:0.6649
Epoch: 0280 Model_1_loss: 0.6067 Model_2_loss: 0.6417 Model_1_trainacc: 0.9667 Model_2_trainacc: 0.9667 Model_1_val:0.6672 Model_2_val:0.6747
Epoch: 0300 Model_1_loss: 0.5455 Model_2_loss: 0.6224 Model_1_trainacc: 1.0000 Model_2_trainacc: 0.9833 Model_1_val:0.6793 Model_2_val:0.6636
Epoch: 0320 Model_1_loss: 0.5576 Model_2_loss: 0.5545 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9667/home/kzhan/ijcai2020/mt/utils.py:29: RuntimeWarning: divide by zero encountered in power
  r_inv = np.power(rowsum, -1).flatten()
 Model_1_val:0.6666 Model_2_val:0.6741
Epoch: 0340 Model_1_loss: 0.5575 Model_2_loss: 0.5224 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9750 Model_1_val:0.6649 Model_2_val:0.6643
Epoch: 0360 Model_1_loss: 0.5216 Model_2_loss: 0.5233 Model_1_trainacc: 0.9417 Model_2_trainacc: 1.0000 Model_1_val:0.6728 Model_2_val:0.6695
Epoch: 0380 Model_1_loss: 0.5038 Model_2_loss: 0.5218 Model_1_trainacc: 0.9833 Model_2_trainacc: 0.9750 Model_1_val:0.6751 Model_2_val:0.6757
Epoch: 0400 Model_1_loss: 0.5254 Model_2_loss: 0.4478 Model_1_trainacc: 0.9750 Model_2_trainacc: 0.9833 Model_1_val:0.6705 Model_2_val:0.6757
Model_one_test:0.6951 Model_two_test:0.6967
added by two output: 0.6954
Model1 Acc: 0.692551 Model2 Acc: 0.692433
Maxacc Mean: 0.693970
[0.6924372651610259, 0.6927043179398544, 0.6923088360447857, 0.6922086163222224, 0.691536895183715, 0.6943443442678022, 0.6918293560174433, 0.6981663724760395, 0.6906473485346307, 0.6939704534290884]
Maxacc of all experiments: 0.6981663724760395
